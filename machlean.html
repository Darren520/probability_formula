<!DOCTYPE  html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>机器学习</title><style type="text/css"> * {margin:0; padding:0; text-indent:0; }
 .s1 { color: #626760; font-family:宋体; font-style: normal; font-weight: normal; text-decoration: none; font-size: 17pt; }
 .s3 { color: #626760; font-family:Arial, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 13pt; }
 .s4 { color: #626760; font-family:宋体; font-style: normal; font-weight: normal; text-decoration: none; font-size: 12pt; }
 .s5 { color: black; font-family:宋体; font-style: normal; font-weight: normal; text-decoration: none; font-size: 16pt; }
 .p, p { color: black; font-family:宋体; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10.5pt; margin:0pt; }
 .s6 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10.5pt; }
 .a { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10.5pt; }
 .s7 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: bold; text-decoration: none; font-size: 10.5pt; }
 .s8 { color: #000080; font-family:黑体, monospace; font-style: normal; font-weight: normal; text-decoration: none; font-size: 18pt; }
 .h1 { color: #000080; font-family:Arial, sans-serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 18pt; }
 .s9 { color: black; font-family:宋体; font-style: normal; font-weight: normal; text-decoration: none; font-size: 5.5pt; vertical-align: 5pt; }
 .h4, h4 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 10.5pt; }
 .s10 { color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10.5pt; }
 .s11 { color: black; font-family:宋体; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; }
 .s12 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; }
 .s13 { color: black; font-family:宋体; font-style: normal; font-weight: normal; text-decoration: none; font-size: 4.5pt; vertical-align: 4pt; }
 .s14 { color: black; font-family:宋体; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 .s15 { color: black; font-family:宋体; font-style: normal; font-weight: normal; text-decoration: none; font-size: 5pt; vertical-align: 4pt; }
 .s16 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 h2 { color: #008080; font-family:Arial, sans-serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 14pt; }
 .s17 { color: #008080; font-family:黑体, monospace; font-style: normal; font-weight: normal; text-decoration: none; font-size: 14pt; }
 .s18 { color: #F00; font-family:宋体; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10.5pt; }
 .s19 { color: #F00; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10.5pt; }
 .s20 { color: black; font-family:黑体, monospace; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10.5pt; }
 .s21 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 10.5pt; }
 .s22 { color: #F00; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 10.5pt; }
 .s23 { color: #F00; font-family:宋体; font-style: normal; font-weight: normal; text-decoration: none; font-size: 11pt; }
 .s24 { color: #00F; font-family:宋体; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10.5pt; }
 .h3, h3 { color: #800000; font-family:Arial, sans-serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 12pt; }
 .s25 { color: #800000; font-family:黑体, monospace; font-style: normal; font-weight: normal; text-decoration: none; font-size: 12pt; }
 .s26 { color: black; font-family:新宋体, monospace; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10.5pt; }
 .s27 { color: #F00; font-family:"Times New Roman", serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 10.5pt; }
 .s28 { color: #F00; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10.5pt; }
 .s29 { color: #F00; font-family:新宋体, monospace; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10.5pt; }
 .s30 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 12pt; }
 .s31 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 12pt; vertical-align: 3pt; }
 .s32 { color: #800000; font-family:"Times New Roman", serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 12pt; }
 .s33 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 12pt; }
 .s34 { color: black; font-family:"Microsoft Sans Serif", sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10.5pt; }
 .s35 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 7pt; vertical-align: -1pt; }
 .s36 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 7pt; vertical-align: -1pt; }
 .s37 { color: black; font-family:Arial, sans-serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 10.5pt; }
 .s38 { color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 12pt; }
 .s39 { color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 18pt; vertical-align: -3pt; }
 .s40 { color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 7pt; }
 .s41 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 7pt; }
 .s42 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 7pt; }
 .s43 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 5pt; vertical-align: -2pt; }
 .s44 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 5pt; }
 .s45 { color: black; font-family:宋体; font-style: normal; font-weight: normal; text-decoration: none; font-size: 7pt; }
 .s46 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 7pt; vertical-align: 5pt; }
 .s47 { color: black; font-family:宋体; font-style: italic; font-weight: normal; text-decoration: none; font-size: 11pt; }
 .s48 { color: black; font-family:宋体; font-style: normal; font-weight: normal; text-decoration: none; font-size: 11pt; }
 .s49 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 12pt; vertical-align: 3pt; }
 .s50 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 12pt; vertical-align: 6pt; }
 .s51 { color: #00F; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10.5pt; }
 .s52 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 7pt; vertical-align: -3pt; }
 .s53 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 .s54 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 9pt; }
 .s55 { color: black; font-family:Arial, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 .s56 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 9pt; }
 .s57 { color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 .s58 { color: #00F; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 10.5pt; }
 .s59 { color: #00F; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 7pt; vertical-align: -1pt; }
 .s60 { color: #00F; font-family:"Times New Roman", serif; font-style: italic; font-weight: bold; text-decoration: none; font-size: 10.5pt; }
 .s61 { color: #00F; font-family:"Times New Roman", serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 10.5pt; }
 .s62 { color: #00F; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 7pt; }
 .s63 { color: #00F; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10.5pt; }
 .s64 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 6pt; vertical-align: -1pt; }
 .s65 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 6pt; vertical-align: -1pt; }
 .s66 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 6pt; }
 .s67 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 6pt; }
 .s68 { color: black; font-family:"Courier New", monospace; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10.5pt; }
 .s69 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 7pt; vertical-align: -4pt; }
 .s70 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 6pt; vertical-align: 4pt; }
 .s71 { color: black; font-family:Arial, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10.5pt; }
 .s72 { color: black; font-family:Symbol, serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 11pt; }
 .s73 { color: black; font-family:Tahoma, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10.5pt; }
 .s74 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 10pt; }
 .s75 { color: black; font-family:"Microsoft Sans Serif", sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; }
 .s76 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 6.5pt; vertical-align: -1pt; }
 .s77 { color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 7pt; vertical-align: -1pt; }
 .s78 { color: black; font-family:Arial, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 7pt; vertical-align: -1pt; }
 .s79 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 7pt; vertical-align: -3pt; }
 .s80 { color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 6pt; vertical-align: -1pt; }
 .s81 { color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 7pt; vertical-align: -3pt; }
 .s82 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 12pt; vertical-align: 8pt; }
 .s83 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 7pt; vertical-align: 5pt; }
 .s84 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 12pt; vertical-align: 2pt; }
 .s85 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; }
 .s86 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 10pt; }
 .s87 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 .s88 { color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 18pt; vertical-align: -7pt; }
 .s89 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 18pt; }
 .s90 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 7pt; vertical-align: 4pt; }
 .s91 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: underline; font-size: 12pt; }
 .s92 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: underline; font-size: 12pt; }
 .s93 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 12pt; vertical-align: -5pt; }
 .s94 { color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 12pt; vertical-align: -5pt; }
 .s95 { color: black; font-family:宋体; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10.5pt; }
 .s96 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 10.5pt; }
 .s97 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 7pt; vertical-align: -1pt; }
 .s98 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10.5pt; }
 .s99 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: underline; font-size: 10.5pt; }
 .s100 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 12pt; vertical-align: 1pt; }
 .s101 { color: black; font-family:Arial, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 12pt; }
 .s102 { color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 12pt; vertical-align: -2pt; }
 .s103 { color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 12pt; vertical-align: -3pt; }
 .s104 { color: #00F; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 7pt; vertical-align: -1pt; }
 .s105 { color: black; font-family:宋体; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10.5pt; vertical-align: 5pt; }
 .s106 { color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 18pt; vertical-align: 2pt; }
 .s107 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 11.5pt; }
 .s108 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 11.5pt; }
 .s109 { color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 11.5pt; }
 .s110 { color: black; font-family:Arial, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 12pt; vertical-align: 7pt; }
 .s111 { color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; }
 .s112 { color: #00F; font-family:Symbol, serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 11pt; }
 .s113 { color: black; font-family:Symbol, serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 10.5pt; }
 .s114 { color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 12pt; vertical-align: -7pt; }
 .s115 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 12pt; vertical-align: -7pt; }
 .s116 { color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 12pt; vertical-align: 1pt; }
 .s117 { color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: underline; font-size: 12pt; }
 .s118 { color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 12pt; vertical-align: 3pt; }
 .s119 { color: black; font-family:Symbol, serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 12.5pt; }
 .s120 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 7pt; vertical-align: -2pt; }
 .s121 { color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 18pt; }
 .s122 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 7pt; vertical-align: 1pt; }
 .s123 { color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 12pt; vertical-align: -9pt; }
 .s124 { color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 17.5pt; vertical-align: -3pt; }
 .s125 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 12.5pt; }
 .s126 { color: #F00; font-family:Symbol, serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 10.5pt; }
 .s127 { color: black; font-family:Symbol, serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 9.5pt; }
 .s128 { color: black; font-family:"Lucida Sans", sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10.5pt; }
 .s129 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 6.5pt; }
 .s130 { color: #F00; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 7pt; vertical-align: -1pt; }
 .s131 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 12pt; vertical-align: -6pt; }
 .s132 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 12pt; vertical-align: -1pt; }
 .s133 { color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 7pt; vertical-align: 5pt; }
 .s134 { color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 12pt; vertical-align: -1pt; }
 .s135 { color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 17.5pt; }
 .s136 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 17.5pt; }
 .s137 { color: black; font-family:Arial, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 12pt; vertical-align: 9pt; }
 .s138 { color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 18pt; vertical-align: -4pt; }
 .s139 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: underline; font-size: 10.5pt; }
 .s140 { color: black; font-family:宋体; font-style: normal; font-weight: normal; text-decoration: underline; font-size: 10.5pt; }
 .s141 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: underline; font-size: 10.5pt; }
 .s142 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: underline; font-size: 7pt; vertical-align: -1pt; }
 .s143 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: underline; font-size: 7pt; }
 .s144 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 10pt; vertical-align: 1pt; }
 .s145 { color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; vertical-align: 1pt; }
 .s146 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; vertical-align: 1pt; }
 .s147 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; vertical-align: -7pt; }
 .s148 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; vertical-align: -4pt; }
 .s149 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; vertical-align: -6pt; }
 .s150 { color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 12pt; vertical-align: 7pt; }
 .s151 { color: black; font-family:宋体; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10.5pt; vertical-align: -8pt; }
 .s152 { color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 12pt; vertical-align: -8pt; }
 .s153 { color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 18pt; vertical-align: -10pt; }
 .s154 { color: black; font-family:Symbol, serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 12.5pt; vertical-align: 3pt; }
 .s155 { color: black; font-family:宋体; font-style: normal; font-weight: normal; text-decoration: none; font-size: 4.5pt; }
 .s156 { color: black; font-family:宋体; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 .s157 { color: black; font-family:Arial, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 12pt; vertical-align: 2pt; }
 .s158 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 7pt; vertical-align: 1pt; }
 .s159 { color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 12pt; vertical-align: 4pt; }
 .s160 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 12pt; vertical-align: -9pt; }
 .s161 { color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 12pt; vertical-align: -4pt; }
 .s162 { color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 12pt; vertical-align: 2pt; }
 .s163 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 12pt; vertical-align: 6pt; }
 .s164 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 7pt; vertical-align: 3pt; }
 .s165 { color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 12pt; vertical-align: 5pt; }
 .s166 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 7pt; vertical-align: 2pt; }
 .s167 { color: black; font-family:Arial, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 12pt; vertical-align: 1pt; }
 .s168 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 12pt; vertical-align: -6pt; }
 .s169 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 12pt; vertical-align: 7pt; }
 .s170 { color: black; font-family:"Courier New", monospace; font-style: normal; font-weight: normal; text-decoration: none; font-size: 5.5pt; vertical-align: -2pt; }
 .s171 { color: black; font-family:Arial, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 7pt; vertical-align: -3pt; }
 .s172 { color: black; font-family:Arial, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 7pt; }
 .s173 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: bold; text-decoration: none; font-size: 7pt; vertical-align: -1pt; }
 .s174 { color: black; font-family:宋体; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 .s175 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 6pt; vertical-align: -1pt; }
 .s176 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 7pt; vertical-align: -5pt; }
 .s177 { color: black; font-family:宋体; font-style: italic; font-weight: normal; text-decoration: none; font-size: 9.5pt; }
 .s178 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 7pt; vertical-align: -4pt; }
 .s179 { color: black; font-family:Symbol, serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 12.5pt; vertical-align: 8pt; }
 .s180 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 5pt; vertical-align: -1pt; }
 .s181 { color: black; font-family:Symbol, serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 7pt; }
 .s182 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 5pt; vertical-align: 4pt; }
 .s183 { color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 7pt; vertical-align: 10pt; }
 .s184 { color: black; font-family:Symbol, serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 7pt; vertical-align: 5pt; }
 .s185 { color: black; font-family:"Courier New", monospace; font-style: normal; font-weight: normal; text-decoration: none; font-size: 5.5pt; }
 .s186 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 11.5pt; vertical-align: -4pt; }
 .s187 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 9pt; }
 .s188 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 5pt; vertical-align: -2pt; }
 .s189 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 5pt; }
 .s190 { color: black; font-family:Symbol, serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 12.5pt; vertical-align: -6pt; }
 .s191 { color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 12pt; vertical-align: -6pt; }
 .s192 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 7pt; vertical-align: -2pt; }
 .s193 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 12pt; vertical-align: 4pt; }
 .s194 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 6.5pt; }
 .s195 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 12pt; vertical-align: -4pt; }
 .s196 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 12pt; vertical-align: 2pt; }
 .s197 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 5pt; vertical-align: -1pt; }
 .s198 { color: black; font-family:Symbol, serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 7.5pt; vertical-align: -4pt; }
 .s199 { color: black; font-family:Symbol, serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 7pt; vertical-align: -4pt; }
 .s200 { color: black; font-family:Symbol, serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 7.5pt; }
 .s201 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 7pt; }
 .s202 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: bold; text-decoration: none; font-size: 7pt; }
 .s203 { color: #800000; font-family:Arial, sans-serif; font-style: italic; font-weight: bold; text-decoration: none; font-size: 12pt; }
 .s204 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 12pt; vertical-align: -7pt; }
 .s205 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 12pt; vertical-align: 4pt; }
 .s206 { color: black; font-family:Symbol, serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 12.5pt; vertical-align: -2pt; }
 .s207 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 7pt; vertical-align: 4pt; }
 .s208 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: underline; font-size: 7pt; }
 .s209 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 5pt; vertical-align: 3pt; }
 .s210 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 5pt; vertical-align: 1pt; }
 .s211 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 12pt; vertical-align: -1pt; }
 .s212 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 12pt; vertical-align: -8pt; }
 .s213 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 7pt; vertical-align: 3pt; }
 .s215 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 5pt; vertical-align: 4pt; }
 .s216 { color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 18pt; vertical-align: 6pt; }
 .s217 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 10.5pt; vertical-align: 1pt; }
 .s218 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10.5pt; vertical-align: 1pt; }
 .s219 { color: black; font-family:宋体; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10.5pt; vertical-align: 1pt; }
 .s220 { color: black; font-family:Arial, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10.5pt; }
 .s221 { color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10.5pt; }
 .s222 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 7pt; vertical-align: -5pt; }
 .s223 { color: black; font-family:宋体; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10.5pt; }
 .s224 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 8pt; }
 .s225 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 4.5pt; vertical-align: -2pt; }
 .s226 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 8.5pt; }
 .s227 { color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 8.5pt; }
 .s228 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 8.5pt; }
 .s229 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 3.5pt; vertical-align: -1pt; }
 .s230 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 3.5pt; }
 .s231 { color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 5pt; }
 .s232 { color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 13.5pt; vertical-align: -2pt; }
 .s233 { color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 13.5pt; }
 .s234 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 7.5pt; }
 .s235 { color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: underline; font-size: 9.5pt; }
 .s236 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: underline; font-size: 9.5pt; }
 .s238 { color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9.5pt; vertical-align: -3pt; }
 .s239 { color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9.5pt; }
 .s240 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 9.5pt; }
 .s241 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9.5pt; }
 .s242 { color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: underline; font-size: 9pt; }
 .s243 { color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; vertical-align: 2pt; }
 .s244 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 7pt; vertical-align: 6pt; }
 .s245 { color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 12pt; vertical-align: 9pt; }
 .s246 { color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 18pt; vertical-align: -8pt; }
 .s247 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 7pt; vertical-align: 5pt; }
 .s248 { color: black; font-family:Symbol, serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 7pt; vertical-align: 2pt; }
 .s249 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 12pt; vertical-align: -4pt; }
 .s250 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 12pt; vertical-align: 5pt; }
 .s251 { color: black; font-family:Symbol, serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 12.5pt; vertical-align: -9pt; }
 .s252 { color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 7pt; vertical-align: -4pt; }
 .s253 { color: black; font-family:宋体; font-style: normal; font-weight: normal; text-decoration: none; font-size: 5.5pt; }
 .s254 { color: black; font-family:"Courier New", monospace; font-style: normal; font-weight: normal; text-decoration: none; font-size: 4.5pt; }
 .s255 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 12pt; vertical-align: -5pt; }
 .s256 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 6pt; vertical-align: 4pt; }
 .s257 { color: black; font-family:宋体; font-style: italic; font-weight: normal; text-decoration: none; font-size: 4.5pt; vertical-align: 4pt; }
 .s258 { color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 15.5pt; }
 .s259 { color: black; font-family:宋体; font-style: italic; font-weight: normal; text-decoration: none; font-size: 5.5pt; vertical-align: 5pt; }
 .s260 { color: black; font-family:宋体; font-style: italic; font-weight: normal; text-decoration: none; font-size: 5.5pt; }
 .s262 { color: black; font-family:"Courier New", monospace; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 .s263 { color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 12pt; vertical-align: 6pt; }
 .s264 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 12pt; vertical-align: 1pt; }
 .s265 { color: black; font-family:宋体; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; vertical-align: 1pt; }
 .s267 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 7pt; vertical-align: 7pt; }
 .s268 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 7pt; vertical-align: 6pt; }
 .s269 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 10.5pt; vertical-align: -1pt; }
 .s270 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10.5pt; vertical-align: -1pt; }
 .s271 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: bold; text-decoration: none; font-size: 7pt; vertical-align: 5pt; }
 .s272 { color: #00F; font-family:Tahoma, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10.5pt; }
 .s273 { color: black; font-family:"Lucida Sans", sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 .s274 { color: #F00; font-family:"Lucida Sans", sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10.5pt; }
 .s275 { color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 18pt; vertical-align: -2pt; }
 .s276 { color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 11.5pt; vertical-align: 1pt; }
 .s277 { color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 7pt; vertical-align: 6pt; }
 .s278 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 5pt; vertical-align: 5pt; }
 .s281 { color: black; font-family:宋体; font-style: normal; font-weight: normal; text-decoration: none; font-size: 5.5pt; }
 .s282 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 5.5pt; }
 .s283 { color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 5.5pt; }
 .s284 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 5.5pt; }
 .s285 { color: black; font-family:宋体; font-style: normal; font-weight: normal; text-decoration: none; font-size: 5.5pt; vertical-align: 2pt; }
 .s286 { color: #800000; font-family:黑体, monospace; font-style: italic; font-weight: normal; text-decoration: none; font-size: 12.5pt; }
 .s287 { color: black; font-family:Arial, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 .s288 { color: black; font-family:宋体; font-style: italic; font-weight: normal; text-decoration: none; font-size: 9.5pt; }
 .s289 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 5pt; vertical-align: -4pt; }
 .s290 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 11.5pt; vertical-align: 3pt; }
 .s291 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 7pt; vertical-align: 2pt; }
 .s292 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 6.5pt; vertical-align: -3pt; }
 .s293 { color: black; font-family:Symbol, serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 7.5pt; vertical-align: 5pt; }
 .s295 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 6pt; vertical-align: 1pt; }
 .s296 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: bold; text-decoration: none; font-size: 9pt; }
 .s298 { color: #00F; font-family:黑体, monospace; font-style: normal; font-weight: normal; text-decoration: none; font-size: 14pt; }
 .s299 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 7.5pt; }
 .s300 { color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 20pt; }
 li {display: block; }
 #l1 {padding-left: 0pt; }
 #l1> li:before {content: "- "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10.5pt; }
 #l2 {padding-left: 0pt; }
 #l2> li:before {content: "• "; color: black; font-family:"Microsoft Sans Serif", sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; }
 #l3 {padding-left: 0pt; }
 #l3> li:before {content: "• "; color: black; font-family:"Microsoft Sans Serif", sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; }
 #l4 {padding-left: 0pt; }
 #l4> li:before {content: "• "; color: black; font-family:"Microsoft Sans Serif", sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; }
 li {display: block; }
 #l5 {padding-left: 0pt; }
 #l5> li:before {content: " "; color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 12pt; }
 #l6 {padding-left: 0pt; }
 #l6> li:before {content: "· "; color: black; font-family:"Lucida Sans", sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10.5pt; }
 li {display: block; }
 #l7 {padding-left: 0pt; }
 #l7> li:before {content: " "; color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 12pt; }
 #l8 {padding-left: 0pt; }
 #l8> li:before {content: " "; color: black; font-family:Symbol, serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 11pt; }
 #l9 {padding-left: 0pt; }
 #l9> li:before {content: "· "; color: black; font-family:"Lucida Sans", sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10.5pt; }
 #l10 {padding-left: 0pt;counter-reset: g1 4; }
 #l10> li:before {counter-increment: g1; content: counter(g1, decimal)" "; color: black; font-style: normal; font-weight: normal; text-decoration: none; }
 #l11 {padding-left: 0pt;counter-reset: g2 5; }
 #l11> li:before {counter-increment: g2; content: counter(g1, decimal)"."counter(g2, decimal)" "; color: black; font-style: normal; font-weight: normal; text-decoration: none; }
 #l12 {padding-left: 0pt;counter-reset: g3 2; }
 #l12> li:before {counter-increment: g3; content: counter(g1, decimal)"."counter(g2, decimal)"."counter(g3, decimal)" "; color: black; font-style: normal; font-weight: normal; text-decoration: none; }
 #l13 {padding-left: 0pt;counter-reset: g4 0; }
 #l13> li:before {counter-increment: g4; content: counter(g1, decimal)"."counter(g2, decimal)"."counter(g3, decimal)"."counter(g4, decimal)" "; color: black; font-family:Arial, sans-serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 10.5pt; }
 #l14 {padding-left: 0pt; }
 #l14> li:before {content: " "; color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10.5pt; }
 #l15 {padding-left: 0pt;counter-reset: h1 0; }
 #l15> li:before {counter-increment: h1; content: counter(h1, decimal)" "; color: black; font-style: normal; font-weight: normal; text-decoration: underline; }
 #l16 {padding-left: 0pt; }
 #l16> li:before {content: " "; color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 12pt; }
 li {display: block; }
 #l17 {padding-left: 0pt; }
 #l17> li:before {content: " "; color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 12pt; }
 li {display: block; }
 #l18 {padding-left: 0pt; }
 #l18> li:before {content: " "; color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 12pt; }
 li {display: block; }
 #l19 {padding-left: 0pt;counter-reset: k1 7; }
 #l19> li:before {counter-increment: k1; content: "("counter(k1, lower-latin)") "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 12pt; }
 #l20 {padding-left: 0pt;counter-reset: l1 7; }
 #l20> li:before {counter-increment: l1; content: counter(l1, decimal)" "; color: black; font-style: normal; font-weight: normal; text-decoration: none; }
 #l21 {padding-left: 0pt;counter-reset: l2 5; }
 #l21> li:before {counter-increment: l2; content: counter(l1, decimal)"."counter(l2, decimal)" "; color: black; font-style: normal; font-weight: normal; text-decoration: none; }
 #l22 {padding-left: 0pt;counter-reset: l3 1; }
 #l22> li:before {counter-increment: l3; content: counter(l1, decimal)"."counter(l2, decimal)"."counter(l3, decimal)" "; color: #800000; font-family:Arial, sans-serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 12pt; }
 #l23 {padding-left: 0pt; }
 #l23> li:before {content: " "; color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 12pt; }
 #l24 {padding-left: 0pt; }
 #l24> li:before {content: " "; color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10.5pt; }
 #l25 {padding-left: 0pt; }
 #l25> li:before {content: " "; color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10.5pt; }
 #l26 {padding-left: 0pt; }
 #l26> li:before {content: " "; color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 12pt; }
 #l27 {padding-left: 0pt;counter-reset: p1 10; }
 #l27> li:before {counter-increment: p1; content: counter(p1, decimal)" "; color: black; font-style: normal; font-weight: normal; text-decoration: none; }
 #l28 {padding-left: 0pt;counter-reset: p2 5; }
 #l28> li:before {counter-increment: p2; content: counter(p1, decimal)"."counter(p2, decimal)" "; color: black; font-style: normal; font-weight: normal; text-decoration: none; }
 #l29 {padding-left: 0pt;counter-reset: p3 3; }
 #l29> li:before {counter-increment: p3; content: counter(p1, decimal)"."counter(p2, decimal)"."counter(p3, decimal)" "; color: #800000; font-family:Arial, sans-serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 12pt; }
 #l30 {padding-left: 0pt; }
 #l30> li:before {content: " "; color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10.5pt; }
 #l31 {padding-left: 0pt; }
 #l31> li:before {content: "• "; color: black; font-family:"Microsoft Sans Serif", sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 #l32 {padding-left: 0pt; }
 #l32> li:before {content: " "; color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10.5pt; }
 #l33 {padding-left: 0pt; }
 #l33> li:before {content: " "; color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10.5pt; }
 #l34 {padding-left: 0pt;counter-reset: t1 12; }
 #l34> li:before {counter-increment: t1; content: counter(t1, decimal)" "; color: black; font-style: normal; font-weight: normal; text-decoration: none; }
 #l35 {padding-left: 0pt;counter-reset: t2 5; }
 #l35> li:before {counter-increment: t2; content: counter(t1, decimal)"."counter(t2, decimal)" "; color: black; font-style: normal; font-weight: normal; text-decoration: none; }
 #l36 {padding-left: 0pt;counter-reset: t3 0; }
 #l36> li:before {counter-increment: t3; content: counter(t1, decimal)"."counter(t2, decimal)"."counter(t3, decimal)" "; color: #800000; font-family:Arial, sans-serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 12pt; }
 #l37 {padding-left: 0pt; }
 #l37> li:before {content: " "; color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10.5pt; }
 #l38 {padding-left: 0pt; }
 #l38> li:before {content: " "; color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 12pt; }
 #l39 {padding-left: 0pt; }
 #l39> li:before {content: " "; color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 12pt; }
</style></head><body><p style="text-indent: 0pt;text-align: left;"><span><img width="676" height="972" alt="image" src="机器学习/Image_001.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s1" style="padding-top: 7pt;padding-left: 1pt;text-indent: 0pt;text-align: center;">吨’ <span style=" color: #5777A8;">. </span><span class="s3">1\1 E </span><span class="s4">』 〈</span></p><p class="s5" style="padding-top: 1pt;text-indent: 0pt;text-align: right;">序 言</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 113%;text-align: justify;">机器学习这门学科所关注的问题是：计算机程序如何随着经验积累自动提高性能？近年 来，机器学习被成功地应用于很多领域，从检测信用卡交易欺诈的数据挖掘程序，到获取用 户阅读兴趣的信息过滤系统，再到能在高速公路上自动行驶的汽车。同时，这个学科的基础 理论和算法也有了重大的进展。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 113%;text-align: justify;">这本教材的目标是展现机器学习中核心的算法和理论。机器学习从很多学科吸收了成果 和概念，包括统计学、人工智能、哲学、信息论、生物学、认知科学、计算复杂性和控制论 等。我相信，研究机器学习的最佳途径是从这些学科的观点看待机器学习，并且以此来理解 问题的背景、算法以及其中隐含的假定。这些在以往很难做到，因为在这一领域缺少包容广 泛的原始资料。这本书的主要目的就是提供这样的一份资料。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 112%;text-align: justify;">由于素材的多学科性，这本书不要求读者具有相应的知识背景，而是在必要时介绍其他 一些学科的基本概念，如统计学、人工智能、信息论等。介绍的重点是与机器学习关系最密 切的那些概念。本书可以作为计算机科学与工程、统计学和社会科学等专业的大学生或研究 生的教材，也可作为软件研究人员或从业人员的参考。指导这本书写作的两条原则为：<span class="s6">1. </span>它是在校大学生可以理解的；<span class="s6">2.</span>它应该包含博士生在开始研究机器学习前要掌握的内容。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 5pt;text-indent: 21pt;line-height: 111%;text-align: justify;"><a href="http://www.cs.cmu.edu/%7Etom/mlbook.html" class="s223" target="_blank">指导这本书写作的第三条原则是：它应该体现理论和实践两者的平衡。机器学习理论致 力于回答这样的问题“学习性能是怎样随着给定的训练样例的数量变化的？”和“对于不同 类型的学习任务，哪个学习算法最适合？”利用来自统计学、计算复杂性和贝叶斯分析的理 论成果，这本书讨论了这一类理论问题。同时本书也覆盖了很多实践方面的内容：介绍了这 一领域的主要算法，并阐明了算法的运行过程。一些算法的实现和数据可以在互联网上通过 网址 </a>http://www.cs.cmu.edu/~tom/mlbook.html <span class="p">得到。其中包括用于人脸识别的神经网络、用 于信贷分析的决策树学习、及分析文本文档的贝叶斯分类器各自的源代码和所需数据。我很 感谢那些帮助我创建这些在线资源的同事，包括 </span>Jason Rennie<span class="p">、</span>Paul Hsiung<span class="p">、</span>Jeff Shufelt<span class="p">、 </span>Matt Glickman<span class="p">、</span>Scott Davies<span class="p">、</span>Joseph O’Sullivan<span class="p">、</span>Ken Lang<span class="p">、</span>Andrew McCallum <span class="p">和 </span>Thorsten Joachims<span class="p">。</span></p><p style="padding-top: 1pt;padding-left: 26pt;text-indent: 0pt;line-height: 28pt;text-align: left;">致谢 在写作这本书的过程中，我幸运地得到了机器学习领域很多学科分支的技术专家的帮</p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 12pt;text-align: left;">助。没有他们的帮助这本书是不可能完成的。我深深地感激下面的科学家们，他们花时间检</p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">阅本书的草稿，并且以他们各自领域的专长对我进行了指导。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 26pt;text-indent: 0pt;text-align: left;">（ ）</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 113%;text-align: justify;">我也很感谢各所大学的很多讲师和学生，他们实地测试了本书的很多草稿并提出了他们 的建议。尽管没有足够的版面来感谢上百名的学生、讲师和其他测试了草稿的人，我要感谢 下面各位，感谢他们特别有帮助的建议和讨论。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 26pt;text-indent: 0pt;text-align: left;">（ ）</p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">我感谢 <span class="s6">Joan Mitchell </span>建立了本书的索引。我也感谢 <span class="s6">Jean Harpley </span>帮助编辑了很多插图。 <span class="s6">ETP Harrison </span>的 <span class="s6">Jane Loftus </span>帮助整理了本书的手稿。我的编辑，<span class="s6">McGraw Hill </span>出版社的 <span class="s6">Eric Munson </span>在项目的整个过程中提供了鼓励和意见。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 110%;text-align: left;">通常，一个人最该感谢的是他的同事、朋友和家庭。对于我，尤其要表达自己的感激。 我很难想象有人比我在 <span class="s6">Carnegie Mellon </span>拥有更好的智者云集的环境和更多的鼎力相助的朋 友。在这些很多帮助过我的人当中，我特别感谢 <span class="s6">Sebastian Thrun</span>，在这个项目的自始至终， 他一直对我进行着精神鼓励、技术指导等各种支持。我的父母，与以往一样的鼓励我并在最 恰当的时候问“已经完成了吗？”最后，我一定要感谢我的家人：<span class="s6">Meghan</span>，<span class="s6">Shannon </span>和 <span class="s6">Joan</span>。 他们在不知不觉中以各种方式对此书作出了贡献。这本书是献给他们的。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s7" style="text-indent: 0pt;text-align: right;">Tom M. Mitchell</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s8" style="padding-left: 3pt;text-indent: 0pt;line-height: 24pt;text-align: center;">第<span class="h1">1</span>章 绪论</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 8pt;text-indent: 21pt;line-height: 113%;text-align: left;">自从计算机被发明以来，人们就想知道它们能不能学习。如果我们理解了计算机学习的 内在机制，即怎样使它们根据经验来自动提高，那么影响将是空前的。想象一下，在未来， 计算机能从医疗记录中学习，获取治疗新疾病的最有效方法；住宅管理系统分析住户的用电 模式，以降低能源消耗；个人软件助理跟踪用户的兴趣，并为其选择最感兴趣的在线新 闻 。对计算机学习的成功理解将开辟出全新的应用领域，并使其计算能力和可定制性上 升到新的层次。同时，透彻地理解机器学习的信息处理算法，也会有助于更好地理解人类的 学习能力。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 8pt;text-indent: 21pt;line-height: 113%;text-align: justify;">目前，我们还不知道怎样使计算机的学习能力和人类相媲美。然而一些针对特定学习任 务的算法已经产生。关于学习的理论认识已开始逐步形成。人们开发出了很多实践性的计算 机程序来实现不同类型的学习，一些商业化的应用也已经出现。例如对于语音识别这样的课 题，至今为止，基于机器学习的算法明显胜过其他的方法。在数据挖掘领域，机器学习算法 理所当然地得到应用，从包含设备维护记录、借贷申请、金融交易、医疗记录等类似信息的 大型数据库中发现有价值的信息。随着对计算机的理解的日益成熟，机器学习必将在计算机 科学和技术中扮演越来越重要的角色！</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 7pt;text-indent: 21pt;line-height: 109%;text-align: left;">通过一些特定的成就我们可以看到这门技术的现状：计算机已经能够成功地识别人类的 讲话（<span class="s6">Waibel 1989</span>；<span class="s6">Lee 1989</span>）；预测肺炎患者的康复率（<span class="s6">Cooper et al. 1997</span>）；检测信用卡 欺诈；在高速公路上驾驶（<span class="s6">Pomerleau 1989</span>）；以接近人类世界冠军的水平对弈西洋双陆棋<span class="s9">①</span>这 样的游戏（<span class="s6">Tesauro 1992, 1995</span>）。已有了很多理论成果能够对训练样例数量、假设空间大小、 和学得假设错误率这三者间的基本关系进行刻画。我们正在开始获取人类和动物学习的原始 模型，用以理解它们和计算机的学习算法间的关系（例如，<span class="s6">Laird et al. 1986</span>；<span class="s6">Anderson 1991</span>； <span class="s6">Qin et al. 1992</span>；<span class="s6">Chi &amp; Bassock 1989</span>；<span class="s6">Ahn &amp; Brewer 1993</span>）。在过去的十年中无论是应用、算 法、理论，还是生物系统的研究都取得了值得注目的进步。机器学习最近的几种应用被归纳 在表 <span class="s6">1-1 </span>中。<span class="s6">Langley &amp; Simon</span>（<span class="s6">1995</span>）以及<span class="s6">Rumelhart et al.</span>（<span class="s6">1994</span>）调查了机器学习的一些 其他应用。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 152pt;text-indent: 0pt;text-align: left;">表 <span class="h4">1-1 </span>机器学习的一些成功应用</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 2pt;text-align: left;"><span><img width="560" height="2" alt="image" src="机器学习/Image_002.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s11" style="padding-top: 7pt;padding-left: 18pt;text-indent: -10pt;line-height: 94%;text-align: left;"><span class="s10"> </span><span class="p">学习识别人类的讲话 </span>所有最成功的语音识别系统都使用了某种形式的机器学习技术。例如，<span class="s12">Sphinx </span>系统（参见 <span class="s12">Lee 1989</span>）可学习特定讲话者的语音识别策略，从检测到的语音信号中识别出基本的音素</p><p class="s11" style="padding-left: 18pt;text-indent: 0pt;text-align: justify;">（<span class="s12">phoneme</span>）和单词。神经网络学习方法（例如 <span class="s12">Waibel et al. 1989</span>）和隐式马尔可夫模型（<span class="s12">hidden Markov model</span>）的学习方法（例如 <span class="s12">Lee 1989</span>）在语音识别系统中也非常有效，它们可以让系 统自动适应不同的讲话者、词汇、麦克风特性和背景噪音等等。类似的技术在很多信号解 释课题中有应用潜力。</p><p class="s10" style="padding-left: 8pt;text-indent: 0pt;line-height: 14pt;text-align: left;"> <span class="p">学习驾驶车辆</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 28pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="193" height="1" alt="image" src="机器学习/Image_003.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s13" style="padding-top: 2pt;padding-left: 9pt;text-indent: 0pt;text-align: left;">①<span class="s14">译注：一种类似飞行棋的游戏，双方各持十五子，通过掷骰子来决定棋子移动的步数。</span></p><p class="s11" style="padding-top: 1pt;padding-left: 18pt;text-indent: 0pt;text-align: justify;">机器学习方法已被用于训练计算机控制的车辆，使其在各种类型的道路上正确行驶。例如 <span class="s12">ALVINN </span>系统（<span class="s12">Pomerleau 1989</span>）已经利用它学会的策略独自在高速公路的其他车辆之间奔 驰，以 <span class="s12">70 </span>英里的时速共行驶了 <span class="s12">90 </span>英里。类似的技术可能在很多基于传感器的控制问题中 得到应用。</p><p class="s11" style="padding-left: 18pt;text-indent: -10pt;text-align: left;"><span class="s10"> </span><span class="p">学习分类新的天文结构 </span>机器学习方法已经被用于从各种大规模的数据库中发现隐藏的一般规律。例如，决策树学 习算法已经被美国国家航空和航天局（<span class="s12">NASA</span>）用来分类天体，数据来自第二帕洛马天文台 太空调查（<span class="s12">Fayyad et al. 1995</span>）。这一系统现在被用于自动分类太空调查中的所有天体，其 中包含了 <span class="s12">3T </span>字节的图像数据。</p><p class="s11" style="padding-left: 18pt;text-indent: -10pt;text-align: left;"><span class="s10"> </span><span class="p">学习以世界级的水平对弈西洋双陆棋 </span>最成功的博弈类（如西洋双陆棋）计算机程序是基于机器学习算法的。例如，世界最好的 西洋双陆棋程序 <span class="s12">TD-Gammon</span>（<span class="s12">Tesauro 1992, 1995</span>）是通过一百万次以上的和自己对弈来学 习其策略的。现在它的水平能与人类的世界冠军相当。类似的技术被应用于许多实际问题， 其中需要高效地搜索庞大的搜索空间。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 2pt;text-align: left;"><span><img width="560" height="2" alt="image" src="机器学习/Image_004.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 7pt;text-indent: 21pt;line-height: 112%;text-align: justify;">本书针对机器学习这个领域，描述了多种学习范型、算法、理论以及应用。机器学习从 本质上是一个多学科的领域。它吸取了人工智能、概率统计、计算复杂性理论、控制论、信 息论、哲学、生理学、神经生物学等学科的成果。表 <span class="s6">1-2 </span>归纳了这些学科中影响机器学习的 关键思想。本书的素材基于不同学科的成果，然而读者不必精通每一个学科。来自这些学科 的关键理论将使用非专业的词汇讲解，其中不熟悉的术语和概念会在需要时加以介绍。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 129pt;text-indent: 0pt;text-align: left;">表 <span class="h4">1-2 </span>一些学科和它们对机器学习的影响</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 2pt;text-align: left;"><span><img width="560" height="2" alt="image" src="机器学习/Image_005.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s10" style="padding-left: 18pt;text-indent: -10pt;text-align: left;"> <span class="p">人工智能 </span><span class="s11">学习概念的符号表示。作为搜索问题的机器学习。作为提高问题求解能力途径的学习。使 用先验的知识和训练数据一起引导学习。</span></p><p class="s10" style="padding-left: 18pt;text-indent: -10pt;text-align: left;"> <span class="p">贝叶斯方法 </span><span class="s11">作为计算假设概率的基础的贝叶斯法则。朴素贝叶斯分类器。估计未观测到变量的值的算 法。</span></p><p class="s10" style="padding-left: 8pt;text-indent: 0pt;line-height: 14pt;text-align: left;"> <span class="p">计算复杂性理论</span></p><p class="s11" style="padding-left: 18pt;text-indent: 0pt;line-height: 13pt;text-align: left;">不同学习任务中固有的复杂性的理论边界，以计算量、训练样例数量、出错数量等衡量。</p><p class="s10" style="padding-left: 8pt;text-indent: 0pt;line-height: 14pt;text-align: left;"> <span class="p">控制论</span></p><p class="s11" style="padding-left: 18pt;text-indent: 0pt;line-height: 13pt;text-align: left;">为了优化预定目标，学习对各种处理过程进行控制，学习预测被控制的过程的下一个状态。</p><p class="s10" style="padding-left: 18pt;text-indent: -10pt;text-align: left;"> <span class="p">信息论 </span><span class="s11">熵和信息内容的度量。学习的最小描述长度方法。编码假设时，它的最佳编码和与最佳训 练序列的关系。</span></p><p class="s10" style="padding-left: 8pt;text-indent: 0pt;line-height: 14pt;text-align: left;"> <span class="p">哲学</span></p><p class="s11" style="padding-left: 18pt;text-indent: 0pt;line-height: 13pt;text-align: left;">“奥坎姆的剃刀”（<span class="s12">Occam’s razor</span>）<span class="s15">①</span>：最简单的假设是最好的。从观察到的数据泛化的理 由分析。</p><p class="s10" style="padding-left: 8pt;text-indent: 0pt;line-height: 13pt;text-align: left;"> <span class="p">心理学和神经生物学</span></p><p class="s11" style="padding-left: 18pt;text-indent: 0pt;line-height: 13pt;text-align: left;">实践的幂定律（<span class="s12">power law of practice</span>），该定律指出对于很大范围内的学习问题，人们的反 应速度随着实践次数的幂级提高。激发人工神经网络的学习模式的神经生物学研究。</p><p class="s10" style="padding-left: 8pt;text-indent: 0pt;line-height: 13pt;text-align: left;"> <span class="p">统计学</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 28pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="193" height="1" alt="image" src="机器学习/Image_006.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-left: 9pt;text-indent: 0pt;text-align: left;"><span class="s13">① </span>译注：也称“吝啬律（<span class="s16">Law of Parsimony’</span>”或“节约律（<span class="s16">Law of Economy</span>）”，主要思想为简单的理论</p><p class="s14" style="padding-top: 3pt;padding-left: 8pt;text-indent: 0pt;text-align: left;">（或假设）优于复杂的，因英国哲学家奥坎姆（<span class="s16">1285~1349</span>）频繁使用这一原则，故称为“奥坎姆剃刀”。</p><p class="s11" style="padding-top: 1pt;padding-left: 18pt;text-indent: 0pt;text-align: left;">在估计有限数据样本上的假设精度时出现的误差（例如偏差和方差）的刻画。置信区间， 统计检验。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 2pt;text-align: left;"><span><img width="560" height="2" alt="image" src="机器学习/Image_007.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 57pt;text-indent: 0pt;text-align: left;">1.1 <span class="s17">学习问题的标准描述</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 8pt;text-indent: 21pt;line-height: 113%;text-align: justify;">让我们从几个实际的学习任务开始研究机器学习。根据本书的目的，我们给学习一个宽 广的定义，以使其包括任何计算机程序<span style=" color: #F00;">通过经验来提高某任务处理性能的行为</span>。更准确地讲，</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s19" style="padding-left: 28pt;text-indent: 0pt;text-align: left;">//<span class="s18">利用经验改善系统自身的性能</span>//</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 28pt;text-indent: 21pt;text-align: justify;"><span class="s20">定义： </span>对于某类任务 <span class="s21">T </span>和性能度量 <span class="s21">P</span>，如果一个计算机程序在 <span class="s21">T</span><span class="s22">(</span><span class="s23">任务</span><span class="s22">)</span>上以 <span class="s21">P</span><span class="s23">（性 能标准）</span>衡量的性能随着经验 <span class="s21">E </span>而自我完善，那么我们称这个计算机程序在从经验 <span class="s21">E </span>学习。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 8pt;text-indent: 21pt;line-height: 113%;text-align: justify;">例如，对于学习下西洋跳棋<span class="s9">①</span>的计算机程序，它可以通过和自己下棋获取经验，它担负 的任务是参与西洋跳棋对弈，它的性能用它赢棋的能力来衡量。通常，为了很好地定义一个 学习问题，我们必须明确这样三个特征：<span style=" color: #F00;">任务的种类；衡量任务提高的标准；经验的来源</span>。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 29pt;text-indent: 0pt;text-align: left;">西洋跳棋学习问题：</p><p style="padding-top: 5pt;padding-left: 47pt;text-indent: 0pt;line-height: 14pt;text-align: left;"><span class="s10"> </span>任务 <span class="s21">T</span>：下西洋跳棋</p><p style="padding-left: 47pt;text-indent: 0pt;line-height: 14pt;text-align: left;"><span class="s10"> </span>性能标准 <span class="s21">P</span>：比赛中击败对手的百分比</p><p style="padding-left: 28pt;text-indent: 18pt;line-height: 149%;text-align: left;"><span class="s10"> </span>训练经验 <span class="s21">E</span>：和自己进行对弈 我们可以用以上方法定义很多学习问题，例如学习手写识别、学习自动驾驶机器人汽车。</p><p style="padding-top: 8pt;padding-left: 28pt;text-indent: 0pt;text-align: left;">手写识别学习问题：</p><p style="padding-top: 5pt;padding-left: 47pt;text-indent: 0pt;line-height: 14pt;text-align: left;"><span class="s10"> </span>任务 <span class="s21">T</span>：识别和分类图像中的手写文字</p><p style="padding-left: 47pt;text-indent: 0pt;line-height: 14pt;text-align: left;"><span class="s10"> </span>性能标准 <span class="s21">P</span>：分类的正确率</p><p style="padding-left: 28pt;text-indent: 18pt;line-height: 148%;text-align: left;"><span class="s10"> </span>训练经验 <span class="s21">E</span>：已知分类的手写文字数据库 机器人驾驶学习问题：</p><p style="padding-left: 47pt;text-indent: 0pt;text-align: left;"><span class="s10"> </span>任务 <span class="s21">T</span>：通过视觉传感器在四车道高速公路上驾驶</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 28pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="193" height="1" alt="image" src="机器学习/Image_008.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-top: 2pt;padding-left: 7pt;text-indent: 1pt;line-height: 125%;text-align: left;"><span class="s13">① </span>译注：为了更好理解本例，下面简要介绍一下这种跳棋。棋盘为 <span class="s16">8</span>×<span class="s16">8 </span>方格，深色棋格不可着子。可单 步行走，亦可每步跨对方一子单跳或连跳，被跨越的子被杀出局。到达对方底线的子成为王，可回向行走</p><p class="s14" style="padding-top: 1pt;padding-left: 7pt;text-indent: 0pt;text-align: left;">（成为王前只可前行），又可隔空格飞行。下图为西洋跳棋棋盘示例（起始状态）。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 172pt;text-indent: 0pt;line-height: 103pt;text-align: left;"><span><img width="139" height="136" alt="image" src="机器学习/Image_009.gif"/></span></p><p style="padding-left: 45pt;text-indent: 0pt;line-height: 14pt;text-align: left;"><span class="s10"> </span>性能标准 <span class="s21">P</span>：平均无差错行驶里程（差错由人类的监督裁定）</p><p style="padding-left: 26pt;text-indent: 18pt;line-height: 149%;text-align: left;"><span class="s10"> </span>训练经验 <span class="s21">E</span>：注视人类驾驶时录制的一系列图像和驾驶指令 这里对学习的定义很宽广，足以包括大多数惯于被称为“学习”的任务，就像我们日常</p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 10pt;text-align: left;">使用的这个词一样。同时，它也包括了以非常简明的方式<span style=" color: #00F;">通过经验自我提高的计算机程序</span>。</p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 0pt;line-height: 113%;text-align: left;">例如，一个允许用户更新数据条目的数据库系统，也符合我们对学习系统的定义：它根据从 数据库更新得到的经验提高它回答数据查询的能力。与其担心这种行为与“学习”这个词日 常谈论的非正式含义相混淆，我们索性简单地采用我们的科技型定义——一类计算机程序通 过经验提高的过程。在这个范畴内，我们会发现很多问题或多或少需要较复杂的解决办法。 这里我们并非要分析“学习”这个单词的日常含义。而是要精确地定义一类囊括我们感兴趣 的学习形式的问题，探索解决这类问题的方法，并理解学习问题的基础结构和过程。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 55pt;text-indent: 0pt;text-align: left;">1.2 <span class="s17">设计一个学习系统</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 113%;text-align: left;">为了演示一些机器学习的基本设计方法和途径，考虑设计一个学习下西洋跳棋的程序。 我们的目标是让它进入西洋跳棋世界锦标赛。我们采用最显而易见的标准衡量它的性能：在 世界锦标赛上打赢的比赛占总参赛次数的百分比。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 51pt;text-indent: 0pt;text-align: left;">1.2.1 <span class="s25">选择训练方式</span></h3><p style="padding-top: 10pt;padding-left: 6pt;text-indent: 21pt;line-height: 111%;text-align: left;">我们面临的第一个设计问题是<span style=" color: #F00;">选取训练经验的类型</span>，使系统从中进行学习。给学习器提 供的训练经验对它的成败有重大的影响。一个关键属性是训练经验能否为系统的决策提供直 接或间接的反馈。例如，对于学习下西洋跳棋，系统可以从直接的（<span class="s6">direct</span>）训练样例，即 各种棋盘状态和相应的正确走子中学习。另一种情况，它可能仅有间接（<span class="s6">indirect</span>）的信息， 包含很多过去的对弈序列和最终结局。对于后一种情况，关于博弈中较早走子的正确性必须 从对弈最终的输赢来推断。这时学习器又额外面临一个<span class="s26">信用分配</span>（<span class="s6">credit assignment</span>）问题， 也就是考虑每一次走子对最终结果的贡献程度。信用分配可能是一个非常难以解决的问题， 因为如果后面下得很差，那么即使起初的走子是最佳的，这盘棋也会输掉。所以通常从直接 的训练反馈来学习比间接的简单。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 113%;text-align: left;">训练经验的第二个重要属性是学习器可以在多大程度上控制训练样例序列。例如，学习 器可能依赖施教者选取棋盘状态，和提供每一次的正确移动。或者，学习器可能自己提出它 认为特别困惑的棋局并向施教者询问正确的走子。或者，学习器可以完全控制棋局和（间接 的）训练分类，就像没有施教者时它和自己对弈进行学习一样。注意对于最后一种情况学习 器可能选择以下两种情况中的一种：第一，试验它还未考虑过的全新棋局；第二，在它目前 发现的最奏效的路线的微小变化上对弈，以磨砺它的技能。后续的章节考虑一些学习框架， 包括了以下几种情况：训练经验是以超乎学习器控制的随机过程提供的；学习器可向施教者 提出不同类型的查询；以及学习器通过自动探索环境来搜集训练样例。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 110%;text-align: justify;">训练经验的第三个重要属性是，训练样例的分布能多好地表示实例分布，而最终系统的 性能 <span class="s21">P </span>是通过后者来衡量的。一般而言，当训练样例的分布和将来的测试样例的分布相似 时，学习具有最大的可信度。对于我们的西洋跳棋学习，性能指标 <span class="s21">P </span>是该系统在世界锦标 赛上赢棋的百分比。如果它的训练经验 <span class="s21">E </span>仅由和它自己对弈的训练组成，便存在一个明显 的危险：这个训练可能不能充分地表示该系统以后被测试时的情形。例如，学习器可能在训 练中从来未遇到过某些非常关键性的棋局，而它们又非常可能被人类世界冠军采用。实际上，</p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 113%;text-align: justify;">学习的样例通常与最终系统被评估时的样例有一定差异，学习器必须能从中进行学习（举例 来说，世界级的西洋跳棋冠军可能不会有兴趣教一个程序下棋）。这的确是一个问题，因为 掌握了样例的一种分布，不一定会导致对其他的分布也有好的性能。可以看到，目前多数机 器学习理论都是基于训练样例与测试样例分布一致这一前提。尽管我们需要这样的前提以便 得到理论的结果，但同样必须记住在实践中这个假设经常是不严格成立的。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 113%;text-align: justify;">下面继续进行算法设计，我们决定系统将通过和自己对弈来训练。这样的好处是不需要 外界的训练者，所以可以让系统产生无限多的训练数据，只要时间允许。现在有了一个完整 的学习任务。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 27pt;text-indent: 0pt;text-align: left;">西洋跳棋学习问题：</p><p style="padding-top: 5pt;padding-left: 45pt;text-indent: 0pt;line-height: 14pt;text-align: left;"><span class="s10"> </span>任务 <span class="s21">T</span>：下西洋跳棋</p><p style="padding-left: 45pt;text-indent: 0pt;line-height: 14pt;text-align: left;"><span class="s10"> </span>性能标准 <span class="s21">P</span>：世界锦标赛上击败对手的百分比</p><p style="padding-left: 26pt;text-indent: 18pt;line-height: 149%;text-align: left;"><span class="s10"> </span>训练经验 <span class="s21">E</span>：和自己进行对弈 为了完成这个学习系统的设计，现在需要选择：</p><p class="s6" style="padding-left: 48pt;text-indent: 0pt;line-height: 14pt;text-align: left;">1. <span class="p">要学习的知识的确切类型</span></p><p class="s6" style="padding-left: 48pt;text-indent: 0pt;line-height: 14pt;text-align: left;">2. <span class="p">对于这个目标知识的表示</span></p><p class="s6" style="padding-left: 48pt;text-indent: 0pt;line-height: 14pt;text-align: left;">3. <span class="p">一种学习机制</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 51pt;text-indent: 0pt;text-align: left;">1.2.2 <span class="s25">选择目标函数</span></h3><p style="padding-top: 10pt;padding-left: 6pt;text-indent: 21pt;line-height: 112%;text-align: justify;">下一个设计选择是决定要学习的知识的确切类型，以及执行程序怎样使用这些知识。我 们从一个对于任何棋局都能产生合法（<span class="s6">legal</span>）走子的西洋跳棋博弈程序开始。那么，最终的 程序仅须学会从这些合法的走子中选择最佳的。这个学习任务代表了一大类任务：合法走子 定义了某个先验已知的巨大搜索空间，但<span style=" color: #F00;">最佳的搜索策略</span>未知。很多最优化问题都可归于此 类，例如对于生产过程的调度和控制问题，生产中的每一步都很清楚，但调度这些步骤的最 佳策略未知。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s18" style="padding-left: 6pt;text-indent: 21pt;line-height: 109%;text-align: justify;"><span style=" color: #000;">为了学习从合法走子中作出选择，很明显，要学习的信息类型就是一个程序或函数，它 对任何 给 定的棋 局 能选出 最 好的走 法 。可称 此 函数为 </span><span class="s21">ChooseMove </span><span style=" color: #000;">，并用记法 </span><span class="s21">ChooseMove</span><span class="s6">:</span><span class="s21">B</span><span class="s6">→</span><span class="s21">M </span><span style=" color: #000;">来表示这个函数以合法棋局集合中的棋盘状态作为输入，并从合法走子 集合中产生某个走子作为输出。在关于机器学习的所有讨论中，我们</span>发现可以把对任务 <span class="s22">T </span>提高性能 <span class="s22">P </span>的问题简化为学习象 <span class="s22">ChooseMove </span>这样某个特定的目标函数（<span class="s27">target function</span>） 的问题<span style=" color: #000;">。所以目标函数的选择是一个关键的设计问题。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s18" style="padding-left: 5pt;text-indent: 21pt;line-height: 109%;text-align: left;"><span style=" color: #000;">尽管在例子中很明显应把 </span><span class="s21">ChooseMove </span><span style=" color: #000;">作为目标函数，但我们会发现学习这个目标函数 是非常困难的，原因是提供给系统的是间接的训练经验。另外一个可供选择的目标函数是一 个评估函数，它为任何给定棋局赋予一个数字的评分。可以发现，对于本例，学习这个目标 函数更简单。</span>令这个目标函数为 <span class="s22">V</span>，并用 <span class="s22">V</span>：<span class="s22">B</span><span class="s19">→</span><span class="s28"> </span>来表示 <span class="s22">V </span>把任何合法的棋局映射到某一 个实数值（用<span class="s28"></span>来表示实数集合）<span style=" color: #000;">。我们打算让这个目标函数 </span><span class="s21">V </span><span style=" color: #000;">给好的棋局赋予较高的评分。 如果系统能够成功地学会这个目标函数 </span><span class="s21">V</span><span style=" color: #000;">，那么它便能使用此函数轻松地找到当前棋局的最 佳走法。实现的方法是，先产生每一个合法走子对应的所有后续棋局，然后使用 </span><span class="s21">V </span><span style=" color: #000;">来选取 其中最佳的后继棋局，从而选择最好的走子。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">对于任意棋局，目标函数 <span class="s21">V </span>的准确值应该是多少呢？当然任何对较好的棋局赋予较高 的分数的评估函数都适用。然而，最好在那些产生最佳对弈的众多方法中定义一个特定的目</p><p class="s21" style="padding-left: 6pt;text-indent: 0pt;line-height: 107%;text-align: left;"><span class="p">标函数 </span>V<span class="p">。可以看到，这将使得设计一个训练算法变得简单。因此，对于集合 </span>B <span class="p">中的任意的 棋局状态 </span>b<span class="p">，我们如下定义目标函数 </span>V<span class="s6">(</span>b<span class="s6">)</span><span class="p">：</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 48pt;text-indent: 0pt;text-align: left;"><span class="s6">1. </span><span class="p">如果 </span>b <span class="p">是一最终的胜局，那么 </span>V<span class="s6">(</span>b<span class="s6">)=100</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 48pt;text-indent: 0pt;text-align: left;"><span class="s6">2. </span><span class="p">如果 </span>b <span class="p">是一最终的负局，那么 </span>V<span class="s6">(</span>b<span class="s6">)=-100</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 48pt;text-indent: 0pt;text-align: left;"><span class="s6">3. </span><span class="p">如果 </span>b <span class="p">是一最终的和局，那么 </span>V<span class="s6">(</span>b<span class="s6">)=0</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 26pt;text-indent: 21pt;line-height: 107%;text-align: left;"><span class="s6">4. </span><span class="p">如果 </span>b <span class="p">不是最终棋局，那么 </span>V<span class="s6">(</span>b<span class="s6">)=</span>V<span class="s6">(</span>b<span class="s6">′)</span><span class="p">，其中 </span>b<span class="s6">′</span><span class="p">是从 </span>b <span class="p">开始双方都采取最优对 弈后可达到的终局。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 109%;text-align: justify;">然而，由于这个定义的递归性，它的运算效率不高，所以这个定义对于西洋跳棋比赛者 不可用。除了无关紧要的前三种终局的情况，对于某一个棋盘状态（情况 <span class="s6">4</span>）<span class="s21">b</span>要决定它的 值<span class="s21">V</span>（<span class="s21">b</span>）需要向前搜索到达终局的所有路线！由于这个定义不能由西洋跳棋程序高效地运 算，这个定义被称为<span class="s26">不可操作的定义。</span>当前的目标是发现一个可操作的定义<span class="s21">V</span>，它能够被西 洋跳棋程序用来在合理的时间内评估棋局并选取走法。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 106%;text-align: left;">这样，这种情况的学习任务被简化成发现一个<span class="s26">理想目标函数 </span><span class="s7">V </span><span class="s26">的可操作描述</span>。通常要 完美地学习这样一个 <span class="s21">V </span>的可操作的形式是非常困难的。事实上，我们经常希望学习算法仅 得到目标函数的某个近似（<span class="s6">approximation</span>），由于这个原因<span style=" color: #F00;">学习目标函数的过程常被称为</span><span class="s29">函 数逼近（</span><span class="s19">function approximation</span><span class="s29">）</span>。在当前的讨论中，用<span class="s30">V</span><span class="s31">ˆ </span>来表示程序中实际学习到的函数， 以区别理想目标函数 <span class="s21">V</span>。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s32" style="padding-top: 1pt;padding-left: 51pt;text-indent: 0pt;text-align: left;">1.2.3 <span class="s25">选择目标函数的表示</span></p><p style="padding-top: 10pt;padding-left: 5pt;text-indent: 21pt;text-align: left;">至此，我们已经确定了目标函数 <span class="s21">V</span>，接下来必须选择一个表示，被学习程序用来描述要 学习的函数<span class="s30">V</span><span class="s31">ˆ</span><span class="s33"> </span>。对此也有很多设计选择。例如，可以将<span class="s30">V</span><span class="s31">ˆ</span><span class="s33"> </span>表示为一张大表，对于每个惟一 的棋盘状态 <span class="s21">b</span>，表中有惟一的表项来确定它的状态值<span class="s30">V</span><span class="s31">ˆ</span><span class="s33"> </span><span class="s6">(</span><span class="s21">b</span><span class="s6">)</span>。或者，可以让程序用一个规则集 合来匹配棋局的特征以表示<span class="s30">V</span><span class="s31">ˆ</span><span class="s33"> </span>，或采用一个与预定义棋盘特征有关的二次多项式函数，或 者用人工神经元网络。通常，选择这个描述包含一个重要的权衡过程。一方面，我们总希望 选取一个非常有表征力的描述，以最大可能地逼近理想的目标函数 <span class="s21">V</span>。另一方面，越有表征 力的描述需要越多的训练数据，使程序能从它表示的多种假设中做出选择。为了简化讨论， 现在选择一个简单的表示法：对于任何给定的棋盘状态，函数<span class="s30">V</span><span class="s31">ˆ</span><span class="s33"> </span>可以通过以下棋盘参数的 线性组合来计算：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s34" style="padding-top: 1pt;padding-left: 48pt;text-indent: 0pt;text-align: left;">• <span class="s21">x</span><span class="s35">1</span><span class="p">：棋盘上黑子的数量</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s34" style="padding-left: 48pt;text-indent: 0pt;text-align: left;">• <span class="s21">x</span><span class="s35">2</span><span class="p">：棋盘上红子的数量</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s34" style="padding-left: 48pt;text-indent: 0pt;text-align: left;">• <span class="s21">x</span><span class="s35">3</span><span class="p">：棋盘上黑王的数量</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s34" style="padding-left: 48pt;text-indent: 0pt;text-align: left;">• <span class="s21">x</span><span class="s35">4</span><span class="p">：棋盘上红王的数量</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s34" style="padding-left: 48pt;text-indent: 0pt;text-align: left;">• <span class="s21">x</span><span class="s35">5</span><span class="p">：被红子威胁的黑子数量（即会在下一次被红吃掉的子）</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s34" style="padding-left: 48pt;text-indent: 0pt;text-align: left;">• <span class="s21">x</span><span class="s35">6</span><span class="p">：被黑子威胁的红子数量</span></p><p class="s6" style="padding-top: 2pt;padding-left: 27pt;text-indent: 0pt;text-align: left;"><span class="p">于是，学习程序把</span><span class="s30">V</span><span class="s31">ˆ</span><span class="s33"> </span>(<i>b</i>)<span class="p">表示为一个线性函数</span></p><p class="s21" style="padding-top: 12pt;padding-left: 24pt;text-indent: 0pt;text-align: center;"><span class="s30">V</span><span class="s31">ˆ</span><span class="s33"> </span><span class="s6">(</span>b<span class="s6">)=</span>w<span class="s35">0</span><span class="s6">+</span>w<span class="s35">1</span>x<span class="s35">1</span><span class="s6">+</span>w<span class="s35">2</span>x<span class="s35">2</span><span class="s6">+</span>w<span class="s35">3</span>x<span class="s35">3</span><span class="s6">+</span>w<span class="s35">4</span>x<span class="s35">4</span><span class="s6">+</span>w<span class="s35">5</span>x<span class="s35">5</span><span class="s6">+</span>w<span class="s35">6</span>x<span class="s35">6</span></p><p style="padding-top: 12pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">其中<span class="s21">w</span><span class="s35">0</span>到<span class="s21">w</span><span class="s35">6</span>为数字系数，或叫权，由学习算法来选择。在决定某一个棋盘状态的分值时，</p><p class="s21" style="padding-left: 27pt;text-indent: -21pt;text-align: left;">w<span class="s35">1 </span><span class="p">到 </span>w<span class="s35">6</span><span class="p">决定了不同的棋盘特征的相对重要性，而权</span>w<span class="s35">0</span><span class="p">为一个附加的常量。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 113%;text-align: justify;">概括一下目前为止的设计。我们已经详细阐述了这个学习问题的原型，即为它选择一种 类型的训练经验、一个要学习的目标函数和这个目标函数的一种表示法。现在的学习任务是：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 26pt;text-indent: 0pt;text-align: left;">西洋跳棋程序的部分设计</p><p style="padding-top: 5pt;padding-left: 45pt;text-indent: 0pt;line-height: 14pt;text-align: left;"><span class="s10"> </span>任务 <span class="s21">T</span>：下西洋跳棋</p><p style="padding-left: 45pt;text-indent: 0pt;line-height: 14pt;text-align: left;"><span class="s10"> </span>性能标准 <span class="s21">P</span>：世界锦标赛上击败对手的百分比</p><p style="padding-left: 45pt;text-indent: 0pt;line-height: 14pt;text-align: left;"><span class="s10"> </span>训练经验 <span class="s21">E</span>：和自己进行训练对弈</p><p style="padding-left: 45pt;text-indent: 0pt;line-height: 14pt;text-align: left;"><span class="s10"> </span>目标函数：<span class="s21">V</span>：<span class="s21">B</span><span class="s6">→</span><span class="s10"></span></p><p class="s21" style="padding-left: 45pt;text-indent: 0pt;text-align: left;"><span class="s10"> </span><span class="p">目标函数的表示：</span><span class="s30">V</span><span class="s31">ˆ</span><span class="s33"> </span><span class="s6">(</span>b<span class="s6">)=</span>w<span class="s35">0</span><span class="s6">+</span>w<span class="s35">1</span>x<span class="s35">1</span><span class="s6">+</span>w<span class="s35">2</span>x<span class="s35">2</span><span class="s6">+</span>w<span class="s35">3</span>x<span class="s35">3</span><span class="s6">+</span>w<span class="s35">4</span>x<span class="s35">4</span><span class="s6">+</span>w<span class="s35">5</span>x<span class="s35">5</span><span class="s6">+</span>w<span class="s35">6</span>x<span class="s35">6</span></p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 21pt;line-height: 108%;text-align: justify;">前三条是对学习任务的说明，后两条制定了为实现这个学习程序的设计方案。注意这个 设计的关键作用是把学习西洋跳棋战略的问题简化为学习目标函数描述中系数<span class="s21">w</span><span class="s35">0</span>到<span class="s21">w</span><span class="s35">6</span>值的 问题。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 51pt;text-indent: 0pt;text-align: left;">1.2.4 <span class="s25">选择函数逼近算法</span></h3><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 3pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">为了学习目标函数<span class="s30">V</span><span class="s31">ˆ</span></p><p style="padding-top: 5pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">，需要一系列训练样例，每一个样例描述了特定的棋盘状态<span class="s21">b</span>和</p><p class="s21" style="padding-left: 5pt;text-indent: 0pt;text-align: justify;"><span class="p">它的训练值</span>V<span class="s36">train</span><span class="s6">(</span>b<span class="s6">)</span><span class="p">。换言之，每一个训练样例是形式为</span><span class="s6">&lt;</span>b<span class="p">，</span>V<span class="s36">train</span><span class="s6">(</span>b<span class="s6">)&gt;</span><span class="p">的序偶。举例来说，下 面的训练实例描述了一个黑棋胜利（注意</span>x<span class="s35">2</span><span class="s6">=0 </span><span class="p">表示红棋已经没有子了）的棋盘状态</span>b<span class="p">，它的 目标函数值</span>V<span class="s36">train</span><span class="s6">(</span>b<span class="s6">)</span><span class="p">为 </span><span class="s6">100</span><span class="p">。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 111pt;text-indent: 0pt;text-align: left;">&lt;&lt;<i>x</i><span class="s35">1</span>=3<span class="p">，</span><i>x</i><span class="s35">2</span>=0<span class="p">，</span><i>x</i><span class="s35">3</span>=1<span class="p">，</span><i>x</i><span class="s35">4</span>=0<span class="p">，</span><i>x</i><span class="s35">5</span>=0<span class="p">，</span><i>x</i><span class="s35">6</span>=0&gt;<span class="p">，</span>+100&gt;</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 113%;text-align: left;">下文描述了一个过程，它先从学习器可得的间接训练经验中导出上面的训练样例，然后 调整权值<span class="s21">w</span><span class="s36">i</span>以最佳拟合这些训练样例。</p><p class="s37" style="padding-top: 10pt;padding-left: 48pt;text-indent: 0pt;text-align: left;">1.2.4.1 <span class="s20">估计训练值</span></p><p style="padding-top: 8pt;padding-left: 6pt;text-indent: 20pt;line-height: 113%;text-align: left;">根据以上的学习模型，学习器可以得到的训练信息仅是对弈最后的胜负。 另一方面， 我们需要训练样例为每个棋盘状态赋予一个分值。给对弈结束时的棋盘状态评分是容易的， 而要给对弈结束前的大量中间棋局评分就不那么容易了。因为，一盘棋的最终输赢未必能说 明这盘棋当中的每一个棋盘状态的好或坏。例如，即使某个程序输了一盘棋，仍会有这样的 情况，这盘棋前面的棋局应该给予很高的评价，失败的原因在于后来糟糕的走法。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 5pt;text-indent: 21pt;line-height: 106%;text-align: justify;"><span class="p">尽管估计中间棋局训练值具有内在的模糊性，但令人惊讶的是有一个简单的方法却取得 了良好结果。这种方法对于任何中间棋局</span>b<span class="p">的训练值</span>V<span class="s36">train</span><span class="s6">(</span>b<span class="s6">)</span><span class="p">等于</span><span class="s30">V</span><span class="s31">ˆ </span><span class="s6">(</span>Successor<span class="s6">(</span>b<span class="s6">))</span><span class="p">，其中</span><span class="s30">V</span><span class="s31">ˆ </span><span class="p">是 学习器采用的对</span>V<span class="p">的近似，</span>Successor<span class="s6">(</span>b<span class="s6">) </span><span class="p">表示</span>b<span class="p">之后再轮到程序走棋时的棋盘状态（也就是程 序走了一步和对手回应一步后的棋局）。</span></p><p style="padding-left: 27pt;text-indent: 0pt;text-align: left;">这种估计训练值的方法可被归纳为：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">训练值估计法则</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 27pt;text-indent: 0pt;text-align: left;"><i>V</i><span class="s36">train</span>(<i>b</i>)←<span class="s30">V</span><span class="s31">ˆ </span>(<i>Successor</i>(<i>b</i>)) <span class="p">（</span>1.1<span class="p">）</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 3pt;padding-left: 5pt;text-indent: 21pt;line-height: 106%;text-align: left;">或许这看起来有点离奇，只使用当前的<span class="s30">V</span><span class="s31">ˆ </span>来估计训练值，这一训练值又被用来更新<span class="s30">V</span><span class="s31">ˆ </span>。 但请注意，我们是在用后续棋局<span class="s21">Successor</span><span class="s6">(</span><span class="s21">b</span><span class="s6">)</span>的估计值来估计棋局<span class="s21">b</span>的值。凭直觉，我们可以 看到越接近游戏结束的棋局的<span class="s30">V</span><span class="s31">ˆ </span>越趋向精确。事实上，在特定条件下（将在第 <span class="s6">13 </span>章讨论） 这种基于对后继棋局进行估计的迭代估计训练值的方法，已被证明可以近乎完美地收敛到 <span class="s21">V</span><span class="s36">train</span>估计值。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s37" style="padding-left: 48pt;text-indent: 0pt;text-align: left;">1.2.4.2 <span class="s20">权值调整</span></p><p style="padding-top: 8pt;padding-left: 5pt;text-indent: 21pt;text-align: left;">剩下的事情就是为这个学习算法选择最适合训练样例<span class="s6">{&lt;</span><span class="s21">b</span><span class="s6">, </span><span class="s21">V</span><span class="s36">train</span><span class="s6">(</span><span class="s21">b</span><span class="s6">)&gt;}</span>的权<span class="s21">w</span><span class="s36">i</span>。第一步必须 定义<span class="s26">最佳拟合（</span><span class="s6">best fit</span><span class="s26">）</span>训练数据的含义。一种常用的方法是把最佳的假设（或权向量集合） 定义为使训练值和假设<span class="s30">V</span><span class="s31">ˆ</span><span class="s33"> </span>预测出的值间的误差平方<span class="s21">E</span>最小。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="padding-top: 2pt;padding-left: 127pt;text-indent: 0pt;line-height: 20pt;text-align: left;">E <span class="s38"> </span><span class="s39"></span></p><p class="s41" style="padding-left: 150pt;text-indent: 0pt;line-height: 9pt;text-align: left;"><span class="s40"> </span>b <span class="s42">,</span>V<span class="s43">train</span><span class="s44"> </span><span class="s42">( </span>b <span class="s42">) </span><span class="s40"></span><span class="s45">训练样例</span></p><p class="s31" style="padding-top: 6pt;padding-left: 1pt;text-indent: 0pt;text-align: left;">(<i>V</i><span class="s41">train</span></p><p class="s33" style="padding-top: 3pt;padding-left: 1pt;text-indent: 0pt;text-align: left;">(<i>b</i>) <span class="s38"> </span><i>V</i><span class="s31">ˆ</span> (<i>b</i>)) <span class="s46">2</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 3pt;padding-left: 6pt;text-indent: 20pt;line-height: 106%;text-align: justify;">至此，我们的目标就是寻找权值（等价地，寻找<span class="s30">V</span><span class="s31">ˆ</span><span class="s33"> </span>），使对于观测到的训练数据 <span class="s21">E </span>值最 小化。第 <span class="s6">6 </span>章将讨论在什么条件下，最小化误差平方和等价于寻找给定观测训练数据下的最 可能假设。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 6pt;text-indent: 21pt;line-height: 109%;text-align: left;">已经知道一些算法可以得到线性函数的权使此定义的 <span class="s21">E </span>最小化。在这里需要一个算法， 它可以在有了新的训练样例时进一步改进权值，并且它对估计的训练数据中的差错有好的健 壮性。一个这样的算法被称作最小均方法（<span class="s6">least mean squares</span>），或叫 <span class="s6">LMS </span>训练法则。对于 每一训练样例，它把权值向减小这个训练数据误差的方向略微调整。如第 <span class="s6">4 </span>章讨论的那样， 这个算法可被看作对可能的假设（权值）空间进行随机的梯度下降搜索，以使误差平方和 <span class="s21">E </span>最小化。<span class="s6">LMS </span>算法是这样定义的：</p><p class="s21" style="padding-top: 2pt;padding-left: 27pt;text-indent: 0pt;line-height: 28pt;text-align: left;"><b>LMS </b><span class="p">权值更新法则 对于每一个训练样例</span><span class="s6">&lt;</span>b<span class="p">，</span>V<span class="s36">train</span><span class="s6">(</span>b<span class="s6">)&gt;</span></p><p class="s6" style="padding-top: 3pt;padding-left: 45pt;text-indent: 0pt;line-height: 16pt;text-align: left;"><span class="s10"> </span><span class="p">使用当前的权计算</span><span class="s30">V</span><span class="s31">ˆ</span><span class="s33"> </span>(<i>b</i>)</p><p style="padding-left: 45pt;text-indent: 0pt;line-height: 15pt;text-align: left;"><span class="s10"> </span>对每一个权值<span class="s21">w</span><span class="s36">i</span>进行如下更新</p><p class="s21" style="padding-top: 5pt;padding-left: 24pt;text-indent: 0pt;text-align: center;">w<span class="s36">i</span><span class="p">←</span>w<span class="s36">i</span><span class="s6">+</span>η<span class="s6">(</span>V<span class="s36">train</span><span class="s6">(</span>b<span class="s6">)-</span><span class="s30">V</span><span class="s31">ˆ </span><span class="s6">(</span>b<span class="s6">)) </span>x<span class="s36">i</span></p><p style="padding-top: 11pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">这里<span class="s47">η</span>是一个小的常数（比如 <span class="s6">0.1</span>）用来调整权值更新的幅度。为了直观地理解这个权</p><p class="s21" style="padding-top: 2pt;padding-left: 6pt;text-indent: 0pt;text-align: left;"><span class="p">值更新法则的工作原理，请注意当误差（</span>V<span class="s36">train</span><span class="s6">(</span>b<span class="s6">)-</span></p><p class="s6" style="padding-left: 4pt;text-indent: 0pt;text-align: left;"><span class="s30">V</span><span class="s31">ˆ </span>(<i>b</i>)<span class="p">）为 </span>0 <span class="p">时，权不会被改变。当</span></p><p class="s6" style="padding-left: 5pt;text-indent: 0pt;text-align: justify;">(<i>V</i><span class="s36">train</span>(<i>b</i>)-<span class="s30">V</span><span class="s31">ˆ</span><span class="s33"> </span>(<i>b</i>))<span class="p">为正时（例如，当</span><span class="s30">V</span><span class="s31">ˆ</span><span class="s33"> </span>(<i>b</i>)<span class="p">太低时）每一个权值会根据其对应特征值增加一定的 比例。这会提升</span><span class="s30">V</span><span class="s31">ˆ</span><span class="s33"> </span>(<i>b</i>)<span class="p">的值而减小误差。注意如果某个参数</span><i>x</i><span class="s36">i</span><span class="p">为 </span>0<span class="p">，那么它的值不会因这个误 差而改变，这样便使只有那些在训练样例的棋局中确实出现的特征的权值才被更新。令人吃 惊的是，在一定的条件下，这种简单的权值调整方法被证明可以收敛到</span><i>V</i><span class="s36">train</span><span class="s41"> </span><span class="p">值的最小误差 平方逼近（就像第 </span>4 <span class="p">章所讨论的）。</span></p><h3 style="padding-left: 27pt;text-indent: 24pt;text-align: left;">1.2.5 <span class="s25">最终的设计</span></h3><p style="padding-top: 10pt;padding-left: 6pt;text-indent: 21pt;line-height: 113%;text-align: left;">西洋跳棋学习系统的最终设计可以自然地用四个清楚的程序模块来描述，这些模块在很 多学习系统中是核心组件。这四个模块被归纳在图 <span class="s6">1-1 </span>中，它们是：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s26" style="padding-top: 1pt;padding-left: 6pt;text-indent: 21pt;line-height: 110%;text-align: justify;">执行系统（<span class="h4">Performance system</span>）<span class="p">，这个模块是用学会的目标函数来解决给定的任务， 在此就是对弈西洋跳棋。它把新问题（新一盘棋）的实例作为输入，产生一组解答路线（对 弈历史记录）作为输出。在这里，执行系统采用的选择下一步走法的策略是由学到的评估函 数</span><span class="s30">V</span><span class="s31">ˆ</span><span class="s33"> </span><span class="p">来决定的。所以我们期待它的性能会随着评估函数的日益准确而提高。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 25pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="531" height="1" alt="image" src="机器学习/Image_010.png"/></span></p><p class="s48" style="padding-left: 27pt;text-indent: 0pt;text-align: left;">插图——原书页码： <span class="s21">12</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">Experiment Generator-<span class="p">试验生成器</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 27pt;text-indent: 0pt;text-align: left;">New Problem(initial game board)-<span class="p">新问题（初始棋局）</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-top: 1pt;padding-left: 26pt;text-indent: 0pt;text-align: left;">Performance System-<span class="p">执行系统</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 27pt;text-indent: 0pt;text-align: left;">Solution trace(game history)-<span class="p">解答路线（对弈历史）</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">Critic-<span class="p">鉴定器</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 26pt;text-indent: 0pt;text-align: left;">Training examples-<span class="p">训练样例</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-top: 1pt;padding-left: 26pt;text-indent: 0pt;line-height: 190%;text-align: left;">Generalizer-<span class="p">泛化器 </span>Hypothesis-<span class="p">假设</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 14pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="531" height="1" alt="image" src="机器学习/Image_011.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 26pt;text-indent: 112pt;text-align: left;">图 <span class="h4">1-1 </span>西洋跳棋学习程序的最终设计</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 110%;text-align: justify;"><span class="s26">鉴定器（</span><span class="s6">Critic</span><span class="s26">）</span>，它以对弈的路线或历史记录作为输入，输出目标函数的一系列训练样 例。如图所示，每一个训练样例对应路线中的某个棋盘状态和目标函数给这个样例的评估值 <span class="s21">V</span><span class="s36">train</span>。在我们的例子中，鉴定器对应式 <span class="s6">1.1 </span>给出的训练法则。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 106%;text-align: justify;"><span class="s26">泛化器（</span><span class="s6">Generalizer</span><span class="s26">），</span>它以训练样例作为输入，输出一个假设，作为它对目标函数的 估计。它从特定的训练样例中泛化，猜测一个一般函数，使其能够覆盖这些样例以及样例之 外的情形。在我们的例子中，泛化器对应<span class="s6">LMS</span>算法，输出假设是用学习到的权值<span class="s21">w</span><span class="s35">0 </span><span class="s6">,..., </span><span class="s21">w</span><span class="s35">6</span>描 述的函数<span class="s49">V</span><span class="s50">ˆ</span><span class="s33"> </span>。</p><p style="padding-top: 12pt;padding-left: 6pt;text-indent: 20pt;line-height: 112%;text-align: left;">实验生成器（<span class="h4">Experiment Generator</span>），它以当前的假设（当前学到的函数）作为输入， 输出一个新的问题（例如，最初的棋局）供执行系统去探索。它的角色是挑选新的练习问题， 以使整个系统的学习速率最大化。在我们的例子中，实验生成器采用了非常简单的策略：它 总是给出一个同样的初始棋局来开始新的一盘棋。更完善的策略可能致力于精心设计棋子位 置以探索棋盘空间的特定区域。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">总体来看，我们为西洋跳棋程序作的设计就是产生执行系统、鉴定器、泛化器和实验生</p><p style="padding-left: 6pt;text-indent: 0pt;text-align: left;">成器的特定实例。很多机器学习系统通常可以用这四个通用模块来刻画。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;line-height: 112%;text-align: justify;">设计西洋跳棋程序的流程被归纳在图 <span class="s6">1-2 </span>中。这个设计已经在几方面把学习任务限制在 较小的范围内。要学习的知识类型被限制为一个单一的线性评估函数。而且这个评估函数被 限制为仅依赖于六个棋盘特征。如果目标函数真的可表示为这些特定参数的线性组合，那么 程序学到这个目标函数的可能性很大。反之，最多只希望它学到一个合理的近似，因为一个 程序当然不能学会它根本不能表示的东西。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 25pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="531" height="1" alt="image" src="机器学习/Image_012.png"/></span></p><p class="s48" style="padding-left: 27pt;text-indent: 0pt;text-align: left;">插图——原书页码： <span class="s21">13</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">Determine Type of Training Experience- <span class="p">决定训练经验形式</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 27pt;text-indent: 0pt;text-align: left;">Games against experts- <span class="p">与专家对弈</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 27pt;text-indent: 0pt;text-align: left;">Games against self- <span class="p">与自己对弈</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 27pt;text-indent: 0pt;text-align: left;">Table of correct moves- <span class="p">正确走子的表格</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 27pt;text-indent: 0pt;text-align: left;">Determine Target Function- <span class="p">决定目标函数</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 27pt;text-indent: 0pt;text-align: left;"><span class="s6">Board-&gt;move- </span>棋盘<span class="s10"></span>走子</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 27pt;text-indent: 0pt;text-align: left;"><span class="s6">Board-&gt;value- </span>棋盘<span class="s10"></span>分值</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 27pt;text-indent: 0pt;line-height: 190%;text-align: left;">Determine Representation of Learned Function-<span class="p">决定目标函数的表示 </span>Polynomial- <span class="p">多项式</span></p><p class="s6" style="padding-top: 2pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">Linear function of six features- <span class="p">六个参数的线性函数</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 27pt;text-indent: 0pt;text-align: left;">Artificial neural network- <span class="p">人工神经网络</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 27pt;text-indent: 0pt;text-align: left;">Determine Learning Algorithm- <span class="p">决定学习算法</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 27pt;text-indent: 0pt;text-align: left;">Gradient descent- <span class="p">梯度下降</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 27pt;text-indent: 0pt;text-align: left;">Linear programming- <span class="p">线性规划</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 27pt;text-indent: 0pt;text-align: left;">Completed Design- <span class="p">完成的设计</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 14pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="531" height="1" alt="image" src="机器学习/Image_013.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 130pt;text-indent: 0pt;text-align: left;">图 <span class="h4">1-2 </span>西洋跳棋学习程序的设计过程概述</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 109%;text-align: justify;">我们假定真实函数 <span class="s21">V </span>的合理的近似确实可被表示为这种形式。那么问题变成这种学习 技术是否确保能发现一个合理的近似。第 <span class="s6">13 </span>章提供了一种理论分析，表明对于某些类型的 搜索问题，在相当严格的前提下，这种方法确实收敛到期望的评估函数。很幸运，实践经验 表明这种学习评估函数的途径经常是成功的，甚至在能被证明的情形之外也是如此。</p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 110%;text-align: left;">已经设计的程序能学得足够好而击败人类的西洋跳棋冠军吗？或许不能。部分地，这是 因为<span class="s30">V</span><span class="s31">ˆ </span>的线性函数表示太简单以致于不能很好捕捉这种棋的微妙之处。然而，如果给与一 个更完善的目标函数表示法，这种通用的途径事实上可以非常成功。例如，<span class="s6">Tesauro(1992, 1995) </span>报告了学习下西洋双陆棋的程序的类似设计，方法是学习一个非常类似的棋局评估函数。它 的程序使用人工神经元网络表示学到的评估函数，它考虑对棋局的完整描述而不是棋盘的几 个参数。经历了一百万次以上的自我生成的训练比赛后，他的程序能够和一流的人类西洋双 陆棋选手一争高下。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 111%;text-align: justify;">当然还可能为西洋跳棋学习任务设计很多其他的算法。例如，一种可能只简单地存储训 练样例，然后去寻找保存的“最接近的”情形来匹配新的情况（最近邻算法，第 <span class="s6">8 </span>章）。或 者可以产生大量候选的西洋跳棋程序，并让它们相互比赛，保留最成功的程序并进一步用模 拟进化的方式来培育或变异它们（遗传算法，第 <span class="s6">9 </span>章）。人类似乎遵循另一种途径寻找学习</p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 110%;text-align: justify;">策略，他们分析或向自己解释比赛中碰到的成败的原因（基于解释的学习，第 <span class="s6">11 </span>章）。上面 的设计是这些种类中的一个简单的算法，它是为了给我们今后的针对特定类别的任务的学习 方法的设计奠定基础。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 55pt;text-indent: 0pt;text-align: left;">1.3 <span class="s17">机器学习的一些观点和问题</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;line-height: 111%;text-align: left;">在机器学习方面，一个有效的观点是机器学习问题经常归结于搜索问题，即对非常大的 假设空间进行搜索，以确定最佳拟合观察到的数据和学习器已有知识的假设。例如，考虑一 下上面的西洋跳棋学习程序输出的假设空间。这个假设空间包含所有可由权<span class="s21">w</span><span class="s35">0</span>到<span class="s21">w</span><span class="s35">6</span>的不同值 的评估函数。于是学习器的任务就是搜索这个大的空间，寻找与训练数据最佳拟合的假设。 针对拟合权值的<span class="s6">LMS</span>算法通过迭代调整权值实现了这个目的，每当假设的评估函数预测出 一个与训练数据有偏差的值时就对每个权值进行校正。当学习器考虑的假设表示定义了一个 连续的参数化的潜在假设空间时，这个算法很有效。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 113%;text-align: left;">本书的很多章节给出了对一些基本表示（例如，线性函数、逻辑描述、决策树、人工神 经元网络）定义的假设空间的搜索算法。这些不同的假设表示法适合于学习不同的目标函数。 对于其中的每一种假设表示法，对应的学习算法发挥不同内在结构的优势来组织对假设空间 的搜索。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 113%;text-align: justify;">自始至终，本书都贯穿着这种把学习问题视为搜索问题的看法，从而通过搜索策略和学 习器探索的搜索空间的内在结构来刻画学习方法。我们也会发现，这种观点对于形式化地分 析要搜索的假设空间的大小、可利用的训练样例的数量以及一个与训练数据一致的假设能泛 化到未见实例的置信度这三者之间的关系非常有用。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 51pt;text-indent: 0pt;text-align: left;">1.3.1 <span class="s25">机器学习的问题</span></h3><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 6pt;text-indent: 21pt;line-height: 113%;text-align: left;">西洋跳棋例子提出了机器学习方面很多普遍问题。机器学习这门学科，和本书的绝大部 分，都致力于回答类似下面的问题：</p><p class="s51" style="padding-top: 4pt;padding-left: 66pt;text-indent: -21pt;text-align: justify;"> <span class="s24">从特定的训练数据学习一般的目标函数存在什么样的算法？如果提供了充 足的训练数据，什么样的条件下会使特定的算法收敛到期望的函数？哪个算 法对哪些问题和表示的性能最好。</span></p><p class="s51" style="padding-top: 1pt;padding-left: 66pt;text-indent: -21pt;line-height: 14pt;text-align: justify;"> <span class="s24">多少训练数据是充足的？怎样找到学习到的假设的置信度与训练数据的数 量及提供给学习器的假设空间特性之间的一般关系？</span></p><p class="s51" style="padding-top: 1pt;padding-left: 66pt;text-indent: -21pt;line-height: 14pt;text-align: left;"> <span class="s24">学习器拥有的先验知识是怎样引导从样例进行泛化的过程的？当先验知识 仅仅是近似正确时，它们会有帮助吗？</span></p><p class="s51" style="padding-left: 66pt;text-indent: -21pt;line-height: 14pt;text-align: left;"> <span class="s24">对于选择有用的后续训练经验，什么样的策略最好？这个策略的选择会怎样 影响学习问题的复杂性？</span></p><p class="s51" style="padding-left: 66pt;text-indent: -21pt;line-height: 14pt;text-align: left;"> <span class="s24">怎样把学习任务简化为一个或多个函数逼近问题？换一种方式，系统该试图 学习哪些函数？这个过程本身能自动化吗？</span></p><p class="s51" style="padding-left: 45pt;text-indent: 0pt;line-height: 13pt;text-align: left;"> <span class="s24">学习器怎样自动地改变表示法来提高表示和学习目标函数的能力？</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 55pt;text-indent: 0pt;text-align: left;">1.4 <span class="s17">如何阅读本书</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 6pt;text-indent: 21pt;line-height: 113%;text-align: justify;">这本书介绍了机器学习的主要算法和途径；不同学习任务可行性和特定算法能力的理论 结果；以及机器学习应用于解决现实问题的例子。只要可能，各章的写作都力争与阅读顺序 无关。然而一些相互依赖性是不可避免的。如果本书被用作教科书，我建议首先完成第一和 第二章，余下各章基本可以以任意顺序阅读。长度为一个学期的机器学习课程可以包括前七 章以及额外的几个最感兴趣的章节。下面简要浏览一下各章。</p><p style="padding-top: 5pt;padding-left: 66pt;text-indent: -21pt;line-height: 14pt;text-align: justify;"><span class="s10"> </span>第 <span class="s6">2 </span>章包括基于符号和逻辑表示的概念学习。也讨论了假设的一般到特殊偏 序结构，以及学习中引入归纳偏置的必要性。</p><p style="padding-left: 66pt;text-indent: -21pt;line-height: 14pt;text-align: justify;"><span class="s10"> </span>第 <span class="s6">3 </span>章包括决策树学习和过度拟合训练数据的问题。这一章也剖析了奥坎姆 剃刀——该原则建议在与数据一致的假设中选择最短假设。</p><p style="padding-left: 66pt;text-indent: -21pt;line-height: 14pt;text-align: justify;"><span class="s10"> </span>第 <span class="s6">4 </span>章包括人工神经网络的知识，特别是研究已久的反向传播算法，以及梯 度下降的一般方法。这一章包含一个详细的基于神经网络的人脸识别实例，</p><p style="padding-left: 66pt;text-indent: 0pt;line-height: 12pt;text-align: left;">该例子需要的数据和算法可以在万维网上得到。</p><p style="padding-left: 66pt;text-indent: -21pt;text-align: justify;"><span class="s10"> </span>第 <span class="s6">5 </span>章给出了来自统计和估计理论的基础概念，着重于使用有限的样本数据 评估假设的精度。这一章包含了用于估计假设精度的置信空间，和对不同学 习算法的精度进行比较的方法。</p><p style="padding-left: 66pt;text-indent: -21pt;text-align: justify;"><span class="s10"> </span>第 <span class="s6">6 </span>章介绍机器学习的贝叶斯观点。既包括了使用贝叶斯分析刻画非贝叶斯 学习算法，又包括了直接处理概率的贝叶斯算法。这一章包括一个应用贝叶 斯分类器来分类文本文档的详细例子，所需的数据和软件可以在万维网上得 到。</p><p style="padding-left: 66pt;text-indent: -21pt;line-height: 94%;text-align: justify;"><span class="s10"> </span>第 <span class="s6">7 </span>章覆盖了计算学习理论，包括可能近似正确（<span class="s6">Probably Approximately Correct</span>，<span class="s6">PAC</span>）学习模型和出错界限（<span class="s6">Mistake-Bound</span>）学习模型。本章讨论 了联合多个学习方法的加权多数（<span class="s6">Weighted Majority</span>）算法。</p><p style="padding-left: 66pt;text-indent: -21pt;line-height: 14pt;text-align: justify;"><span class="s10"> </span>第 <span class="s6">8 </span>章描述了基于实例的学习方法，包括最近邻学习，局部加权回归，和基 于案例的推理。</p><p style="padding-left: 45pt;text-indent: 0pt;line-height: 13pt;text-align: left;"><span class="s10"> </span>第 <span class="s6">9 </span>章讨论了根据生物进化建模的学习算法，包括遗传算法和遗传编程。</p><p style="padding-left: 66pt;text-indent: -21pt;line-height: 14pt;text-align: left;"><span class="s10"> </span>第 <span class="s6">10 </span>章覆盖了一组学习规则集合的算法，包括学习一阶 <span class="s6">Horn </span>子句的归纳逻 辑编程方法。</p><p style="padding-left: 66pt;text-indent: -21pt;line-height: 14pt;text-align: left;"><span class="s10"> </span>第 <span class="s6">11 </span>章包含了基于解释的学习，即一种使用以前的知识解释观察到的实例， 然后根据这些解释泛化的学习方法。</p><p style="padding-left: 66pt;text-indent: -21pt;line-height: 14pt;text-align: left;"><span class="s10"> </span>第 <span class="s6">12 </span>章讨论了把以前的近似知识结合进现有的训练数据中以提高学习精度 的方法。在其中符号算法和神经网络算法都有讨论。</p><p style="padding-left: 66pt;text-indent: -21pt;line-height: 14pt;text-align: left;"><span class="s10"> </span>第 <span class="s6">13 </span>章讨论了增强学习。这种方法是为了处理来自训练信息中的间接的或 延迟的反馈。本章前面提及的下棋学习程序是增强学习的一个简单的例子。</p><p class="s6" style="padding-top: 6pt;padding-left: 5pt;text-indent: 21pt;line-height: 110%;text-align: justify;"><a href="http://www.cs.cmu.edu/%7Etom/mlbook.html" class="s223" target="_blank">每章的结尾包含了所覆盖的主要概念的小结、进一步阅读的参考和习题。其他对章节的 更新，包括数据集和算法的实现，都可从网址 </a>http://www.cs.cmu.edu/~tom/mlbook.html <span class="p">访问 到。</span></p><h2 style="padding-left: 55pt;text-indent: 0pt;line-height: 19pt;text-align: left;">1.5 <span class="s17">小结和补充读物</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 113%;text-align: left;">机器学习致力于研究建立能够根据经验自我提高处理性能的计算机程序。本章的要点包 括：</p><p style="padding-top: 4pt;padding-left: 66pt;text-indent: -21pt;text-align: justify;"><span class="s10"> </span>机器学习算法在很多应用领域被证明有很大的实用价值。它们在以下方面特 别有用：（<span class="s6">a</span>）数据挖掘问题，即从大量数据中发现可能包含在其中的有价 值的规律（例如，从患者数据库中分析治疗的结果，或者从财务数据中得到 信用贷款的普遍规则）；（<span class="s6">b</span>）在某些困难的领域中，人们可能还不具有开 发出高效的算法所需的知识（比如，从图像库中识别出人脸）；（<span class="s6">c</span>）计算 机程序必须动态地适应变化的领域（例如，在原料供给变化的环境下进行生 产过程控制，或适应个人阅读兴趣的变化）。</p><p class="s10" style="padding-top: 1pt;padding-left: 66pt;text-indent: -21pt;line-height: 14pt;text-align: left;"> <span class="p">机器学习从不同的学科吸收概念，包括人工智能，概率和统计，计算复杂性， 信息论，心理学和神经生物学、控制论、以及哲学。</span></p><p class="s10" style="padding-left: 66pt;text-indent: -21pt;line-height: 14pt;text-align: justify;"> <span class="p">一个完整定义的学习问题需要一个明确界定的任务、性能度量标准以及训练 经验的来源。</span></p><p class="s10" style="padding-left: 66pt;text-indent: -21pt;line-height: 14pt;text-align: justify;"> <span class="p">机器学习算法的设计过程中包含许多选择，包括选择训练经验的类型、要学 习的目标函数、该目标函数的表示形式、以及从训练样例中学习目标函数的</span></p><p style="padding-left: 66pt;text-indent: 0pt;line-height: 12pt;text-align: left;">算法。</p><p class="s10" style="padding-left: 66pt;text-indent: -21pt;text-align: justify;"> <span class="p">学习的过程即搜索的过程，搜索包含可能假设的空间，使得到的假设最符合 已有的训练样例和其他先验的约束或知识。本书的大部分内容围绕着搜索各 种假设空间（例如，包含数值函数、神经网络、决策树、符号规则的空间） 的不同学习方法，和理论上这些搜索方法在什么条件下会收敛到最佳假设。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 26pt;text-indent: 0pt;text-align: left;">有很多关于机器学习最新研究成果的优秀资源可供阅读。相关的杂志包括《机器学习》</p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 0pt;text-align: justify;">（<span class="s21">Machine Learning</span>），《神经计算》（<span class="s21">Neural Computation</span>），《神经网络》（<span class="s21">Neural Networks</span>），</p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 0pt;line-height: 107%;text-align: justify;">《美国统计协会期刊》（<span class="s21">Journal of the American Statistical Association</span>）和《<span class="s6">IEEE </span>模式识别和 机器智能学报》（<span class="s21">IEEE Transactions on Pattern Analysis and Machine Intelligence</span>）。也有大量 的年会覆盖了机器学习的各个方面，包括国际机器学习会议<span class="s6">(ICML)</span>，神经信息处理系统 <span class="s6">(NIPS)</span>，计算学习理论会议<span class="s6">(CCLT)</span>，国际遗传算法会议<span class="s6">(ICGA)</span>，国际知识发现和数据挖掘 会议<span class="s6">(ICKDD)</span>，欧洲机器学习会议<span class="s6">(ECML)</span>等。</p><p style="padding-left: 27pt;text-indent: 0pt;text-align: left;">习题</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 6pt;text-indent: 21pt;line-height: 107%;text-align: left;">1.1 <span class="p">给出三种机器学习方法适合的应用，三种不适合的应用。挑选本书未提及的应用， 并对每个应用以一句话来评价。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 6pt;text-indent: 21pt;line-height: 110%;text-align: left;">1.2 <span class="p">挑选一些本书未提到的学习任务。用英文写一段话非正式地加以描述。再尽可能精 确地描述出它的任务、性能衡量标准和训练经验。最后，给出要学习的目标函数和它的表示。 讨论这个任务设计中考虑的主要折中。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;text-align: left;"><span class="s6">1.3 </span>证明本章描述的<span class="s6">LMS</span>权更新法则采用了梯度下降方法使误差平方最小化。确切地 讲，像文中那样定义方差<span class="s21">E</span>。然后计算<span class="s21">E</span>对权<span class="s21">w</span><span class="s36">i</span>的导数，其中假定<span class="s30">V</span><span class="s31">ˆ</span><span class="s33"> (</span><span class="s30">b</span><span class="s33">) </span>与文中定义的一样，</p><p class="s38" style="padding-top: 1pt;padding-left: 24pt;text-indent: 0pt;line-height: 10pt;text-align: center;"><span class="s30">E</span></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 12pt;text-align: left;">是一个线性函数。梯度下降是通过与 <span class="s38"></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="25" height="1" alt="image" src="机器学习/Image_014.png"/></span></p><p class="s38" style="padding-left: 1pt;text-indent: 0pt;text-align: left;"><span class="s30">w</span><span class="s52">i</span></p><p style="text-indent: 0pt;line-height: 11pt;text-align: left;">成比例地更新每个权值实现的。所以，必须证明</p><p style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">对于所遇到的每一个训练样例，<span class="s6">LMS</span>训练法则都是按这个比例来改变权值。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-top: 1pt;padding-left: 6pt;text-indent: 21pt;line-height: 107%;text-align: justify;">1.4 <span class="p">图 </span>1-1 <span class="p">中实验生成器模块可采用其他一些策略。确切地讲，考虑实验生成器用下面 的策略提出新的棋局：</span></p><p class="s10" style="padding-top: 5pt;padding-left: 45pt;text-indent: 0pt;line-height: 14pt;text-align: left;"> <span class="p">产生随机的合法的棋局</span></p><p class="s10" style="padding-left: 45pt;text-indent: 0pt;line-height: 14pt;text-align: left;"> <span class="p">从前面的对弈中挑选一个棋局，然后走一步上次没有走的棋而产生新的棋局</span></p><p class="s10" style="padding-left: 27pt;text-indent: 18pt;line-height: 148%;text-align: left;"> <span class="p">一种你自己设计的策略 讨论这些策略的优劣。如果训练样例的数量是固定的，哪一个效果最好？假定性能衡量</span></p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 11pt;text-align: left;">标准是在世界锦标赛上赢棋最多。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 107%;text-align: justify;"><span class="s6">1.5 </span>使用类似于西洋跳棋问题的算法，实现一个更简单的<span class="s6">tic-tac-toe</span>游戏<span class="s9">①</span>。把学习到的 函数<span class="s30">V</span><span class="s31">ˆ </span>表示为自选的棋局参数的线性组合。要训练这个程序，可以让它和它的另一个拷贝 反复比赛，后者使用手工建立的固定评估函数。用图表绘出你的程序胜利的百分比，对应于 训练次数。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">参考文献</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 26pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="193" height="1" alt="image" src="机器学习/Image_015.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-top: 2pt;padding-left: 7pt;text-indent: 0pt;text-align: left;"><span class="s13">① </span>译注：该游戏棋盘为 <span class="s16">3X3 </span>方格，双方交互落子，首先实现自方三子连一线者胜。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s8" style="padding-left: 87pt;text-indent: 0pt;line-height: 24pt;text-align: left;">第<span class="h1">2</span>章 概念学习和一般到特殊序</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 53pt;text-indent: 21pt;line-height: 113%;text-align: justify;">从特殊的训练样例中归纳出一般函数是机器学习的中心问题。本章介绍概念学 习：给定某一类别的若干正例和反例，从中获得该类别的一般定义。概念学习也可 被看作一个搜索问题，它在预定义的假设空间中搜索假设，使其与训练样例有最佳 的拟合度。多数情形下，为了高效的搜索，可以利用假设空间中一种自然形成的结 构——即一般到特殊偏序结构。本章展示了几种概念学习算法，并讨论了这些算法 能收敛得到正确假设的条件。这里还分析了归纳学习的本质，以及任意程序能从训 练数据中泛化的理由。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 11pt;text-indent: 0pt;text-align: left;">2.1 <span class="s17">介绍</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 11pt;text-indent: 21pt;line-height: 113%;text-align: left;">许多机器学习问题涉及到从特殊训练样例中得到一般概念。比如人们不断学习的一些一 般概念和类别包括：鸟类、汽车、勤奋的学习等。每个概念可被看作一个对象或事件集合， 它是从更大的集合中选取的子集（如从动物的集合中选取鸟类），或者是在这个较大集合中 定义的布尔函数（如在动物集合中定义的函数，它对鸟类产生 <span class="s21">true </span>并对其他动物产生 <span class="s21">false</span>）。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;line-height: 110%;text-align: justify;">本章考虑的问题是，给定一样例集合以及每个样例是否属于某一概念的标注，怎样自动 推断出该概念的一般定义。这一问题被称为概念学习（<span class="s6">concept learning</span>），或称从样例中逼 近布尔值函数。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 52pt;text-indent: -21pt;line-height: 113%;text-align: left;">定义： 概念学习是指从有关某个布尔函数的输入输出训练样例中，推断出该布尔函 数。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 11pt;text-indent: 0pt;text-align: left;">2.2 <span class="s17">一个概念学习任务</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;line-height: 107%;text-align: justify;">为了良好地理解概念学习，考虑一个概念学习的例子，目标概念是：“<span class="s6">Aldo </span>进行水上运 动的日子”。表 <span class="s6">2-1 </span>描述了一系列日子的样例，每个样例表示为属性的集合。属性 <span class="s21">EnjoySport </span>表示这一天 <span class="s6">Aldo </span>是否乐于进行水上运动。这个任务的目的是，基于某天的各属性，以预测 出该天 <span class="s21">EnjoySport </span>的值。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 134pt;text-indent: 0pt;text-align: left;">表 <span class="h4">2-1 </span>目标概念 <span class="s7">EnjoySport </span>的正例和反例</p><p style="text-indent: 0pt;text-align: left;"><br/></p><table style="border-collapse:collapse;margin-left:5.60001pt" cellspacing="0"><tr style="height:16pt"><td style="width:55pt;border-top-style:solid;border-top-width:2pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s53" style="padding-top: 1pt;padding-left: 10pt;text-indent: 0pt;text-align: left;">Example</p></td><td style="width:49pt;border-top-style:solid;border-top-width:2pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s54" style="padding-top: 1pt;text-indent: 0pt;text-align: center;">Sky</p></td><td style="width:55pt;border-top-style:solid;border-top-width:2pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s54" style="padding-top: 1pt;padding-left: 13pt;text-indent: 0pt;text-align: left;">AirTemp</p></td><td style="width:56pt;border-top-style:solid;border-top-width:2pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s54" style="padding-top: 1pt;padding-left: 10pt;text-indent: 0pt;text-align: left;">Humidity</p></td><td style="width:52pt;border-top-style:solid;border-top-width:2pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s54" style="padding-top: 1pt;padding-left: 14pt;text-indent: 0pt;text-align: left;">Wind</p></td><td style="width:48pt;border-top-style:solid;border-top-width:2pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s54" style="padding-top: 1pt;padding-left: 15pt;text-indent: 0pt;text-align: left;">Water</p></td><td style="width:52pt;border-top-style:solid;border-top-width:2pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s54" style="padding-top: 1pt;padding-left: 11pt;text-indent: 0pt;text-align: left;">Forecast</p></td><td style="width:59pt;border-top-style:solid;border-top-width:2pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s54" style="padding-top: 1pt;padding-left: 8pt;text-indent: 0pt;text-align: left;">EnjoySport</p></td></tr><tr style="height:16pt"><td style="width:55pt;border-top-style:solid;border-top-width:1pt"><p class="s53" style="padding-top: 1pt;padding-right: 2pt;text-indent: 0pt;text-align: center;">1</p></td><td style="width:49pt;border-top-style:solid;border-top-width:1pt"><p class="s53" style="padding-top: 1pt;padding-left: 12pt;text-indent: 0pt;text-align: left;">Sunny</p></td><td style="width:55pt;border-top-style:solid;border-top-width:1pt"><p class="s53" style="padding-top: 1pt;padding-left: 17pt;text-indent: 0pt;text-align: left;">Warm</p></td><td style="width:56pt;border-top-style:solid;border-top-width:1pt"><p class="s53" style="padding-top: 1pt;padding-left: 13pt;text-indent: 0pt;text-align: left;">Normal</p></td><td style="width:52pt;border-top-style:solid;border-top-width:1pt"><p class="s53" style="padding-top: 1pt;padding-left: 12pt;text-indent: 0pt;text-align: left;">Strong</p></td><td style="width:48pt;border-top-style:solid;border-top-width:1pt"><p class="s53" style="padding-top: 1pt;padding-left: 14pt;text-indent: 0pt;text-align: left;">Warm</p></td><td style="width:52pt;border-top-style:solid;border-top-width:1pt"><p class="s53" style="padding-top: 1pt;padding-left: 17pt;text-indent: 0pt;text-align: left;">Same</p></td><td style="width:59pt;border-top-style:solid;border-top-width:1pt"><p class="s53" style="padding-top: 1pt;padding-right: 1pt;text-indent: 0pt;text-align: center;">Yes</p></td></tr><tr style="height:15pt"><td style="width:55pt"><p class="s53" style="padding-top: 1pt;padding-right: 2pt;text-indent: 0pt;text-align: center;">2</p></td><td style="width:49pt"><p class="s53" style="padding-top: 1pt;padding-left: 12pt;text-indent: 0pt;text-align: left;">Sunny</p></td><td style="width:55pt"><p class="s53" style="padding-top: 1pt;padding-left: 17pt;text-indent: 0pt;text-align: left;">Warm</p></td><td style="width:56pt"><p class="s53" style="padding-top: 1pt;padding-left: 18pt;text-indent: 0pt;text-align: left;">High</p></td><td style="width:52pt"><p class="s53" style="padding-top: 1pt;padding-left: 12pt;text-indent: 0pt;text-align: left;">Strong</p></td><td style="width:48pt"><p class="s53" style="padding-top: 1pt;padding-left: 14pt;text-indent: 0pt;text-align: left;">Warm</p></td><td style="width:52pt"><p class="s53" style="padding-top: 1pt;padding-left: 17pt;text-indent: 0pt;text-align: left;">Same</p></td><td style="width:59pt"><p class="s53" style="padding-top: 1pt;padding-right: 1pt;text-indent: 0pt;text-align: center;">Yes</p></td></tr><tr style="height:15pt"><td style="width:55pt"><p class="s53" style="padding-top: 1pt;padding-right: 2pt;text-indent: 0pt;text-align: center;">3</p></td><td style="width:49pt"><p class="s53" style="padding-top: 1pt;padding-left: 13pt;text-indent: 0pt;text-align: left;">Rainy</p></td><td style="width:55pt"><p class="s53" style="padding-top: 1pt;padding-left: 19pt;text-indent: 0pt;text-align: left;">Cold</p></td><td style="width:56pt"><p class="s53" style="padding-top: 1pt;padding-left: 18pt;text-indent: 0pt;text-align: left;">High</p></td><td style="width:52pt"><p class="s53" style="padding-top: 1pt;padding-left: 12pt;text-indent: 0pt;text-align: left;">Strong</p></td><td style="width:48pt"><p class="s53" style="padding-top: 1pt;padding-left: 15pt;text-indent: 0pt;text-align: left;">Warm</p></td><td style="width:52pt"><p class="s53" style="padding-top: 1pt;padding-left: 13pt;text-indent: 0pt;text-align: left;">Change</p></td><td style="width:59pt"><p class="s53" style="padding-top: 1pt;padding-right: 1pt;text-indent: 0pt;text-align: center;">No</p></td></tr><tr style="height:15pt"><td style="width:55pt;border-bottom-style:solid;border-bottom-width:2pt"><p class="s53" style="padding-top: 1pt;padding-right: 2pt;text-indent: 0pt;text-align: center;">4</p></td><td style="width:49pt;border-bottom-style:solid;border-bottom-width:2pt"><p class="s53" style="padding-top: 1pt;padding-left: 12pt;text-indent: 0pt;text-align: left;">Sunny</p></td><td style="width:55pt;border-bottom-style:solid;border-bottom-width:2pt"><p class="s53" style="padding-top: 1pt;padding-left: 17pt;text-indent: 0pt;text-align: left;">Warm</p></td><td style="width:56pt;border-bottom-style:solid;border-bottom-width:2pt"><p class="s53" style="padding-top: 1pt;padding-left: 18pt;text-indent: 0pt;text-align: left;">High</p></td><td style="width:52pt;border-bottom-style:solid;border-bottom-width:2pt"><p class="s53" style="padding-top: 1pt;padding-left: 12pt;text-indent: 0pt;text-align: left;">Strong</p></td><td style="width:48pt;border-bottom-style:solid;border-bottom-width:2pt"><p class="s53" style="padding-top: 1pt;padding-left: 17pt;text-indent: 0pt;text-align: left;">Cool</p></td><td style="width:52pt;border-bottom-style:solid;border-bottom-width:2pt"><p class="s53" style="padding-top: 1pt;padding-left: 13pt;text-indent: 0pt;text-align: left;">Change</p></td><td style="width:59pt;border-bottom-style:solid;border-bottom-width:2pt"><p class="s53" style="padding-top: 1pt;padding-right: 1pt;text-indent: 0pt;text-align: center;">Yes</p></td></tr></table><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 11pt;text-indent: 21pt;line-height: 110%;text-align: justify;">在这种情况下，采取什么样的形式来表示假设呢？可以先考虑一个较为简单的形式，即 实例的各属性约束的合取式。在这里，可令每个假设为 <span class="s6">6 </span>个约束的向量，这些约束指定了属 性 <span class="s21">Sky</span>、<span class="s21">AirTemp</span>、<span class="s21">Humidity</span>、<span class="s21">Wind</span>、<span class="s21">Water </span>和 <span class="s21">Forecast </span>的值。每个属性可取值为：</p><p style="padding-top: 3pt;padding-left: 33pt;text-indent: 0pt;text-align: left;"><span class="s34">• </span>由“<span class="s6">?</span>”表示任意值</p><p class="s21" style="padding-left: 34pt;text-indent: 0pt;line-height: 14pt;text-align: left;"><span class="s34">• </span><span class="p">明确指定的属性值（如 </span>AirTemp<span class="s6">=</span>Warm<span class="p">）</span></p><p style="padding-left: 34pt;text-indent: 0pt;line-height: 14pt;text-align: left;"><span class="s34">• </span>由“<span class="s10"></span>”表示不接受任何值</p><p style="padding-top: 7pt;padding-left: 12pt;text-indent: 21pt;line-height: 107%;text-align: justify;">如果某些实例 <span class="s21">x </span>满足假设 <span class="s21">h </span>的所有约束，那么 <span class="s21">h </span>将 <span class="s21">x </span>分类为正例，（<span class="s21">h</span><span class="s6">(</span><span class="s21">x</span><span class="s6">)=1 </span>）。比如， 为判定 <span class="s6">Aldo </span>只在寒冷和潮湿的日子里进行水上运动（并与其他属性无关），这样的假设可表 示为下面的表达式：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 31pt;text-indent: 0pt;text-align: center;">&lt;?, <i>Cold</i>, <i>High</i>, ?, ?, ?&gt;</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 33pt;text-indent: 0pt;text-align: left;">最一般的假设是每一天都是正例，可表示为：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 31pt;text-indent: 0pt;text-align: center;">&lt;?, ?, ?, ?, ?, ?&gt;</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 33pt;text-indent: 0pt;text-align: left;">而最特殊的假设即每一天都是反例，表示为：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 31pt;text-indent: 0pt;text-align: center;">&lt;<span class="s10"></span>, <span class="s10"></span>, <span class="s10"></span>, <span class="s10"></span>, <span class="s10"></span>, <span class="s10"> </span>&gt;</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 12pt;text-indent: 21pt;line-height: 111%;text-align: justify;">综上所述，<span class="s21">EnjoySport </span>这个概念学习任务需要学习的是使 <span class="s21">EnjoySport</span><span class="s6">=</span><span class="s21">Yes </span>的日子，并将 其表示为属性约束的合取式。一般说来，任何概念学习任务能被描述为：实例的集合、实例 集合上的目标函数、候选假设的集合以及训练样例的集合。以这种一般形式定义的 <span class="s21">EnjoySport </span>概念学习任务见表 <span class="s6">2-2</span>。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 31pt;text-indent: 0pt;text-align: center;">表 <span class="h4">2-2 </span><span class="s7">EnjoySport </span>概念学习任务</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 2pt;text-align: left;"><span><img width="570" height="2" alt="image" src="机器学习/Image_016.png"/></span></p><p class="s55" style="padding-left: 12pt;text-indent: 0pt;text-align: left;">n <span class="s14">已知：</span></p><p class="s14" style="padding-top: 3pt;padding-left: 30pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span>实例集 <span class="s56">X</span>：可能的日子，每个日子由下面的属性描述：</p><p class="s56" style="padding-top: 3pt;padding-left: 48pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span>Sky<span class="s14">（可取值为 </span>Sunny<span class="s14">，</span>Cloudy <span class="s14">和 </span>Rainy<span class="s14">）</span></p><p class="s56" style="padding-top: 3pt;padding-left: 48pt;text-indent: 0pt;line-height: 126%;text-align: left;"><span class="s55">n </span>AirTemp<span class="s14">（可取值为 </span>Warm <span class="s14">和 </span>Cold<span class="s14">） </span><span class="s55">n </span>Humidity<span class="s14">（可取值为 </span>Normal <span class="s14">和 </span>High<span class="s14">） </span><span class="s55">n </span>Wind<span class="s14">（可取值为 </span>Strong <span class="s14">和 </span>Weak<span class="s14">）</span></p><p class="s56" style="padding-left: 48pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span>Water<span class="s14">（可取值为 </span>Warm <span class="s14">和 </span>Cool<span class="s14">）</span></p><p class="s56" style="padding-top: 3pt;padding-left: 48pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span>Forecast<span class="s14">（可取值为 </span>Same <span class="s14">和 </span>Change<span class="s14">）</span></p><p class="s14" style="padding-top: 4pt;padding-left: 33pt;text-indent: -3pt;line-height: 12pt;text-align: left;"><span class="s55">n </span>假设集 <span class="s56">H</span>：每个假设描述为 <span class="s16">6 </span>个属性 <span class="s56">Sky</span>，<span class="s56">AirTemp</span>，<span class="s56">Humidity</span>，<span class="s56">Wind</span>，<span class="s56">Water </span>和 <span class="s56">Forecast </span>的值约 束的合取。约束可以为“<span class="s16">?</span>”（表示接受任意值），“<span class="s57"></span>”（表示拒绝所有值），或一特定值。</p><p class="s56" style="padding-top: 2pt;padding-left: 30pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span><span class="s14">目标概念 </span>c<span class="s16">: </span>EnjoySport<span class="s16">: </span>X<span class="s14">→</span><span class="s16">{0, 1}</span></p><p class="s14" style="padding-top: 3pt;padding-left: 30pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span>训练样例集 <span class="s56">D</span>：目标函数的正例和反例（见表 <span class="s16">2-1</span>）</p><p class="s55" style="padding-top: 3pt;padding-left: 12pt;text-indent: 0pt;text-align: left;">n <span class="s14">求解：</span></p><p class="s56" style="padding-top: 3pt;padding-left: 30pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span>H <span class="s14">中的一假设 </span>h<span class="s14">，使对于 </span>X <span class="s14">中任意 </span>x<span class="s14">，</span>h<span class="s16">(</span>x<span class="s16">)=</span>c<span class="s16">(</span>x<span class="s16">)</span><span class="s14">。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 2pt;text-align: left;"><span><img width="570" height="2" alt="image" src="机器学习/Image_017.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 12pt;text-indent: 0pt;text-align: left;">2.2.1 <span class="s25">术语定义</span></h3><p class="s21" style="padding-top: 10pt;padding-left: 11pt;text-indent: 21pt;line-height: 107%;text-align: left;"><span class="p">在本书中，我们使用以下的术语来讨论概念学习问题。概念定义在一个实例（</span><span class="s6">instance</span><span class="p">） 集合之上，这个集合表示为 </span>X<span class="p">。在本例中，</span>X <span class="p">是所有可能的日子，每个日子由 </span>Sky<span class="p">、</span>AirTemp<span class="p">、 </span>Humidity<span class="p">、</span>Wind<span class="p">、</span>Water <span class="p">和 </span>Forecast <span class="p">六个属性表示。待学习的概念或函数称为目标概念 </span><span class="s6">(target concept)</span><span class="p">，记作 </span>c<span class="p">。一般来说，</span>c <span class="p">可以是定义在实例 </span>X <span class="p">上的任意布尔函数，即 </span>c<span class="s6">:</span>X<span class="p">→</span><span class="s6">{0, 1}</span><span class="p">。在 这个例子里，目标概念对应于属性 </span>EnjoySport <span class="p">的值，当 </span>EnjoySport<span class="s6">=</span>Yes <span class="p">时 </span>c<span class="s6">(</span>x<span class="s6">)=1</span><span class="p">，当 </span>EnjoySport<span class="s6">=</span>No <span class="p">时 </span>c<span class="s6">(</span>x<span class="s6">)=0</span><span class="p">。</span></p><p class="s6" style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: left;"><span class="p">在学习目标概念时，必须提供一套训练样例（</span>training examples<span class="p">），每个样例为 </span><i>X </i><span class="p">中的一 个实例 </span><i>x </i><span class="p">以及它的目标概念值 </span><i>c</i>(<i>x</i>)<span class="p">（如表 </span>2-1 <span class="p">中的训练样例）。对于 </span><i>c</i>(<i>x</i>)=1 <span class="p">的实例被称为正 例</span>(positive example)<span class="p">，或称为目标概念的成员。对于 </span><i>c</i>(<i>x</i>)=0 <span class="p">的实例为反例</span>(negative example)<span class="p">， 或称为非目标概念成员。经常可以用序偶</span>&lt;<i>x</i>,<i>c</i>(<i>x</i>)&gt;<span class="p">来描述训练样例，表示其包含了实例 </span><i>x </i><span class="p">和 目标概念值 </span><i>c</i>(<i>x</i>)<span class="p">。符号 </span><i>D </i><span class="p">用来表示训练样例的集合。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;"><span class="p">一旦给定目标概念 </span>c <span class="p">的训练样例集，学习器面临的问题就是假设或估计 </span>c<span class="p">。使用符号 </span>H <span class="p">来表示所有可能假设</span><span class="s6">(all possible hypotheses)</span><span class="p">的集合，这个集合内才是为确定目标概念所考虑 的范围。通常 </span>H <span class="p">依设计者所选择的假设表示而定。</span>H <span class="p">中每个的假设 </span>h <span class="p">表示 </span>X <span class="p">上定义的布尔 函数，即 </span>h<span class="s6">:</span>X<span class="p">→</span><span class="s6">{0,1}</span><span class="p">。机器学习的目标就是寻找一个假设 </span>h<span class="p">，使对于 </span>X <span class="p">中的所有 </span>x<span class="p">，</span>h<span class="s6">(</span>x<span class="s6">)=</span>c<span class="s6">(</span>x<span class="s6">)</span><span class="p">。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">2.2.2 <span class="s25">归纳学习假设</span></h3><p style="padding-top: 10pt;padding-left: 5pt;text-indent: 21pt;line-height: 110%;text-align: justify;">机器学习的任务是在整个实例集合 <span class="s21">X </span>上确定与目标概念 <span class="s21">c </span>相同的假设 <span class="s21">h</span>，然而我们对于 <span class="s21">c </span>仅有的信息只是它在训练样例上的值。因此，归纳学习算法最多只能保证输出的假设能与 训练样例相拟合。如果没有更多的信息，我们只能假定，<span style=" color: #00F;">对于未见实例最好的假设就是与训 练数据最佳拟合的假设。这是归纳学习的一个基本假定</span>，本书中将对此做更多的阐述。这里 我们简单提及，在第 <span class="s6">5</span>、<span class="s6">6</span>、<span class="s6">7 </span>章将更形式化和定量地审定和分析这一假定。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s24" style="padding-left: 26pt;text-indent: 0pt;line-height: 113%;text-align: left;">归纳学习假设 任一假设如果在足够大的训练样例集中很好地逼近目标函数，它也能在 未见实例中很好地逼近目标函数<span style=" color: #000;">。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">2.3 <span class="s17">作为搜索的概念学习</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 109%;text-align: left;">概念学习可以看作是一个搜索的过程，范围是假设的表示所隐含定义的整个空间。搜索 的目标是为了寻找能最好地拟合训练样例的假设。必须注意到，当假设的表示形式选定后， 那么也就隐含地为学习算法确定了所有假设的空间。这些假设是学习程序所能表示的，也是 它能够学习的。考虑在 <span class="s21">EnjoySport </span>学习任务中的实例集合 <span class="s21">X </span>和假设集合 <span class="s21">H</span>。如果属性 <span class="s21">Sky </span>有 <span class="s6">3 </span>种可能的值，而 <span class="s21">AirTemp</span>、<span class="s21">Humidity</span>、<span class="s21">Wind</span>、<span class="s21">Water </span>和 <span class="s21">Forecast </span>都只有两种可能值，则 实例空间 <span class="s21">X </span>包含了 <span class="s6">3×2×2×2×2×2=96 </span>种不同的实例。类似的计算可得，在假设空间 <span class="s21">H </span>中有 <span class="s6">5×4×4×4×4×4=5120 </span>种语法不同<span class="s6">(syntactically distinct)</span>的假设。然而，注意到包含有<span class="s10"></span>符号的 假设代表空实例集合，即它们将每个实例都分类为反例。因此，语义不同<span class="s6">(semantically distinct) </span>的假设只有 <span class="s6">1+4×3×3×3×3×3=973 </span>个。这里的 <span class="s6">EnjoySport </span>例子是一个非常简单的学习任务， 它的假设空间相对较小且有限。多数实际的学习任务包含更大的、有时是无限的假设空间。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 113%;text-align: justify;">如果把学习看作是一个搜索问题，那么很自然，对学习算法的研究需要考查假设空间搜 索的不同策略。特别引起我们兴趣的算法应能有效地搜索非常大的或无限的假设空间，以找 到最佳拟合训练数据的假设。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">2.3.1 <span class="s25">假设的一般到特殊序</span></h3><p style="padding-top: 10pt;padding-left: 6pt;text-indent: 21pt;line-height: 113%;text-align: justify;">许多概念学习算法中，搜索假设空间的方法依赖于其中一种很有用的结构：假设的一般 到特殊序关系。利用假设空间的这种自然结构，我们可以在无限的假设空间中进行彻底的搜 索，而不需要明确地列举所有的假设。为说明一般到特殊序，考虑以下两个假设：</p><p class="s21" style="padding-top: 2pt;padding-left: 24pt;text-indent: 0pt;text-align: center;">h<span class="s35">1</span><span class="s6">=&lt;</span>Sunny<span class="s6">, ?, ?, </span>Strong<span class="s6">, ?, ?&gt;</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 24pt;text-indent: 0pt;text-align: center;">h<span class="s35">2</span><span class="s6">=&lt;</span>Sunny<span class="s6">, ?, ?, ?, ?, ?&gt;</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 20pt;text-align: justify;">哪些实例可被<span class="s21">h</span><span class="s35">1</span>和<span class="s21">h</span><span class="s35">2</span>划分为正例？由于<span class="s21">h</span><span class="s35">2</span>包含的实例约束较少，它划分出的正例也较多。 实际上，任何被<span class="s21">h</span><span class="s35">1</span>划分为正例的实例都会被<span class="s21">h</span><span class="s35">2</span>划分为正例，因此，我们说<span class="s21">h</span><span class="s35">2</span>比<span class="s21">h</span><span class="s35">1</span>更一般。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 5pt;text-indent: 21pt;line-height: 106%;text-align: justify;"><span class="p">直观上的“比 更一般”这种关系可以如下精确定义。首先，对</span>X<span class="p">中任意实例</span>x<span class="p">和</span>H<span class="p">中 任意假设 </span>h <span class="p">，我们说 </span>x <span class="p">满足 </span>h <span class="p">当且仅当 </span>h<span class="s6">(</span>x<span class="s6">)=1 </span><span class="p">。现在以 实例集合 的形式定 义一个 </span><b>more</b><b>-</b><b>general</b><b>-</b><b>than</b><b>-</b><b>or</b><b>-</b><b>equal</b><b>-</b><b>to</b><span class="p">的关系：给定假设</span>h<span class="s36">j</span><span class="p">和</span>h<span class="s36">k</span><span class="p">，</span>h<span class="s36">j</span><span class="s41"> </span>more<span class="s6">-</span>general<span class="s6">-</span>than<span class="s6">-</span>or<span class="s6">-</span>equal<span class="s6">-</span>to h<span class="s36">k</span><span class="p">， 当且仅当任意一个满足</span>h<span class="s36">k</span><span class="p">的实例同时也满足</span>h<span class="s36">j</span><span class="p">。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s24" style="padding-left: 47pt;text-indent: -21pt;text-align: left;">定义： 令<span class="s58">h</span><span class="s59">j</span>和<span class="s58">h</span><span class="s59">k</span>为在<span class="s58">X</span>上定义的布尔函数。定义一个<span class="s60">more</span><span class="s61">-</span><span class="s60">general</span><span class="s61">-</span><span class="s60">than</span><span class="s61">-</span><span class="s60">or</span><span class="s61">-</span><span class="s60">equal</span><span class="s61">-</span><span class="s60">to</span>关 系，记做≥<span class="s59">g</span>。称<span class="s58">h</span><span class="s59">j</span>≥<span class="s59">g</span><span class="s62"> </span><span class="s58">h</span><span class="s59">k</span>当且仅当</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s63" style="padding-left: 24pt;text-indent: 0pt;text-align: center;">(<span class="s51"></span><i>x</i><span class="s24">∈</span><i>X</i>)[(<i>h</i><span class="s59">k</span>(<i>x</i>)=1)<span class="s24">→</span>(<i>h</i><span class="s59">j</span>(<i>x</i>)=1)]</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s36" style="padding-left: 5pt;text-indent: 21pt;text-align: justify;"><span class="p">有必要 考虑 一假设 严格 地比另 一假 设更一 般的 情形。 因此 ，我们 说 </span><span class="s21">h</span>j<span class="s41"> </span><span class="p">严格的 </span><span class="s7">more</span><span class="h4">-</span><span class="s7">general</span><span class="h4">-</span><span class="s7">than </span><span class="s21">h</span>k<span class="p">（写作</span><span class="s21">h</span>j<span class="p">＞</span>g<span class="s21">h</span>k<span class="p">），当且仅当</span><span class="s6">(</span><span class="s21">h</span>j<span class="p">≥</span>g<span class="s21">h</span>k<span class="s6">)</span><span class="p">∧</span><span class="s10"></span><span class="s6">(</span><span class="s21">h</span>k<span class="p">≥</span>g<span class="s21">h</span>j<span class="s6">)</span><span class="p">。最后，还可以定义逆向 的关系“比 更特殊”为</span><span class="s21">h</span>j<span class="s41"> </span><span class="s7">more</span><span class="h4">-</span><span class="s7">specific</span><span class="h4">-</span><span class="s7">than </span><span class="s21">h</span>k<span class="p">，当</span><span class="s21">h</span>k<span class="s41"> </span><span class="s21">more</span><span class="s6">-</span><span class="s21">general</span><span class="s6">-</span><span class="s21">than h</span>j<span class="p">。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 13pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="547" height="1" alt="image" src="机器学习/Image_018.png"/></span></p><p class="s48" style="padding-left: 15pt;text-indent: 0pt;text-align: left;">插图——原书页码： <span class="s21">25</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;line-height: 190%;text-align: left;">Instances: <span class="p">实例集 </span>Hypotheses<span class="p">：假设集 </span>Specific<span class="p">：特殊 </span>General<span class="p">：一般</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 14pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="531" height="1" alt="image" src="机器学习/Image_019.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><h4 style="padding-top: 1pt;padding-left: 37pt;text-indent: 85pt;text-align: left;"><span class="p">图 </span>2-1 <span class="p">实例、假设和 </span><i>more</i>-<i>general</i>-<i>than </i><span class="p">关系</span></h4><p class="s56" style="padding-top: 6pt;padding-left: 37pt;text-indent: 0pt;line-height: 12pt;text-align: justify;"><span class="s14">左边的方框代表所有实例的集合</span>X<span class="s14">，右边的方框代表所有假设集合</span>H<span class="s14">。右边的每个假设对应左边</span>X<span class="s14">中 某个子集——即被此假设划分为正例的集合。连接假设的箭头代表</span>more<span class="s16">-</span>general<span class="s16">-</span>than<span class="s14">关系。箭头所 指为较特殊的假设。注意到</span>h<span class="s64">2</span><span class="s14">对应的实例子集包含了</span>h<span class="s64">1</span><span class="s14">对应的实例子集，因此</span>h<span class="s64">2 </span>more<span class="s16">-</span>general<span class="s16">-</span>than h<span class="s64">1</span><span class="s14">。</span></p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 21pt;text-align: left;">为说明这些定义，考虑<span class="s21">EnjoySport</span>例子中的<span class="s21">h</span><span class="s35">1</span>、<span class="s21">h</span><span class="s35">2</span>、<span class="s21">h</span><span class="s35">3</span>，如图 <span class="s6">2-1 </span>所示。这三个假设是如 何由≥<span class="s36">g</span>关系相关联起来的？如前所述，<span class="s21">h</span><span class="s35">2</span>比<span class="s21">h</span><span class="s35">1</span>更一般是因为每个满足<span class="s21">h</span><span class="s35">1</span>的实例都满足<span class="s21">h</span><span class="s35">2</span>。相 似的，<span class="s21">h</span><span class="s35">2</span>也比<span class="s21">h</span><span class="s35">3</span>更一般。注意<span class="s21">h</span><span class="s35">1</span>和<span class="s21">h</span><span class="s35">3</span>之间相互之间不存在≥<span class="s36">g</span>关系，虽然满足这两个假设的实 例有交叠，但没有一个集合完全包含另一个集合。注意≥<span class="s36">g</span>和＞<span class="s36">g</span>关系的定义独立于目标概念。 它们只依赖于满足这两个假设的实例，而与哪些实例满足目标概念无关。用形式化的语言来 说，≥<span class="s36">g</span>关系定义了假设空间<span class="s21">H</span>上的一个偏序（即这个关系是自反、反对称和传递的）。偏序 关系的含义（对应于全序）是，可能存在<span class="s21">h</span><span class="s35">1</span>和<span class="s21">h</span><span class="s35">3</span>这样的假设对，<span class="s10"> </span><span class="s6">(</span><span class="s21">h</span><span class="s35">1</span>≥<span class="s36">g</span><span class="s21">h</span><span class="s35">3</span><span class="s6">)</span>而且<span class="s10"> </span><span class="s6">(</span><span class="s21">h</span><span class="s35">3</span>≥<span class="s36">g</span><span class="s21">h</span><span class="s35">1</span><span class="s6">)</span>。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 20pt;text-align: left;">≥<span class="s36">g</span>关系很重要，因为它在假设空间<span class="s21">H</span>上对任意概念学习问题提供了一种有用的结构。 后面的章节将阐述概念学习算法如何利用这一偏序结构，以有效地搜索假设空间。</p><h2 style="padding-left: 12pt;text-indent: 0pt;line-height: 19pt;text-align: left;">2.4 Find-S<span class="s17">：寻找极大特殊假设</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 11pt;text-indent: 21pt;line-height: 110%;text-align: justify;">如何使用 <span class="s21">more</span><span class="s6">-</span><span class="s21">general</span><span class="s6">-</span><span class="s21">than </span>偏序来搜索与训练样例相一致的假设？一种办法是从 <span class="s21">H </span>中 最特殊假设开始，然后在该假设覆盖正例失败时将其一般化（当一假设能正确地划分一个正 例时，称该假设“覆盖”该正例）。使用偏序实现的 <span class="s6">Find-S </span>算法的精确描述见表 <span class="s6">2-3</span>。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 31pt;text-indent: 0pt;text-align: center;">表 <span class="h4">2-3 Find-S </span>算法</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 2pt;text-align: left;"><span><img width="570" height="2" alt="image" src="机器学习/Image_020.png"/></span></p><p class="s14" style="padding-left: 12pt;text-indent: 0pt;text-align: left;"><span class="s16">1. </span>将 <span class="s56">h </span>初始化为 <span class="s56">H </span>中最特殊假设</p><p class="s16" style="padding-top: 3pt;padding-left: 12pt;text-indent: 0pt;text-align: left;">2. <span class="s14">对每个正例 </span><i>x</i></p><p class="s14" style="padding-top: 3pt;padding-left: 56pt;text-indent: -27pt;line-height: 118%;text-align: left;"><span class="s55">n </span>对<span class="s56">h</span>的每个属性约束<span class="s56">a</span><span class="s65">i </span>如果 <span class="s56">x</span>满足<span class="s56">a</span><span class="s65">i</span></p><p class="s14" style="padding-left: 57pt;text-indent: 0pt;text-align: left;">那么 不做任何事</p><p class="s14" style="padding-top: 3pt;padding-left: 57pt;text-indent: 0pt;text-align: left;">否则 将<span class="s56">h</span>中<span class="s56">a</span><span class="s65">i</span>替换为<span class="s56">x</span>满足的紧邻的更一般约束</p><p class="s16" style="padding-top: 2pt;padding-left: 12pt;text-indent: 0pt;text-align: left;">3. <span class="s14">输出假设 </span><i>h</i></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 2pt;text-align: left;"><span><img width="570" height="2" alt="image" src="机器学习/Image_021.png"/></span></p><p style="padding-top: 6pt;padding-left: 12pt;text-indent: 21pt;line-height: 107%;text-align: justify;">为说明这一算法，假定给予学习器的一系列训练样例如表 <span class="s6">2-1 </span>所示。<span class="s6">Find-S </span>的第一步是 将 <span class="s21">h </span>初始化为 <span class="s21">H </span>中最特殊假设：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 31pt;text-indent: 0pt;text-align: center;"><i>h</i><span class="p">←</span>&lt;<span class="s10"></span>, <span class="s10"></span>, <span class="s10"></span>, <span class="s10"></span>, <span class="s10"></span>, <span class="s10"></span>&gt;</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 12pt;text-indent: 21pt;line-height: 107%;text-align: justify;">在扫描到表 <span class="s6">2-1 </span>中第一个训练样例时，它刚好是个正例。很清楚，这时的 <span class="s21">h </span>太特殊了。 <span class="s21">h </span>中的每一个<span class="s10"></span>约束都不被该样例满足，因此，每个属性都被替换成能拟合该例的紧邻的更 一般的值约束，也就是这一样例的属性值本身：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 31pt;text-indent: 0pt;text-align: center;">h<span class="p">←</span><span class="s6">&lt;</span>Sunny<span class="s6">, </span>Warm<span class="s6">, </span>Normal<span class="s6">, </span>Strong<span class="s6">, </span>Warm<span class="s6">, </span>Same<span class="s6">&gt;</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 12pt;text-indent: 21pt;line-height: 107%;text-align: justify;">这个 <span class="s21">h </span>仍旧太特殊了，它把除了第一个样例以外的所有实例都划分为反例。下一步，第 <span class="s6">2 </span>个训练样例（仍然为正例）迫使该算法进一步将 <span class="s21">h </span>泛化。这次使用“<span class="s6">?</span>”代替 <span class="s21">h </span>中不能满 足新样例的属性值。之后的假设变为：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 31pt;text-indent: 0pt;text-align: center;">h<span class="p">←</span><span class="s6">&lt;</span>Sunny<span class="s6">, </span>Warm<span class="s6">, ?, </span>Strong<span class="s6">, </span>Warm<span class="s6">, </span>Same<span class="s6">&gt;</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 11pt;text-indent: 21pt;line-height: 107%;text-align: justify;"><span class="p">然后处理第三个训练样例，这里是一个反例，</span>h <span class="p">不变。实际上，</span><span class="s6">Find-S </span><span class="p">算法简单地忽略 每一个反例！这一开始似乎有点奇怪。注意这时假设 </span>h <span class="p">仍然与新的反例一致（即 </span>h <span class="p">能将此例 正确地划分为反例），因此不需要对 </span>h <span class="p">作任何更改。一般情况下，只要我们假定假设空间 </span>H <span class="p">确实包含真正的目标概念 </span>c<span class="p">，而且训练样例不包含错误，那么当前的假设 </span>h <span class="p">不需要因反例出 现而更改。原因在于当前假设 </span>h <span class="p">是 </span>H <span class="p">中与所观察到的正例相一致的最特殊的假设，由于假 定目标概念 </span>c <span class="p">在 </span>H <span class="p">中，而且它一定是与所有正例一致的，那么 </span>c <span class="p">一定比 </span>h <span class="p">更一般。而目标 概念 </span>c <span class="p">不会覆盖一个反例，因此 </span>h <span class="p">也不会（由 </span>more<span class="s6">-</span>general<span class="s6">-</span>than <span class="p">的定义）。因此，对反例，</span>h <span class="p">不需要作出任何修改。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 33pt;text-indent: 0pt;text-align: left;">接着完成 <span class="s6">Find-S </span>算法，第四个正例使得 <span class="s21">h </span>更一般：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 31pt;text-indent: 0pt;text-align: center;">h<span class="p">←</span><span class="s6">&lt;</span>Sunny<span class="s6">, </span>Warm<span class="s6">, ?, </span>Strong<span class="s6">, ?, ?&gt;</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 31pt;text-indent: 0pt;text-align: center;">Find-S <span class="p">算法演示了一种利用 </span><i>more</i>-<i>general</i>-<i>than </i><span class="p">偏序来搜索假设空间的方法。这一搜索沿</span></p><p class="s6" style="padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: left;"><span class="p">着偏序链，从较特殊的假设逐渐转移到较一般的假设。图 </span>2-2 <span class="p">说明了在实例和假设空间中的 这种搜索过程。在每一步，假设只在需要覆盖新的正例时被泛化。因此，每一步得到的假设， 都是在那一点上与训练样例一致的最特殊的假设。这也是其名字 </span>Find-S <span class="p">的由来。概念学习 的思想在许多不同的算法中用到，它们使用了同样的 </span><i>more</i>-<i>general</i>-<i>than </i><span class="p">偏序。一部分算法在 本章讨论，另一些放在第 </span>10 <span class="p">章。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 13pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="547" height="1" alt="image" src="机器学习/Image_022.png"/></span></p><p class="s48" style="padding-left: 15pt;text-indent: 0pt;text-align: left;">插图——原书页码： <span class="s21">27</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;line-height: 190%;text-align: left;">Instances: <span class="p">实例集 </span>Hypotheses<span class="p">：假设集 </span>Specific<span class="p">：特殊 </span>General<span class="p">：一般</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 14pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="531" height="1" alt="image" src="机器学习/Image_023.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 37pt;text-indent: 113pt;text-align: left;">图 <span class="h4">2-2 Find-S </span>中的假设空间搜索</p><p class="s14" style="padding-top: 6pt;padding-left: 37pt;text-indent: 0pt;line-height: 12pt;text-align: left;">搜索开始于<span class="s56">H</span>中最特殊的假设<span class="s56">h</span><span class="s64">0</span>，然后根据训练样例逐渐一般化（<span class="s56">h</span><span class="s64">1</span>到<span class="s56">h</span><span class="s64">4</span>）。在实例空间图中，正 例被标以“<span class="s16">+</span>”，反例标以“<span class="s16">-</span>”，而没有包含在训练样例中的实例则以实心圆点表示。</p><p class="s24" style="padding-top: 6pt;padding-left: 6pt;text-indent: 21pt;line-height: 107%;text-align: justify;"><span class="s6">Find-S </span><span style=" color: #000;">算法的关键特点在于：</span>对以属性约束的合取式描述的假设空间（如 <span class="s58">EnjoySport </span>中的 <span class="s58">H</span>），<span class="s63">Find-S </span>保证输出为 <span class="s58">H </span>中与正例一致的最特殊的假设<span style=" color: #000;">。只要正确的目标概念包含在 </span><span class="s21">H </span><span style=" color: #000;">中，并且训练数据都是正确的，最终的假设也与所有反例一致。然而，这一学习算法仍存 在一些未解决的问题：</span></p><p style="padding-top: 5pt;padding-left: 49pt;text-indent: -21pt;text-align: left;"><span class="s34">• </span>学习过程是否收敛到了正确的目标概念？虽然 <span class="s6">Find-S </span>找到了与训练数据一致的 假设，但没办法确定它是否找到了惟一合适的假设（即目标概念本身），或是 否还有其他可能的假设。我们希望算法知道它能否收敛到目标概念，如果不能， 至少要描述出这种不确定性。</p><p style="padding-left: 49pt;text-indent: -21pt;text-align: justify;"><span class="s34">• </span>为什么要用最特殊的假设。如果有多个与训练样例一致的假设，<span class="s6">Find-S </span>只能找 到最特殊的。为什么我们偏好最特殊的假设，而不选最一般假设，抑或一般程 度位于两者之间的某个假设。</p><p style="padding-left: 49pt;text-indent: -21pt;text-align: justify;"><span class="s34">• </span>训练样例是否相互一致？在多数实际的学习问题中，训练数据中常出现某些错 误或噪声，这样的不一致的训练集将严重破坏 <span class="s6">Find-S </span>算法，因为它忽略了所有 反例。我们期望的算法至少能检测出训练数据的不一致性，并且最好能容纳这 样的错误。</p><p style="padding-left: 49pt;text-indent: -21pt;text-align: justify;"><span class="s34">• </span>如果有多个极大特殊假设怎么办？在 <span class="s21">EnjoySport </span>任务的假设语言 <span class="s21">H </span>中，总有一 个惟一的最特殊假设与训练数据一致。然而，对其他一些假设空间（后面将讨 论到）可能有多个极大特殊假设。这种情况下，<span class="s6">Find-S </span>必须被扩展，以允许其 在选择怎样泛化假设的路径上回溯，以容纳目标假设位于偏序结构的另一分支 上的可能性。更进一步，我们可以定义一个不存在极大特殊假设的假设空间， 然而这是一个更理论性的问题而不是实践问题（见习题 <span class="s6">2.7</span>）</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">2.5 <span class="s17">变型空间和候选消除算法</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 107%;text-align: justify;">本节描述的是概念学习的另一种途径即候选消除算法（<span class="s6">Candidate-Elimination</span>）。它能解 决 <span class="s6">Find-S </span>中的若干不足之处。<span class="s6">Find-S </span>输出的假设只是 <span class="s21">H </span>中能够拟合训练样例的多个假设中</p><p class="s21" style="padding-left: 12pt;text-indent: 0pt;line-height: 111%;text-align: left;"><span class="p">的一个。而在候选消除算法中，输出的是与训练样例一致的所有假设的集合。令人惊奇地是， 候选消除算法在描述这一集合时不需要明确列举其所有成员。这也归功于 </span>more<span class="s6">-</span>general<span class="s6">-</span>than <span class="p">偏序结构。在这里需要维护一个一致假设集合的简洁表示，然后在遇到新的训练样例时逐步 精化这一表示。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 12pt;text-indent: 21pt;line-height: 109%;text-align: justify;">候选消除算法的应用有：从化学质谱分析（<span class="s6">chemical mass spectroscopy</span>）中学习规则性 <span class="s6">(Mitchell 1979)</span>；和学习启发式搜索的控制规则<span class="s6">(Mitchell et al. 1983)</span>。然而，候选消除算法和 <span class="s6">Find-S </span>算法的实际应用都受到限制，因为它们在训练数据含有噪声时性能较差。在这里介绍 候选消除算法的目的，是为了基础的机器学习理论提供一个良好的概念框架。本章其余部分 将展示这一算法及相关的问题。从下一章开始将考察面对有噪声数据时更常用的学习算法。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 12pt;text-indent: 0pt;text-align: left;">2.5.1 <span class="s25">表示</span></h3><p style="padding-top: 10pt;padding-left: 11pt;text-indent: 21pt;line-height: 110%;text-align: justify;">候选消除算法寻找所有与训练样例一致的假设。为精确描述这一算法，这里先引入一些 基本的定义。首先，我们称一个假设是与训练样例一致的<span class="s6">(consistent)</span>，当它能正确分类这些 样例。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s24" style="padding-left: 31pt;text-indent: 0pt;text-align: center;">定义： 一个假设 <span class="s58">h </span>与训练样例集合 <span class="s58">D </span>一致<span class="s63">(consistent)</span>，当且仅当对 <span class="s58">D </span>中每一个样例</p><p class="s63" style="padding-top: 1pt;padding-left: 54pt;text-indent: 0pt;text-align: left;">&lt;<i>x</i>,<i>c</i>(<i>x</i>)&gt;<span class="s24">，</span><i>h</i>(<i>x</i>)=<i>c</i>(<i>x</i>)<span class="s24">。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s63" style="padding-left: 31pt;text-indent: 0pt;text-align: center;"><i>Consistent</i>(<i>h</i>,<i>D</i>)<span class="s24">≡</span>(<span class="s51"></span>&lt;<i>x</i>,<i>c</i>(<i>x</i>)&gt; <span class="s24">∈ </span><i>D</i>) <i>h</i>(<i>x</i>)=<i>c</i>(<i>x</i>)</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 11pt;text-indent: 21pt;line-height: 107%;text-align: justify;"><span class="p">注意这里定义的一致与前面定义的满足有关键的不同。一个样例 </span>x <span class="p">在 </span>h<span class="s6">(</span>x<span class="s6">)=1 </span><span class="p">时称为满 足假设 </span>h<span class="p">，不论 </span>x <span class="p">是目标概念的正例还是反例。然而，这一样例是否与 </span>h <span class="p">一致与目标概念有 关，即是否 </span>h<span class="s6">(</span>x<span class="s6">)=</span>c<span class="s6">(</span>x<span class="s6">)</span><span class="p">。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 11pt;text-indent: 21pt;line-height: 110%;text-align: justify;">候选消除算法能够表示与训练样例一致的所有假设。在假设空间中的这一子集被称为关 于假设空间 <span class="s21">H </span>和训练样例 <span class="s21">D </span>的变型空间<span class="s6">(version space)</span>，因为它包含的是目标概念的所有合 理的变型。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 31pt;text-indent: 0pt;text-align: center;">定义： 关于假设空间<span class="s21">H</span>和训练样例集<span class="s21">D</span>的变型空间<span class="s6">(version space)</span>，标记为<span class="s21">VS</span><span class="s36">H</span><span class="s42">,</span><span class="s41">D</span>，是<span class="s21">H</span></p><p style="padding-left: 53pt;text-indent: 0pt;text-align: left;">中与训练样例<span class="s21">D</span>一致的所有假设构成的子集。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 12pt;text-indent: 149pt;text-align: left;">VS<span class="s36">H</span><span class="s42">,</span><span class="s41">D</span><span class="p">≡</span><span class="s6">{</span>h<span class="p">∈</span>H<span class="s6">|</span>Consistent<span class="s6">(</span>h<span class="s6">,</span>D<span class="s6">)}</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 12pt;text-indent: 0pt;text-align: left;">2.5.2 <span class="s25">列表后消除算法</span></h3><p style="padding-top: 10pt;padding-left: 12pt;text-indent: 21pt;line-height: 113%;text-align: justify;">显然，表示变型空间的一种方法是列出其所有成员。这样可产生一个简单的算法，称为 列表后消除（<span class="s6">List-Then-Eliminate</span>）算法。其定义见表 <span class="s6">2-4</span>。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 31pt;text-indent: 0pt;text-align: center;">表 <span class="h4">2-4 </span>列表后消除算法</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 2pt;text-align: left;"><span><img width="570" height="2" alt="image" src="机器学习/Image_024.png"/></span></p><p class="s14" style="padding-left: 12pt;text-indent: 0pt;text-align: left;">列表后消除算法</p><p class="s14" style="padding-top: 3pt;padding-left: 12pt;text-indent: 0pt;text-align: left;"><span class="s16">1. </span>变型空间 <span class="s56">VersionSpace</span>←包含 <span class="s56">H </span>中所有假设的列表</p><p class="s16" style="padding-top: 3pt;padding-left: 12pt;text-indent: 0pt;text-align: left;">2. <span class="s14">对每个训练样例</span>&lt;<i>x</i>, <i>c</i>(<i>x</i>)&gt;</p><p class="s56" style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: center;"><span class="s14">从变型空间中移除所有 </span>h<span class="s16">(</span>x<span class="s16">)</span><span class="s14">≠</span>c<span class="s16">(</span>x<span class="s16">)</span><span class="s14">的假设 </span>h</p><p class="s14" style="padding-top: 3pt;padding-left: 12pt;text-indent: 0pt;text-align: left;"><span class="s16">3. </span>输出 <span class="s56">VersionSpace </span>中的假设列表</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 2pt;text-align: left;"><span><img width="570" height="2" alt="image" src="机器学习/Image_025.png"/></span></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 112%;text-align: justify;">列表后消除算法首先将变型空间初始化为包含 <span class="s21">H </span>中所有假设，然后从中去除与任一训 练样例不一致的假设。包含候选假设的变型空间随着观察到越来越多的样例而缩减，直到只 剩一个（理想情况下）与所有样例一致的假设。这可能就是所要的目标概念。如果没有充足 的数据使变型空间缩减到只有一个假设，那么该算法将输出一个集合，这个集合中所有的假 设与训练样例都一致。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 110%;text-align: justify;">原则上，只要假设空间是有限的，就可使用列表后消除算法。它具有很多优点，如能保 证得到所有与训练数据一致的假设。但是，这一算法非常烦琐地列出了 <span class="s21">H </span>中所有假设，这 对于大多数实际的假设空间是不现实的要求。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">2.5.3 <span class="s25">变型空间的更简明表示</span></h3><p style="padding-top: 10pt;padding-left: 6pt;text-indent: 21pt;line-height: 113%;text-align: justify;">候选消除算法与上面的列表后消除算法遵循同样的原则。然而，它使用一种更简明的变 型空间的表示法。在此，变型空间被表示为它的最一般的和最特殊的成员。这些成员形成了 一般和特殊边界的集合，这些边界在整个偏序结构中划分出变型空间。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 13pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="547" height="1" alt="image" src="机器学习/Image_026.png"/></span></p><p class="s48" style="padding-left: 15pt;text-indent: 0pt;text-align: left;">插图——原书页码： <span class="s21">31</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 14pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="531" height="1" alt="image" src="机器学习/Image_027.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 37pt;text-indent: 91pt;text-align: left;">图 <span class="h4">2-3 </span>变型空间及其一般和特殊边界集合</p><p class="s14" style="padding-top: 6pt;padding-left: 37pt;text-indent: 0pt;line-height: 12pt;text-align: justify;">变型空间中包含了所有的 <span class="s16">6 </span>个假设，但可以简单地用 <span class="s56">S </span>和 <span class="s56">G </span>来表示。箭头表示实例间的 <span class="s56">more</span><span class="s16">-</span><span class="s56">general</span><span class="s16">-</span><span class="s56">than </span>关系。这个变型空间对应于表 <span class="s16">2-1 </span>中描述的 <span class="s56">EnjoySport </span>概念学习问题及其训练样 例。</p><p style="padding-top: 6pt;padding-left: 6pt;text-indent: 20pt;line-height: 107%;text-align: left;">为说明变型空间的这种表示，再一次考虑表 <span class="s6">2-2 </span>中描述的 <span class="s21">EnjoySport </span>概念学习问题。对 于表 <span class="s6">2-1 </span>中给定的 <span class="s6">4 </span>个训练样例，<span class="s6">Find-S </span>输出假设：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 151pt;text-indent: 0pt;text-align: left;">h<span class="p">＝</span><span class="s6">&lt;</span>Sunny<span class="s6">, </span>Warm<span class="s6">, ?, </span>Strong<span class="s6">, ?, ?&gt;</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 107%;text-align: justify;">实际上，这只是 <span class="s21">H </span>中与训练样例一致的所有 <span class="s6">6 </span>个假设之一。所有 <span class="s6">6 </span>个假设在图 <span class="s6">2-3 </span>中 表示出。它们构成了与该数据集合和假设表示相对应的变型空间。<span class="s6">6 </span>个假设之间的箭头表示 实例间的 <span class="s21">more</span><span class="s6">-</span><span class="s21">general</span><span class="s6">-</span><span class="s21">than </span>关系。候选消除算法通过使用最一般成员（在图 <span class="s6">2-3 </span>中标为 <span class="s21">G</span>） 和最特殊成员（图中标为 <span class="s21">S</span>）来表示变型空间。只给定这两个集合 <span class="s21">S </span>和 <span class="s21">G</span>，就可以列举出变 型空间中的所有成员，方法是使用一般到特殊偏序结构来生成 <span class="s21">S </span>和 <span class="s21">G </span>集合之间的所有假设。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 113%;text-align: left;">可以直观地看出，使用最一般和最特殊集合表示变型空间的作法是合理的。下面我们精 确地定义 <span class="s21">S </span>和 <span class="s21">G </span>这两个边界集合，并且证明它们确实代表了变型空间。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 47pt;text-indent: -21pt;line-height: 107%;text-align: left;">定义： 关于假设空间 <span class="s21">H </span>和训练数据 <span class="s21">D </span>的一般边界（<span class="s6">General boundary</span>）<span class="s21">G</span>，是在 <span class="s21">H </span>中 与 <span class="s21">D </span>相一致的极大一般（<span class="s6">maximally general</span>）成员的集合。</p><p class="s21" style="padding-left: 33pt;text-indent: 33pt;text-align: left;">G<span class="p">≡</span><span class="s6">{ </span>g<span class="p">∈</span>H <span class="s6">| </span>Consistent<span class="s6">(</span>g<span class="s6">, </span>D<span class="s6">)</span><span class="p">∧</span><span class="s6">(</span><span class="s10"></span>g<span class="s6">´</span><span class="p">∈</span>H<span class="s6">)[(</span>g<span class="s6">´ </span><span class="p">＞</span><span class="s36">g </span>g<span class="s6">) </span><span class="p">∧</span>Consistent<span class="s6">(</span>g<span class="s6">´, </span>D<span class="s6">)]}</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 53pt;text-indent: -21pt;line-height: 107%;text-align: left;">定义： 关于假设空间 <span class="s21">H </span>和训练数据 <span class="s21">D </span>的特殊边界（<span class="s6">Specific boundary</span>）<span class="s21">S</span>，是在 <span class="s21">H </span>中 与 <span class="s21">D </span>相一致的极大特殊（<span class="s6">maximally specific</span>）成员的集合。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 31pt;text-indent: 0pt;text-align: center;">S<span class="p">≡</span><span class="s6">{ </span>s<span class="p">∈</span>H <span class="s6">| </span>Consistent<span class="s6">(</span>s<span class="s6">, </span>D<span class="s6">)</span><span class="p">∧</span><span class="s6">(</span><span class="s10"></span>s<span class="s6">´</span><span class="p">∈</span>H<span class="s6">)[(</span>s<span class="p">＞</span><span class="s36">g </span>s<span class="s6">´) </span><span class="p">∧</span>Consistent<span class="s6">(</span>s<span class="s6">´, </span>D<span class="s6">)]}</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 11pt;text-indent: 21pt;line-height: 107%;text-align: justify;">只要集合 <span class="s21">G </span>和 <span class="s21">S </span>被良好地定义了（见习题 <span class="s6">2.7</span>），它们就完全规定了变型空间。这里还 可以证明，变型空间的确切组成是：<span class="s21">G </span>中包含的假设集，<span class="s21">S </span>中包含的假设集，以及 <span class="s21">G </span>和 <span class="s21">S </span>之间偏序结构所规定的假设。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s56" style="padding-left: 33pt;text-indent: 21pt;line-height: 125%;text-align: justify;"><span class="s14">定理 </span><span class="s16">2-1 </span><span class="s14">变型空间表示定理。令 </span>X <span class="s14">为一任意的实例集合，</span>H <span class="s14">与为 </span>X <span class="s14">上定义的布尔假设的集合。 令 </span>c<span class="s16">: </span>X<span class="s14">→</span><span class="s16">{0, 1}</span><span class="s14">为 </span>X <span class="s14">上定义的任一目标概念，并令 </span>D <span class="s14">为任一训练样例的集合</span><span class="s16">{&lt;</span>x<span class="s16">, </span>c<span class="s16">(</span>x<span class="s16">)&gt;}</span><span class="s14">。对所有的 </span>X<span class="s14">， </span>H<span class="s14">，</span>c<span class="s14">，</span>D <span class="s14">以及良好定义的 </span>S <span class="s14">和 </span>G<span class="s14">：</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s56" style="padding-left: 154pt;text-indent: 0pt;text-align: left;">VS<span class="s65">H</span><span class="s66">,</span><span class="s67">D </span><span class="s16">= { </span>h<span class="s14">∈</span>H <span class="s16">| (</span><span class="s57"></span>s<span class="s14">∈</span>S<span class="s16">) (</span><span class="s57"></span>g<span class="s14">∈</span>G<span class="s16">) (</span>g<span class="s14">≥</span><span class="s65">g</span>h<span class="s14">≥</span><span class="s65">g</span>s<span class="s16">)}</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-left: 33pt;text-indent: 21pt;line-height: 117%;text-align: justify;">证明：为证明该定理只需证明：<span class="s16">(1)</span>每一个满足上式右边的<span class="s56">h</span>都在<span class="s56">VS</span><span class="s65">H</span><span class="s66">,</span><span class="s67">D</span>中，<span class="s16">(2) </span><span class="s56">VS</span><span class="s65">H</span><span class="s66">,</span><span class="s67">D</span>的每个成员都 满足等式右边。为证明（<span class="s16">1</span>），令<span class="s56">g</span>为<span class="s56">G</span>中任意一个成员，<span class="s56">s</span>为<span class="s56">S</span>中任一成员，<span class="s56">h</span>为<span class="s56">H</span>的任一成员而且<span class="s56">g</span>≥<span class="s65">g</span><span class="s56">h</span></p><p class="s14" style="padding-left: 32pt;text-indent: 0pt;line-height: 117%;text-align: left;">≥<span class="s65">g</span><span class="s56">s</span>。由<span class="s56">S</span>的定义，<span class="s56">s</span>必须被<span class="s56">D</span>中所有的正例满足。因为<span class="s56">h</span>≥<span class="s65">g </span><span class="s56">s</span>， <span class="s56">h</span>也被<span class="s56">D</span>中所有正例满足。相似地，由<span class="s56">G </span>的定义，<span class="s56">g</span>必须不被<span class="s56">D</span>中任一反例满足，且由于 <span class="s56">g</span>≥<span class="s65">g </span><span class="s56">h</span>，<span class="s56">h</span>也不被<span class="s56">D</span>中所有反例满足。由于 <span class="s56">h</span>被<span class="s56">D</span>中所有 正例满足且不被其中所有反例满足，因此<span class="s56">h</span>与<span class="s56">D</span>一致，因此<span class="s56">h</span>是<span class="s56">VS</span><span class="s65">H</span><span class="s66">,</span><span class="s67">D</span>的成员。这证明了步骤（<span class="s16">1</span>）。（<span class="s16">2</span>） 的讨论稍微有些复杂，可以使用反证法，假定<span class="s56">VS</span><span class="s65">H</span><span class="s66">,</span><span class="s67">D</span>中某一<span class="s56">h</span>不满足等式右边，那么将产生矛盾（见习 题 <span class="s16">2.6</span>）。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 12pt;text-indent: 0pt;text-align: left;">2.5.4 <span class="s25">候选消除学习算法</span></h3><p style="padding-top: 10pt;padding-left: 11pt;text-indent: 21pt;line-height: 107%;text-align: justify;">候选消除算法计算出的变型空间，包含 <span class="s21">H </span>中所有与训练样例的观察到的序列一致的假 设。开始，变型空间被初始化为 <span class="s21">H </span>中所有假设的集合。即将 <span class="s21">G </span>边界集合初始化为 <span class="s21">H </span>中最一 般的假设：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 31pt;text-indent: 0pt;text-align: center;">G<span class="s35">0</span><span class="p">←</span><span class="s6">{&lt;?, ?, ?, ?, ?, ?&gt;}</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 32pt;text-indent: 0pt;text-align: left;">并将 <span class="s21">S </span>边界集合初始化为最特殊假设：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 31pt;text-indent: 0pt;text-align: center;"><i>S</i><span class="s35">0</span><span class="p">←</span>{&lt;<span class="s10"></span>, <span class="s10"></span>, <span class="s10"></span>, <span class="s10"></span>, <span class="s10"></span>, <span class="s10"></span>&gt;}</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 11pt;text-indent: 21pt;line-height: 108%;text-align: left;">这两个边界集合包含了整个假设空间。因为<span class="s21">H</span>中所有假设都比<span class="s21">S</span><span class="s35">0</span>更一般，且比<span class="s21">G</span><span class="s35">0</span>更特殊。 算法在处理每个训练样例时，<span class="s21">S</span>和<span class="s21">G</span>边界集合分别被泛化和特化，从变型空间中逐步消去与 样例不一致的假设。在所有训练样例处理完后，得到的变型空间就包含了所有与样例一致的 假设，而且只包含这样的假设。这一算法在表 <span class="s6">2-5 </span>中描述：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 31pt;text-indent: 0pt;text-align: center;">表 <span class="h4">2-5 </span>使用变型空间的候选消除算法</p><p style="text-indent: 0pt;text-align: left;"><span><img width="570" height="2" alt="image" src="机器学习/Image_028.png"/></span></p><p class="s14" style="padding-top: 5pt;padding-left: 12pt;text-indent: 31pt;line-height: 122%;text-align: left;">注意正例和反例是怎样同时影响 <span class="s56">S </span>和 <span class="s56">G </span>的。 将 <span class="s56">G </span>集合初始化为 <span class="s56">H </span>中极大一般假设</p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 2pt;text-align: left;"><span><img width="570" height="2" alt="image" src="机器学习/Image_029.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 2pt;text-align: left;"><span><img width="570" height="2" alt="image" src="机器学习/Image_030.png"/></span></p><p class="s14" style="padding-left: 12pt;text-indent: 0pt;line-height: 126%;text-align: left;">将 <span class="s56">S </span>集合初始化为 <span class="s56">H </span>中极大特殊假设 对每个训练样例 <span class="s56">d</span>，进行以下操作： <span class="s55">n </span>如果 <span class="s56">d </span>是一正例</p><p class="s14" style="padding-left: 39pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span>从 <span class="s56">G </span>中移去所有与 <span class="s56">d </span>不一致的假设</p><p class="s14" style="padding-top: 3pt;padding-left: 39pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span>对 <span class="s56">S </span>中每个与 <span class="s56">d </span>不一致的假设 <span class="s56">s</span></p><p class="s14" style="padding-top: 3pt;padding-left: 57pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span>从 <span class="s56">S </span>中移去 <span class="s56">s</span></p><p class="s14" style="padding-top: 3pt;padding-left: 57pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span>把 <span class="s56">s </span>的所有的极小泛化式 <span class="s56">h </span>加入到 <span class="s56">S </span>中，其中 <span class="s56">h </span>满足</p><p class="s56" style="padding-top: 3pt;padding-left: 32pt;text-indent: 0pt;text-align: center;"><span class="s55">n </span>h <span class="s14">与 </span>d <span class="s14">一致，而且 </span>G <span class="s14">的某个成员比 </span>h <span class="s14">更一般</span></p><p class="s14" style="padding-top: 3pt;padding-left: 57pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span>从 <span class="s56">S </span>中移去所有这样的假设：它比 <span class="s56">S </span>中另一假设更一般</p><p class="s14" style="padding-top: 3pt;padding-left: 12pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span>如果 <span class="s56">d </span>是一个反例</p><p class="s14" style="padding-top: 3pt;padding-left: 39pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span>从 <span class="s56">S </span>中移去所有与 <span class="s56">d </span>不一致的假设</p><p class="s14" style="padding-top: 3pt;padding-left: 39pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span>对 <span class="s56">G </span>中每个与 <span class="s56">d </span>不一致的假设 <span class="s56">g</span></p><p class="s14" style="padding-top: 3pt;padding-left: 57pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span>从 <span class="s56">G </span>中移去 <span class="s56">g</span></p><p class="s14" style="padding-top: 3pt;padding-left: 57pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span>把 <span class="s56">g </span>的所有的极小特化式 <span class="s56">h </span>加入到 <span class="s56">G </span>中，其中 <span class="s56">h </span>满足</p><p class="s56" style="padding-top: 3pt;padding-left: 32pt;text-indent: 0pt;text-align: center;"><span class="s55">n </span>h <span class="s14">与 </span>d <span class="s14">一致，而且 </span>S <span class="s14">的某个成员比 </span>h <span class="s14">更特殊</span></p><p class="s14" style="padding-top: 3pt;padding-left: 33pt;text-indent: 24pt;text-align: left;"><span class="s55">n </span>从 <span class="s56">G </span>中移去所有这样的假设：它比 <span class="s56">G </span>中另一假设更特殊</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 2pt;text-align: left;"><span><img width="570" height="2" alt="image" src="机器学习/Image_031.png"/></span></p><p style="padding-top: 6pt;padding-left: 12pt;text-indent: 21pt;line-height: 113%;text-align: justify;">注意算法中的操作，包括对给定假设的极小泛化式和极小特化式的计算，并确定那些非 极小和非极大的假设。具体的实现当然依赖于实例和假设的表示方式。然而，只要这些操作 被良好地定义了，该算法就可应用于任意概念学习和任意假设空间。在以下将实际演示算法 的运行步骤，从中可以看到在 <span class="s21">EnjoySport </span>这个例子中，这些操作是怎样实现的。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 12pt;text-indent: 0pt;text-align: left;">2.5.5 <span class="s25">算法的示例</span></h3><p style="padding-top: 10pt;padding-left: 12pt;text-indent: 21pt;line-height: 107%;text-align: justify;">图 <span class="s6">2-4 </span>演示了候选消除算法应用到表 <span class="s6">2-1 </span>中头两个训练样例时的运行步骤。如上所述， 边界集合先被初始化为<span class="s21">G</span><span class="s35">0</span>和<span class="s21">S</span><span class="s35">0</span>，分别代表<span class="s21">H</span>中最一般和最特殊的假设。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 19pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="547" height="1" alt="image" src="机器学习/Image_032.png"/></span></p><p class="s48" style="padding-left: 21pt;text-indent: 0pt;text-align: left;">插图——原书页码： <span class="s21">34</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-top: 1pt;padding-left: 12pt;text-indent: 0pt;text-align: left;">Training examples: <span class="p">训练样例</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 20pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="531" height="1" alt="image" src="机器学习/Image_033.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 43pt;text-indent: 124pt;text-align: left;">图 <span class="h4">2-4 </span>候选消除算法步骤 <span class="h4">1</span></p><p class="s14" style="padding-top: 6pt;padding-left: 43pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><span class="s56">S</span><span class="s64">0</span>和<span class="s56">G</span><span class="s64">0</span>为最初的边界集合，分别对应最特殊和最一般假设。训练样例 <span class="s16">1 </span>和 <span class="s16">2 </span>使得<span class="s56">S</span>边界变得更一般， 如<span class="s16">Find-S</span>算法中一样。这些样例对<span class="s56">G</span>边界没有影响。</p><p style="padding-top: 6pt;padding-left: 11pt;text-indent: 21pt;line-height: 108%;text-align: left;">当第一个训练样例出现时（这里为一正例），候选消除算法检查<span class="s21">S</span>边界，并发现它过于特 殊了——因为它不能覆盖该正例。这一边界就被修改为紧邻更一般的假设，以覆盖新的样例。 修改后的边界在图 <span class="s6">2-4 </span>中显示为<span class="s21">S</span><span class="s35">1</span>。<span class="s21">G</span>边界不需要修改，因为<span class="s21">G</span><span class="s35">0</span>能够正确地覆盖该样例。当 处理第二个训练样例时（也是－正例），同样地，需要将<span class="s21">S</span>进一步泛化到<span class="s21">S</span><span class="s35">2</span>，<span class="s21">G</span>仍旧不变</p><p class="s21" style="padding-left: 11pt;text-indent: 0pt;line-height: 15pt;text-align: left;"><span class="p">（</span>G<span class="s35">2</span><span class="s6">=</span>G<span class="s35">1</span><span class="s6">=</span>G<span class="s35">0</span><span class="p">）。注意对头两个正例的处理非常类似于</span><span class="s6">Find-S</span><span class="p">算法。</span></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 107%;text-align: left;">在头两步的算法中，正例使得变型空间的<span class="s21">S</span>边界逐渐泛化。而反例扮演的角色恰好相反， 使得<span class="s21">G</span>边界逐渐特化。考虑第三个训练样例，如图 <span class="s6">2-5 </span>所示。这一反例显示，<span class="s21">G</span>边界过于一 般了。也就是说，<span class="s21">G</span>中的假设错误地将该例判定为正例了。因此<span class="s21">G</span>边界中的假设必须被特化， 使它能对新的反例正确分类。如图 <span class="s6">2-5 </span>所示，这里有几种可选的极小更特殊的假设。这些全 都成为新的<span class="s21">G</span><span class="s35">3</span>边界集合的成员。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 13pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="547" height="1" alt="image" src="机器学习/Image_034.png"/></span></p><p class="s48" style="padding-left: 15pt;text-indent: 0pt;text-align: left;">插图——原书页码： <span class="s21">35</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">Training examples: <span class="p">训练样例</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 14pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="531" height="1" alt="image" src="机器学习/Image_035.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 24pt;text-indent: 0pt;text-align: center;">图 <span class="h4">2-5 </span>候选消除算法步骤 <span class="h4">2</span></p><p class="s14" style="padding-top: 5pt;padding-left: 37pt;text-indent: 0pt;text-align: left;">样例 <span class="s16">3 </span>是一反例，它把<span class="s56">G</span><span class="s64">2</span>边界特化为<span class="s56">G</span><span class="s64">3</span>。注意在<span class="s56">G</span><span class="s64">3</span>中有多个可选的极大一般假设。</p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 21pt;text-align: justify;">有 <span class="s6">6 </span>个属性可以用来使<span class="s21">G</span><span class="s35">2</span>特化，为什么只有 <span class="s6">3 </span>个在<span class="s21">G</span><span class="s35">3</span>中呢？比如<span class="s21">h</span><span class="s6">=&lt;?, ?, </span><span class="s21">Normal</span><span class="s6">, ?, ?, ?&gt; </span>是<span class="s21">G</span><span class="s35">2</span>的一个极小特化式，它能够将新的样例正确地划分为反例，但它不在<span class="s21">G</span><span class="s35">3</span>中。将这一假 设排除在外的原因是，它与以前遇到的正例不一致。在算法中只是简单地判断<span class="s21">h</span>并不比当前 特殊边界<span class="s21">S</span><span class="s35">2</span>更一般。实际上变型空间的<span class="s21">S</span>边界形成了以往正例的摘要说明，它可以用来判断 任何给定的假设是否与以往样例一致。根据定义，任何比<span class="s21">S</span>更一般的假设能够覆盖所有<span class="s21">S</span>能覆 盖的样例，即以往的所有正例。同样，<span class="s21">G</span>边界说明了以往所有反例的信息。任何比<span class="s21">G</span>更特殊 的假设能保证与所有反例相一致。这是因为根据定义，任一假设不会覆盖<span class="s21">G</span>所不能覆盖的样 例。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 109%;text-align: left;">第四个训练样例，如图 <span class="s6">2-6 </span>所示，使变型空间的 <span class="s21">S </span>边界更一般化。它也导致 <span class="s21">G </span>边界中 的一个成员被删除，因为这个成员不能覆盖新的正例。最后这一动作来自于表 <span class="s6">2-5 </span>算法中“如 果 <span class="s21">d </span>是一正例”下的第一步骤。为理解这一步的原因，需要考虑为什么不一致的假设要从 <span class="s21">G </span>中移去。注意这一假设不能再被特化，因为这样它将不能覆盖新的样例。它也不能被泛化， 因为按照 <span class="s21">G </span>的定义，任何更一般的假设至少会覆盖一个反例。这样，这一假设必须从 <span class="s21">G </span>中 移去，也相当于移去了变型空间的偏序结构中的一整个分支。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 13pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="547" height="1" alt="image" src="机器学习/Image_036.png"/></span></p><p class="s48" style="padding-left: 15pt;text-indent: 0pt;text-align: left;">插图——原书页码： <span class="s21">36 </span><i>上</i></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">Training examples: <span class="p">训练样例</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 14pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="531" height="1" alt="image" src="机器学习/Image_037.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 24pt;text-indent: 0pt;text-align: center;">图 <span class="h4">2-6 </span>候选消除算法步骤 <span class="h4">3</span></p><p class="s14" style="padding-top: 5pt;padding-left: 20pt;text-indent: 0pt;text-align: center;">正例使<span class="s56">S</span>边界更一般，从<span class="s56">S</span><span class="s64">3</span>变为<span class="s56">S</span><span class="s64">4</span>。<span class="s56">G</span><span class="s64">3</span>的一个成员也必须被删除，因为它不再比<span class="s56">S</span><span class="s64">4</span>边界更一般。</p><p style="padding-left: 27pt;text-indent: 0pt;text-align: left;">在处理完这 <span class="s6">4 </span>个样例后，边界集合<span class="s21">S</span><span class="s35">4</span>和<span class="s21">G</span><span class="s35">4</span>划分出的变型空间包含了与样例一致的所有假</p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 108%;text-align: justify;">设的集合。整个变型空间，包含那些由<span class="s21">S</span><span class="s35">4</span>和<span class="s21">G</span><span class="s35">4</span>界定的假设都在图 <span class="s6">2-7 </span>中示出。这一变型空间 不依赖于训练样本出现的次序（因为最终它包含了与训练样例集一致的所有假设）。如果提 供更多的训练数据，<span class="s21">S</span>和<span class="s21">G</span>边界将继续单调移动并相互靠近，划分出越来越小的变型空间来。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 13pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="547" height="1" alt="image" src="机器学习/Image_038.png"/></span></p><p class="s48" style="padding-left: 15pt;text-indent: 0pt;text-align: left;">插图——原书页码： <span class="s21">36 </span><i>下</i></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 14pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="531" height="1" alt="image" src="机器学习/Image_039.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 24pt;text-indent: 0pt;text-align: center;">图 <span class="h4">2-7 </span><span class="s7">EnjoySport </span>概念学习问题中的最终的变型空间</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">2.6 <span class="s17">关于变型空间和候选消除的说明</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">2.6.1 <span class="s25">候选消除算法是否会收敛到正确的假设</span></h3><p style="padding-top: 10pt;padding-left: 6pt;text-indent: 21pt;line-height: 109%;text-align: justify;">由候选消除算法得到的变型空间能够收敛到描述目标概念的假设的条件是（<span class="s6">1</span>）在训练 样例中没有错误（<span class="s6">2</span>）在 <span class="s21">H </span>中确实包含描述目标概念的正确假设。实际上，如果遇到新的训 练样例，可以监测变型空间以判定其与真正的目标概念之间是否还有分歧，以及为精确确定 目标概念还需要多少训练样例。当 <span class="s21">S </span>和 <span class="s21">G </span>边界集合收敛到单个的可确定的假设时，目标概 念才真正获得。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 112%;text-align: justify;">如果训练数据中包含错误会怎样？比如，以上例子中第二个样例被错误地标示为一反 例。这种情况下，很不幸，算法肯定会从变型空间中删除正确的目标概念。因为它会删除所 有与样例不一致的假设，所以在遇到这一错误的反例时，算法将从变型空间中移去正确的目 标概念。当然，如果给定足够的训练数据，最终，我们会发现 <span class="s21">S </span>和 <span class="s21">G </span>边界收敛得到一个空 的变型空间，从而得知训练数据有误。空的变型空间表示 <span class="s21">H </span>中没有假设能够与样例一致。 相似的情形会出现在另一种环境中：当训练样例正确，但目标概念不能由假设表示方式所描 述（比如目标概念是某几个属性特征的析取，而假设空间只支持合取的形式）。以后我们将 详细考虑这些可能性。目前，我们只考虑样例数据是正确的并且目标概念确实在假设空间中。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">2.6.2 <span class="s25">下一步需要什么样的训练样例</span></h3><p style="padding-top: 10pt;padding-left: 6pt;text-indent: 21pt;line-height: 112%;text-align: left;">到这里我们都假定训练样例由某个外部的施教者提供。假想学习器可以主宰实验进程， 下一步它要自己选择一个实例，然后从外界（自然界或一个施教者）获得该实例的正确分类 结果。这一场景可分为两种情况，一种是学习器在自然界中进行实验（如造一座新桥然后让 自然界决定其是否牢固），或在一个施教者指导下学习（提出一座新桥梁的设计，然后让施 教者来判断它是否牢固）。我们这里用查询（<span class="s6">query</span>）来代表学习器建立的这个实例，然后由 外界来对它分类。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 27pt;text-indent: 0pt;text-align: left;">再次考虑图 <span class="s6">2-3 </span>中所示的从 <span class="s21">EnjoySport </span>的 <span class="s6">4 </span>个样例中学习到的变型空间。这时学习器怎</p><p style="padding-left: 11pt;text-indent: 0pt;line-height: 113%;text-align: justify;">样能提出一个较好的查询？一般情况下怎样采取一种好的查询策略？显然学习器应试图在 当前变型空间中选择假设，以进一步划分该空间。因此，需要选择的实例需满足：它能被变 型空间中一些假设分类为正例，另一些分类为反例。其中一个这样的实例是：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 29pt;text-indent: 0pt;text-align: center;">&lt;<i>Sunny</i>, <i>Warm</i>, <i>Normal</i>, <i>Light</i>, <i>Warm</i>, <i>Same</i>&gt;</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 11pt;text-indent: 21pt;line-height: 107%;text-align: justify;">注意这一实例满足变型空间的 <span class="s6">6 </span>个假设中的 <span class="s6">3 </span>个。如果施教者将实例划分为正例，变型 空间的 <span class="s21">S </span>边界就需要被泛化。相反，如果施教者划分其为反例，<span class="s21">G </span>边界需要被特化。无论哪 种情况，机器将能够学到更多的知识，以确定目标概念，并将变型空间缩小到原来的一半。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 11pt;text-indent: 21pt;line-height: 109%;text-align: justify;"><span class="p">一般来说，概念学习的最优查询策略，是产生实例以满足当前变型空间中大致半数的假 设。如此，变型空间的大小可以在遇到每个新样例时减半，正确的目标概念就可在</span><span class="s10">⎡</span>log<span class="s35">2</span>|<i>VS</i>|<span class="s10">⎤</span> <span class="p">次实验后得到。这有点象玩“</span>20  <span class="p">问”游戏，通过问题的是／否回答逐渐获得问题的最终答 案，玩 </span>20 <span class="p">问游戏的策略是提的问题最好能把候选答案减半。虽然在图 </span>2-3 <span class="p">的变型空间中， 我们可以生成一个实例将其精确地分半。但一般情况下，可能无法构造出这样的精确分半的 实例。这样，查询的数目可能会多于</span><span class="s10">⎡</span>log<span class="s35">2</span>|<i>VS</i>|<span class="s10">⎤</span><span class="p">。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 11pt;text-indent: 0pt;text-align: justify;">2.6.3 <span class="s25">怎样使用不完全学习概念</span></h3><p style="padding-top: 10pt;padding-left: 29pt;text-indent: 0pt;text-align: center;">在上面的例子中，如果除了 <span class="s6">4 </span>个样例之外没有更多的训练样例，但机器现在要对未见过</p><p style="padding-top: 1pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">的实例进行分类。虽然图 <span class="s6">2-3 </span>的变型空间中仍包含多个假设，即目标概念还未完全学习到，</p><p style="padding-top: 1pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">仍然有可能对新样例进行一定可信度的分类。为示范这一过程，假定机器需要对表 <span class="s6">2-6 </span>中的</p><p class="s6" style="padding-top: 1pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">4 <span class="p">个新实例进行分类。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 29pt;text-indent: 0pt;text-align: center;">表 <span class="h4">2-6 </span>待分类的新实例</p><p style="text-indent: 0pt;text-align: left;"><br/></p><table style="border-collapse:collapse;margin-left:5.60001pt" cellspacing="0"><tr style="height:16pt"><td style="width:55pt;border-top-style:solid;border-top-width:2pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s53" style="padding-top: 1pt;padding-left: 11pt;text-indent: 0pt;text-align: left;">Instance</p></td><td style="width:49pt;border-top-style:solid;border-top-width:2pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s54" style="padding-top: 1pt;text-indent: 0pt;text-align: center;">Sky</p></td><td style="width:55pt;border-top-style:solid;border-top-width:2pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s54" style="padding-top: 1pt;padding-left: 13pt;text-indent: 0pt;text-align: left;">AirTemp</p></td><td style="width:56pt;border-top-style:solid;border-top-width:2pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s54" style="padding-top: 1pt;padding-left: 10pt;text-indent: 0pt;text-align: left;">Humidity</p></td><td style="width:52pt;border-top-style:solid;border-top-width:2pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s54" style="padding-top: 1pt;padding-left: 14pt;text-indent: 0pt;text-align: left;">Wind</p></td><td style="width:48pt;border-top-style:solid;border-top-width:2pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s54" style="padding-top: 1pt;padding-left: 15pt;text-indent: 0pt;text-align: left;">Water</p></td><td style="width:52pt;border-top-style:solid;border-top-width:2pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s54" style="padding-top: 1pt;padding-left: 11pt;text-indent: 0pt;text-align: left;">Forecast</p></td><td style="width:59pt;border-top-style:solid;border-top-width:2pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s54" style="padding-top: 1pt;padding-left: 8pt;text-indent: 0pt;text-align: left;">EnjoySport</p></td></tr><tr style="height:16pt"><td style="width:55pt;border-top-style:solid;border-top-width:1pt"><p class="s53" style="padding-top: 1pt;padding-right: 1pt;text-indent: 0pt;text-align: center;">A</p></td><td style="width:49pt;border-top-style:solid;border-top-width:1pt"><p class="s53" style="padding-top: 1pt;padding-left: 13pt;text-indent: 0pt;text-align: left;">Sunny</p></td><td style="width:55pt;border-top-style:solid;border-top-width:1pt"><p class="s53" style="padding-top: 1pt;padding-left: 17pt;text-indent: 0pt;text-align: left;">Warm</p></td><td style="width:56pt;border-top-style:solid;border-top-width:1pt"><p class="s53" style="padding-top: 1pt;padding-left: 13pt;text-indent: 0pt;text-align: left;">Normal</p></td><td style="width:52pt;border-top-style:solid;border-top-width:1pt"><p class="s53" style="padding-top: 1pt;padding-left: 12pt;text-indent: 0pt;text-align: left;">Strong</p></td><td style="width:48pt;border-top-style:solid;border-top-width:1pt"><p class="s53" style="padding-top: 1pt;padding-left: 17pt;text-indent: 0pt;text-align: left;">Cool</p></td><td style="width:52pt;border-top-style:solid;border-top-width:1pt"><p class="s53" style="padding-top: 1pt;padding-left: 13pt;text-indent: 0pt;text-align: left;">Change</p></td><td style="width:59pt;border-top-style:solid;border-top-width:1pt"><p class="s53" style="padding-top: 1pt;padding-right: 1pt;text-indent: 0pt;text-align: center;">?</p></td></tr><tr style="height:15pt"><td style="width:55pt"><p class="s53" style="padding-top: 1pt;padding-right: 1pt;text-indent: 0pt;text-align: center;">B</p></td><td style="width:49pt"><p class="s53" style="padding-top: 1pt;padding-left: 14pt;text-indent: 0pt;text-align: left;">Rainy</p></td><td style="width:55pt"><p class="s53" style="padding-top: 1pt;padding-left: 19pt;text-indent: 0pt;text-align: left;">Cold</p></td><td style="width:56pt"><p class="s53" style="padding-top: 1pt;padding-left: 13pt;text-indent: 0pt;text-align: left;">Normal</p></td><td style="width:52pt"><p class="s53" style="padding-top: 1pt;padding-left: 14pt;text-indent: 0pt;text-align: left;">Light</p></td><td style="width:48pt"><p class="s53" style="padding-top: 1pt;padding-left: 14pt;text-indent: 0pt;text-align: left;">Warm</p></td><td style="width:52pt"><p class="s53" style="padding-top: 1pt;padding-left: 17pt;text-indent: 0pt;text-align: left;">Same</p></td><td style="width:59pt"><p class="s53" style="padding-top: 1pt;padding-right: 1pt;text-indent: 0pt;text-align: center;">?</p></td></tr><tr style="height:15pt"><td style="width:55pt"><p class="s53" style="padding-top: 1pt;padding-right: 1pt;text-indent: 0pt;text-align: center;">C</p></td><td style="width:49pt"><p class="s53" style="padding-top: 1pt;padding-left: 13pt;text-indent: 0pt;text-align: left;">Sunny</p></td><td style="width:55pt"><p class="s53" style="padding-top: 1pt;padding-left: 17pt;text-indent: 0pt;text-align: left;">Warm</p></td><td style="width:56pt"><p class="s53" style="padding-top: 1pt;padding-left: 13pt;text-indent: 0pt;text-align: left;">Normal</p></td><td style="width:52pt"><p class="s53" style="padding-top: 1pt;padding-left: 14pt;text-indent: 0pt;text-align: left;">Light</p></td><td style="width:48pt"><p class="s53" style="padding-top: 1pt;padding-left: 14pt;text-indent: 0pt;text-align: left;">Warm</p></td><td style="width:52pt"><p class="s53" style="padding-top: 1pt;padding-left: 17pt;text-indent: 0pt;text-align: left;">Same</p></td><td style="width:59pt"><p class="s53" style="padding-top: 1pt;padding-right: 1pt;text-indent: 0pt;text-align: center;">?</p></td></tr><tr style="height:15pt"><td style="width:55pt;border-bottom-style:solid;border-bottom-width:2pt"><p class="s53" style="padding-top: 1pt;padding-right: 1pt;text-indent: 0pt;text-align: center;">D</p></td><td style="width:49pt;border-bottom-style:solid;border-bottom-width:2pt"><p class="s53" style="padding-top: 1pt;padding-left: 13pt;text-indent: 0pt;text-align: left;">Sunny</p></td><td style="width:55pt;border-bottom-style:solid;border-bottom-width:2pt"><p class="s53" style="padding-top: 1pt;padding-left: 20pt;text-indent: 0pt;text-align: left;">Cold</p></td><td style="width:56pt;border-bottom-style:solid;border-bottom-width:2pt"><p class="s53" style="padding-top: 1pt;padding-left: 13pt;text-indent: 0pt;text-align: left;">Normal</p></td><td style="width:52pt;border-bottom-style:solid;border-bottom-width:2pt"><p class="s53" style="padding-top: 1pt;padding-left: 12pt;text-indent: 0pt;text-align: left;">Strong</p></td><td style="width:48pt;border-bottom-style:solid;border-bottom-width:2pt"><p class="s53" style="padding-top: 1pt;padding-left: 14pt;text-indent: 0pt;text-align: left;">Warm</p></td><td style="width:52pt;border-bottom-style:solid;border-bottom-width:2pt"><p class="s53" style="padding-top: 1pt;padding-left: 17pt;text-indent: 0pt;text-align: left;">Same</p></td><td style="width:59pt;border-bottom-style:solid;border-bottom-width:2pt"><p class="s53" style="padding-top: 1pt;padding-right: 1pt;text-indent: 0pt;text-align: center;">?</p></td></tr></table><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-top: 1pt;padding-left: 10pt;text-indent: 21pt;line-height: 109%;text-align: justify;"><span class="p">注意，虽然实例 </span>A <span class="p">不在训练样例中，但当前变型空间中，每个假设（见图 </span><span class="s6">2-3</span><span class="p">）都将其 分类为正例。由于变型空间的所有假设一致同意实例 </span>A <span class="p">为正例，学习器将 </span>A <span class="p">划分为正例的 可信度，与只有单个的目标概念时一样。不管变型空间中哪个假设最终成为目标概念，它都 会将其划分为正例。进一步，我们知道不需要列举变型空间中所有的假设，就可知道每个假 设都会将其划分为正例。这一条件成立当且仅当实例满足 </span>S <span class="p">的每个成员（为什么？）。原因 是变型空间中的其他每个假设，都至少比 </span>S <span class="p">的某个成员更一般。由我们的 </span>more<span class="s6">-</span>general<span class="s6">-</span>than <span class="p">的定义，如果新的实例满足 </span>S <span class="p">的所有成员，它一定也满足这些更一般的假设。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;line-height: 107%;text-align: justify;">相似地，实例 <span class="s21">B </span>被变型空间中的每个假设划分为反例。所以这个实例可被放心地划分 为反例，即使概念是不完全学习的。对这一条件的测试的有效方法是，判断实例不满足 <span class="s21">G </span>中的所有成员（为什么？）。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;line-height: 107%;text-align: justify;">实例 <span class="s21">C </span>的情况有所不同。变型空间中半数的假设划分其为正例，半数划分为反例。因 此，学习器无法可信地分类这一样例，除非提供更多的训练样例。注意到，实例 <span class="s21">C </span>与前一 节提出的一个最优查询相同。这是可以预见的，因为最有分类歧义性的实例也一定最能提供</p><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;">新的分类信息。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;line-height: 107%;text-align: justify;">最后，实例 <span class="s21">D </span>在变型空间中被两个假设分为正例，被其他 <span class="s6">4 </span>个假设分为反例。这个例 子的分类可信度比实例 <span class="s21">A </span>和 <span class="s21">B </span>要小。投票选举要倾向于反例分类，所以我们可以输出拥有 最大票数的分类，还可附带一个可信度比例以表明投票的倾向程度。在第 <span class="s6">6 </span>章将讨论到，如 果假定 <span class="s21">H </span>中所有假设是有相等的先验概率，那么投票的方法能得到新实例的最可能分类。 进一步的，投正例票假设所占的比例可视为：在给定训练数据时，实例为正例的可能性。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 11pt;text-indent: 0pt;text-align: left;">2.7 <span class="s17">归纳偏置</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 11pt;text-indent: 21pt;line-height: 113%;text-align: justify;">如上所述，在给定正确的训练样例并且保证初始假设空间包含目标概念时，候选消除算 法可以收敛到目标概念。如果目标概念不在假设空间中怎么办？是否可设计一包含所有假设 的空间来解决这一困难？假设空间的大小对于算法推广到未见实例的能力有什么影响？假 设空间的大小对所需训练样例的数量有什么影响？这些都是归纳推理中的一些基本问题。这 里我们在候选消除算法中考察这些问题。然而可以看到，这里的分析中得到的结论可以应用 于任意的概念学习系统。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 11pt;text-indent: 0pt;text-align: left;">2.7.1 <span class="s25">一个有偏的假设空间</span></h3><p class="s21" style="padding-top: 10pt;padding-left: 10pt;text-indent: 21pt;line-height: 109%;text-align: justify;"><span class="p">如果想保证假设空间包含目标概念，一个明显的方法是扩大假设空间，使每个可能的假 设都包含在内。再一次使用 </span>EnjoySport <span class="p">这个例子，其中我们将假设空间限制为只包含属性值 的合取。由于这一限制，假设空间不能够表示最简单的析取形式的目标概念，如“</span>Sky<span class="s6">=</span>Sunny <span class="p">或 </span>Sky<span class="s6">=</span>Cloudy<span class="p">”。实际上，如果给定以下三个训练样例，它们来自于该析取式假设，我们的 算法将得到一个空的变型空间。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><table style="border-collapse:collapse;margin-left:5.60001pt" cellspacing="0"><tr style="height:16pt"><td style="width:55pt;border-top-style:solid;border-top-width:2pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s53" style="padding-top: 1pt;padding-left: 10pt;text-indent: 0pt;text-align: left;">Example</p></td><td style="width:50pt;border-top-style:solid;border-top-width:2pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s54" style="padding-top: 1pt;text-indent: 0pt;text-align: center;">Sky</p></td><td style="width:54pt;border-top-style:solid;border-top-width:2pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s54" style="padding-top: 1pt;padding-left: 12pt;text-indent: 0pt;text-align: left;">AirTemp</p></td><td style="width:56pt;border-top-style:solid;border-top-width:2pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s54" style="padding-top: 1pt;padding-left: 10pt;text-indent: 0pt;text-align: left;">Humidity</p></td><td style="width:52pt;border-top-style:solid;border-top-width:2pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s54" style="padding-top: 1pt;padding-left: 14pt;text-indent: 0pt;text-align: left;">Wind</p></td><td style="width:48pt;border-top-style:solid;border-top-width:2pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s54" style="padding-top: 1pt;padding-left: 15pt;text-indent: 0pt;text-align: left;">Water</p></td><td style="width:52pt;border-top-style:solid;border-top-width:2pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s54" style="padding-top: 1pt;padding-left: 11pt;text-indent: 0pt;text-align: left;">Forecast</p></td><td style="width:59pt;border-top-style:solid;border-top-width:2pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s54" style="padding-top: 1pt;padding-left: 8pt;text-indent: 0pt;text-align: left;">EnjoySport</p></td></tr><tr style="height:16pt"><td style="width:55pt;border-top-style:solid;border-top-width:1pt"><p class="s53" style="padding-top: 1pt;padding-right: 1pt;text-indent: 0pt;text-align: center;">1</p></td><td style="width:50pt;border-top-style:solid;border-top-width:1pt"><p class="s53" style="padding-top: 1pt;padding-left: 13pt;text-indent: 0pt;text-align: left;">Sunny</p></td><td style="width:54pt;border-top-style:solid;border-top-width:1pt"><p class="s53" style="padding-top: 1pt;padding-left: 16pt;text-indent: 0pt;text-align: left;">Warm</p></td><td style="width:56pt;border-top-style:solid;border-top-width:1pt"><p class="s53" style="padding-top: 1pt;padding-left: 13pt;text-indent: 0pt;text-align: left;">Normal</p></td><td style="width:52pt;border-top-style:solid;border-top-width:1pt"><p class="s53" style="padding-top: 1pt;padding-left: 12pt;text-indent: 0pt;text-align: left;">Strong</p></td><td style="width:48pt;border-top-style:solid;border-top-width:1pt"><p class="s53" style="padding-top: 1pt;padding-left: 17pt;text-indent: 0pt;text-align: left;">Cool</p></td><td style="width:52pt;border-top-style:solid;border-top-width:1pt"><p class="s53" style="padding-top: 1pt;padding-left: 13pt;text-indent: 0pt;text-align: left;">Change</p></td><td style="width:59pt;border-top-style:solid;border-top-width:1pt"><p class="s53" style="padding-top: 1pt;padding-right: 1pt;text-indent: 0pt;text-align: center;">Yes</p></td></tr><tr style="height:15pt"><td style="width:55pt"><p class="s53" style="padding-top: 1pt;padding-right: 1pt;text-indent: 0pt;text-align: center;">2</p></td><td style="width:50pt"><p class="s53" style="padding-top: 1pt;padding-left: 11pt;text-indent: 0pt;text-align: left;">Cloudy</p></td><td style="width:54pt"><p class="s53" style="padding-top: 1pt;padding-left: 16pt;text-indent: 0pt;text-align: left;">Warm</p></td><td style="width:56pt"><p class="s53" style="padding-top: 1pt;padding-left: 13pt;text-indent: 0pt;text-align: left;">Normal</p></td><td style="width:52pt"><p class="s53" style="padding-top: 1pt;padding-left: 12pt;text-indent: 0pt;text-align: left;">Strong</p></td><td style="width:48pt"><p class="s53" style="padding-top: 1pt;padding-left: 17pt;text-indent: 0pt;text-align: left;">Cool</p></td><td style="width:52pt"><p class="s53" style="padding-top: 1pt;padding-left: 13pt;text-indent: 0pt;text-align: left;">Change</p></td><td style="width:59pt"><p class="s53" style="padding-top: 1pt;padding-right: 1pt;text-indent: 0pt;text-align: center;">Yes</p></td></tr><tr style="height:15pt"><td style="width:55pt;border-bottom-style:solid;border-bottom-width:2pt"><p class="s53" style="padding-top: 1pt;padding-right: 1pt;text-indent: 0pt;text-align: center;">3</p></td><td style="width:50pt;border-bottom-style:solid;border-bottom-width:2pt"><p class="s53" style="padding-top: 1pt;padding-left: 14pt;text-indent: 0pt;text-align: left;">Rainy</p></td><td style="width:54pt;border-bottom-style:solid;border-bottom-width:2pt"><p class="s53" style="padding-top: 1pt;padding-left: 16pt;text-indent: 0pt;text-align: left;">Warm</p></td><td style="width:56pt;border-bottom-style:solid;border-bottom-width:2pt"><p class="s53" style="padding-top: 1pt;padding-left: 13pt;text-indent: 0pt;text-align: left;">Normal</p></td><td style="width:52pt;border-bottom-style:solid;border-bottom-width:2pt"><p class="s53" style="padding-top: 1pt;padding-left: 12pt;text-indent: 0pt;text-align: left;">Strong</p></td><td style="width:48pt;border-bottom-style:solid;border-bottom-width:2pt"><p class="s53" style="padding-top: 1pt;padding-left: 17pt;text-indent: 0pt;text-align: left;">Cool</p></td><td style="width:52pt;border-bottom-style:solid;border-bottom-width:2pt"><p class="s53" style="padding-top: 1pt;padding-left: 13pt;text-indent: 0pt;text-align: left;">Change</p></td><td style="width:59pt;border-bottom-style:solid;border-bottom-width:2pt"><p class="s53" style="padding-top: 1pt;padding-right: 1pt;text-indent: 0pt;text-align: center;">No</p></td></tr></table><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 10pt;text-indent: 21pt;line-height: 107%;text-align: justify;">之所以不存在与这 <span class="s6">3 </span>个样例一致的假设的原因是，与头两个样例一致，并且能在给定假 设空间 <span class="s21">H </span>中表示的最特殊的假设是：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 133pt;text-indent: 0pt;text-align: left;">S<span class="s35">2</span><span class="s6">: &lt;?, </span>Warm<span class="s6">, </span>Nornal<span class="s6">, </span>Strong<span class="s6">, </span>Cool<span class="s6">, </span>Change<span class="s6">&gt;</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;line-height: 110%;text-align: justify;">这一假设虽然是 <span class="s21">H </span>中与样例一致的最特殊的假设，它仍然过于一般化了：它将第三个 样例错误地划为正例。问题在于，我们使学习器偏向于只考虑合取的假设，这里需要表示能 力更强的假设空间。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 11pt;text-indent: 0pt;text-align: left;">2.7.2 <span class="s25">无偏的学习器</span></h3><p style="padding-top: 10pt;padding-left: 10pt;text-indent: 21pt;line-height: 110%;text-align: justify;">很显然，为了保证目标概念在假设空间中，需要提供一个假设空间，它能表达所有的可 教授概念<span class="s6">(every teachable concept)</span>。换言之，它能够表达实例集 <span class="s21">X </span>的所有可能的子集。一般 地，我们把集合 <span class="s21">X </span>所有子集的集合称为 <span class="s21">X </span>的幂集（<span class="s6">power set</span>）。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;line-height: 107%;text-align: justify;">例如在<span class="s21">EnjoySport</span>学习任务中，使用 <span class="s6">6 </span>种属性描述的实例空间<span class="s21">X</span>的大小为 <span class="s6">96</span>。在这一实 例集合上可以定义多少概念？换言之，<span class="s21">X</span>的幂集大小是什么？一般说来在集合<span class="s21">X</span>上定义的相</p><p style="padding-top: 2pt;padding-left: 5pt;text-indent: 0pt;line-height: 107%;text-align: justify;">异子集数目（即<span class="s21">X</span>幂集的大小）为 <span class="s6">2</span><span class="s46">|</span><span class="s41">X</span><span class="s42">|</span>，其中<span class="s6">|</span><span class="s21">X</span><span class="s6">|</span>是<span class="s21">X</span>的元素数目。因此在这一实例空间上可定 义 <span class="s6">2</span><span class="s46">96</span>，或大约是 <span class="s6">10</span><span class="s46">28</span>个不同的目标概念，这也是学习器所需要学习的目标概念数目。回忆 <span class="s6">2.3 </span>节中合取假设空间只能表示 <span class="s6">973 </span>个假设——实在是一个偏置很大的假设空间！</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: left;"><span class="p">现在将 </span>EnjoySport <span class="p">学习任务重新定义为一种无偏的形式。方法是定义一个新的假设空间 </span>H<span class="s6">´</span><span class="p">，它能表示实例的每一个子集，也就是把 </span>H<span class="s6">´</span><span class="p">对应到 </span>X <span class="p">的幂集。定义 </span>H<span class="s6">´</span><span class="p">的一种办法是，</span><span class="s24">允 许使用前面的假设的任意析取、合取和否定式</span><span class="p">。例如目标概念“</span>Sky<span class="s6">=</span>Sunny <span class="p">或 </span>Sky<span class="s6">=</span>Cloudy<span class="p">” 可被描述为：</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 26pt;text-indent: 0pt;text-align: left;">&lt;<i>Sunny</i>, ?, ?, ?, ?, ?&gt; <span class="p">∨ </span>&lt;<i>Cloudy</i>, ?, ?, ?, ?, ?&gt;</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 113%;text-align: justify;">给定这样的假设空间，我们就可以安全地使用候选消除算法，而不必担心无法表达目标 概念。然而，虽然这个假设空间排除了表达能力的问题，它又产生了一个新的、同样困难的 问题：概念学习算法将完全无法从训练样例中泛化！其原因如下，假定我们提供了 <span class="s6">3 </span>个正例</p><p style="padding-left: 6pt;text-indent: 0pt;text-align: justify;">（<span class="s21">x</span><span class="s35">1</span>，<span class="s21">x</span><span class="s35">2</span>，<span class="s21">x</span><span class="s35">3</span>）以及两个反例（<span class="s21">x</span><span class="s35">4</span>，<span class="s21">x</span><span class="s35">5</span>）给学习器。这时，变型空间的<span class="s21">S</span>边界包含的假设正好 是三个正例的析取：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 27pt;text-indent: 0pt;text-align: left;">S<span class="s6">: { (</span>x<span class="s35">1</span><span class="p">∨</span>x<span class="s35">2</span><span class="p">∨</span>x<span class="s35">3</span><span class="s6">) }</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">因为这是能覆盖 <span class="s6">3 </span>个正例的最特殊假设。相似地，<span class="s21">G </span>边界将由那些刚好能排除掉反例的 那些假设组成。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 26pt;text-indent: 0pt;text-align: left;">G<span class="s6">: {</span><span class="s10"> </span><span class="s6">(</span>x<span class="s35">4</span><span class="p">∨</span>x<span class="s35">5</span><span class="s6">)}</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: left;">问题在于，这一非常具有表达力的假设表示方法中，<span class="s21">S </span>边界总是简单的所有正例析取式， <span class="s21">G </span>边界总是所有反例的析取的否定式。这样能够由 <span class="s21">S </span>和 <span class="s21">G </span>无歧义地分类的，只有已见到的 训练样例本身。要想获得单个的目标概念，就必须提供 <span class="s21">X </span>中所有的实例作为训练样例。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 109%;text-align: justify;">看起来避免这一问题的方法可以使用此部分学习的变型空间，然后如 <span class="s6">2.6.3 </span>节中那样由 变型空间的所有成员投票。不幸的是，能够产生一致投票的只有那些已见过的训练样例。对 其他所有的实例，进行投票没有任何效果：每一个未见过的实例都会被变型空间中刚好半数 的假设划分为正例，而被另一半划分为反例（为什么？）。原因如下，若 <span class="s21">H </span>是 <span class="s21">X </span>的幂集，而 <span class="s21">x </span>是某个未出现过的实例，则对于变型空间中一覆盖 <span class="s21">x </span>的假设 <span class="s21">h</span>，必然存在另一假设 <span class="s21">h</span><span class="s6">´</span>，它 与 <span class="s21">h </span>几乎相等只不过对 <span class="s21">x </span>的分类不同。而且如果 <span class="s21">h </span>在变型空间中，那么 <span class="s21">h</span><span class="s6">´</span>也在，因为它对于 已往训练样例的划分与 <span class="s21">h </span>完全一样。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 6pt;text-indent: 0pt;text-align: justify;">2.7.3 <span class="s25">无偏学习的无用性</span></h3><p style="padding-top: 10pt;padding-left: 6pt;text-indent: 21pt;line-height: 112%;text-align: justify;">以上的讨论说明了归纳推理的一个基本属性：学习器如果不对目标概念的形式做预先的 假定，它从根本上无法对未见实例进行分类。实际上在我们原来的 <span class="s21">EnjoySport </span>任务中，候选 消除算法能够从训练样例中泛化，其惟一的原因就是它是有偏的，它隐含假定了目标概念可 以由属性值的合取来表示。如果这一假定正确（并且训练数据无错），对于新实例的分类也 会是正确的。但如果这个假定不正确，候选消除算法肯定会错误地分类 <span class="s21">X </span>中某些实例。</p><p class="s21" style="padding-top: 2pt;padding-left: 5pt;text-indent: 21pt;line-height: 108%;text-align: justify;"><span class="p">由于归纳学习需要某种形式的预先假定，或称为</span><span class="s24">归纳偏置（</span><span class="s63">Inductive bias</span><span class="s24">）</span><span class="s46">*</span><span class="p">，我们可以 用归纳偏置来描述不同学习方法的特征。现在来精确地定义归纳偏置。这里要获取的关键思 想在于，学习器在从训练样例中泛化并推断新实例的分类过程中所采用的策略。因此，考虑 一般情况下任意的学习算法</span>L<span class="p">，以及为任意目标概念</span>c<span class="p">提供的任意训练数据</span>D<span class="s36">c</span><span class="s6">={&lt;</span>x<span class="s6">, </span>c<span class="s6">(</span>x<span class="s6">)&gt;}</span><span class="p">。 训练过程结束后，</span>L<span class="p">需要对新的实例</span>x<span class="s36">i</span><span class="p">进行分类。令</span>L<span class="s6">(</span>x<span class="s36">i</span><span class="s6">, </span>D<span class="s36">c</span><span class="s6">)</span><span class="p">表示在对训练数据</span>D<span class="s36">c</span><span class="p">学习后</span>L<span class="p">赋 予</span>x<span class="s36">i</span><span class="p">的分类（正例或反例），我们可以如下描述</span>L<span class="p">所进行的这一归纳推理过程：</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 24pt;text-indent: 0pt;text-align: center;"><span class="s6">(</span>D<span class="s36">c</span><span class="p">∧</span>x<span class="s36">i</span><span class="s6">) </span><span class="s68">f </span>L<span class="s6">(</span>x<span class="s36">i</span><span class="s6">,</span>D<span class="s36">c</span><span class="s6">)</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 26pt;text-indent: 0pt;text-align: left;"><span class="p">这里的记号</span>y <span class="s68">f </span>z<span class="p">表示</span>z<span class="p">从</span>y<span class="p">归纳推理得到，例如，如果令</span>L<span class="p">为候选消除算法，</span>D<span class="s36">c</span><span class="p">为表 </span><span class="s6">2-1</span></p><p class="s21" style="padding-left: 27pt;text-indent: -21pt;text-align: left;"><span class="p">中的训练数据，</span>x<span class="s36">i</span><span class="p">为表 </span><span class="s6">2-6 </span><span class="p">中第一个实例，则归纳推理可得到结论</span>L<span class="s6">(</span>x<span class="s36">i</span><span class="s6">, </span>D<span class="s36">c</span><span class="s6">)=(</span>EnjoySport<span class="s6">=</span>yes<span class="s6">)</span><span class="p">。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 6pt;text-indent: 21pt;text-align: left;"><span class="p">由于</span>L<span class="p">是一归纳学习算法，则一般情况下</span>L<span class="s6">(</span>x<span class="s36">i</span><span class="s6">, </span>D<span class="s36">c</span><span class="s6">)</span><span class="p">这一推论出的结果正确性无法证明；也 就是说，分类</span>L<span class="s6">(</span>x<span class="s36">i</span><span class="s6">, </span>D<span class="s36">c</span><span class="s6">)</span><span class="p">并非从训练数据</span>D<span class="s36">c</span><span class="p">和新实例</span>x<span class="s36">i</span><span class="p">中演绎派生。然而问题是，需要在</span>D<span class="s36">c</span><span class="p">∧</span>x<span class="s36">i </span><span class="p">上附加怎样的前提，以使</span>L<span class="s6">(</span>x<span class="s36">i</span><span class="s6">,</span>D<span class="s36">c</span><span class="s6">)</span><span class="p">能演绎派生。我们定义</span>L<span class="p">的归纳偏置为这些附加前提的集合。 更精确地说，我们定义</span>L<span class="p">的归纳偏置为前提集合</span>B<span class="p">，使所有的新实例</span>x<span class="s36">i</span><span class="p">满足。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 26pt;text-indent: 0pt;text-align: left;"><span class="s6">(</span>B<span class="p">∧</span>D<span class="s36">c</span><span class="p">∧</span>x<span class="s36">i</span><span class="s6">) </span><span class="p">├ </span>L<span class="s6">(</span>x<span class="s36">i</span><span class="s6">, </span>D<span class="s36">c</span><span class="s6">)</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">这里的记号 <span class="s21">y</span>├<span class="s21">z </span>表示 <span class="s21">z </span>从 <span class="s21">y </span>演绎派生（<span class="s6">follow deductively</span>，或 <span class="s21">z </span>可以由 <span class="s21">y </span>证明得出）。这 样，我们定义学习器的归纳编向为附加的前提集合 <span class="s21">B</span>，通过 <span class="s21">B </span>充分地使归纳推理由演绎推理 来论证。以下是该定义的总结：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 47pt;text-indent: -21pt;text-align: justify;"><span class="p">定义： 考虑对于实例集合</span>X<span class="p">的概念学习算法</span>L<span class="p">。令</span>c<span class="p">为</span>X<span class="p">上定义的任一概念，并令</span>D<span class="s36">c</span><span class="s6">={&lt;</span>x<span class="s6">, </span>c<span class="s6">(</span>x<span class="s6">)&gt;}</span><span class="p">为</span>c<span class="p">的任意训练样例集合。令</span>L<span class="s6">(</span>x<span class="s36">i</span><span class="s6">, </span>D<span class="s36">c</span><span class="s6">)</span><span class="p">表示经过数据</span>D<span class="s36">c</span><span class="p">的训练后，</span>L<span class="p">赋予实例</span>x<span class="s36">i </span><span class="p">的分类。</span>L<span class="p">的归纳偏置是最小断言集合</span>B<span class="p">，它使任意目标概念</span>c<span class="p">和相应的训练样例</span>D<span class="s36">c</span><span class="s41"> </span><span class="p">满足：</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 24pt;text-indent: 0pt;text-align: center;"><span class="s6">(</span><span class="s10"></span>x<span class="s36">i</span><span class="p">∈</span>X<span class="s6">)[ (</span>B<span class="p">∧</span>D<span class="s36">c</span><span class="p">∧</span>x<span class="s36">i</span><span class="s6">) </span><span class="p">├ </span>L<span class="s6">(</span>x<span class="s36">i</span><span class="s6">, </span>D<span class="s36">c</span><span class="s6">)] (2.1)</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 5pt;text-indent: 21pt;text-align: justify;"><span class="p">那么，候选消除算法的归纳偏置是什么呢？首先确定这一算法的</span>L<span class="s6">(</span>x<span class="s36">i</span><span class="s6">, </span>D<span class="s36">c</span><span class="s6">)</span><span class="p">：给定数据集 </span>D<span class="s36">c</span><span class="p">，候选消除算法首先计算变型空间</span>VS<span class="s36">H</span><span class="s42">,</span><span class="s41">D</span><span class="s69">c</span><span class="p">，然后在变型空间所包含的假设中投票，进行新 实例</span>x<span class="s36">i</span><span class="p">的分类。这里假定产生</span>x<span class="s36">i</span><span class="p">的分类的条件是投票一致为正或为负，否则不进行分类。现 在来回答什么是候选消除算法</span>L<span class="s6">(</span>x<span class="s36">i</span><span class="s6">, </span>D<span class="s36">c</span><span class="s6">)</span><span class="p">的归纳偏置的问题：很简单，就是</span>c<span class="p">∈</span>H<span class="p">这个前提。有 了这一前提，候选消除算法所执行的每一归纳推理都可以被演绎论证。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 5pt;text-indent: 21pt;text-align: justify;"><span class="p">现在看一看为什么</span>L<span class="s6">(</span>x<span class="s36">i</span><span class="s6">, </span>D<span class="s36">c</span><span class="s6">)</span><span class="p">这一分类可由</span>B<span class="s6">={</span>c<span class="p">∈</span>H<span class="s6">}</span><span class="p">、数据</span>D<span class="s36">c</span><span class="p">和实例</span>x<span class="s36">i</span><span class="p">演绎派生。首先， 注意如果假定</span>c<span class="p">∈</span>H<span class="p">，那么可演绎派生出</span>c<span class="p">∈</span>VS<span class="s36">H</span><span class="s42">,</span><span class="s41">Dc</span><span class="p">。这一派生的条件除</span>c<span class="p">∈</span>H<span class="p">，还包括变型空 间</span>VS<span class="s36">H</span><span class="s42">,</span><span class="s41">Dc</span><span class="p">的定义（即</span>H<span class="p">中与</span>D<span class="s36">c</span><span class="p">一致的所有假设集合），以及对</span>D<span class="s36">c</span><span class="s6">={&lt;</span>x<span class="s6">, </span>c<span class="s6">(</span>x<span class="s6">)&gt;}</span><span class="p">的定义（即与目标 概念一致的训练数据）。其次，由于</span>L<span class="s6">(</span>x<span class="s36">i</span><span class="s6">, </span>D<span class="s36">c</span><span class="s6">)</span><span class="p">是一分类，它定义为变型空间中所有假设的一致 投票。因此，如果</span>L<span class="p">输出分类</span>L<span class="s6">(</span>x<span class="s36">i</span><span class="s6">, </span>D<span class="s36">c</span><span class="s6">)</span><span class="p">，那么</span>VS<span class="s36">H</span><span class="s42">,</span><span class="s41">Dc</span><span class="p">中每一假设必将产生同样的分类，包括假 设</span>c<span class="p">∈</span>VS<span class="s36">H</span><span class="s42">,</span><span class="s41">Dc</span><span class="p">。因此</span>c<span class="s6">(</span>x<span class="s36">i</span><span class="s6">)=</span>L<span class="s6">(</span>x<span class="s36">i</span><span class="s6">, </span>D<span class="s36">c</span><span class="s6">)</span><span class="p">候选消除算法的归纳偏置概括说明如下：</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 26pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="193" height="1" alt="image" src="机器学习/Image_040.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-top: 3pt;padding-left: 5pt;text-indent: 21pt;line-height: 125%;text-align: left;"><span class="s70">* </span>这里的术语归纳偏置（<span class="s16">inductive bias</span>）不要和统计学中普遍使用的估计偏差（<span class="s16">estimation bias</span>）混淆。 估计偏差将在第 <span class="s16">5 </span>章讨论。</p><p style="padding-left: 27pt;text-indent: 0pt;text-align: left;">候选消除算法的归纳偏置：目标概念 <span class="s21">c </span>包含在给定的假设空间 <span class="s21">H </span>中。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 13pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="547" height="1" alt="image" src="机器学习/Image_041.png"/></span></p><p class="s48" style="padding-left: 15pt;text-indent: 0pt;text-align: left;">插图——原书页码： <span class="s21">44</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;line-height: 190%;text-align: left;">Inductive system: <span class="p">归纳系统 </span>Training examples: <span class="p">训练样例 </span>New instance: <span class="p">新实例</span></p><p class="s6" style="padding-top: 2pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">Candidate Elimination Algorithm <span class="p">候选消除算法</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 6pt;text-indent: 0pt;text-align: left;">Using Hypothesis Space H: <span class="p">使用假设空间 </span>H</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 6pt;text-indent: 0pt;text-align: left;">Classification of new instance, or “don&#39;t know”: <span class="p">对新实例的分类，或“无法分类”</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Equivalent deductive system: <span class="p">等价的演绎系统</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Assertion “H contains the target concept”: <span class="p">断言：“</span>H <span class="p">包含目标概念”</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Theorem Prover:<span class="p">定理证明器</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Inductive bias made explicit: <span class="p">被明确化的归纳偏置</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 14pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="531" height="1" alt="image" src="机器学习/Image_042.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 129pt;text-indent: 0pt;text-align: left;">图 <span class="h4">2-8 </span>用等价的演绎系统来模拟归纳系统</p><p class="s14" style="padding-top: 6pt;padding-left: 37pt;text-indent: 0pt;line-height: 12pt;text-align: justify;">使用假设空间 <span class="s56">H </span>的候选消除算法的输入输出行为，等价于利用了断言“<span class="s56">H </span>包含目标概念”的演绎 定理证明器。该断言因此被称为候选消除算法的归纳偏置。用归纳偏置来刻画归纳系统，可以便于 使用等价的演绎系统来模拟它们。这提供了一种对归纳系统进行比较的方法，通过它们从训练数据 中泛化的策略。</p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 21pt;line-height: 110%;text-align: left;">图 <span class="s6">2-8 </span>为一示意图解。上面的图显示的候选消除算法有两个输入：训练样例和待分类的 新实例。下面的图为一演绎定理证明器，它的输入包括同样的两组数据，再加上断言“<span class="s21">H </span>包 含目标概念”。这两个系统对所有可能的训练样例输入和新实例输入产生同样的输出。当然， 在定理证明器中显式输入的归纳偏置只是隐含在了候选消除算法的代码中。在某种意义上， 归纳偏置只在我们的印象中存在，但它确实是能被完整定义的断言集合。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 113%;text-align: left;">将归纳推理系统看作是包含了归纳偏置，好处在于它提供了一种非程序化的描述手段， 以描述学习器从观察到的数据中进行泛化的策略。其次它还可以对归纳偏置强度不同的学习 器进行比较。例如，考虑以下 <span class="s6">3 </span>个学习算法，按其有偏程度从弱到强进行排序：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 32pt;text-indent: 0pt;line-height: 110%;text-align: left;">1. <span class="p">机械学习器（</span>Rote-Learner<span class="p">）。简单地将每个观察到的训练样例存储下来。后续的实 例的分类通过在内存中匹配进行。如果实例在内存中找到了，存储的分类结果被输出。 否则系统拒绝进行分类。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 33pt;text-indent: 0pt;line-height: 107%;text-align: left;">2. <span class="p">候选消除算法。新的实例只在变型空间所有成员都进行同样分类时才输出分类结 果，否则系统拒绝分类。</span></p><p class="s6" style="padding-left: 27pt;text-indent: 6pt;line-height: 107%;text-align: left;">3. Find-S<span class="p">。如前所述，这一算法寻找与训练样例一致的最特殊的假设，它用这一假设 来分类后续实例。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 112%;text-align: justify;">记忆学习器没有归纳偏置。对于新实例所做的分类能从已观察到的训练样例中演绎派 生，不需要附加的前提。候选消除算法有较强的归纳偏置：即目标概念须在假设空间中能表 示。由于它是有偏的，所以能够对记忆学习器不能分类的实例进行分类。当然分类的正确性 也完全依赖于归纳偏置的正确性。<span class="s6">Find-S</span>算法有更强的归纳偏置，除了假定目标概念须在假 设空间中，它还有另一额外的归纳偏置前提：任何实例，除非它的逆实例可由其他知识逻辑 推出，否则它为反例。<span class="s46">*</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 111%;text-align: justify;">在研究其他的归纳推理方法时，有必要牢记这种归纳偏置的存在及其强度。一种算法如 果有偏性越强，那它的归纳能力越强，可以分类更多的未见实例。某些归纳偏置是对类别的 假定，以确定目标概念的范围。如“假设空间 <span class="s21">H </span>包含目标概念”。其他的归纳偏置只是对假 设进行排序，以描述偏好程度，比如“偏向于特殊假设，而不是一般假设。”某些偏置隐含 在学习器中不可更改，如这里所讨论的例子。在第 <span class="s6">11 </span>和 <span class="s6">12 </span>章可以看到明确表示归纳偏置的 系统，它们将偏置表示为断言的集合并可由学习器操纵。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 5pt;text-indent: 0pt;text-align: center;">2.8 <span class="s17">小结和补充读物</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 27pt;text-indent: 0pt;text-align: left;">本章的要点包括：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s71" style="padding-left: 27pt;text-indent: 0pt;text-align: left;">n <span class="p">概念学习可看作是搜索预定义潜在假设空间的过程。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s71" style="padding-left: 48pt;text-indent: -21pt;line-height: 108%;text-align: left;">n <span class="p">假设的一般到特殊偏序结构可以定义在任何概念学习问题中，它提供了一种有用的 结构以便于假设空间的搜索。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s71" style="padding-left: 48pt;text-indent: -21pt;line-height: 107%;text-align: left;">n <span class="s6">Find-S </span><span class="p">算法使用了一般到特殊序，在偏序结构的一个分支上执行的一般到特殊搜 索，以寻找与样例一致的最特殊假设。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 48pt;text-indent: -21pt;line-height: 107%;text-align: left;"><span class="s71">n </span>候选消除算法利用一般到特殊序，通过渐进地计算极大特殊假设集合 <span class="s21">S </span>和极大一般 假设集合 <span class="s21">G </span>计算变型空间（即所有与训练数据一致的假设集）。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 48pt;text-indent: -21pt;line-height: 111%;text-align: left;"><span class="s71">n </span>由于 <span class="s21">S </span>和 <span class="s21">G </span>从整个假设集合中划分出了与训练数据一致的那部分集合，它们提供 了对目标概念的不确定性描述。含有多个假设的变型空间可以用来判断学习器是否 已收敛到了目标概念；判断训练数据是否不一致；产生查询以进一步精化变型空间； 以及确定未见过的实例是否能用不完全学习到的概念来无歧义地分类。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 48pt;text-indent: -21pt;line-height: 110%;text-align: justify;"><span class="s71">n </span>变型空间和候选消除算法为研究概念学习提供了一种有用的框架，然而这一算法缺 少鲁棒性，特别是在遇到有噪声的数据以及目标概念无法在假设空间中表示的情况 下。第 <span class="s6">10 </span>章描述了几种基于一般到特殊序关系的概念学习算法，它们能够处理有 噪声数据。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 26pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="193" height="1" alt="image" src="机器学习/Image_043.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s70" style="padding-top: 3pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">* <span class="s14">注意最后面这个归纳偏置假定，它包含了某种默认推理，或非单调推理。</span></p><p style="padding-top: 2pt;padding-left: 48pt;text-indent: -21pt;line-height: 107%;text-align: justify;"><span class="s71">n </span>归纳学习算法能够对未见数据进行分类，是因为它们在选择一致的假设时隐含的归 纳偏置。候选消除算法中的偏置为：目标概念可以在假设空间中找到（<span class="s21">c</span>∈<span class="s21">H</span>）。输 出的假设和对后续实例的分类可由这一前提及训练样例演绎推出。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s71" style="padding-left: 48pt;text-indent: -21pt;line-height: 111%;text-align: justify;">n <span class="p">如果假设空间被扩展，使对应实例集的每一个子集（实例的幂集）都有一个假设， 将使候选消除算法中的归纳偏置消失。然而，这也将消除其对新实例分类的能力。 无偏的学习器无法对未见样例进行归纳。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 5pt;text-indent: 21pt;line-height: 108%;text-align: left;"><span class="p">概念学习以及使用一般到特殊序的相关研究由来也久。</span>Bruner et al.<span class="p">（</span>1957<span class="p">）较早地对人 类的概念学习作出研究，而 </span>Hunt &amp; Hovland<span class="p">（</span>1963<span class="p">）较早将其自动化。</span>Winston<span class="p">（</span>1970<span class="p">）的 有名的博士论文中将概念学习看作是包含泛化和特化操作的搜索过程。</span>Plotkin<span class="p">（</span>1970, 1971<span class="p">） 较早地提供了形式化的 </span><i>more</i>-<i>general</i>-<i>than </i><span class="p">关系，以及一个相关的概念</span><span class="s72"></span>-<span class="p">包容（在第 </span>10 <span class="p">章中 讨论）。</span>Simon <span class="p">和 </span>Lea<span class="p">（</span>1973<span class="p">）将学习的过程看作是在假设空间中搜索的过程。其他一些较 早的概念学习系统包括（</span>Popplestone 1969<span class="p">；</span>Michalski 1973<span class="p">；</span>Buchanan 1974<span class="p">；</span>Vere 1975<span class="p">； </span>Hayes-Roth 1974<span class="p">）。大量的基于符号表示的概念学习算法已被开发出来。第 </span>10 <span class="p">章描述了几种 近期的概念学习算法。包括用一阶逻辑表示的概念学习算法，对有噪声数据有鲁棒性的算法， 以及当目标概念无法在学习器的假设空间中表示时能较好地降级学习的算法。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 27pt;text-indent: 0pt;text-align: left;">变型空间和候选消除算法由 <span class="s6">Mitchell</span>（<span class="s6">1977</span>，<span class="s6">1982</span>）提出，这一算法已应用于质谱分析</p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: left;">（<span class="s6">mass spectroscopy</span>）中的规则推理（<span class="s6">Mitchell 1979</span>）以及应用于学习搜索控制规则（<span class="s6">Mitchell et al. 1983</span>）。<span class="s6">Haussler</span>（<span class="s6">1988</span>）证明即使当假设空间只包含简单的特征合取时，一般边界的 大小根据训练样例的数目指数增长。<span class="s6">Smith &amp; Rosenbloom</span>（<span class="s6">1990</span>）提出对 <span class="s21">G </span>集合的表示进行 简单的更改，以改进其特定情况下的复杂性，<span class="s6">Hirsh</span>（<span class="s6">1992</span>）提出在某些情况下不存储 <span class="s21">G </span>集 合时学习过程为样例数目的多项式函数。<span class="s6">Subramanian &amp; Feigenbaum</span>（<span class="s6">1986</span>）讨论了特定情 况下通过分解变型空间以生成有效查询一种方法。候选消除算法的一个最大的实际限制是它 要求训练数据是无噪声的。<span class="s6">Mitchell</span>（<span class="s6">1979</span>）描述了该算法的一种扩展，以处理可预见的有 限数量的误分类样例，<span class="s6">Hirsh</span>（<span class="s6">1990, 1994</span>）提出一种良好的扩展以处理具有实数值属性的训 练样例中的有限噪声。<span class="s6">Hirsh</span>（<span class="s6">1990</span>）描述了一种递增变型空间合并算法，它将候选消除算 法扩展到能处理由不同类型的值约束表示的训练信息。来自每个约束的信息由变型空间来表 示，然后用交叠变型空间的办法合并这些约束。<span class="s6">Sebag</span>（<span class="s6">1994, 1996</span>）展示了一种被称为析取 变型空间的方法来从有噪声数据中学习析取概念。从每个正例中学到一个分立的变型空间， 然后用这不同变型空间进行投票以分类新实例。她在几个问题领域进行了实验，得出她的方 法同其他广泛使用的归纳方法有同样良好的性能，如决策树和 <span class="s21">k</span><span class="s6">-</span>近邻方法。</p><p style="padding-left: 27pt;text-indent: 0pt;text-align: left;">习题</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;"><span class="s6">2.1 </span>解释为什么 <span class="s21">EnjoySport </span>学习任务的假设空间的大小为 <span class="s6">973</span>。如果增加一属性 <span class="s21">WaterCurrent</span>，可取值 <span class="s21">Light</span>、<span class="s21">Moderate </span>和 <span class="s21">Strong</span>，那么可能的实例数和可能的假设数将会增 加多少？推广到一般，增加一新属性 <span class="s21">A</span>，有 <span class="s21">k </span>种取值，实例数和假设数将会增加多少？</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 109%;text-align: justify;"><span class="s6">2.2 </span>在候选消除算法中，如果训练样例按表 <span class="s6">2-1 </span>中的逆序出现，请分步给出 <span class="s21">S </span>和 <span class="s21">G </span>边界 集合。虽然不论样例出现顺序如何，最终的变型空间相同（为什么？），在中间步骤中得到 的 <span class="s21">S </span>和 <span class="s21">G </span>仍将依赖于该顺序。是否有办法对训练样例排序，以使 <span class="s21">EnjoySport </span>例子中的所有 <span class="s21">S </span>和 <span class="s21">G </span>集合的中间结果的大小之和为最小？</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;"><span class="s6">2.3 </span>继续考虑 <span class="s21">EnjoySport </span>学习任务和 <span class="s6">2.2 </span>节中描述的假设空间 <span class="s21">H</span>。如果定义一个新的假 设空间 <span class="s21">H</span><span class="s6">´</span>，它包含 <span class="s21">H </span>中所有假设的成对析取。如 <span class="s21">H</span><span class="s6">´</span>中一假设为：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 26pt;text-indent: 0pt;text-align: left;">&lt;?, <i>Cold</i>, <i>High</i>, ?, ?, ?&gt;<span class="p">∨</span>&lt;<i>Sunny</i>, ?, <i>High</i>, ?, ?, <i>Same</i>&gt;</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">试跟踪运行使用该假设空间 <span class="s21">H</span><span class="s6">´</span>的候选消除算法，给定的训练样例如表 <span class="s6">2-1 </span>所示（需要 分步列出 <span class="s21">S </span>和 <span class="s21">G </span>集合）。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;"><span class="s6">2.4 </span><span class="p">假定一实例空间包含 </span>x<span class="p">，</span>y <span class="p">平面中的整数点，假设集合 </span>H <span class="p">为矩形集。更精确地，假 设的形式为 </span>a<span class="p">≤</span>x<span class="p">≤</span>b<span class="p">，</span>c<span class="p">≤</span>y<span class="p">≤</span>d<span class="p">，其中 </span>a<span class="s6">,</span>b<span class="s6">,</span>c<span class="s6">,</span>d <span class="p">为任意整数。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">（<span class="s6">a</span>）考虑对应于下图所示正例（＋）和反例（－）集合的变型空间，它的 <span class="s21">S </span>边界是什 么？写出其中的假设并在图中画出。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 13pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="547" height="1" alt="image" src="机器学习/Image_044.png"/></span></p><p class="s48" style="padding-left: 15pt;text-indent: 0pt;text-align: left;">插图——原书页码： <span class="s21">48</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 14pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="531" height="1" alt="image" src="机器学习/Image_045.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">（<span class="s6">b</span>）变型空间的 <span class="s21">G </span>边界是什么，写出其中的假设并在图中画出。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: left;"><span class="p">（</span>c<span class="p">）假定学习器可提出一个新实例</span>(<i>x</i>, <i>y</i>)<span class="p">，并要求施教者进行分类，试给出一个查询， 无论施教者怎样分类都能保证减小变型空间。再给出一个不能保证的查询。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: left;">（<span class="s6">d</span>）作为施教者，如果想让学习器学习一特定的目标概念（如 <span class="s6">3</span>≤<span class="s21">x</span>≤<span class="s6">5</span>，<span class="s6">2</span>≤<span class="s21">y</span>≤<span class="s6">9</span>）， 为使候选消除算法完全学习到目标概念，需要提供的的训练样例数目最小是多少。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: left;"><span class="s6">2.5 </span><span class="p">请看以下的正例和反例序例，它们描述的概念是“两个住在同一房间中的人”。每个 训练样例描述了一个有序对，每个人由其性别、头发颜色（</span>black<span class="s6">, </span>brown <span class="p">或 </span>blonde<span class="p">）、身高</span></p><p class="s21" style="padding-left: 6pt;text-indent: 0pt;text-align: left;"><span class="p">（</span>tall<span class="s6">, </span>medium <span class="p">或 </span>short<span class="p">）以及国籍（</span>US<span class="s6">, </span>French<span class="s6">, </span>German<span class="s6">, </span>Irish<span class="s6">, </span>Indian<span class="s6">, </span>Chinese <span class="p">或 </span>Portuguese<span class="p">）。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 27pt;text-indent: 0pt;text-align: left;">+ &lt; &lt;<i>male brown tall US</i>&gt;, &lt;<i>female black short US</i>&gt; &gt;</p><p class="s6" style="padding-top: 2pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">+ &lt; &lt;<i>male brown short French</i>&gt;, &lt;<i>female black short US</i>&gt; &gt;</p><p style="text-indent: 0pt;text-align: left;"><br/></p><ul id="l1"><li style="padding-left: 51pt;text-indent: -24pt;text-align: left;"><p class="s6" style="display: inline;">&lt; &lt;<i>female brown tall German</i>&gt;, &lt;<i>female black short Indian</i>&gt; &gt;</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 26pt;text-indent: 0pt;text-align: left;">+ &lt; &lt;<i>male brown tall Irish</i>&gt;, &lt;<i>female brown short Irish</i>&gt; &gt;</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: left;">考虑在这些实例上定义的假设空间为：其中所有假设以一对 <span class="s6">4 </span>元组表示，其中每个值约 束与 <span class="s21">EnjoySport </span>中的假设表示相似，可以为：特定值、“<span class="s6">?</span>”或者“<span class="s10"></span>”。例如，下面的假设：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 26pt;text-indent: 0pt;text-align: left;">&lt; &lt;<i>male </i>? <i>Tall </i>? &gt; &lt;<i>female </i>? ? <i>French</i>&gt; &gt;</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 113%;text-align: left;">它表示了所有这样的有序对：第一个人为高个男性（国籍和发色任意），第二个人为法 国女性（发色和身高任意）。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: left;">（<span class="s6">a</span>）根据上述提供的训练样例和假设表示，手动执行候选消除算法。特别是要写出处 理了每一个训练样例后变型空间的特殊和一般边界。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 26pt;text-indent: 0pt;text-align: left;">（<span class="s6">b</span>）计算给定的假设空间中有多少假设与下面的正例一致：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 26pt;text-indent: 0pt;text-align: left;">+ &lt; &lt;<i>male black short Portuguese</i>&gt; &lt;<i>female blonde tall Indian</i>&gt; &gt;</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 111%;text-align: left;">（<span class="s6">c</span>）如果学习器只有一个训练样例如（<span class="s6">b</span>）中所示，现在由学习器提出查询，并由施教 者给出其分类。求出一个特定的查询序列，以保证学习器收敛到单个正确的假设，而不论该 假设是哪一个（假定目标概念可以使用给定的假设表示语言来描述）。求出最短的查询序列。 这一序列的长度与问题（<span class="s6">b</span>）的答案有什么关联？</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 110%;text-align: justify;">（<span class="s6">d</span>）注意到这里的假设表示语言不能够表示这些实例上的所有概念（如我们可定义出 一系列的正例和反例，它们并没有相应的可描述假设）。如果要扩展这一语言，使其能够表 达该实例语言上的所有概念，那么（<span class="s6">c</span>）的答案应该如何更改。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 26pt;text-indent: 0pt;text-align: left;">2.6 <span class="p">完成变型空间表示定理的证明（定理 </span>2.1<span class="p">）。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 109%;text-align: justify;"><span class="s6">2.7 </span>考虑一个概念学习问题，其中每个实例为一实数，而每个假设为实数中的区间。精 确地定义为：假设空间 <span class="s21">H </span>中的每个假设形式为 <span class="s21">a</span><span class="s6">&lt;</span><span class="s21">x</span><span class="s6">&lt;</span><span class="s21">b</span>，其中 <span class="s21">a</span>、<span class="s21">b </span>为任意实常数，<span class="s21">x </span>代表该 实例。例如 <span class="s6">4.5&lt;</span><span class="s21">x</span><span class="s6">&lt;6.1 </span>这个假设将 <span class="s6">4.5 </span>和 <span class="s6">6.1 </span>之间的实例划分为正例，其他为反例。简要解 释为什么不存在一个对任意正例集合都一致的最特殊假设。试修改假设的表示方法以避免这 一缺点。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 108%;text-align: justify;"><span class="s6">2.8 </span>本章中指出如果给定一个无偏的假设空间（即实例的幂集），学习器将发现每一未观 察的实例将刚好与变型空间中半数的成员匹配，而不论已经过了怎样的训练样例。证明这一 结论。确切地讲，证明对于任意实例空间<span class="s21">X</span>，任意训练样例集<span class="s21">D</span>，和任意不包含在<span class="s21">D</span>中的实 例<span class="s21">x</span>∈<span class="s21">X</span>，如果<span class="s21">H</span>是<span class="s21">X</span>的幂集，那么在<span class="s21">VS</span><span class="s36">H</span><span class="s42">,</span><span class="s41">D</span>中有恰好半数的假设将<span class="s21">x</span>划分为正例，另外半数划 分为反例。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 5pt;text-indent: 21pt;text-align: left;"><span class="s6">2.9 </span><span class="p">有一学习问题，其中每个实例都由</span>n<span class="p">个布尔值属性</span>a<span class="s35">1</span><span class="s6">, </span>a<span class="s35">2</span><span class="s6">, … ,</span>a<span class="s36">n</span><span class="p">的合取来描述。因此， 一个典型的实例如下：</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 26pt;text-indent: 0pt;text-align: left;">(<i>a</i><span class="s35">1</span>=<i>T</i>)<span class="p">∧</span>(<i>a</i><span class="s35">2</span>=<i>F</i>)<span class="p">∧</span>…<span class="p">∧</span>(<i>a</i><span class="s36">n</span>=<i>T</i>)</p><p style="padding-left: 27pt;text-indent: 0pt;text-align: left;">现考虑一个假设空间 <span class="s21">H </span>中，每个假设是这些属性约束的析取，例如：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 26pt;text-indent: 0pt;text-align: left;">(<i>a</i><span class="s35">1</span>=<i>T</i>)<span class="p">∨</span>(<i>a</i><span class="s35">5</span>=<i>F</i>)<span class="p">∨</span>(<i>a</i><span class="s35">7</span>=<i>T</i>)</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 113%;text-align: left;">设计一算法，它经过一系列的样例训练后输出一个一致的假设（如存在的话）。算法的 时间要求为 <span class="s21">n </span>和训练样例数目的多项式函数。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 110%;text-align: justify;"><span class="s6">2.10 </span>实现 <span class="s6">Find-S </span>算法。首先，验证它可成功地产生 <span class="s6">2.4 </span>节中 <span class="s21">EnjoySport </span>例子中各步骤结 果。然后使用这一程序，研究为了学习到确切的目标概念所需的随机训练样例数目。实现一 训练样例生成器来生成这些随机的实例，再用下面的目标概念产生分类结果：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 27pt;text-indent: 0pt;text-align: left;"><span class="s6">&lt;</span>Sunny<span class="p">，</span>Warm<span class="p">，？，？，？，？</span><span class="s6">&gt;</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: left;">试用随机产生的样例训练你的 <span class="s6">Find-S </span>算法，并测量需要多少样例才能使程序的假设与 目标概念相等。能否预测所需的平均样例数目？运行该实验 <span class="s6">20 </span>次并报告所需样例的平均数。 这一数目会怎样随着目标概念中的“<span class="s6">?</span>”数目而变动？以及它会怎样随着实例或假设中属性 的数目而变动？</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s8" style="padding-left: 136pt;text-indent: 0pt;line-height: 24pt;text-align: left;">第<span class="h1">3</span>章 决策树学习</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 48pt;text-indent: 21pt;line-height: 112%;text-align: left;">决策树学习是应用最广的归纳推理算法之一。它是一种逼近离散函数的方法， 且对噪声数据有很好的鲁棒性，能够学习析取表达式。本章描述了一系列决策树学 习算法，包括象 <span class="s71">ID3</span>、<span class="s71">ASSISTANT </span>和 <span class="s71">C4.5 </span>这样广为应用的算法。这些决策树学 习方法搜索完整表示的假设空间，从而避免了受限假设空间的不足。决策树学习的 归纳偏置是优先选择较小的树。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 16pt;text-indent: 0pt;text-align: left;">3.1 <span class="s17">简介</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 16pt;text-indent: 21pt;line-height: 111%;text-align: left;">决策树学习是一种逼近离散值目标函数的方法，在这种方法中学习到的函数被表示 为一棵决策树。学习得到的决策树也能再被表示为多个 <span class="s6">if-then </span>的规则，以提高可读性。 这种学习算法是最流行的归纳推理算法之一，已经被成功地应用到从学习医疗诊断到学 习评估贷款申请的信用风险的广阔领域。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 16pt;text-indent: 0pt;text-align: left;">3.2 <span class="s17">决策树表示法</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 16pt;text-indent: 21pt;line-height: 110%;text-align: justify;">决策树通过把实例从根结点排列（<span class="s6">sort</span>）到某个叶子结点来分类实例，叶子结点即 为实例所属的分类。树上的每一个结点指定了对实例的某个属性（<span class="s6">attribute</span>）的测试， 并且该结点的每一个后继分支对应于该属性的一个可能值。分类实例的方法是从这棵树 的根结点开始，测试这个结点指定的属性，然后按照给定实例的该属性值对应的树枝向 下移动。这个过程再在以新结点为根的子树上重复。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 13pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="547" height="1" alt="image" src="机器学习/Image_046.png"/></span></p><p class="s48" style="padding-left: 15pt;text-indent: 0pt;text-align: left;">插图——原书页码： <span class="s21">53</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 14pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="556" height="1" alt="image" src="机器学习/Image_047.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 33pt;text-indent: 116pt;text-align: left;">图 <span class="h4">3-1 </span>概念 <span class="s7">PlayTennis </span>的决策树</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-left: 33pt;text-indent: 0pt;text-align: left;">分类一个样例的方法是，将其沿根结点排列到合适的叶子结点，然后返回与这个叶子结点关联的分类</p><p class="s14" style="padding-top: 3pt;padding-left: 33pt;text-indent: 0pt;text-align: left;">（本例中为 <span class="s56">Yes </span>或 <span class="s56">No</span>）。这棵决策树根据天气分类“星期六上午是否适合打网球”。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 16pt;text-indent: 21pt;line-height: 107%;text-align: left;">图 <span class="s6">3-1 </span>画出了一棵典型的学习到的决策树。这棵决策树根据天气情况分类“星期六 上午是否适合打网球”。例如，下面的实例：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 16pt;text-indent: 50pt;text-align: left;"><span class="s6">&lt; </span>Outlook<span class="s6">=</span>Sunny<span class="p">，</span>Temperature<span class="s6">=</span>Hot<span class="p">，</span>Humidity<span class="s6">=</span>High<span class="p">，</span>Wind<span class="s6">=</span>Strong <span class="s6">&gt;</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 16pt;text-indent: 0pt;line-height: 110%;text-align: justify;">将被沿着这棵决策树的最左分支向下排列，因而被评定为反例（也就是这棵树预测这个 实例 <span class="s21">PlayTennis</span><span class="s6">=</span><span class="s21">No</span>）。这棵树以及表 <span class="s6">3-2 </span>中用来演示 <span class="s6">ID3 </span>学习算法的例子摘自（<span class="s6">Quinlan 1986</span>）。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s24" style="padding-left: 16pt;text-indent: 21pt;line-height: 107%;text-align: left;">通常决策树代表实例属性值约束的合取（<span class="s63">conjunction</span>）的析取式（<span class="s63">disjunction</span>）<span style=" color: #000;">。从 树根到树叶的每一条路径对应一组属性测试的合取，树本身对应这些合取的析取。例如，</span></p><p style="padding-left: 16pt;text-indent: 0pt;text-align: left;">图 <span class="s6">3-1 </span>表示的决策树对应于以下表达式：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 134pt;text-indent: 0pt;line-height: 190%;text-align: center;"><span class="p">（</span>Outlook<span class="s6">=</span>Sunny <span class="s73">٨ </span>Humidity<span class="s6">=</span>Normal<span class="p">） </span><span class="s73">٧</span><span class="p">（</span>Outlook<span class="s6">=</span>Overcast<span class="p">） </span><span class="s73">٧</span><span class="p">（</span>Outlook<span class="s6">=</span>Rain <span class="s73">٨ </span>Wind<span class="s6">=</span>Weak<span class="p">）</span></p><h2 style="padding-top: 5pt;padding-left: 16pt;text-indent: 0pt;text-align: left;">3.3 <span class="s17">决策树学习的适用问题</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 16pt;text-indent: 21pt;line-height: 113%;text-align: justify;">尽管已经开发的种种决策树学习算法有这样或那样不太一致的能力和要求，通常决 策树学习最适合具有以下特征的问题：</p><p style="padding-top: 5pt;padding-left: 49pt;text-indent: -21pt;line-height: 94%;text-align: justify;"><span class="s34">• </span>实例是由“属性<span class="h4">-</span>值”对（<span class="h4">pair</span>）表示的。实例是用一系列固定的属性（例如， <span class="s21">Temperature</span>）和它们的值（例如，<span class="s21">Hot</span>）来描述的。最简单的决策树学习中，每 一个属性取少数的分离的值（例如，<span class="s21">Hot</span>、<span class="s21">Mild</span>、<span class="s21">Cold</span>）。然而，扩展的算法（在 <span class="s6">3.7.2 </span>节中讨论）也允许处理值域为实数的属性（例如，数字表示的温度）。</p><p style="padding-left: 28pt;text-indent: 0pt;line-height: 13pt;text-align: left;"><span class="s34">• </span>目标函数具有离散的输出值。图 <span class="s6">3-1 </span>的决策树给每个实例赋予一个布尔型的分类</p><p style="padding-left: 49pt;text-indent: 0pt;text-align: left;">（例如，<span class="s21">yes </span>或 <span class="s21">no</span>）。决策树方法很容易扩展到学习有两个以上输出值的函数。 一种更强有力的扩展算法允许学习具有实数值输出的函数，尽管决策树在这种 情况下的应用不太常见。</p><p style="padding-top: 1pt;padding-left: 49pt;text-indent: -21pt;line-height: 14pt;text-align: justify;"><span class="s34">• </span>可能需要析取的描述（<span class="h4">disjunctive description</span>）。如上面指出的，决策树很自然 地代表了析取表达式。</p><p class="s34" style="padding-left: 49pt;text-indent: -21pt;line-height: 13pt;text-align: justify;">• <span class="p">训练数据可以包含错误。决策树学习对错误有很好的鲁棒性，无论是训练样例</span></p><p style="padding-left: 49pt;text-indent: 0pt;line-height: 13pt;text-align: left;">所属的分类错误还是描述这些样例的属性值错误。</p><p style="padding-left: 49pt;text-indent: -21pt;text-align: justify;"><span class="s34">• </span>训练数据可以包含缺少属性值的实例。决策树学习甚至可以在有未知属性值的 训练样例中使用（例如，仅有一部分训练样例知道当天的湿度）。这个问题将 在第 <span class="s6">3.7.4 </span>小节中讨论。</p><p style="padding-top: 7pt;padding-left: 16pt;text-indent: 21pt;line-height: 113%;text-align: justify;">已经发现很多实际的问题符合这些特征，所以决策树学习已经被应用到很多问题 中。例如根据疾病分类患者；根据起因分类设备故障；根据拖欠支付的可能性分类贷款 申请。对于这些问题，核心任务都是要把样例分类到各可能的离散值对应的类别</p><p style="padding-left: 37pt;text-indent: -21pt;text-align: left;">（<span class="s6">category</span>）中，因此经常被称为分类问题（<span class="s6">Classification Problem</span>）。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 16pt;text-indent: 21pt;line-height: 108%;text-align: justify;">这一章的其余部分是这样安排的。<span class="s6">3.4 </span>节给出学习决策树的基本 <span class="s6">ID3 </span>算法并演示它 的具体操作。<span class="s6">3.5 </span>节分析使用这种学习算法进行的假设空间搜索，并与第 <span class="s6">2 </span>章的算法进 行了比较。<span class="s6">3.6 </span>节刻画了决策树学习算法的归纳偏置，并更一般化的探索了一种被称为 奥坎姆剃刀的归纳偏置，该偏置优先选择最简单的假设。<span class="s6">3.7 </span>节讨论了训练数据的过度 拟合（<span class="s6">overfitting</span>），以及解决这种问题的策略，比如规则后修剪（<span class="s6">post-pruning</span>）。这一 节还讨论了一些更深入的话题，比如将算法扩展以适应实数值属性、带有未观测到属性 的训练数据、以及有不同代价的属性。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 16pt;text-indent: 0pt;text-align: left;">3.4 <span class="s17">基本的决策树学习算法</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 16pt;text-indent: 21pt;line-height: 110%;text-align: justify;">大多数已开发的决策树学习算法是一种核心算法的变体。该算法采用自顶向下的贪 婪搜索遍历可能的决策树空间。这种方法是 <span class="s6">ID3 </span>算法（<span class="s6">Quinlan 1986</span>）和后继的 <span class="s6">C4.5 </span>算法（<span class="s6">Quinlan 1993</span>）的基础，也是这里讨论的重点。这一节将给出决策树学习的基本</p><p style="padding-left: 16pt;text-indent: 0pt;line-height: 107%;text-align: left;">算法，大致相当于 <span class="s6">ID3 </span>算法。在 <span class="s6">3.7 </span>节我们考虑该基本算法的一些扩展，包括被合并到 <span class="s6">C4.5 </span>的扩展和其他一些较新的决策树学习算法。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 16pt;text-indent: 21pt;line-height: 111%;text-align: justify;">基本的 <span class="s6">ID3 </span>算法通过自顶向下构造决策树来进行学习。<span style=" color: #00F;">构造过程是从“哪一个属 性将在树的根结点被测试？</span>”这个问题开始的。为了回答这个问题，使用统计测试来确 定每一个实例属性单独分类训练样例的能力。分类能力最好的属性被选作树的根结点的 测试。然后为根结点属性的每个可能值产生一个分支，并把训练样例排列到适当的分支</p><p style="padding-left: 16pt;text-indent: 0pt;line-height: 113%;text-align: left;">（也就是，样例的该属性值对应的分支）之下。然后重复整个过程，用每个分支结点关 联的训练样例来选取在该点被测试的最佳属性。这形成了对合格决策树的贪婪搜索</p><p style="padding-left: 16pt;text-indent: 0pt;line-height: 107%;text-align: left;">（<span class="s6">greedy search</span>），也就是算法从不回溯重新考虑以前的选择。表 <span class="s6">3-1 </span>描述了该算法的一 个简化版本——专门用来学习布尔值函数（即概念学习）。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 123pt;text-indent: 0pt;text-align: left;">表 <span class="h4">3-1 </span>专用于学习布尔函数的 <span class="h4">ID3 </span>算法概要</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s16" style="padding-left: 33pt;text-indent: 0pt;line-height: 125%;text-align: left;">ID3 <span class="s14">是一种自顶向下增长树的贪婪算法，在每个结点选取能最好地分类样例的属性。继续这个过程直 到这棵树能完美分类训练样例，或所有的属性都使用过了。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 14pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="515" height="1" alt="image" src="机器学习/Image_048.png"/></span></p><p class="s74" style="padding-left: 19pt;text-indent: 0pt;line-height: 11pt;text-align: left;"><span class="s12">ID3(</span>Examples<span class="s11">，</span>Target<span class="s12">_</span>attribute<span class="s11">，</span>Attributes<span class="s12">)</span></p><p class="s74" style="padding-left: 30pt;text-indent: 0pt;text-align: left;">Examples <span class="s11">即训练样例集。</span>Target<span class="s12">_</span>attribute <span class="s11">是这棵树要预测的目标属性。</span>Attributes <span class="s11">是除目标属性外供学习到的决策树测试的属性列表。返回能正确分类给定 </span>Examples <span class="s11">的决策树。</span></p><p class="s11" style="padding-left: 33pt;text-indent: 0pt;line-height: 13pt;text-align: left;"><span class="s75">• </span>创建树的 <span class="s74">Root </span>结点</p><ul id="l2"><li style="padding-left: 54pt;text-indent: -21pt;line-height: 13pt;text-align: left;"><p class="s11" style="display: inline;">如果 <span class="s74">Examples </span>都为正，那么返回 <span class="s12">label =+ </span>的单结点树 <span class="s74">Root</span></p></li><li style="padding-left: 54pt;text-indent: -21pt;line-height: 13pt;text-align: left;"><p class="s11" style="display: inline;">如果 <span class="s74">Examples </span>都为反，那么返回 <span class="s12">label =- </span>的单结点树 <span class="s74">Root</span></p></li><li style="padding-left: 54pt;text-indent: -21pt;line-height: 13pt;text-align: left;"><p class="s74" style="display: inline;"><span class="s11">如果 </span>Attributes <span class="s11">为空，那么返回单结点树 </span>Root<span class="s11">，</span><span class="s12">label=</span>Examples <span class="s11">中最普遍的 </span>Target<span class="s12">_</span>attribute <span class="s11">值</span></p><p class="s75" style="padding-left: 33pt;text-indent: 0pt;line-height: 12pt;text-align: left;">• <span class="s11">否则</span></p><ul id="l3"><li style="padding-left: 83pt;text-indent: -23pt;line-height: 13pt;text-align: left;"><p class="s11" style="display: inline;"><span class="s74">A</span>←<span class="s74">Attributes </span>中分类 <span class="s74">Examples </span>能力最好<span class="s12">*</span>的属性</p><p class="s74" style="padding-left: 60pt;text-indent: 0pt;line-height: 13pt;text-align: left;"><span class="s75">• </span>Root <span class="s11">的决策属性←</span>A</p><p class="s11" style="padding-left: 60pt;text-indent: 0pt;line-height: 13pt;text-align: left;"><span class="s75">• </span>对于<span class="s74">A</span>的每个可能值<span class="s74">v</span><span class="s76">i</span></p><p class="s74" style="padding-left: 87pt;text-indent: 0pt;line-height: 14pt;text-align: left;"><span class="s75">• </span><span class="s11">在</span>Root<span class="s11">下加一个新的分支对应测试</span>A<span class="s12">= </span>v<span class="s76">i</span></p><p class="s41" style="text-indent: 0pt;line-height: 7pt;text-align: left;">v</p><p style="text-indent: 0pt;text-align: left;"/><ul id="l4"><li style="padding-left: 104pt;text-indent: -17pt;line-height: 13pt;text-align: right;"><p class="s11" style="display: inline;">令 <span class="s30">Examples</span></p><p class="s44" style="text-indent: 0pt;line-height: 5pt;text-align: right;">i</p><p class="s11" style="text-indent: 0pt;text-align: left;">为<span class="s74">Examples</span>中满足<span class="s74">A</span>属性值为<span class="s74">v</span><span class="s76">i</span>的子集</p><p class="s41" style="text-indent: 0pt;line-height: 7pt;text-align: left;">v</p><p style="text-indent: 0pt;text-align: left;"/></li><li style="padding-top: 1pt;padding-left: 104pt;text-indent: -17pt;line-height: 13pt;text-align: left;"><p class="s11" style="display: inline;">如果 <span class="s30">Examples </span>为空</p><p class="s44" style="padding-left: 75pt;text-indent: 0pt;line-height: 5pt;text-align: center;">i</p><p class="s75" style="padding-left: 114pt;text-indent: 0pt;line-height: 13pt;text-align: left;">• <span class="s11">在这个新分支下加一个叶子结点，结点的 </span><span class="s12">label=</span><span class="s74">Examples</span></p><p class="s74" style="padding-left: 132pt;text-indent: 0pt;line-height: 13pt;text-align: left;"><span class="s11">中最普遍的 </span>Target<span class="s12">_</span>attribute <span class="s11">值</span></p><p class="s41" style="text-indent: 0pt;line-height: 7pt;text-align: left;">v</p><p style="text-indent: 0pt;text-align: left;"/><p class="s11" style="padding-top: 1pt;padding-left: 114pt;text-indent: 0pt;line-height: 13pt;text-align: left;"><span class="s75">• </span>否则在这个新分支下加一个子树 <span class="s12">ID3</span>（ <span class="s30">Examples </span><span class="s12">,</span></p><p class="s44" style="text-indent: 0pt;line-height: 5pt;text-align: right;">i</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s75" style="padding-left: 33pt;text-indent: 0pt;line-height: 13pt;text-align: left;">• <span class="s11">结束</span></p></li></ul></li></ul></li><li style="padding-left: 54pt;text-indent: -21pt;line-height: 13pt;text-align: left;"><p class="s11" style="display: inline;">返回 <span class="s74">Root</span></p></li></ul></li></ul><p class="s74" style="padding-left: 33pt;text-indent: 0pt;line-height: 13pt;text-align: left;">Target<span class="s12">_</span>attribute<span class="s12">, </span>Attributes<span class="s12">-{</span>A<span class="s12">}</span><span class="s11">）</span></p><p style="padding-left: 12pt;text-indent: 0pt;line-height: 2pt;text-align: left;"><span><img width="517" height="2" alt="image" src="机器学习/Image_049.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s16" style="padding-top: 2pt;padding-left: 37pt;text-indent: 0pt;text-align: left;">*<span class="s14">根据公式 </span>3.4 <span class="s14">的定义，具有最高信息增益（</span>information gain<span class="s14">）的属性是最好的属性。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 40pt;text-indent: 0pt;text-align: left;">3.4.1 <span class="s25">哪个属性是最佳的分类属性？</span></h3><p class="s6" style="padding-top: 10pt;padding-left: 16pt;text-indent: 21pt;line-height: 109%;text-align: justify;">ID3 <span class="p">算法的核心问题是选取在树的每个结点要测试的属性。我们希望选择的是最有 助于分类实例的属性。那么衡量属性价值的一个好的定量标准是什么呢？这里将定义一 个统计属性，称为“信息增益（</span>information gain<span class="p">）”，用来衡量给定的属性区分训练样例 的能力。</span>ID3 <span class="p">算法在增长树的每一步使用这个信息增益标准从候选属性中选择属性。</span></p><p class="s37" style="padding-top: 1pt;padding-left: 37pt;text-indent: 0pt;text-align: left;">3.4.1.1 <span class="s20">用熵度量样例的均一性</span></p><p style="padding-top: 8pt;padding-left: 37pt;text-indent: 0pt;text-align: left;">为了精确地定义信息增益，我们先定义信息论中广泛使用的一个度量标准，称为熵</p><p style="padding-top: 1pt;padding-left: 16pt;text-indent: 0pt;line-height: 107%;text-align: left;">（<span class="s6">entropy</span>），它刻画了<span style=" color: #00F;">任意样例集的纯度</span>（<span class="s6">purity</span>）。给定包含关于某个目标概念的正反 样例的样例集 <span class="s21">S</span>，那么 <span class="s21">S </span>相对这个布尔型分类的熵为：</p><p class="s21" style="padding-top: 2pt;padding-left: 37pt;text-indent: 100pt;line-height: 28pt;text-align: left;">Entropy<span class="s6">(</span>S<span class="s6">) </span><span class="s10"></span><span class="s6">-</span>p<span class="s77"></span><span class="s6">log</span><span class="s35">2</span>p<span class="s77"></span><span class="s6">-</span>p<span class="s78">Θ</span><span class="s6">log</span><span class="s35">2</span>p<span class="s78">Θ </span><span class="p">（</span><span class="s71">3.1</span><span class="p">） 其中</span>p<span class="s77"></span><span class="p">是在</span>S<span class="p">中正例的比例，</span>p<span class="s78">Θ</span><span class="p">是在</span>S<span class="p">中负例的比例。在有关熵的所有计算中我们定</span></p><p style="padding-left: 16pt;text-indent: 0pt;line-height: 12pt;text-align: left;">义 <span class="s6">0log0 </span>为 <span class="s6">0</span>。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 16pt;text-indent: 21pt;line-height: 107%;text-align: justify;">举例说明，假设 <span class="s21">S </span>是一个关于某布尔概念的有 <span class="s6">14 </span>个样例的集合，它包括 <span class="s6">9 </span>个正例 和 <span class="s6">5 </span>个反例（我们采用记号<span class="s6">[9+</span>，<span class="s6">5-]</span>来概括这样的数据样例）。那么 <span class="s21">S </span>相对于这个布尔 分类的熵（<span class="s6">Entropy</span>）为：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s33" style="padding-top: 2pt;padding-left: 78pt;text-indent: 0pt;text-align: left;"><i>Entropy</i>([9<span class="s38"></span>,5<span class="s38"></span>]) <span class="s38"> </span><span class="s38"></span>(9 /14) log <span class="s79">2</span><span class="s42"> </span>(9 /14) <span class="s38"> </span>(5 /14) log <span class="s79">2</span><span class="s42"> </span>(5 /14)</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-top: 1pt;padding-left: 162pt;text-indent: 0pt;text-align: left;">=0.940 <span class="p">（</span>3.2<span class="p">）</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 16pt;text-indent: 21pt;line-height: 107%;text-align: left;">注意，如果<span class="s21">S</span>的所有成员属于同一类，那么<span class="s21">S</span>的熵为 <span class="s6">0</span>。例如，如果所有的成员是正 的 （ <span class="s21">p</span><span class="s77"></span><span class="s6">=1 </span>） ， 那 么 <span class="s21">p</span><span class="s78">Θ </span>就 是 <span class="s6">0 </span>， 于 是 <span class="s21">Entropy</span><span class="s6">(</span><span class="s21">S</span><span class="s6">) =</span></p><p class="s33" style="padding-left: 16pt;text-indent: 1pt;line-height: 16pt;text-align: left;"><span class="s38"> </span>1<span class="s38"> </span>log <span class="s79">2</span><span class="s42"> </span>(1) <span class="s38"> </span>(0) <span class="s38"> </span>log <span class="s79">2</span><span class="s42"> </span>(0) <span class="s38"> </span><span class="s38"></span>1<span class="s38"> </span>0 <span class="s38"> </span>0 <span class="s38"> </span>log <span class="s79">2</span><span class="s42"> </span>0 <span class="s38"> </span>0 <span class="p">。另外，当集合中正反样例的数量</span></p><p style="padding-left: 16pt;text-indent: 0pt;line-height: 107%;text-align: left;">相等时熵为 <span class="s6">1</span>。如果集合中正反例的数量不等时，熵介于 <span class="s6">0 </span>和 <span class="s6">1 </span>之间。图 <span class="s6">3-2 </span>显示了关 于某布尔分类的熵函数随着<span class="s21">p</span><span class="s77"></span>从 <span class="s6">0 </span>到 <span class="s6">1 </span>变化的曲线。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 13pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="547" height="1" alt="image" src="机器学习/Image_050.png"/></span></p><p class="s48" style="padding-left: 15pt;text-indent: 0pt;text-align: left;">插图——原书页码： <span class="s21">57</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 14pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="556" height="1" alt="image" src="机器学习/Image_051.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 144pt;text-indent: 0pt;text-align: left;">图 <span class="h4">3-2 </span>关于某布尔分类的的熵函数</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-left: 33pt;text-indent: 0pt;text-align: left;">图中画出了随着正例所占比例<span class="s56">p</span><span class="s80"></span>从 <span class="s16">0 </span>到 <span class="s16">1</span>，熵函数变化的曲线。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 16pt;text-indent: 21pt;line-height: 108%;text-align: justify;">信息论中熵的一种解释是，熵确定了要编码集合 <span class="s21">S </span>中任意成员（即以均匀的概率随 机抽出的一个成员）的分类所需要的最少二进制位数。举例来说，如果 <span class="s30">p</span><span class="s81"></span><span class="s40"> </span>是 <span class="s6">1</span>，接收 者知道抽出的样例必为正，所以不必发任何消息，此时的熵为 <span class="s6">0</span>。另一方面，如果 <span class="s30">p</span><span class="s81"></span><span class="s40"> </span>是 <span class="s6">0.5</span>，必须用一个二进制位来说明抽出的样例是正还是负。如果 <span class="s30">p</span><span class="s81"> </span>是 <span class="s6">0.8</span>，那么对所需 的消息编码方法是赋给正例集合较短的编码，可能性较小的反例集合较长的编码，平均 每条消息的编码少于 <span class="s6">1 </span>个二进制位<span class="s11">。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 37pt;text-indent: 0pt;text-align: left;">至此我们讨论了目标分类是布尔型的情况下的熵。更一般的，如果目标属性具有 <span class="s21">c</span></p><p style="padding-top: 1pt;padding-left: 16pt;text-indent: 0pt;text-align: left;">个不同的值，那么 <span class="s21">S </span>相对于 <span class="s21">c </span>个状态（<span class="s21">c</span><span class="s6">-wise</span>）的分类的熵定义为：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s41" style="padding-top: 4pt;text-indent: 0pt;line-height: 6pt;text-align: right;">c</p><p class="s30" style="padding-left: 152pt;text-indent: 0pt;line-height: 19pt;text-align: left;">Entropy<span class="s33">(</span>S <span class="s33">) </span><span class="s38"> </span><span class="s39"></span><span class="s38"> </span>p<span class="s52">i </span><span class="s33">log</span><span class="s79">2</span><span class="s42"> </span>p<span class="s52">i</span></p><p class="s41" style="text-indent: 0pt;line-height: 7pt;text-align: right;">i<span class="s40"></span><span class="s42">1</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="text-indent: 0pt;text-align: right;">(3.3)</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 37pt;text-indent: 0pt;text-align: left;">其中<span class="s21">p</span><span class="s36">i</span>是<span class="s21">S</span>中属于类别<span class="s21">i</span>的比例。请注意对数的底数仍然为 <span class="s6">2</span>，原因是熵是以<span class="s20">二进制</span>位</p><p style="padding-left: 16pt;text-indent: 0pt;text-align: left;">的个数来度量编码长度的。同时注意如果目标属性具有<span class="s21">c</span>个可能值，那么熵最大可能到</p><p class="s6" style="padding-top: 1pt;padding-left: 16pt;text-indent: 0pt;text-align: left;">log<span class="s35">2</span><i>c</i><span class="p">。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s37" style="padding-left: 37pt;text-indent: 0pt;text-align: left;">3.4.1.2 <span class="s20">用信息增益度量期望的熵降低</span></p><p style="padding-top: 8pt;padding-left: 16pt;text-indent: 21pt;line-height: 111%;text-align: justify;">已经有了熵作为衡量训练样例集合纯度的标准，现在可以定义属性分类训练数据的 效力的度量标准。这个标准被称为“信息增益（<span class="s6">information gain</span>）”。简单的说，一个属 性的信息增益就是由于使用这个属性分割样例而导致的期望熵降低。更精确地讲，一个 属性 <span class="s21">A </span>相对样例集合 <span class="s21">S </span>的信息增益 <span class="s21">Gain</span><span class="s6">(</span><span class="s21">S,A</span><span class="s6">)</span>被定义为</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="padding-top: 10pt;padding-left: 94pt;text-indent: 0pt;text-align: left;">Gain<span class="s33">(</span>S<span class="s33">, </span>A<span class="s33">) </span><span class="s38"> </span>Entropy<span class="s33">(</span>S <span class="s33">) </span><span class="s38"></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="30" height="1" alt="image" src="机器学习/Image_052.png"/></span></p><p class="s41" style="text-indent: 0pt;line-height: 7pt;text-align: left;">v</p><p style="text-indent: 0pt;text-align: left;"/><p class="s30" style="padding-top: 3pt;padding-left: 12pt;text-indent: 0pt;line-height: 22pt;text-align: left;"><span class="s39"> </span><span class="s82">| </span>S<span class="s83">v </span><span class="s82">| </span>Entropy<span class="s33">(</span>S <span class="s33">)</span></p><p class="s41" style="text-indent: 0pt;line-height: 10pt;text-align: left;">v<span class="s40"></span>Values<span class="s42">( </span>A<span class="s42">) </span><span class="s84">| </span><span class="s30">S </span><span class="s33">|</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 35pt;text-indent: 0pt;text-align: left;">（<span class="s6">3.4</span>）</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 2pt;padding-left: 16pt;text-indent: 21pt;line-height: 109%;text-align: left;">其中 <span class="s21">Values</span><span class="s6">(</span><span class="s21">A</span><span class="s6">)</span>是属性<span class="s21">A</span>所有可能值的集合，<span class="s30">S</span><span class="s52">v </span>是<span class="s21">S</span>中属性<span class="s21">A</span>的值为<span class="s21">v</span>的子集（也就是， <span class="s30">S</span><span class="s52">v </span><span class="s6">={</span><span class="s21">s</span><span class="s72"></span><span class="s21">S|A(s)=v</span><span class="s6">}</span>）。请注意，等式（<span class="s6">3.4</span>）的第一项就是原来集合<span class="s21">S</span>的熵，第二项是用<span class="s21">A </span>分类<span class="s21">S</span>后熵的期望值。这个第二项描述的期望熵就是每个子集的熵的加权和，权值为属</p><p class="s33" style="padding-left: 74pt;text-indent: 0pt;line-height: 10pt;text-align: center;">| <i>S</i><span class="s52">v</span><span class="s41"> </span>|</p><p style="padding-left: 16pt;text-indent: 0pt;line-height: 12pt;text-align: left;">于<span class="s21">S</span><span class="s36">v</span>的样例占原始样例<span class="s21">S</span>的比例</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="30" height="1" alt="image" src="机器学习/Image_053.png"/></span></p><p class="s33" style="padding-left: 2pt;text-indent: 0pt;text-align: left;">| <i>S </i>|</p><p class="s21" style="text-indent: 0pt;line-height: 11pt;text-align: left;"><span class="p">。所以</span>Gain<span class="s6">(</span>S,A<span class="s6">)</span><span class="p">是由于知道属性</span>A<span class="p">的值而导致的期</span></p><p class="s21" style="padding-top: 2pt;padding-left: 16pt;text-indent: 0pt;line-height: 107%;text-align: justify;"><span class="p">望熵减少。换句话来讲，</span>Gain<span class="s6">(</span>S,A<span class="s6">)</span><span class="p">是由于给定属性</span>A<span class="p">的值而得到的关于目标函数值的信 息。当对</span>S<span class="p">的一个任意成员的目标值编码时，</span>Gain<span class="s6">(</span>S,A<span class="s6">)</span><span class="p">的值是在知道属性</span>A<span class="p">的值后可以 节省的二进制位数。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 16pt;text-indent: 21pt;line-height: 106%;text-align: justify;">例如，假定 <span class="s21">S </span>是一套有关天气的训练样例，描述它的属性包括可能是具有 <span class="s21">Weak </span>和 <span class="s21">Strong </span>两个值的 <span class="s21">Wind</span>。像前面一样，假定 <span class="s21">S </span>包含 <span class="s6">14 </span>个样例，<span class="s6">[9+</span>，<span class="s6">5-]</span>。在这 <span class="s6">14 </span>个样例 中，假定正例中的 <span class="s6">6 </span>个和反例中的 <span class="s6">2 </span>个有 <span class="s21">Wind =Weak</span><span class="s47">，</span>其他的有 <span class="s21">Wind=Strong</span>。由于按 照属性 <span class="s21">Wind </span>分类 <span class="s6">14 </span>个样例得到的信息增益可以计算如下。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="padding-top: 2pt;padding-left: 43pt;text-indent: 0pt;text-align: left;">Values(Wind) <span class="s38"> </span>Weak,Strong</p><p class="s38" style="padding-top: 3pt;padding-left: 101pt;text-indent: 0pt;text-align: left;"><span class="s30">S </span> <span class="s33">[9</span><span class="s33">,5-]</span></p><p class="s49" style="padding-top: 4pt;padding-left: 78pt;text-indent: 3pt;line-height: 115%;text-align: right;">S<span class="s41">Weak </span>S<span class="s41">Strong</span></p><p class="s38" style="padding-top: 3pt;padding-left: 3pt;text-indent: 0pt;text-align: left;"> <span class="s33">[6</span><span class="s33">,2</span><span class="s33">]</span></p><p class="s38" style="padding-top: 3pt;padding-left: 3pt;text-indent: 0pt;text-align: left;"> <span class="s33">[3</span><span class="s33">,3</span><span class="s33">]</span></p><p class="s30" style="padding-top: 8pt;padding-left: 39pt;text-indent: 0pt;line-height: 12pt;text-align: left;">Gain<span class="s33">(</span>S<span class="s33">,</span>Wind <span class="s33">) </span><span class="s38"> </span>Entropy<span class="s33">(</span>S <span class="s33">) </span><span class="s38"></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="30" height="1" alt="image" src="机器学习/Image_054.png"/></span></p><p class="s82" style="padding-top: 1pt;padding-left: 19pt;text-indent: 0pt;line-height: 19pt;text-align: left;"><span class="s39"> </span>| <i>S</i><span class="s83">v </span>|<span class="s33"> </span><i>Entropy</i><span class="s33">(</span></p><p class="s30" style="padding-top: 9pt;text-indent: 0pt;line-height: 11pt;text-align: left;">S<span class="s41">v</span><span class="s84">)</span></p><p class="s41" style="padding-left: 157pt;text-indent: 0pt;line-height: 13pt;text-align: center;">v<span class="s40"></span><span class="s42">{</span>Weak <span class="s42">,</span>Strong<span class="s42">} </span><span class="s84">| </span><span class="s30">S </span><span class="s33">|</span></p><p class="s33" style="padding-top: 3pt;padding-left: 111pt;text-indent: 0pt;text-align: left;"><span class="s38"> </span><i>Entropy</i>(<i>S </i>) <span class="s38"> </span>(8 /14)<i>Entropy</i>(<i>S</i><span class="s52">Weak</span><span class="s41"> </span>) <span class="s38"> </span>(6 /14)<i>Entropy</i>(<i>S</i><span class="s52">Strong</span><span class="s41"> </span>)</p><p class="s38" style="padding-top: 3pt;padding-left: 111pt;text-indent: 0pt;text-align: left;"> <span class="s33">0.940 </span> <span class="s33">(8 /14)0.811 </span> <span class="s33">(6 /14)1.00</span></p><p class="s38" style="padding-top: 3pt;padding-left: 111pt;text-indent: 0pt;text-align: left;"> <span class="s33">0.048</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 16pt;text-indent: 21pt;line-height: 107%;text-align: left;">信息增益正是 <span class="s6">ID3 </span>算法增长树的每一步中选取最佳属性的度量标准。图 <span class="s6">3-3 </span>概述了 如何使用信息增益来评估属性的分类能力。在这个图中，计算了两个不同属性：湿度</p><p style="padding-top: 1pt;padding-left: 16pt;text-indent: 0pt;line-height: 107%;text-align: left;">（<span class="s21">Humidity</span>）和风力（<span class="s21">Wind</span>）的信息增益，以便决定对于分类表 <span class="s6">3-2 </span>的训练样例哪一个 属性更好。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 13pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="547" height="1" alt="image" src="机器学习/Image_055.png"/></span></p><p class="s48" style="padding-left: 15pt;text-indent: 0pt;text-align: left;">插图——原书页码： <span class="s21">59</span></p><p class="s6" style="padding-left: 42pt;text-indent: 0pt;text-align: left;">Which attribute is the best classifier? <span class="p">哪一个属性是最佳的分类属性？</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 19pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="556" height="1" alt="image" src="机器学习/Image_056.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 37pt;text-indent: 127pt;text-align: left;">图 <span class="h4">3-3 </span>计算属性的信息增益</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-left: 37pt;text-indent: 0pt;line-height: 125%;text-align: justify;">相对于目标分类（即星期六上午是否适合打网球），<span class="s56">Humidity </span>比 <span class="s56">Wind </span>有更大的信息增益。这里，<span class="s56">E </span>代 表熵，<span class="s56">S </span>代表原始样例集合。已知初始集合 <span class="s56">S </span>有 <span class="s16">9 </span>个正例和 <span class="s16">5 </span>个负例，即<span class="s16">[9+</span>，<span class="s16">5-]</span>。用 <span class="s56">Humidity </span>分类这 些样例产生了子集<span class="s16">[3+</span>，<span class="s16">4-]</span>（<span class="s56">Humidity</span><span class="s16">=</span><span class="s56">High</span>）和<span class="s16">[6+</span>，<span class="s16">1-]</span>（<span class="s56">Humidity</span><span class="s16">=</span><span class="s56">Normal</span>）。这种分类的信息增益 为 <span class="s16">0.151</span>，而对于属性 <span class="s56">Wind </span>增益仅为 <span class="s16">0.048</span>。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 45pt;text-indent: 0pt;text-align: left;">3.4.2 <span class="s25">示例</span></h3><p style="padding-top: 10pt;padding-left: 21pt;text-indent: 21pt;line-height: 109%;text-align: left;">为了演示 <span class="s6">ID3 </span>算法的具体操作，考虑表 <span class="s6">3-2 </span>的训练数据所代表的学习任务。这里， 目标属性 <span class="s21">PlayTennis </span>对于不同的星期六上午具有 <span class="s21">yes </span>和 <span class="s21">no </span>两个值，我们将根据其他属 性来预测这个目标属性值。先考虑这个算法的第一步，创建决策树的最顶端结点。哪一 个属性该在树上第一个被测试呢？<span class="s21">ID</span><span class="s6">3 </span>算法计算每一个候选属性（也就是 <span class="s21">Outlook</span>， <span class="s21">Temperature</span>，<span class="s21">Humidity</span>，和 <span class="s21">Wind</span>）的信息增益，然后选择信息增益最高的一个。其中 两个属性的信息增益的计算显示在图 <span class="s6">3-3 </span>中。所有四个属性的信息增益为</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 53pt;text-indent: 0pt;line-height: 229%;text-align: left;">Gain<span class="s6">(</span>S<span class="s6">,</span>Outlook<span class="s6">)=0.246 </span>Gain<span class="s6">(</span>S<span class="s6">,</span>Humidity<span class="s6">)=0.151 </span>Gain<span class="s6">(</span>S<span class="s6">,</span>Wind<span class="s6">)=0.048 </span>Gain<span class="s6">(</span>S<span class="s6">,</span>Temperature<span class="s6">)=0.029</span></p><p style="padding-left: 42pt;text-indent: 0pt;line-height: 12pt;text-align: left;">其中 <span class="s6">S </span>表示来自表 <span class="s6">3-2 </span>的训练样例的集合。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 138pt;text-indent: 0pt;text-align: left;">表 <span class="h4">3-2 </span>目标概念 <span class="s7">PlayTennis </span>的训练样例</p><p style="text-indent: 0pt;text-align: left;"><br/></p><table style="border-collapse:collapse;margin-left:5.60001pt" cellspacing="0"><tr style="height:17pt"><td style="width:51pt;border-top-style:solid;border-top-width:2pt;border-top-color:#808080;border-bottom-style:solid;border-bottom-width:1pt;border-bottom-color:#808080"><p class="s85" style="padding-left: 15pt;text-indent: 0pt;line-height: 11pt;text-align: left;">Day</p></td><td style="width:70pt;border-top-style:solid;border-top-width:2pt;border-top-color:#808080;border-bottom-style:solid;border-bottom-width:1pt;border-bottom-color:#808080"><p class="s86" style="padding-left: 18pt;text-indent: 0pt;line-height: 11pt;text-align: left;">Outlook</p></td><td style="width:85pt;border-top-style:solid;border-top-width:2pt;border-top-color:#808080;border-bottom-style:solid;border-bottom-width:1pt;border-bottom-color:#808080"><p class="s86" style="padding-left: 15pt;text-indent: 0pt;line-height: 11pt;text-align: left;">Temperature</p></td><td style="width:75pt;border-top-style:solid;border-top-width:2pt;border-top-color:#808080;border-bottom-style:solid;border-bottom-width:1pt;border-bottom-color:#808080"><p class="s86" style="padding-left: 18pt;text-indent: 0pt;line-height: 11pt;text-align: left;">Humidity</p></td><td style="width:65pt;border-top-style:solid;border-top-width:2pt;border-top-color:#808080;border-bottom-style:solid;border-bottom-width:1pt;border-bottom-color:#808080"><p class="s86" style="padding-left: 19pt;text-indent: 0pt;line-height: 11pt;text-align: left;">Wind</p></td><td style="width:80pt;border-top-style:solid;border-top-width:2pt;border-top-color:#808080;border-bottom-style:solid;border-bottom-width:1pt;border-bottom-color:#808080"><p class="s86" style="padding-left: 18pt;text-indent: 0pt;line-height: 11pt;text-align: left;">PlayTennis</p></td></tr><tr style="height:15pt"><td style="width:51pt;border-top-style:solid;border-top-width:1pt;border-top-color:#808080"><p class="s85" style="padding-left: 15pt;text-indent: 0pt;line-height: 11pt;text-align: left;">D1</p></td><td style="width:70pt;border-top-style:solid;border-top-width:1pt;border-top-color:#808080"><p class="s85" style="padding-left: 18pt;text-indent: 0pt;line-height: 11pt;text-align: left;">Sunny</p></td><td style="width:85pt;border-top-style:solid;border-top-width:1pt;border-top-color:#808080"><p class="s85" style="padding-left: 20pt;text-indent: 0pt;line-height: 11pt;text-align: left;">Hot</p></td><td style="width:75pt;border-top-style:solid;border-top-width:1pt;border-top-color:#808080"><p class="s85" style="padding-left: 18pt;text-indent: 0pt;line-height: 11pt;text-align: left;">High</p></td><td style="width:65pt;border-top-style:solid;border-top-width:1pt;border-top-color:#808080"><p class="s85" style="padding-left: 19pt;text-indent: 0pt;line-height: 11pt;text-align: left;">Weak</p></td><td style="width:80pt;border-top-style:solid;border-top-width:1pt;border-top-color:#808080"><p class="s85" style="padding-left: 18pt;text-indent: 0pt;line-height: 11pt;text-align: left;">No</p></td></tr><tr style="height:16pt"><td style="width:51pt"><p class="s85" style="padding-top: 1pt;padding-left: 15pt;text-indent: 0pt;text-align: left;">D2</p></td><td style="width:70pt"><p class="s85" style="padding-top: 1pt;padding-left: 18pt;text-indent: 0pt;text-align: left;">Sunny</p></td><td style="width:85pt"><p class="s85" style="padding-top: 1pt;padding-left: 20pt;text-indent: 0pt;text-align: left;">Hot</p></td><td style="width:75pt"><p class="s85" style="padding-top: 1pt;padding-left: 18pt;text-indent: 0pt;text-align: left;">High</p></td><td style="width:65pt"><p class="s85" style="padding-top: 1pt;padding-left: 19pt;text-indent: 0pt;text-align: left;">Strong</p></td><td style="width:80pt"><p class="s85" style="padding-top: 1pt;padding-left: 18pt;text-indent: 0pt;text-align: left;">No</p></td></tr><tr style="height:16pt"><td style="width:51pt"><p class="s85" style="padding-top: 1pt;padding-left: 15pt;text-indent: 0pt;text-align: left;">D3</p></td><td style="width:70pt"><p class="s85" style="padding-top: 1pt;padding-left: 18pt;text-indent: 0pt;text-align: left;">Overcast</p></td><td style="width:85pt"><p class="s85" style="padding-top: 1pt;padding-left: 20pt;text-indent: 0pt;text-align: left;">Hot</p></td><td style="width:75pt"><p class="s85" style="padding-top: 1pt;padding-left: 18pt;text-indent: 0pt;text-align: left;">High</p></td><td style="width:65pt"><p class="s85" style="padding-top: 1pt;padding-left: 19pt;text-indent: 0pt;text-align: left;">Weak</p></td><td style="width:80pt"><p class="s85" style="padding-top: 1pt;padding-left: 18pt;text-indent: 0pt;text-align: left;">Yes</p></td></tr><tr style="height:16pt"><td style="width:51pt"><p class="s85" style="padding-top: 1pt;padding-left: 15pt;text-indent: 0pt;text-align: left;">D4</p></td><td style="width:70pt"><p class="s85" style="padding-top: 1pt;padding-left: 18pt;text-indent: 0pt;text-align: left;">Rain</p></td><td style="width:85pt"><p class="s85" style="padding-top: 1pt;padding-left: 20pt;text-indent: 0pt;text-align: left;">Mild</p></td><td style="width:75pt"><p class="s85" style="padding-top: 1pt;padding-left: 18pt;text-indent: 0pt;text-align: left;">High</p></td><td style="width:65pt"><p class="s85" style="padding-top: 1pt;padding-left: 19pt;text-indent: 0pt;text-align: left;">Weak</p></td><td style="width:80pt"><p class="s85" style="padding-top: 1pt;padding-left: 18pt;text-indent: 0pt;text-align: left;">Yes</p></td></tr><tr style="height:16pt"><td style="width:51pt"><p class="s85" style="padding-top: 1pt;padding-left: 15pt;text-indent: 0pt;text-align: left;">D5</p></td><td style="width:70pt"><p class="s85" style="padding-top: 1pt;padding-left: 18pt;text-indent: 0pt;text-align: left;">Rain</p></td><td style="width:85pt"><p class="s85" style="padding-top: 1pt;padding-left: 20pt;text-indent: 0pt;text-align: left;">Cool</p></td><td style="width:75pt"><p class="s85" style="padding-top: 1pt;padding-left: 18pt;text-indent: 0pt;text-align: left;">Normal</p></td><td style="width:65pt"><p class="s85" style="padding-top: 1pt;padding-left: 19pt;text-indent: 0pt;text-align: left;">Weak</p></td><td style="width:80pt"><p class="s85" style="padding-top: 1pt;padding-left: 18pt;text-indent: 0pt;text-align: left;">Yes</p></td></tr><tr style="height:16pt"><td style="width:51pt"><p class="s85" style="padding-top: 1pt;padding-left: 15pt;text-indent: 0pt;text-align: left;">D6</p></td><td style="width:70pt"><p class="s85" style="padding-top: 1pt;padding-left: 18pt;text-indent: 0pt;text-align: left;">Rain</p></td><td style="width:85pt"><p class="s85" style="padding-top: 1pt;padding-left: 20pt;text-indent: 0pt;text-align: left;">Cool</p></td><td style="width:75pt"><p class="s85" style="padding-top: 1pt;padding-left: 18pt;text-indent: 0pt;text-align: left;">Normal</p></td><td style="width:65pt"><p class="s85" style="padding-top: 1pt;padding-left: 20pt;text-indent: 0pt;text-align: left;">Strong</p></td><td style="width:80pt"><p class="s85" style="padding-top: 1pt;padding-left: 18pt;text-indent: 0pt;text-align: left;">No</p></td></tr><tr style="height:16pt"><td style="width:51pt"><p class="s85" style="padding-top: 1pt;padding-left: 15pt;text-indent: 0pt;text-align: left;">D7</p></td><td style="width:70pt"><p class="s85" style="padding-top: 1pt;padding-left: 18pt;text-indent: 0pt;text-align: left;">Overcast</p></td><td style="width:85pt"><p class="s85" style="padding-top: 1pt;padding-left: 20pt;text-indent: 0pt;text-align: left;">Cool</p></td><td style="width:75pt"><p class="s85" style="padding-top: 1pt;padding-left: 18pt;text-indent: 0pt;text-align: left;">Normal</p></td><td style="width:65pt"><p class="s85" style="padding-top: 1pt;padding-left: 19pt;text-indent: 0pt;text-align: left;">Strong</p></td><td style="width:80pt"><p class="s85" style="padding-top: 1pt;padding-left: 18pt;text-indent: 0pt;text-align: left;">Yes</p></td></tr><tr style="height:16pt"><td style="width:51pt"><p class="s85" style="padding-top: 1pt;padding-left: 15pt;text-indent: 0pt;text-align: left;">D8</p></td><td style="width:70pt"><p class="s85" style="padding-top: 1pt;padding-left: 18pt;text-indent: 0pt;text-align: left;">Sunny</p></td><td style="width:85pt"><p class="s85" style="padding-top: 1pt;padding-left: 20pt;text-indent: 0pt;text-align: left;">Mild</p></td><td style="width:75pt"><p class="s85" style="padding-top: 1pt;padding-left: 18pt;text-indent: 0pt;text-align: left;">High</p></td><td style="width:65pt"><p class="s85" style="padding-top: 1pt;padding-left: 19pt;text-indent: 0pt;text-align: left;">Weak</p></td><td style="width:80pt"><p class="s85" style="padding-top: 1pt;padding-left: 18pt;text-indent: 0pt;text-align: left;">No</p></td></tr><tr style="height:16pt"><td style="width:51pt"><p class="s85" style="padding-top: 1pt;padding-left: 15pt;text-indent: 0pt;text-align: left;">D9</p></td><td style="width:70pt"><p class="s85" style="padding-top: 1pt;padding-left: 18pt;text-indent: 0pt;text-align: left;">Sunny</p></td><td style="width:85pt"><p class="s85" style="padding-top: 1pt;padding-left: 20pt;text-indent: 0pt;text-align: left;">Cool</p></td><td style="width:75pt"><p class="s85" style="padding-top: 1pt;padding-left: 18pt;text-indent: 0pt;text-align: left;">Normal</p></td><td style="width:65pt"><p class="s85" style="padding-top: 1pt;padding-left: 19pt;text-indent: 0pt;text-align: left;">Weak</p></td><td style="width:80pt"><p class="s85" style="padding-top: 1pt;padding-left: 18pt;text-indent: 0pt;text-align: left;">Yes</p></td></tr><tr style="height:16pt"><td style="width:51pt"><p class="s85" style="padding-top: 1pt;padding-left: 15pt;text-indent: 0pt;text-align: left;">D10</p></td><td style="width:70pt"><p class="s85" style="padding-top: 1pt;padding-left: 18pt;text-indent: 0pt;text-align: left;">Rain</p></td><td style="width:85pt"><p class="s85" style="padding-top: 1pt;padding-left: 20pt;text-indent: 0pt;text-align: left;">Mild</p></td><td style="width:75pt"><p class="s85" style="padding-top: 1pt;padding-left: 18pt;text-indent: 0pt;text-align: left;">Normal</p></td><td style="width:65pt"><p class="s85" style="padding-top: 1pt;padding-left: 20pt;text-indent: 0pt;text-align: left;">Weak</p></td><td style="width:80pt"><p class="s85" style="padding-top: 1pt;padding-left: 18pt;text-indent: 0pt;text-align: left;">Yes</p></td></tr><tr style="height:16pt"><td style="width:51pt"><p class="s85" style="padding-top: 1pt;padding-left: 15pt;text-indent: 0pt;text-align: left;">D11</p></td><td style="width:70pt"><p class="s85" style="padding-top: 1pt;padding-left: 18pt;text-indent: 0pt;text-align: left;">Sunny</p></td><td style="width:85pt"><p class="s85" style="padding-top: 1pt;padding-left: 20pt;text-indent: 0pt;text-align: left;">Mild</p></td><td style="width:75pt"><p class="s85" style="padding-top: 1pt;padding-left: 18pt;text-indent: 0pt;text-align: left;">Normal</p></td><td style="width:65pt"><p class="s85" style="padding-top: 1pt;padding-left: 19pt;text-indent: 0pt;text-align: left;">Strong</p></td><td style="width:80pt"><p class="s85" style="padding-top: 1pt;padding-left: 18pt;text-indent: 0pt;text-align: left;">Yes</p></td></tr><tr style="height:16pt"><td style="width:51pt"><p class="s85" style="padding-top: 1pt;padding-left: 15pt;text-indent: 0pt;text-align: left;">D12</p></td><td style="width:70pt"><p class="s85" style="padding-top: 1pt;padding-left: 18pt;text-indent: 0pt;text-align: left;">Overcast</p></td><td style="width:85pt"><p class="s85" style="padding-top: 1pt;padding-left: 20pt;text-indent: 0pt;text-align: left;">Mild</p></td><td style="width:75pt"><p class="s85" style="padding-top: 1pt;padding-left: 18pt;text-indent: 0pt;text-align: left;">High</p></td><td style="width:65pt"><p class="s85" style="padding-top: 1pt;padding-left: 19pt;text-indent: 0pt;text-align: left;">Strong</p></td><td style="width:80pt"><p class="s85" style="padding-top: 1pt;padding-left: 18pt;text-indent: 0pt;text-align: left;">Yes</p></td></tr><tr style="height:16pt"><td style="width:51pt"><p class="s85" style="padding-top: 1pt;padding-left: 15pt;text-indent: 0pt;text-align: left;">D13</p></td><td style="width:70pt"><p class="s85" style="padding-top: 1pt;padding-left: 18pt;text-indent: 0pt;text-align: left;">Overcast</p></td><td style="width:85pt"><p class="s85" style="padding-top: 1pt;padding-left: 20pt;text-indent: 0pt;text-align: left;">Hot</p></td><td style="width:75pt"><p class="s85" style="padding-top: 1pt;padding-left: 18pt;text-indent: 0pt;text-align: left;">Normal</p></td><td style="width:65pt"><p class="s85" style="padding-top: 1pt;padding-left: 19pt;text-indent: 0pt;text-align: left;">Weak</p></td><td style="width:80pt"><p class="s85" style="padding-top: 1pt;padding-left: 18pt;text-indent: 0pt;text-align: left;">Yes</p></td></tr><tr style="height:19pt"><td style="width:51pt;border-bottom-style:solid;border-bottom-width:2pt;border-bottom-color:#808080"><p class="s85" style="padding-top: 1pt;padding-left: 15pt;text-indent: 0pt;text-align: left;">D14</p></td><td style="width:70pt;border-bottom-style:solid;border-bottom-width:2pt;border-bottom-color:#808080"><p class="s85" style="padding-top: 1pt;padding-left: 18pt;text-indent: 0pt;text-align: left;">Rain</p></td><td style="width:85pt;border-bottom-style:solid;border-bottom-width:2pt;border-bottom-color:#808080"><p class="s85" style="padding-top: 1pt;padding-left: 20pt;text-indent: 0pt;text-align: left;">Mild</p></td><td style="width:75pt;border-bottom-style:solid;border-bottom-width:2pt;border-bottom-color:#808080"><p class="s85" style="padding-top: 1pt;padding-left: 18pt;text-indent: 0pt;text-align: left;">High</p></td><td style="width:65pt;border-bottom-style:solid;border-bottom-width:2pt;border-bottom-color:#808080"><p class="s85" style="padding-top: 1pt;padding-left: 20pt;text-indent: 0pt;text-align: left;">Strong</p></td><td style="width:80pt;border-bottom-style:solid;border-bottom-width:2pt;border-bottom-color:#808080"><p class="s85" style="padding-top: 1pt;padding-left: 18pt;text-indent: 0pt;text-align: left;">No</p></td></tr></table><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 42pt;text-indent: 0pt;text-align: left;">根据信息增益标准，属性 <span class="s21">Outlook </span>在训练样例上提供了对目标属性 <span class="s21">PlayTennis </span>的最</p><p class="s21" style="padding-left: 16pt;text-indent: 0pt;line-height: 107%;text-align: left;"><span class="p">好预测。所以，</span>Outlook <span class="p">被选作根结点的决策属性，并为它的每一个可能值（也就是 </span>Sunny<span class="s47">， </span>Overcast <span class="p">和 </span>Rain<span class="p">）在根结点下创建分支。部分决策树的结果显示在图 </span><span class="s6">3-4 </span><span class="p">中，同时画出 的还有被排列到每个新的后继结点的训练样例。注意到每一个 </span>Outlook<span class="s6">=</span>Overcast <span class="p">的样例 也都是 </span>PlayTennis <span class="p">的正例。所以，树的这个结点成为一个叶子结点，它对目标属性的分 类是 </span>PlayTennis<span class="s6">=</span>Yes<span class="p">。相反，对应 </span>Outlook<span class="s6">=</span>Sunny <span class="p">和 </span>Outlook<span class="s6">=</span>Rain <span class="p">的后继结点还有非 </span><span class="s6">0 </span><span class="p">的熵，所以决策树会在这些结点下进一步展开。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 16pt;text-indent: 21pt;line-height: 110%;text-align: justify;">对于非终端的后继结点，再重复前面的过程选择一个新的属性来分割训练样例，这 一次仅使用与这个结点关联的训练样例。已经被收编入树的较高结点的属性被排除在 外，以便任何给定的属性在树的任意路径上最多仅出现一次。对于每一个新的叶子结点 继续这个过程，直到满足以下两个条件中的任一个：（<span class="s6">1</span>）所有的属性已经被这条路径包 括，或（<span class="s6">2</span>）与这个结点关联的所有训练样例都具有同样的目标属性值（也就是它们的 熵为 <span class="s6">0</span>）。图 <span class="s6">3-4 </span>列出了下一步增长树要计算的信息增益。从表 <span class="s6">3-2 </span>的 <span class="s6">14 </span>个训练样例通 过 <span class="s6">ID3 </span>算法得到的最终决策树被画在图 <span class="s6">3-1 </span>中。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 13pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="547" height="1" alt="image" src="机器学习/Image_057.png"/></span></p><p class="s48" style="padding-left: 15pt;text-indent: 0pt;text-align: left;">插图——原书页码： <span class="s21">61</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="556" height="1" alt="image" src="机器学习/Image_058.png"/></span></p><p style="padding-top: 1pt;padding-left: 125pt;text-indent: -88pt;line-height: 200%;text-align: left;"><span class="s6">Which attribute should be test here? </span>哪一个属性应在这里被测试？ 图 <span class="h4">3-4 ID3 </span>算法第一步后形成的部分决策树</p><p class="s14" style="padding-top: 3pt;padding-left: 32pt;text-indent: 0pt;line-height: 125%;text-align: left;">训练样例被排列到对应的分支结点。分支 <span class="s56">Overcast </span>的所有样例都是正例，所以成为目标分类为 <span class="s56">Yes </span>的 叶结点。另两个结点将被进一步展开，方法是按照新的样例子集选取信息增益最高的属性。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 16pt;text-indent: 0pt;text-align: left;">3.5 <span class="s17">决策树学习中的假设空间搜索</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 16pt;text-indent: 21pt;line-height: 110%;text-align: justify;">与其他的归纳学习算法一样，<span class="s6">ID3 </span>算法可以被描述为从一个假设空间中搜索一个拟 合训练样例的假设。被 <span class="s6">ID3 </span>算法搜索的假设空间就是可能的决策树的集合。<span class="s6">ID3 </span>算法以 一种从简单到复杂的爬山算法遍历这个假设空间，从空的树开始，然后逐步考虑更加复 杂的假设，目的是搜索到一个正确分类训练数据的决策树。引导这种爬山搜索的评估函 数是信息增益度量。图 <span class="s6">3-5 </span>描述了这种搜索。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 13pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="547" height="1" alt="image" src="机器学习/Image_059.png"/></span></p><p class="s48" style="padding-left: 15pt;text-indent: 0pt;text-align: left;">插图——原书页码： <span class="s21">62</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 14pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="556" height="1" alt="image" src="机器学习/Image_060.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 19pt;text-indent: 0pt;text-align: center;">图 <span class="h4">3-5 ID3 </span>搜索的假设空间</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s16" style="padding-left: 33pt;text-indent: 0pt;text-align: left;">ID3 <span class="s14">遍历可能决策树的空间，从最简单的树到逐渐复杂的树。其搜索由信息增益启发式规则引导。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 16pt;text-indent: 21pt;line-height: 107%;text-align: left;">通过观察 <span class="s6">ID3 </span>算法的搜索空间和搜索策略，我们可以深入认识这个算法的优势和 不足。</p><p class="s6" style="padding-top: 6pt;padding-left: 49pt;text-indent: -21pt;line-height: 14pt;text-align: left;"><span class="s34">• </span>ID3 <span class="p">算法中的假设空间包含所有的决策树，它是相对于现有属性的有限离散值函 数的一个完整空间。因为每个有限离散值函数可被表示为某个决策树，所以 </span>ID3</p><p style="padding-top: 1pt;padding-left: 49pt;text-indent: 0pt;line-height: 14pt;text-align: left;">算法避免了搜索不完整假设空间（例如那些仅考虑合取假设的方法）的一个主 要风险：假设空间可能不包含目标函数。</p><p style="padding-left: 49pt;text-indent: -21pt;line-height: 14pt;text-align: left;"><span class="s34">• </span>当遍历决策树空间时，<span class="s6">ID3 </span>仅维护单一的当前假设。这与第 <span class="s6">2 </span>章讨论的变型空间 候选消除方法不同，后者维护了与当前的训练样例一致的所有假设的集合。因</p><p style="padding-left: 49pt;text-indent: 0pt;line-height: 14pt;text-align: left;">为仅考虑单一的假设，<span class="s6">ID3 </span>算法失去了表示所有一致假设所带来的优势。例如， 它不能判断有多少个其他的决策树也是与现有的训练数据一致的，或者使用新</p><p style="padding-left: 49pt;text-indent: 0pt;line-height: 12pt;text-align: left;">的实例查询来最优地区分这些竞争假设。</p><p style="padding-left: 49pt;text-indent: -21pt;text-align: justify;"><span class="s34">• </span>基本的 <span class="s6">ID3 </span>算法在搜索中不进行回溯。每当在树的某一层次选择了一个属性进 行测试，它不会再回溯重新考虑这个选择。所以，它易受无回溯的爬山搜索中 常见风险影响：收敛到局部最优的答案，但不是全局最优的。对于 <span class="s6">ID3 </span>算法， 一个局部最优的答案对应着它在一条搜索路径上探索时选择的决策树。然而， 这个局部最优的答案可能不如沿着另一条分支搜索到的更令人满意。后面我们 讨论一个扩展，增加一种形式的回溯（后修剪决策树）。</p><p class="s6" style="padding-left: 49pt;text-indent: -21pt;text-align: left;"><span class="s34">• </span>ID3 <span class="p">算法在搜索的每一步都使用当前的所有训练样例，以统计为基础决定怎样精 化当前的假设。这与那些基于单独的训练样例递增作出决定的方法（例如，</span>Find-S <span class="p">或候选消除法）不同。使用所有样例的统计属性（例如，信息增益）的一个优 点是大大减小了对个别训练样例错误的敏感性。因此，通过修改 </span>ID3 <span class="p">算法的终 止准则以接受不完全拟合训练数据的假设，它可以被很容易地扩展到处理含有 噪声的训练数据。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 16pt;text-indent: 0pt;text-align: justify;">3.6 <span class="s17">决策树学习的归纳偏置</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 16pt;text-indent: 21pt;line-height: 107%;text-align: justify;">ID3 <span class="p">算法从观测到的训练数据泛化以分类未见实例的策略是什么呢？换句话说，它 的归纳偏置是什么？回忆第 </span>2 <span class="p">章中，归纳偏置是一系列前提，这些前提与训练数据一起 演绎论证未来实例的分类。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 16pt;text-indent: 21pt;line-height: 110%;text-align: left;">如果给定一个训练样例的集合，那么通常有很多决策树与这些样例一致。所以，要 描述 <span class="s6">ID3 </span>算法的归纳偏置，应找到它从所有一致的假设中选择一个的根据。<span class="s6">ID3 </span>从这些 决策树中选择哪一个呢？它选择在使用简单到复杂的爬山算法遍历可能的树空间时遇 到的第一个可接受的树。概略地讲，<span class="s6">ID3 </span>的搜索策略为（<span class="s6">a</span>）优先选择较短的树而不是 较长的，和（<span class="s6">b</span>）选择那些信息增益高的属性离根结点较近的树。在 <span class="s6">ID3 </span>中使用的选择 属性的启发式规则和它遇到的特定训练样例之间存在着微妙的相互作用，由于这一点， 很难准确地刻划出 <span class="s6">ID3 </span>的归纳偏置。然而我们可以近似地把它的归纳偏置描述为一种 对短的决策树的偏好。</p><p style="padding-top: 3pt;padding-left: 37pt;text-indent: 0pt;line-height: 28pt;text-align: left;">近似的 <span class="h4">ID3 </span>算法归纳偏置：较短的树比较长的优先 事实上，我们可以想象一个类似于 <span class="s6">ID3 </span>的算法，它精确地具有这种归纳偏置。考</p><p style="padding-left: 16pt;text-indent: 0pt;line-height: 12pt;text-align: justify;">虑一种算法，它从一个空的树开始广度优先（<span class="s6">breadth first</span>）搜索逐渐复杂的树，先考虑</p><p style="padding-top: 1pt;padding-left: 16pt;text-indent: 0pt;line-height: 110%;text-align: justify;">所有深度为 <span class="s6">1 </span>的树，然后所有深度为 <span class="s6">2 </span>的，⋯⋯。一旦它找到了一个与训练数据一致的 决策树，它返回搜索深度的最小的一致树（例如，具有最少结点的树）。让我们称这种 广度优先搜索（<span class="s6">breadth first search</span>）算法为 <span class="h4">BFS-ID3</span>。<span class="s6">BFS-ID3 </span>寻找最短的决策树，因 此精确地具有“较短的树比较长的得到优先”的偏置。<span class="s6">ID3 </span>可被看作 <span class="s6">BFS-ID3 </span>的一个有 效近似，它使用一种贪婪的启发式搜索企图发现最短的树，而不用进行完整的广度优先 搜索来遍历假设空间。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 37pt;text-indent: 0pt;text-align: left;">因为 <span class="s6">ID3 </span>使用信息增益启发式规则和“爬山”策略，它包含比 <span class="s6">BFS-ID3 </span>更复杂的</p><p style="padding-left: 16pt;text-indent: 0pt;line-height: 113%;text-align: justify;">偏置。尤其是，它并非总是找最短的一致树，而是倾向于那些信息增益高的属性更靠近 根结点的树。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h4 style="padding-left: 16pt;text-indent: 21pt;line-height: 107%;text-align: justify;">ID3 <span class="p">归纳偏置的更贴切近似：较短的树比较长的得到优先。那些信息增益高的属性 更靠近根结点的树得到优先。</span></h4><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 40pt;text-indent: 0pt;text-align: left;">3.6.1 <span class="s25">限定偏置和优选偏置</span></h3><p style="padding-top: 10pt;padding-left: 16pt;text-indent: 21pt;line-height: 107%;text-align: justify;">在 <span class="s6">ID3 </span>算法和第 <span class="s6">2 </span>章讨论的候选消除算法显示出的归纳偏置之间有一个有趣的不 同。下面考虑一下这两种方法中对假设空间搜索的差异：</p><p style="padding-top: 5pt;padding-left: 49pt;text-indent: -21pt;text-align: left;"><span class="s34">• </span><span class="s6">ID3 </span>的搜索范围是一个<span class="s20">完整的</span>假设空间（例如，能表示任何有限的离散值函数的 空间）。但它<span class="s20">不彻底地</span>搜索这个空间，从简单的假设到复杂的假设，直到遇到 终止条件（例如，它发现了一个与数据一致的假设）。它的归纳偏置完全是搜 索策略排序假设的结果。它的假设空间没有引入额外的偏置。</p><p style="padding-left: 49pt;text-indent: -21pt;text-align: justify;"><span class="s34">• </span>变型空间候选消除算法的搜索范围是<span class="s20">不完整的</span>假设空间（即一个仅能表示潜在 可教授概念子集的空间）。但它<span class="s20">彻底地</span>搜索这个空间，查找所有与训练数据一 致的假设。它的归纳偏置完全是假设表示的表达能力的结果。它的搜索策略没 有引入额外的偏置。</p><p style="padding-top: 7pt;padding-left: 16pt;text-indent: 21pt;line-height: 107%;text-align: justify;">简单地讲，<span class="s6">ID3 </span>的归纳偏置来自它的<span class="s20">搜索策略</span>，而候选消除算法的归纳偏置来自它 对<span class="s20">搜索空间</span>的定义。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 37pt;text-indent: 0pt;text-align: left;">ID3 <span class="p">的归纳偏置是对某种假设（例如，对于较短的假设）胜过其他假设的一种</span><span class="s20">优选</span></p><p class="s20" style="padding-top: 1pt;padding-left: 16pt;text-indent: 0pt;line-height: 107%;text-align: justify;">（<span class="s6">preference</span>）<span class="p">，它对最终可列举的假设没有硬性限制</span>。<span class="p">这种类型的偏置通常被称为</span>优选 偏置（<span class="s6">preference bias</span>）<span class="p">（或叫</span>搜索偏置（<span class="s6">search bias</span>）<span class="p">）。相反，候选消除算法的偏置是对 待考虑假设的一种</span>限定<span class="p">（</span><span class="s6">restriction</span><span class="p">）。这种形式的偏置通常被称为</span>限定偏置<span class="p">（或者叫</span>语 言偏置<span class="p">（</span><span class="s6">language bias</span><span class="p">）。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 16pt;text-indent: 21pt;line-height: 107%;text-align: justify;">如果需要某种形式的归纳偏置来从训练数据中泛化（见第 <span class="s6">2 </span>章），那么我们该优先 考虑哪种形式的归纳偏置呢：是优选偏置还是限定偏置？</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 16pt;text-indent: 21pt;line-height: 113%;text-align: justify;">通常，优选偏置比限定偏置更合乎需要，因为它允许学习器工作在完整的假设空间 上，这保证了未知的目标函数被包含在内。相反的，限定偏置严格地限制了假设集合的 潜在空间，通常不是我们希望的，因为它同时引入了把未知的目标函数排除在外的可能 性。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 16pt;text-indent: 21pt;line-height: 110%;text-align: justify;">鉴于 <span class="s6">ID3 </span>采用纯粹的优选偏置而候选消除算法采用纯粹的限定偏置，一些学习系 统综合了这两者。例如，考虑第 <span class="s6">1 </span>章描述的下棋程序的例子。其中，学习到的评估函数 被表示为一些固定的棋盘特征的线性组合，学习算法调整这个线性组合的参数来最好地 拟合现有的训练数据。这里，使用线性函数来表示评估函数的决定就引入了限定偏置（非 线性的评估函数不可能被表示成这种形式）。同时，选择特定参数的调整方法（<span class="s6">LMS </span>算 法）引入了一个优选偏置，它源自所有可能参数值空间上的顺序搜索。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 40pt;text-indent: 0pt;text-align: left;">3.6.2 <span class="s25">为什么优先短的假设？</span></h3><p class="s6" style="padding-top: 10pt;padding-left: 16pt;text-indent: 21pt;line-height: 107%;text-align: justify;">ID3 <span class="p">算法中优选较短决策树的归纳偏置，是不是从训练数据中泛化的可靠基础？哲 学家们以及其他学者已经对这样的问题争论几个世纪了，而且这个争论至今还未解决。</span></p><p style="padding-top: 1pt;padding-left: 16pt;text-indent: 0pt;line-height: 107%;text-align: left;">威廉·奥坎姆大约在 <span class="s6">1320 </span>年提出类似的论点<span class="s9">①</span>，是最早讨论这个问题的人之一，所以这 个偏置经常被称为“奥坎姆剃刀”（<span class="s6">Occam’s razor</span>）。</p><p style="padding-top: 2pt;padding-left: 37pt;text-indent: 0pt;line-height: 28pt;text-align: left;">奥坎姆剃刀：优先选择拟合数据的最简单假设。 当然给出一个归纳偏置的名字不等于证明了它。为什么应该优先选择较简单的假设</p><p style="padding-left: 16pt;text-indent: 0pt;line-height: 12pt;text-align: left;">呢？请注意科学家们有时似乎也遵循这个归纳偏置。例如物理学家优先选择行星运动简</p><p style="padding-top: 1pt;padding-left: 16pt;text-indent: 0pt;line-height: 112%;text-align: left;">单的解释，而不用复杂的解释。为什么？一种解释是短假设的数量少于长假设（基于简 单的参数组合），所以找到一个短的假设但同时它与训练数据拟合的可能性较小。相反， 常常有很多非常复杂的假设拟合当前的训练数据，但却无法正确地泛化到后来的数据。 例如考虑决策树假设。<span class="s6">500 </span>个结点的决策树比 <span class="s6">5 </span>个结点的决策树多得多。如果给定一个 <span class="s6">20 </span>个训练样例的集合，可以预期能够找到很多 <span class="s6">500 </span>个结点的决策树与训练数据一致，</p><p style="padding-left: 16pt;text-indent: 0pt;line-height: 14pt;text-align: left;">而如果一个 <span class="s6">5 </span>结点的决策树可以完美地拟合这些数据则是出乎意外的。所以我们会相信</p><p class="s6" style="padding-top: 1pt;padding-left: 37pt;text-indent: -21pt;text-align: left;">5 <span class="p">个结点的树不太可能是统计巧合，因而优先选择这个假设，而不选择 </span>500 <span class="p">个结点的。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 16pt;text-indent: 21pt;line-height: 110%;text-align: left;">根据更深入的分析，可以发现上面的解释有一个主要的困难。为什么我们不反问： 使用同样的推理，应该优先选择包含恰好有 <span class="s6">17 </span>个叶子结点和 <span class="s6">11 </span>个非叶子结点的决策 树？这棵树在根结点使用决策属性<span class="s21">A</span><span class="s35">1</span>，然后以数字顺序测试属性<span class="s21">A</span><span class="s35">2</span>直到<span class="s21">A</span><span class="s35">11</span>。这样的决 策树相当少，因此（用和上面同样的推理），找到其中之一与任意数据集一致的先验可 能性也很小。这里的困难在于可以定义很多小的假设集合——其中的大多数相当晦涩难 解。那么，我们根据什么相信有短描述（<span class="s6">short description</span>）的决策树组成的小假设集合 就比其他众多可定义的小假设集合更适当呢？</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 16pt;text-indent: 21pt;line-height: 113%;text-align: justify;">上面的奥坎姆剃刀原则的解释的第二个难题是，假设的大小是由学习者内部使用的 特定表示决定的。所以两个学习器使用不同的内部表示会得到不同的假设，两者又都用 奥坎姆剃刀原则得到相互矛盾的结论！例如，如果我们定义属性 <span class="s21">XYZ</span>，它对于被图 <span class="s6">3-1</span></p><p style="padding-left: 16pt;text-indent: 0pt;line-height: 107%;text-align: justify;">的决策树分类为正例的实例等于真，相反为假，那么一个学习器就可以把图 <span class="s6">3-1 </span>中决策 树表示的函数表示为只有一个决策结点的树。于是，两个学习器如果一个使用了 <span class="s21">XYZ </span>属性描述它的实例，而另一个只使用 <span class="s21">Outlook</span>、<span class="s21">Temperature</span>、<span class="s21">Humidity </span>和 <span class="s21">Wind </span>属性，但 都应用奥坎姆剃刀原则，那么结果它们会以不同的方式泛化。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 16pt;text-indent: 21pt;line-height: 109%;text-align: left;">以上说明，对于同一套训练样例，当两个学习器以不同内部表示方式理解和使用这 些样例时，会产生两个不同的假设。基于这一点，似乎我们应完全抵制奥坎姆剃刀原则。 不过，让我们看一看下面这个场景，并分析哪一个内部表示会从自然选择和进化中脱颖 而出。想象一个由人造的学习 <span class="s6">agent </span>组成的群体，这个群体是由模拟的进化过程产生的， 进化过程包括 <span class="s6">agent </span>的繁殖、变异和自然选择。假定这个进化过程能够一代接一代地改 变这些 <span class="s6">agent </span>的感知系统，由此改变它们用来感知世界的器官的内部属性。出于论证的 考虑，我们也假定这些学习 <span class="s6">agent </span>采用一个不会被进化所改变的固定的算法（比如 <span class="s6">ID3</span>）。 有理由推断，随着时间的流逝，进化会产生更好的内部表示，使 <span class="s6">agent </span>能愈加成功地生 存在它们的环境中。假定 <span class="s6">agent </span>的成功依赖于它精确泛化的能力，所以我们可以期望， 进化产生的内部表示对任何学习算法和归纳偏置都有很好的性能。如果某个 <span class="s6">agent </span>种群 采用了带有奥坎姆剃刀归纳偏置的学习算法，那么我们期望进化会产生适合奥坎姆剃刀</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 26pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="193" height="1" alt="image" src="机器学习/Image_061.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s13" style="padding-top: 2pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">① <span class="s14">显然是在刮胡须时想到的。</span></p><p style="padding-left: 16pt;text-indent: 0pt;line-height: 110%;text-align: justify;">策略的内部表示。这个论点的精髓在于，进化产生的内部表示使得学习算法的归纳偏置 成为自我实现的预言（<span class="s6">self-fulfilling prophecy</span>），只因为它改变内部表示比改变学习算法 更容易。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 16pt;text-indent: 21pt;line-height: 107%;text-align: left;">暂时，我们放下关于奥坎姆剃刀的争论。第 <span class="s6">6 </span>章我们会再次提起这个话题，那里将 讨论最小描述长度（<span class="s6">Minimum Description Length</span>）原则，它是另一版本的奥坎姆剃刀， 它可用贝叶斯框架来解释。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 16pt;text-indent: 0pt;text-align: justify;">3.7 <span class="s17">决策树学习的常见问题</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 16pt;text-indent: 21pt;line-height: 111%;text-align: justify;">决策树学习的实际问题包括确定决策树增长的深度；处理连续值的属性；选择一个 适当的属性筛选度量标准；处理属性值不完整的训练数据；处理不同代价的属性；以及 提高计算效率。下面我们讨论每一个问题，并针对这些问题扩展基本的 <span class="s6">ID3 </span>算法。事 实上，为了解决其中多数的问题， <span class="s6">ID3 </span>算法已经被扩展了，扩展后的系统被改名为 <span class="s6">C4.5</span></p><p style="padding-left: 16pt;text-indent: 0pt;line-height: 14pt;text-align: justify;">（<span class="s6">Quinlan 1993</span>）。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 40pt;text-indent: 0pt;text-align: left;">3.7.1 <span class="s25">避免过度拟合（</span>Overfitting<span class="s25">）数据</span></h3><p style="padding-top: 10pt;padding-left: 16pt;text-indent: 21pt;line-height: 111%;text-align: justify;">表 <span class="s6">3-1 </span>描述的算法增长树的每一个分支的深度，直到恰好能对训练样例完美地分 类。然而这个策略并非总是行得通的，事实上，当数据中有噪声，或训练样例的数量太 少以至于不能产生目标函数的有代表性的采样时，这个策略便会遇到困难。在以上任一 种情况发生时，这个简单的算法产生的树会过度拟合训练样例。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 16pt;text-indent: 21pt;line-height: 113%;text-align: justify;">对于一个假设，当存在其他的假设对训练样例的拟合比它差，但事实上在实例的整 个分布（也就是包含训练集合以外的实例）上表现的却更好时，我们说这个假设过度拟 合（<span class="s6">overfit</span>）训练样例。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 26pt;text-indent: 21pt;line-height: 107%;text-align: justify;"><span class="p">定义： 给定一个假设空间 </span>H<span class="p">，一个假设 </span>h<span class="s10"></span>H<span class="p">，如果存在其他的假设 </span>h<span class="s6">´</span><span class="s10"></span>H<span class="p">，使 得在训练样例上 </span>h <span class="p">的错误率比 </span>h<span class="s6">´</span><span class="p">小，但在整个实例分布上 </span>h<span class="s6">´</span><span class="p">的错误率比 </span>h <span class="p">小，那么 就说假设 </span>h <span class="p">过度拟合（</span><span class="s6">overfit</span><span class="p">）训练数据。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 15pt;text-indent: 22pt;line-height: 111%;text-align: left;">图 <span class="s6">3-6 </span>画出了在决策树学习的一个典型应用中过度拟合的影响。在这个例子中，<span class="s6">ID3 </span>算法用来学习哪一个病人患有某种糖尿病。这幅图的横轴表示在决策树创建过程中树的 结点总数，纵轴表示决策树作出的预测的精度。实线显示决策树在训练样例上的精度， 虚线显示在一套独立的测试样例（没有被包括在训练样例中）上测量出的精度。可以看 出，随着树的增长，在训练样例上的精度是单调上升的。然而，在独立的测试样例上测 出的精度先上升后下降。如图所示，当树超过大约 <span class="s6">25 </span>个结点时，对树进一步精细化尽 管可以提高它在训练数据上的精度，却降低了它在测试样例上的精度。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 13pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="547" height="1" alt="image" src="机器学习/Image_062.png"/></span></p><p class="s48" style="padding-left: 15pt;text-indent: 0pt;text-align: justify;">插图——原书页码： <span class="s21">67</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">Accuracy – <span class="p">精度</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 27pt;text-indent: 0pt;text-align: left;">Size of tree(number of nodes) – <span class="p">树的规模（结点数）</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 27pt;text-indent: 0pt;text-align: left;">On training data –<span class="p">在训练数据上</span></p><p class="s6" style="padding-left: 27pt;text-indent: 0pt;text-align: left;">On test data – <span class="p">在测试数据上</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 14pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="556" height="1" alt="image" src="机器学习/Image_063.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 146pt;text-indent: 0pt;text-align: left;">图 <span class="h4">3-6 </span>决策树学习中的过度拟合。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s16" style="padding-left: 33pt;text-indent: 0pt;line-height: 129%;text-align: justify;"><span class="s14">随着 </span>ID3 <a href="http://www.cs.cmu.edu/%7Etom/mlbook.html" class="s156" target="_blank">算法增加新的结点增长决策树，在训练样例上的精度是单调上升的。然而，在独立于训练样 例的测 试样 例上， 精度 先上升 ，然 后下降 。实 验这个 图所 需的软 件和 数据可 以通 过网 址 </a>http://www.cs.cmu.edu/~tom/mlbook.html <span class="s14">得到。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 16pt;text-indent: 21pt;line-height: 107%;text-align: justify;">是什么原因导致 <span class="s21">h </span>比 <span class="s21">h</span><span class="s10"></span>更好地拟合训练样例，但对于后来的实例却表现更差呢？这 种情况发生的一种可能原因是训练样例含有随机错误或噪声。举例说明，考虑在表 <span class="s6">3-2 </span>的本来正确的样例中加入一条训练正例，但却被误标示为反例，如下：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="text-indent: 0pt;text-align: right;"><span class="s6">&lt;</span>Outlook<span class="s6">=</span>Sunny<span class="p">，</span>Temperature<span class="s6">=</span>Hot<span class="p">，</span>Humidity<span class="s6">=</span>Normal<span class="p">，</span>Wind<span class="s6">=</span>Strong<span class="p">，</span>PlayTennis<span class="s6">=</span>No<span class="s6">&gt;</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 16pt;text-indent: 21pt;line-height: 108%;text-align: justify;">对于本来没有错误的数据，<span class="s6">ID3 </span>生成图 <span class="s6">3-1 </span>表示的决策树。然而，增加这个不正确 的样例导致 <span class="s6">ID3 </span>建立一个更复杂的树。确切地讲，新的样例会被排列到图 <span class="s6">3-1 </span>表示的树 的左起第二个叶子结点，与以前的正例 <span class="s6">D9 </span>和 <span class="s6">D11 </span>排在一起。因为新的样例被标记为反 例，所以 <span class="s6">ID3 </span>会在这个结点下面进一步搜索更多的细节。当然只要新的错误样例与原 来这个结点的两个样例有任何差异，<span class="s6">ID3 </span>会成功找到一个新的决策属性来把新的样例从 以前的两个正例中分开。这样的结果是 <span class="s6">ID3 </span>会输出一个决策树<span class="s6">(</span><span class="s21">h</span><span class="s6">)</span>，它比图 <span class="s6">3-1 </span>中原来 的树（<span class="s21">h</span>´）更复杂。当然，<span class="s21">h </span>会完美地拟合训练样例集，而较简单的 <span class="s21">h</span>´不会。然而，由 于新的决策结点只是拟合训练样例中噪声的结果，我们可以断定在取自同一实例分布的 后续数据上，<span class="s21">h</span>´会胜过 <span class="s21">h</span>。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 16pt;text-indent: 21pt;line-height: 113%;text-align: justify;">上面的例子演示了训练样例中的随机噪声如何导致过度拟合。事实上，当训练数据 没有噪声时，过度拟合也有可能发生，特别是当少量的样例被关联到叶子结点时。这种 情况下，很可能出现巧合的规律性，使得一些属性恰巧可以很好地分割样例，但却与实 际的目标函数并无关系。一旦这样的巧合的规律性存在，就有过度拟合的风险。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 16pt;text-indent: 21pt;line-height: 110%;text-align: justify;">过度拟合对于决策树学习和其他很多学习算法是一个重要的实践困难。例如，在一 次关于 <span class="s6">ID3 </span>算法的实验研究中（<span class="s6">Mingers 1989b</span>），对于 <span class="s6">5 </span>种带有噪声和不确定数据的不 同学习任务，人们发现在多数问题中过度拟合使决策树的精度降低了 <span class="s6">10-25%</span>。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 37pt;text-indent: 0pt;text-align: justify;">有几种途径用来避免决策树学习中的过度拟合。它们可被分为两类：</p><p style="padding-top: 5pt;padding-left: 28pt;text-indent: 0pt;line-height: 14pt;text-align: left;"><span class="s34">• </span>及早停止增长树法，在 <span class="s6">ID3 </span>算法完美分类训练数据之前停止增长树；</p><p style="padding-left: 37pt;text-indent: -9pt;line-height: 149%;text-align: left;"><span class="s34">• </span>后修剪法（<span class="s6">post-prune</span>），即允许树过度拟合数据，然后对这个树后修剪。 尽管第一种方法可能看起来更直接，但是对过度拟合的树进行后修剪的第二种方法</p><p style="padding-left: 37pt;text-indent: -21pt;line-height: 10pt;text-align: left;">被证明在实践中更成功。这是因为在第一种方法中精确地估计何时停止增长树很困难。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 16pt;text-indent: 21pt;line-height: 113%;text-align: justify;">无论是通过及早停止还是后修剪来得到正确大小的树，一个关键的问题是使用什么 样的准则来确定最终正确树的大小。解决这个问题的方法包括：</p><p class="s34" style="padding-top: 5pt;padding-left: 49pt;text-indent: -21pt;line-height: 14pt;text-align: left;">• <span class="p">使用与训练样例截然不同的一套分离的样例，来评估通过后修剪方法从树上修 剪结点的效用。</span></p><p style="padding-top: 1pt;padding-left: 49pt;text-indent: -21pt;line-height: 94%;text-align: left;"><span class="s34">• </span>使用所有可用数据进行训练，但进行统计测试来估计扩展（或修剪）一个特定 的结点是否有可能改善在训练集合外的实例上的性能。例如，<span class="s6">Quinlan </span>（<span class="s6">1986</span>） 使用一种卡方（<span class="s6">chi-square</span>）测试来估计进一步扩展结点是否能改善在整个实例 分布上的性能，还是仅仅改善了在当前的训练数据上的性能。</p><p class="s34" style="padding-top: 1pt;padding-left: 49pt;text-indent: -21pt;line-height: 14pt;text-align: left;">• <span class="p">使用一个明确的标准来衡量训练样例和决策树编码的复杂度，当这个编码的长 度最小时停止增长树。这个方法基于一种启发式规则，被称为最小描述长度</span></p><p style="padding-left: 49pt;text-indent: 0pt;line-height: 13pt;text-align: left;">（<span class="s6">Minimum Description Length</span>）的准则，我们将在第 <span class="s6">6 </span>章中讨论这种方法。</p><p class="s6" style="padding-left: 37pt;text-indent: 11pt;line-height: 14pt;text-align: left;">Quinlan &amp; Rivest<span class="p">（</span>1989<span class="p">）和 </span>Mehta et al.<span class="p">（</span>1995<span class="p">）也讨论了这种方法。</span></p><p style="padding-top: 7pt;padding-left: 16pt;text-indent: 21pt;line-height: 112%;text-align: justify;">上面的第一种方法是最普通的，它常被称为<span class="s20">训练和验证集</span>（<span class="s6">training and validation set</span>）法。下面我们讨论这种方法的两个主要变种。这种方法中，可用的数据被分成两 个样例集合：一个训练集合用来形成学习到的假设，一个分离的验证集合用来评估这个 假设在后续数据上的精度，确切地说是用来评估修剪这个假设的影响。这个方法的动机 是：即使学习器可能会被训练集合中的随机错误和巧合规律性所误导，但验证集合不大 可能表现出同样的随机波动。所以，验证集合可以用来对过度拟合训练集中的虚假特征 提供一个防护检验。当然，很重要的一点，验证集合应该足够大，以便它本身可提供具 有统计意义的实例样本。一种常见的做法是取出可用样例的三分之一用作验证集合，使 用另外三分之二用作训练集合。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s37" style="padding-left: 37pt;text-indent: 0pt;text-align: left;">3.7.1.1 <span class="s20">错误率降低修剪</span></p><p style="padding-top: 8pt;padding-left: 37pt;text-indent: 0pt;text-align: left;">使用验证集合来防止过度拟合的确切方法是什么？一种称为“错误率降低修剪</p><p style="padding-top: 1pt;padding-left: 16pt;text-indent: 0pt;line-height: 112%;text-align: justify;">（<span class="s6">error-reduced pruning</span>）”的方法（<span class="s6">Quinlan 1987</span>）是考虑将树上的每一个结点作为修剪 的候选对象。修剪一个结点由以下步骤组成：删除以此结点为根的子树；使它成为叶子 结点；把和该结点关联的训练样例的最常见分类赋给它。仅当修剪后的树对于验证集合 的性能不差于原来的树时才删除该结点。这样便使因为训练集合的巧合规律性而加入的 结点很可能被删除，因为同样的巧合不大会发生在验证集合中。反复地修剪结点，每次 总是选取它的删除可以最大提高决策树在验证集合上的精度的结点。继续修剪结点直到 进一步的修剪是有害的（也就是降低了在验证集合上的精度）。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 37pt;text-indent: 0pt;text-align: left;">“错误率降低修剪”对决策树精度的影响被画在图 <span class="s6">3-7 </span>中。和图 <span class="s6">3-6 </span>一样，图 <span class="s6">3-7</span></p><p style="padding-top: 1pt;padding-left: 16pt;text-indent: 0pt;line-height: 111%;text-align: left;">显示了在训练样例和测试样例上的决策树精度。图 <span class="s6">3-7 </span>中另外一条线显示的是随着树的 修剪，它在测试样例上的精度变化。当修剪开始时，树的规模最大，并且它在测试样例 上的精度最小。随着修剪的进行，结点的数量下降，但在测试集合上的精度上升。这里， 可供使用的数据已经被分成 <span class="s6">3 </span>个子集：训练样例、供修剪树用的验证样例和一个测试样 例集合。测试样例用来提供在未来的未见实例上的精度的无偏估计。图中显示了在训练 集和测试集上的精度。在用作修剪的验证集合上的精度没有画出来。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 16pt;text-indent: 21pt;line-height: 112%;text-align: left;">如果有大量的数据可供使用，那么使用分离的数据集合来引导修剪是一个有效的方 法。这个方法的主要缺点是当数据有限时，从中保留一部分用作验证集合进一步减少了 训练可以使用的样例。下一节给出了另一种修剪方法，在数据有限的许多实际情形下， 这种方法很有效。人们还提出了许多其他的技术。例如，以不同的方式多次分割可供使 用的数据，然后平均得到的结果。<span class="s6">Mingers</span>（<span class="s6">1989b</span>）和 <span class="s6">Malerba et al.</span>（<span class="s6">1995</span>）中报告了 对不同树修剪方法的经验评估。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 13pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="547" height="1" alt="image" src="机器学习/Image_064.png"/></span></p><p class="s48" style="padding-left: 15pt;text-indent: 0pt;text-align: left;">插图——原书页码： <span class="s21">Page 70</span></p><p class="s6" style="padding-left: 37pt;text-indent: 0pt;text-align: justify;">Accuracy – <span class="p">精度</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 37pt;text-indent: 0pt;text-align: justify;">Size of tree (number of nodes)- <span class="p">树的规模（结点数量）</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 37pt;text-indent: 0pt;line-height: 190%;text-align: left;">On training data-<span class="p">在训练数据上 </span>On test data-<span class="p">在测试数据上</span></p><p class="s6" style="padding-top: 2pt;padding-left: 37pt;text-indent: 0pt;text-align: justify;">On test data(During pruning)- <span class="p">在测试数据上（修剪期间）</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 14pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="556" height="1" alt="image" src="机器学习/Image_065.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 123pt;text-indent: 0pt;text-align: left;">图 <span class="h4">3-7 </span>决策树学习中错误率降低修剪的效果</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-left: 33pt;text-indent: 0pt;line-height: 125%;text-align: justify;">这幅图显示了与图 <span class="s16">3-6 </span>同样的在训练集和测试集上的精度曲线。另外，它显示了“错误率降低修剪” 对 <span class="s16">ID3 </span>算法产生的树的影响。注意随着树结点的剪除，决策树在测试集合上的精度上升。这里，供修 剪用的验证集合与训练和测试集合都是完全不同的。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s37" style="padding-left: 37pt;text-indent: 0pt;text-align: justify;">3.7.1.2 <span class="s20">规则后修剪</span></p><p style="padding-top: 8pt;padding-left: 16pt;text-indent: 21pt;line-height: 107%;text-align: justify;">实践中，一种用来发现高精度假设的非常成功的方法为“ 规则后修剪（ <span class="s6">rule post-pruning</span>）”。这种修剪方法的一个变体被用在 <span class="s6">C4.5 </span>中（<span class="s6">Quinlan 1993</span>），<span class="s6">C4.5 </span>是从原 始的 <span class="s6">ID3 </span>算法的派生出来的。规则后修剪包括下面的步骤：</p><p class="s6" style="padding-top: 5pt;padding-left: 32pt;text-indent: -9pt;line-height: 14pt;text-align: left;">1. <span class="p">从训练集合推导出决策树，增长决策树直到尽可能好地拟合训练数据，允许过度拟 合发生。</span></p><p class="s6" style="padding-left: 32pt;text-indent: -9pt;line-height: 14pt;text-align: left;">2. <span class="p">将决策树转化为等价的规则集合，方法是为从根结点到叶子结点的每一条路径创建 一条规则。</span></p><p class="s6" style="padding-left: 33pt;text-indent: -9pt;line-height: 14pt;text-align: left;">3. <span class="p">通过删除任何能导致估计精度提高的前件（</span>preconditions<span class="p">）来修剪（泛化）每一条规 则。</span></p><p class="s6" style="padding-left: 33pt;text-indent: -9pt;line-height: 14pt;text-align: left;">4. <span class="p">按照修剪过的规则的估计精度对它们进行排序；并按这样的顺序应用这些规则来分 类后来的实例。</span></p><p style="padding-top: 6pt;padding-left: 6pt;text-indent: 21pt;line-height: 109%;text-align: justify;">为了演示以上过程，再次考虑图 <span class="s6">3-1 </span>中的决策树。在“规则后修剪”算法中，为树中的 每个叶子结点产生一条规则。从根结点到叶子结点路径上的每一个属性测试成为一个规则先 行词（即前件），叶子结点的分类称为规则的结论（即后件）。例如，图 <span class="s6">3-1 </span>中树的最左一条路 径被转换成规则：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 37pt;text-indent: 0pt;line-height: 212%;text-align: left;"><span class="s6">IF </span><span class="p">（</span>Outlook<span class="s6">=</span>Sunny<span class="p">）</span><span class="s73">Λ</span><span class="p">（</span>Humidity<span class="s6">=</span>High<span class="p">） </span><span class="s6">THEN </span>PlayTennis<span class="s6">=</span>No</p><p style="padding-left: 16pt;text-indent: 21pt;line-height: 13pt;text-align: left;">接下来，通过删除不会降低估计精度的先行词来修剪每一个规则。例如对于上面的</p><p class="s21" style="padding-top: 1pt;padding-left: 16pt;text-indent: 0pt;line-height: 110%;text-align: justify;"><span class="p">规则，规则后修剪算法会考虑删除先行词（</span>Outlook<span class="s6">=</span>Sunny<span class="p">）和（</span>Humidity<span class="s6">=</span>High<span class="p">）。它会 选择这些修剪步骤中使估计精度有最大提升的步骤，然后考虑修剪第二个前件作为进一 步的修剪步骤。如果某个修剪步骤降低了估计精度，那么这个步骤不会被执行。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 16pt;text-indent: 21pt;line-height: 113%;text-align: left;">如同前面提出的，估计规则精度的一种方法是使用与训练集和不相交的验证集合。 另一种被 <span class="s6">C4.5 </span>使用的方法是基于训练集合本身评估性能，但使用一种保守估计</p><p style="padding-left: 16pt;text-indent: 0pt;line-height: 14pt;text-align: justify;">（<span class="s6">pessimistic estimate</span>）来弥补训练数据有利于当前规则的估计偏置。更准确地讲，<span class="s6">C4.5</span></p><p style="padding-top: 1pt;padding-left: 16pt;text-indent: 0pt;text-align: justify;">通过以下方法计算保守估计，先计算规则在它应用的训练样例上的精度，然后假定此估</p><p style="padding-left: 18pt;text-indent: 0pt;line-height: 108%;text-align: left;">计精度为二项分布，并计算它的标准差（<span class="s6">standard deviation</span>）。对于一个给定的置信区间， 采用下界估计作为规则性能的度量（例如，对于一个 <span class="s6">95%</span>的置信区间，规则精度被保 守估计为：在训练集合上的观察精度减去 <span class="s6">1.96 </span>乘估计的标准差）。这样做的效果是，对 于大的数据集，保守预测非常接近观察精度（也就是标准差非常小），然而随着数据集 合的减小，它开始离观察精度越来越远。虽然这种启发式方法不是统计有效（<span class="s6">statistically valid</span>）的，但是已经发现它在实践中是有用的。第 <span class="s6">5 </span>章讨论了统计有效的预测均值和置 信区间的方法。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 39pt;text-indent: 0pt;text-align: left;">为什么修剪之前要把决策树转化成规则集呢？这样做主要有三个好处：</p><p class="s34" style="padding-top: 6pt;padding-left: 51pt;text-indent: -21pt;text-align: justify;">• <span class="p">转化为规则集可以区分决策结点使用的不同上下文。因为贯穿决策结点的每条 不同路径产生一条不同的规则，所以对于不同路径，关于一个属性测试的修剪 决策可以不同。相反，如果直接修剪树本身，只有两个选择，要么完全删除决 策结点，要么保留它的本来状态。</span></p><p class="s34" style="padding-left: 51pt;text-indent: -21pt;text-align: justify;">• <span class="p">转化为规则集消除了根结点附近的属性测试和叶结点附近的属性测试的区别。 于是避免了零乱的记录问题，比如若是根结点被修剪了但保留它下面的部分子 树时如何重新组织这棵树。</span></p><p class="s34" style="padding-left: 30pt;text-indent: 0pt;line-height: 14pt;text-align: left;">• <span class="p">转化为规则提高了可读性。对于人来说规则总是更容易理解的。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 42pt;text-indent: 0pt;text-align: left;">3.7.2 <span class="s25">合并连续值属性</span></h3><p style="padding-top: 10pt;padding-left: 18pt;text-indent: 21pt;line-height: 110%;text-align: justify;">我们最初的<span class="s6">ID3 </span>定义限制为取离散值的属性。首先，学习到的决策树要预测的目标 属性必须是离散的。其次，树的决策结点的属性也必须是离散的。可以简单地删除第二 个限制，以便把连续值的决策属性加入到决策树中。这可以通过动态地定义新的离散值 属性来实现，即先把连续值属性的值域分割为离散的区间集合。例如，对于连续值的属 性<span class="s21">A</span>，算法可动态地创建一个新的布尔属性<span class="s21">A</span><span class="s36">c</span>，如果<span class="s21">A&lt;c</span>，那么为<span class="s21">A</span><span class="s36">c</span>真，否则为假。唯 一的问题是如何选取最佳的阈值<span class="s21">c</span>。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 18pt;text-indent: 21pt;line-height: 110%;text-align: justify;">举例来说，假定我们希望在表 <span class="s6">3-2 </span>的学习任务中包含连续值的属性 <span class="s21">Temperature </span>来 描述训练样例。对于与决策树的特定结点关联的训练样例，进一步假定其属性 <span class="s21">Temperature </span>和目标属性 <span class="s21">PlayTennis </span>的值如下：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 2pt;text-align: left;"><span><img width="560" height="2" alt="image" src="机器学习/Image_066.png"/></span></p><p class="s21" style="padding-top: 4pt;padding-left: 28pt;text-indent: 0pt;text-align: left;">Temperature<span class="s6">: 40 48 60 72 80 90</span></p><p class="s21" style="padding-top: 3pt;padding-left: 39pt;text-indent: -10pt;text-align: left;">PlayTennis<span class="s6">: No No Yes Yes Yes No</span></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 2pt;text-align: left;"><span><img width="560" height="2" alt="image" src="机器学习/Image_067.png"/></span></p><p style="padding-top: 7pt;padding-left: 18pt;text-indent: 21pt;line-height: 109%;text-align: justify;">对属性<span class="s21">Temprature</span>，应该定义什么样的基于阈值的布尔属性呢？无疑，我们会选择 产生最大信息增益的阈值<span class="s21">c</span>。首先按照连续属性<span class="s21">A</span>排序样例，然后确定目标分类不同的 相邻实例，于是我们可以产生一组候选阈值，它们的值是相应的<span class="s21">A</span>值之间的中间值。可 以证明产生最大信息增益的<span class="s21">c</span>值必定位于这样的边界中（<span class="s6">Fayyad 1991</span>）。然后可以通过 计算与每个候选阈值关联的信息增益评估这些候选值。在当前的例子中，有两个候选阈 值，它们对应于目标属性<span class="s21">PlayTennis</span>变化时属性<span class="s21">Temperature</span>的值：（<span class="s6">48+60</span>）<span class="s6">/2 </span>和（<span class="s6">80+90</span>）</p><p style="padding-left: 18pt;text-indent: 0pt;text-align: justify;"><span class="s6">/2</span>。然后计算每一个候选属性——<span class="s21">Temperature</span><span class="s36">&gt;</span><span class="s42">54 </span>和<span class="s21">Temperature</span><span class="s36">&gt;</span><span class="s42">85</span>的信息增益，并选择 最好的（<span class="s21">Temperature</span><span class="s36">&gt;</span><span class="s42">54</span>）。现在这个动态创建的布尔属性便可以和其他候选的离散值属 性一同“竞争”，以用于增长决策树。<span class="s6">Fayyad &amp; Irani</span>（<span class="s6">1993</span>）讨论了这种方法的一个扩 展，即把连续的属性分割成多个区间，而不是基于单一阈值的两个区间。<span class="s6">Utgoff &amp; Brodley</span>（<span class="s6">1991</span>）和<span class="s6">Murthy et al.</span>（<span class="s6">1994</span>）讨论了通过对几个连续值属性的线性组合定义 阈值参数的方法。</p><h3 style="padding-left: 37pt;text-indent: 2pt;text-align: left;">3.7.3 <span class="s25">属性选择的其他度量标准</span></h3><p style="padding-top: 10pt;padding-left: 16pt;text-indent: 21pt;line-height: 111%;text-align: left;">信息增益度量存在一个内在偏置，它偏袒具有较多值的属性。举一个极端的例子， 考虑属性 <span class="s21">Date</span>，它有大量的可能值（例如 <span class="s6">March 4,1979</span>）。要是我们把这个属性加到表 <span class="s6">3-2 </span>的数据中，它会在所有属性中有最大的信息增益。这是因为单独 <span class="s21">Date </span>就可以完全预 测训练数据的目标属性。于是这个属性会被选作树的根结点的决策属性并形成一棵深度 为一级但却非常宽的树，这棵树可以理想地分类训练数据。当然，这个决策树对于后来 数据的性能会相当差，因为尽管它完美地分割了训练数据，但它不是一个好的预测器</p><p style="padding-left: 16pt;text-indent: 0pt;text-align: left;">（<span class="s6">predicator</span>）。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 16pt;text-indent: 21pt;line-height: 110%;text-align: justify;">属性 <span class="s21">Date </span>出了什么问题了呢？简单地讲，是因为它太多的可能值必然把训练样例 分割成非常小的空间。因此，相对训练样例，它会有非常高的信息增益，尽管对于未见 实例它是一个非常差的目标函数预测器。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 16pt;text-indent: 21pt;line-height: 109%;text-align: justify;">避免这个不足的一种方法是用其他度量，而不是信息增益，来选择决策属性。一个 可以选择的度量标准是增益比率（<span class="s6">gain ratio</span>）（<span class="s6">Quinlan 1986</span>）。增益比率通过加入一个 称作分裂信息（<span class="s6">split information</span>）的项来惩罚类似 <span class="s21">Date </span>的属性，分裂信息用来衡量属 性分裂数据的广度和均匀性：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s88" style="text-indent: 0pt;line-height: 18pt;text-align: left;"><span class="s89">   </span><span class="s41">i</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s33" style="padding-top: 3pt;text-indent: 0pt;line-height: 10pt;text-align: right;"><span class="s90">c </span>| <i>S </i>|</p><p style="text-indent: 0pt;text-align: left;"><span><img width="28" height="1" alt="image" src="机器学习/Image_068.png"/></span></p><p class="s33" style="padding-left: 117pt;text-indent: 0pt;line-height: 10pt;text-align: left;"><i>SplitInformation</i>(<i>S</i>, <i>A</i>) <span class="s38"> </span><span class="s38"> </span>log<span class="s79">2</span></p><p class="s33" style="text-indent: 0pt;line-height: 4pt;text-align: right;">| <i>S </i>|</p><p class="s33" style="padding-top: 3pt;padding-left: 1pt;text-indent: 0pt;text-align: left;">| <i>S</i><span class="s52">i</span><span class="s41"> </span>|</p><p style="padding-left: 1pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="28" height="1" alt="image" src="机器学习/Image_069.png"/></span></p><p class="s33" style="padding-left: 3pt;text-indent: 0pt;line-height: 8pt;text-align: left;">| <i>S </i>|</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 57pt;text-indent: 0pt;text-align: left;">（<span class="s6">3.5</span>）</p><p class="s41" style="padding-left: 134pt;text-indent: 0pt;line-height: 7pt;text-align: center;">i<span class="s40"></span><span class="s42">1</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 16pt;text-indent: 21pt;text-align: justify;">其中<span class="s21">S</span><span class="s35">1</span>到<span class="s21">S</span><span class="s36">c</span>是<span class="s21">c</span>个值的属性<span class="s21">A</span>分割<span class="s21">S</span>而形成的<span class="s21">c</span>个样例子集。注意分裂信息实际上就是 <span class="s21">S</span>关于属性<span class="s21">A</span>的各值的熵。这与我们前面对熵的使用不同，在那里我们只考虑<span class="s21">S</span>关于学习 到的树要预测的目标属性的值的熵。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 37pt;text-indent: 0pt;text-align: left;">增益比率度量是用前面的增益度量和这里的分裂信息度量来共同定义的，即：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="padding-top: 3pt;padding-left: 121pt;text-indent: 0pt;line-height: 19pt;text-align: left;">GainRatio<span class="s33">(</span>S<span class="s33">, </span>A<span class="s33">) </span><span class="s38"> </span><u>Gain</u><u>(</u><u>S </u><u>, </u><u>A</u><u>)          </u></p><p class="s30" style="padding-left: 213pt;text-indent: 0pt;line-height: 12pt;text-align: left;">SplitInformation<span class="s33">(</span>S<span class="s33">, </span>A<span class="s33">)</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 61pt;text-indent: 0pt;text-align: left;">（<span class="s6">3.6</span>）</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 16pt;text-indent: 21pt;line-height: 106%;text-align: left;">请注意，分裂信息项阻碍选择值为均匀分布的属性。例如，考虑一个含有<span class="s21">n</span>个样例 的集合被属性<span class="s21">A</span>彻底分割（译注：分成<span class="s21">n</span>组，即一个样例一组）。这时分裂信息的值为<span class="s6">log</span><span class="s35">2</span><span class="s21">n</span>。 相反，一个布尔属性<span class="s21">B</span>分割同样的<span class="s21">n</span>个实例，如果恰好平分两半，那么分裂信息是 <span class="s6">1</span>。如 果属性<span class="s21">A</span>和<span class="s21">B</span>产生同样的信息增益，那么根据增益比率度量，明显<span class="s21">B</span>会得分更高。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 16pt;text-indent: 21pt;line-height: 109%;text-align: left;">使用增益比率代替增益来选择属性产生的一个实际问题是，当某个<span class="s21">S</span><span class="s36">i</span>接近<span class="s21">S</span>（<span class="s6">|</span><span class="s21">S</span><span class="s36">i</span><span class="s6">|</span><span class="s10"></span><span class="s6">|</span><span class="s21">S</span><span class="s6">|</span>） 时分母可能为 <span class="s6">0 </span>或非常小。如果某个属性对于<span class="s21">S</span>的所有样例有几乎同样的值，这时要么 导致增益比率未定义，要么是增益比率非常大。为了避免选择这种属性，我们可以采用 这样一些启发式规则，比如先计算每个属性的增益，然后仅对那些增益高过平均值的属 性应用增益比率测试（<span class="s6">Quinlan 1986</span>）。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 16pt;text-indent: 21pt;line-height: 109%;text-align: justify;">除了信息增益，<span class="s6">Lopez de Mantaras</span>（<span class="s6">1991</span>）介绍了另一种直接针对上述问题而设计 的度量，它是基于距离的（<span class="s6">distance-based</span>）。这个度量标准基于所定义的一个数据划分 间的距离尺度。每个属性的评估根据它产生的划分与理想划分（也就是完美分类训练数 据的划分）间的距离。然后选择划分最接近完美划分的属性。<span class="s6">Lopez de Mantaras </span>（<span class="s6">1991</span>）</p><p style="padding-left: 16pt;text-indent: 0pt;line-height: 113%;text-align: justify;">定义了这个距离度量，证明了它不偏向有大量值的属性，并报告了其实验研究，说明这 种方法产生的决策树的预测精度与增益法和增益比率法得到的没有明显的差别。而且这 种距离度量避免了增益比率度量的实际困难，在他的实验中，对于属性值个数差异非常 大的数据集，这种方法产生了效果很好的较小的树。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 16pt;text-indent: 21pt;line-height: 110%;text-align: left;">此外，学者们还提出了多种属性选择度量（例如，<span class="s6">Breiman et al. 1984</span>；<span class="s6">Mingers 1989a</span>； <span class="s6">Kearns &amp; Mansour 1996</span>；<span class="s6">Dietterich et al. 1996</span>）。<span class="s6">Mingers</span>（<span class="s6">1989a</span>）提供了实验分析，比 较了针对不同问题的几种选择度量的有效度。他报告了使用不同属性选择度量产生的未 修剪决策树的大小的显著差异。然而在他的实验中，不同的属性选择度量对最终精度的 影响小于后修剪的程度和方法对最终精度的影响。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 40pt;text-indent: 0pt;text-align: left;">3.7.4 <span class="s25">处理缺少属性值的训练样例</span></h3><p style="padding-top: 10pt;padding-left: 16pt;text-indent: 21pt;line-height: 113%;text-align: justify;">在某些情况下，可供使用的数据可能缺少某些属性的值。例如，在医学领域我们希 望根据多项化验指标预测患者的结果，然而可能仅有部分患者具有验血结果。在这种情 况下，经常需要根据此属性值已知的其他实例，来估计这个缺少的属性值。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 16pt;text-indent: 21pt;line-height: 107%;text-align: justify;"><span class="p">考虑以下情况，为了评估属性 </span>A <span class="p">是否是决策结点 </span>n <span class="p">的最佳测试属性，要计算决策 树在该结点的信息增益 </span>Gain<span class="s6">(</span>S<span class="s6">, </span>A<span class="s6">)</span><span class="p">。假定</span><span class="s6">&lt;</span>x<span class="s6">, </span>c<span class="s6">(</span>x<span class="s6">)&gt;</span><span class="p">是 </span>S <span class="p">中的一个训练样例，并且属性 </span>A <span class="p">的值 </span>A<span class="s6">(</span>x<span class="s6">)</span><span class="p">未知。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 16pt;text-indent: 21pt;line-height: 107%;text-align: justify;">处理缺少属性值的一种策略是赋给它结点 <span class="s21">n </span>的训练样例中该属性的最常见值。另一 种策略是可以赋给它结点 <span class="s21">n </span>的被分类为 <span class="s21">c</span><span class="s6">(</span><span class="s21">x</span><span class="s6">)</span>的训练样例中该属性的最常见值。然后使用 这个估计值的训练样例就可以被现有的决策树学习算法使用了。<span class="s6">Mingers</span>（<span class="s6">1989a</span>）中分 析了这个策略。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 16pt;text-indent: 21pt;line-height: 109%;text-align: left;">第二种稍微复杂的策略是为 <span class="s21">A </span>的每个可能值赋与一个概率，而不是简单地将最常 见的值赋给 <span class="s21">A</span><span class="s6">(</span><span class="s21">x</span><span class="s6">)</span>。根据结点 <span class="s21">n </span>的样例上 <span class="s21">A </span>的不同值的出现频率，这些概率可以被再次 估计。例如，给定一个布尔属性 <span class="s21">A</span>，如果结点 <span class="s21">n </span>包含 <span class="s6">6 </span>个已知 <span class="s21">A</span><span class="s6">=1 </span>和 <span class="s6">6 </span>个 <span class="s21">A</span><span class="s6">=0 </span>的样例， 那么 <span class="s21">A</span><span class="s6">(</span><span class="s21">x</span><span class="s6">)=1 </span>的概率是 <span class="s6">0.6</span>，<span class="s21">A</span><span class="s6">(</span><span class="s21">x</span><span class="s6">)=0 </span>的概率是 <span class="s6">0.4</span>。于是，实例 <span class="s21">x </span>的 <span class="s6">60%</span>被分配到 <span class="s21">A</span><span class="s6">=1 </span>的 分支，<span class="s6">40%</span>被分配到另一个分支。这些片段样例（<span class="s6">fractional examples</span>）的目的是计算信 息增益，另外，如果有第二个缺少值的属性必须被测试，这些样例可以在后继的树分支 被进一步细分。上述的样例的片段也可以在学习之后使用，用来分类缺少属性的新实例。 在这种情况下，新实例的分类就是最可能的分类，计算的方法是通过在树的叶结点对按 不同方式分类的实例片段的加权求和。<span class="s6">C4.5</span>（<span class="s6">Quinlan 1993</span>）使用这种方法处理缺少的 属性值。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 40pt;text-indent: 0pt;text-align: left;">3.7.5 <span class="s25">处理代价不同的属性</span></h3><p style="padding-top: 10pt;padding-left: 16pt;text-indent: 21pt;line-height: 113%;text-align: left;">在某些学习任务中，实例的属性可能与代价相关。例如，在学习分类疾病时我们可 能以这些属性来描述患者：体温、活组织切片检查、脉搏、血液化验结果等。这些属性 在代价方面差别非常大，不论是所需的费用还是患者要承受的不适。对于这样的任务， 我们将优先选择尽可能使用低代价属性的决策树，仅当需要产生可靠的分类时才依赖高 代价属性。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 37pt;text-indent: 0pt;text-align: left;">通过引入一个代价项到属性选择度量，可以使 <span class="s6">ID3 </span>算法考虑属性代价。例如，我</p><p style="padding-left: 16pt;text-indent: 0pt;line-height: 113%;text-align: left;">们可以用信息增益除以属性的代价，以使低代价的属性会被优先选择。虽然这种代价敏 感度量不保证找到最优的代价敏感决策树，它们确实使搜索偏置到有利于低代价属性。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 16pt;text-indent: 21pt;line-height: 112%;text-align: left;">Tan &amp; Schlimmer<span class="p">（</span>1990<span class="p">）和 </span>Tan<span class="p">（</span>1993<span class="p">）描述了一种这样的方法，并把它应用到机 器人感知任务中。在这个任务中机器人必须根据这些物体如何能被它的机械手抓住，从 而学会分辨不同的物体。这种情况下，属性对应于机器人身上的移动声纳获得的不同传 感器读数。属性的代价通过定位或操作声纳来获取属性值所需的秒数来衡量。他们证明， 通过用下面的度量代替信息增益属性选择度量，学到了更加有效的识别策略，同时没有 损失分类的精度。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="80" height="1" alt="image" src="机器学习/Image_070.png"/></span></p><p class="s30" style="padding-top: 4pt;padding-left: 192pt;text-indent: 0pt;line-height: 121%;text-align: center;">Gain<span class="s46">2</span><span class="s42"> </span><span class="s33">(</span>S<span class="s33">, </span>A<span class="s33">) </span>Cost<span class="s33">( </span>A<span class="s33">)</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-top: 1pt;padding-left: 16pt;text-indent: 21pt;line-height: 110%;text-align: justify;">Nunez<span class="p">（</span>1988<span class="p">）中描述了一种有关的方法，并把它应用到学习医疗诊断规则上。这 里属性是具有不同代价的不同症状和化验测试。它的系统使用了稍微有点不同的属性选 择度量：</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="95" height="1" alt="image" src="机器学习/Image_071.png"/></span></p><p class="s33" style="padding-top: 4pt;padding-left: 187pt;text-indent: 2pt;line-height: 115%;text-align: center;"><span class="s93">2</span><span class="s41">Gain</span><span class="s42">( </span><span class="s41">S </span><span class="s42">, </span><span class="s41">A</span><span class="s42">) </span><span class="s94"></span><span class="s38"> </span>1 (<i>Cost</i>( <i>A</i>) <span class="s38"> </span>1) <span class="s83">w</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 16pt;text-indent: 21pt;line-height: 107%;text-align: left;">其中 <span class="s21">w</span><span class="s10"></span><span class="s6">[0</span>，<span class="s6">1]</span>是一个常数，决定代价对信息增益的相对重要性。<span class="s6">Nunez</span>（<span class="s6">1991</span>）针 对一系列任务给出了这两种方法的试验对比。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">3.8 <span class="s17">小结和补充读物</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 37pt;text-indent: 0pt;text-align: left;">这一章的要点包括：</p><p style="padding-top: 6pt;padding-left: 49pt;text-indent: -21pt;text-align: left;"><span class="s34">• </span>决策树学习为概念学习和学习其他离散值的函数提供了一个实用的方法。<span class="s6">ID3 </span>系列算法使用从根向下增长法推断决策树，为每个要加入树的新决策分支贪婪 地选择最好的属性。</p><p class="s34" style="padding-left: 49pt;text-indent: -21pt;text-align: left;">• <span class="s6">ID3 </span><span class="p">算法搜索完整的假设空间（也就是说，决策树空间能够表示任何定义在离散 值实例上的任何离散值函数）。所以它避免了仅考虑有限的假设集合的方法的 主要问题：目标函数可能不在假设空间中。</span></p><p style="padding-top: 1pt;padding-left: 49pt;text-indent: -21pt;line-height: 14pt;text-align: left;"><span class="s34">• </span>隐含在 <span class="s6">ID3 </span>算法中的归纳偏置包括优先选择较小的树，也就是说，它通过对假 设空间的搜索增长树，使树的大小为正好能分类已有的训练样例。</p><p class="s34" style="padding-left: 49pt;text-indent: -21pt;line-height: 14pt;text-align: left;">• <span class="p">过度拟合训练数据是决策树学习中的重要问题。因为训练样例仅仅是所有可能 实例的一个样本，向树增加分支可能提高在训练样例上的性能，但却降低在训</span></p><p style="padding-left: 49pt;text-indent: 0pt;line-height: 14pt;text-align: left;">练实例外的其他实例上的性能。因此，后修剪决策树的方法对于避免决策树学 习中（和其他使用优选偏置的归纳推理方法）的过度拟合是很重要的。</p><p style="padding-left: 49pt;text-indent: -21pt;line-height: 14pt;text-align: left;"><span class="s34">• </span>对于基本 <span class="s6">ID3 </span>算法，研究者已经开发了大量的扩展。其中包括后修剪的方法； 处理实数值的属性；容纳缺少属性值的训练样例；当有了新的训练实例时递增</p><p style="padding-left: 49pt;text-indent: 0pt;line-height: 14pt;text-align: left;">精化决策树；使用信息增益之外的其他属性选择度量；考虑与实例属性关联的 代价。</p><p style="padding-top: 6pt;padding-left: 16pt;text-indent: 21pt;line-height: 107%;text-align: left;">关于决策树学习的最早的著作有 <span class="s6">Hunt </span>的概念学习系统（<span class="s6">Concept Learning System</span>， <span class="s6">CLS</span>）（<span class="s6">Hunt et al. 1966</span>）以及 <span class="s6">Friedman </span>和 <span class="s6">Breiman </span>的 <span class="s6">CART </span>系统（<span class="s6">Friedman 1977;Breiman et al. 1984</span>）。<span class="s6">Quinlan </span>的 <span class="s6">ID3 </span>系统（<span class="s6">Quinlan 1979</span>，<span class="s6">1983</span>）构成了本章讨论的基础。关于 决策树学习的其他早期著作包括 <span class="s6">ASSISTANT</span>（<span class="s6">Kononenko et al. 1984</span>；<span class="s6">Cestnik et al.</span></p><p class="s6" style="padding-left: 37pt;text-indent: -21pt;text-align: left;">1987<span class="p">）。决策树归纳算法在多数计算机平台上的实现可以商业方式得到。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 16pt;text-indent: 21pt;line-height: 107%;text-align: left;">关于决策树归纳的进一步细节，<span class="s6">Quinlan</span>（<span class="s6">1993</span>）是一本精彩的著作，其中讨论了 很多实践问题，并提供了 <span class="s6">C4.5 </span>算法的可执行代码。<span class="s6">Mingers</span>（<span class="s6">1989a</span>）和 <span class="s6">Buntine &amp; Niblett</span></p><p style="padding-left: 16pt;text-indent: 0pt;line-height: 107%;text-align: left;">（<span class="s6">1992</span>）提供了比较不同属性选择度量的实验研究。<span class="s6">Mingers</span>（<span class="s6">1989b</span>）提供了对不同修 剪策略的研究。比较决策树学习和其他学习方法的试验可在众多的论文中找到，包括</p><p style="padding-top: 1pt;padding-left: 16pt;text-indent: 0pt;line-height: 107%;text-align: left;">（<span class="s6">Dietterich et al. 1995; Fisher &amp; McKusick 1989; Quinlan 1988a; Shavlik et al. 1991; Thrun et al. 1991; Weiss and Kapouleas 1989</span>）。</p><p style="padding-left: 6pt;text-indent: 0pt;text-align: left;">习题</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 6pt;text-indent: 0pt;text-align: left;">3.1 <span class="p">画出表示下面布尔函数的决策树：</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 37pt;text-indent: 0pt;text-align: left;">（<span class="s6">a</span>）<span class="s21">A</span><span class="s10"></span><span class="s73">¬</span><span class="s21">B</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 37pt;text-indent: 0pt;text-align: left;"><span class="p">（</span><span class="s6">b</span><span class="p">）</span>A<span class="s10"></span><span class="s6">[</span>B<span class="s10"></span>C<span class="s6">]</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 37pt;text-indent: 0pt;text-align: left;">（<span class="s6">c</span>）<span class="s21">A </span><span class="s6">XOR </span><span class="s21">B</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 37pt;text-indent: 0pt;text-align: left;"><span class="p">（</span>d<span class="p">）</span>[<i>A</i><span class="s10"></span><i>B</i>] <span class="s10"> </span>[<i>C</i><span class="s10"></span><i>D</i>]</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">3.2 <span class="p">考虑下面的训练样例集合：</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><table style="border-collapse:collapse;margin-left:87pt" cellspacing="0"><tr style="height:17pt"><td style="width:42pt;border-top-style:solid;border-top-width:2pt;border-top-color:#808080;border-bottom-style:solid;border-bottom-width:1pt;border-bottom-color:#808080"><p class="s95" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">实例</p></td><td style="width:51pt;border-top-style:solid;border-top-width:2pt;border-top-color:#808080;border-bottom-style:solid;border-bottom-width:1pt;border-bottom-color:#808080"><p class="s95" style="padding-left: 15pt;text-indent: 0pt;text-align: left;">分类</p></td><td style="width:39pt;border-top-style:solid;border-top-width:2pt;border-top-color:#808080;border-bottom-style:solid;border-bottom-width:1pt;border-bottom-color:#808080"><p class="s96" style="padding-top: 3pt;text-indent: 0pt;line-height: 12pt;text-align: center;">a<span class="s97">1</span></p></td><td style="width:48pt;border-top-style:solid;border-top-width:2pt;border-top-color:#808080;border-bottom-style:solid;border-bottom-width:1pt;border-bottom-color:#808080"><p class="s96" style="padding-top: 3pt;padding-left: 14pt;text-indent: 0pt;line-height: 12pt;text-align: left;">a<span class="s97">2</span></p></td></tr><tr style="height:19pt"><td style="width:42pt;border-top-style:solid;border-top-width:1pt;border-top-color:#808080"><p class="s98" style="padding-top: 3pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">1</p></td><td style="width:51pt;border-top-style:solid;border-top-width:1pt;border-top-color:#808080"><p class="s98" style="padding-top: 3pt;padding-left: 15pt;text-indent: 0pt;text-align: left;">+</p></td><td style="width:39pt;border-top-style:solid;border-top-width:1pt;border-top-color:#808080"><p class="s98" style="padding-top: 3pt;padding-right: 1pt;text-indent: 0pt;text-align: center;">T</p></td><td style="width:48pt;border-top-style:solid;border-top-width:1pt;border-top-color:#808080"><p class="s98" style="padding-top: 3pt;padding-left: 14pt;text-indent: 0pt;text-align: left;">T</p></td></tr><tr style="height:16pt"><td style="width:42pt"><p class="s98" style="padding-top: 1pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">2</p></td><td style="width:51pt"><p class="s98" style="padding-top: 1pt;padding-left: 15pt;text-indent: 0pt;text-align: left;">+</p></td><td style="width:39pt"><p class="s98" style="padding-top: 1pt;padding-right: 1pt;text-indent: 0pt;text-align: center;">T</p></td><td style="width:48pt"><p class="s98" style="padding-top: 1pt;padding-left: 14pt;text-indent: 0pt;text-align: left;">T</p></td></tr><tr style="height:16pt"><td style="width:42pt"><p class="s98" style="padding-top: 1pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">3</p></td><td style="width:51pt"><p class="s98" style="padding-top: 1pt;padding-left: 15pt;text-indent: 0pt;text-align: left;">-</p></td><td style="width:39pt"><p class="s98" style="padding-top: 1pt;padding-right: 1pt;text-indent: 0pt;text-align: center;">T</p></td><td style="width:48pt"><p class="s98" style="padding-top: 1pt;padding-left: 14pt;text-indent: 0pt;text-align: left;">F</p></td></tr><tr style="height:16pt"><td style="width:42pt"><p class="s98" style="padding-top: 1pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">4</p></td><td style="width:51pt"><p class="s98" style="padding-top: 1pt;padding-left: 15pt;text-indent: 0pt;text-align: left;">+</p></td><td style="width:39pt"><p class="s98" style="padding-top: 1pt;padding-right: 2pt;text-indent: 0pt;text-align: center;">F</p></td><td style="width:48pt"><p class="s98" style="padding-top: 1pt;padding-left: 14pt;text-indent: 0pt;text-align: left;">F</p></td></tr><tr style="height:16pt"><td style="width:42pt"><p class="s98" style="padding-top: 1pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">5</p></td><td style="width:51pt"><p class="s98" style="padding-top: 1pt;padding-left: 15pt;text-indent: 0pt;text-align: left;">-</p></td><td style="width:39pt"><p class="s98" style="padding-top: 1pt;padding-right: 2pt;text-indent: 0pt;text-align: center;">F</p></td><td style="width:48pt"><p class="s98" style="padding-top: 1pt;padding-left: 14pt;text-indent: 0pt;text-align: left;">T</p></td></tr><tr style="height:17pt"><td style="width:42pt"><p class="s99" style="padding-top: 1pt;text-indent: 0pt;text-align: left;">  6                  </p></td><td style="width:51pt"><p class="s99" style="padding-top: 1pt;padding-left: 15pt;text-indent: 0pt;text-align: left;">-                  </p></td><td style="width:39pt"><p class="s99" style="padding-top: 1pt;padding-left: 15pt;text-indent: 0pt;text-align: left;">F            </p></td><td style="width:48pt"><p class="s99" style="padding-top: 1pt;padding-left: 14pt;text-indent: 0pt;text-align: left;">T          </p></td></tr></table><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 37pt;text-indent: 0pt;text-align: left;">（<span class="s6">a</span>）请计算这个训练样例集合对于目标函数分类的熵。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 37pt;text-indent: 0pt;text-align: left;">（<span class="s6">b</span>）请计算属性<span class="s21">a</span><span class="s35">2</span>相对这些训练样例的信息增益。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 16pt;text-indent: 0pt;line-height: 107%;text-align: left;">3.3 <span class="p">判断以下命题的正误：如果树 </span>D2 <span class="p">是从树 </span>D1 <span class="p">加工的，那么 </span>D1 <i>more</i>-<i>general</i>-<i>than </i>D2<span class="p">。 假定 </span>D1 <span class="p">和 </span>D2 <span class="p">是表示任意布尔函数的决策树，而且当 </span>ID3 <span class="p">能把 </span>D1 <span class="p">扩展成 </span>D2 <span class="p">时，那么 </span>D2 <span class="p">是 </span>D1 <span class="p">的加工。如果正确，给出证明；如果错误，举出一个反例。（</span><i>more</i>-<i>general</i>-<i>than </i><span class="p">被定义在第 </span>2 <span class="p">章中。）</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 16pt;text-indent: 0pt;line-height: 107%;text-align: left;">3.4 ID3 <span class="p">仅寻找一个一致的假设，而候选消除算法寻找所有一致的假设。考虑这两种学 习算法间的对应关系。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 37pt;text-indent: 0pt;text-align: left;">（<span class="s6">a</span>）假定给定 <span class="s21">EnjoySport </span>的四个训练样例，画出 <span class="s6">ID3 </span>学习的决策树。其中 <span class="s21">EnjoySport</span></p><p style="padding-top: 1pt;padding-left: 16pt;text-indent: 0pt;text-align: left;">目标概念列在第 <span class="s6">2 </span>章的表 <span class="s6">2-1 </span>中。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 37pt;text-indent: 0pt;text-align: left;">（<span class="s6">b</span>）学习到的决策树和从同样的样例使用变型空间算法得到的变型空间（见第 <span class="s6">2</span></p><p style="padding-top: 1pt;padding-left: 16pt;text-indent: 0pt;text-align: left;">章图 <span class="s6">2-3</span>）间有什么关系？树等价于变型空间的一个成员吗？</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 16pt;text-indent: 21pt;line-height: 107%;text-align: left;">（<span class="s6">c</span>）增加下面的训练样例，计算新的决策树。这一次，显示出增长树的每一步中 每个候选属性的信息增益。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><table style="border-collapse:collapse;margin-left:11.1pt" cellspacing="0"><tr style="height:29pt"><td style="width:67pt;border-top-style:solid;border-top-width:2pt;border-top-color:#808080;border-bottom-style:solid;border-bottom-width:1pt;border-bottom-color:#808080"><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s96" style="padding-left: 6pt;text-indent: 0pt;text-align: center;">Sky</p></td><td style="width:63pt;border-top-style:solid;border-top-width:2pt;border-top-color:#808080;border-bottom-style:solid;border-bottom-width:1pt;border-bottom-color:#808080"><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s96" style="padding-left: 11pt;text-indent: 0pt;text-align: left;">Air<span class="s98">-</span>Temp</p></td><td style="width:62pt;border-top-style:solid;border-top-width:2pt;border-top-color:#808080;border-bottom-style:solid;border-bottom-width:1pt;border-bottom-color:#808080"><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s96" style="padding-left: 11pt;text-indent: 0pt;text-align: left;">Humidity</p></td><td style="width:46pt;border-top-style:solid;border-top-width:2pt;border-top-color:#808080;border-bottom-style:solid;border-bottom-width:1pt;border-bottom-color:#808080"><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s96" style="padding-left: 11pt;text-indent: 0pt;text-align: left;">Wind</p></td><td style="width:49pt;border-top-style:solid;border-top-width:2pt;border-top-color:#808080;border-bottom-style:solid;border-bottom-width:1pt;border-bottom-color:#808080"><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s96" style="padding-left: 12pt;text-indent: 0pt;text-align: left;">Water</p></td><td style="width:54pt;border-top-style:solid;border-top-width:2pt;border-top-color:#808080;border-bottom-style:solid;border-bottom-width:1pt;border-bottom-color:#808080"><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s96" style="padding-left: 11pt;text-indent: 0pt;text-align: left;">Forecast</p></td><td style="width:77pt;border-top-style:solid;border-top-width:2pt;border-top-color:#808080;border-bottom-style:solid;border-bottom-width:1pt;border-bottom-color:#808080"><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s96" style="padding-left: 4pt;text-indent: 0pt;text-align: left;">Enjoy<span class="s98">-</span>Sport<span class="s98">?</span></p></td></tr><tr style="height:29pt"><td style="width:67pt;border-top-style:solid;border-top-width:1pt;border-top-color:#808080;border-bottom-style:solid;border-bottom-width:2pt;border-bottom-color:#808080"><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s96" style="padding-left: 29pt;text-indent: 0pt;text-align: left;">Sunny</p></td><td style="width:63pt;border-top-style:solid;border-top-width:1pt;border-top-color:#808080;border-bottom-style:solid;border-bottom-width:2pt;border-bottom-color:#808080"><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s96" style="padding-left: 11pt;text-indent: 0pt;text-align: left;">Warm</p></td><td style="width:62pt;border-top-style:solid;border-top-width:1pt;border-top-color:#808080;border-bottom-style:solid;border-bottom-width:2pt;border-bottom-color:#808080"><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s96" style="padding-left: 11pt;text-indent: 0pt;text-align: left;">Normal</p></td><td style="width:46pt;border-top-style:solid;border-top-width:1pt;border-top-color:#808080;border-bottom-style:solid;border-bottom-width:2pt;border-bottom-color:#808080"><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s96" style="padding-left: 11pt;text-indent: 0pt;text-align: left;">Weak</p></td><td style="width:49pt;border-top-style:solid;border-top-width:1pt;border-top-color:#808080;border-bottom-style:solid;border-bottom-width:2pt;border-bottom-color:#808080"><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s96" style="padding-left: 12pt;text-indent: 0pt;text-align: left;">Warm</p></td><td style="width:54pt;border-top-style:solid;border-top-width:1pt;border-top-color:#808080;border-bottom-style:solid;border-bottom-width:2pt;border-bottom-color:#808080"><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s96" style="padding-left: 11pt;text-indent: 0pt;text-align: left;">Same</p></td><td style="width:77pt;border-top-style:solid;border-top-width:1pt;border-top-color:#808080;border-bottom-style:solid;border-bottom-width:2pt;border-bottom-color:#808080"><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s96" style="padding-left: 7pt;text-indent: 0pt;text-align: left;">No</p></td></tr></table><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 37pt;text-indent: 0pt;text-align: left;">（<span class="s6">d</span>）假定我们希望设计一个学习器，它搜索决策树假设空间（类似 <span class="s6">ID3</span>）并寻找</p><p style="padding-left: 16pt;text-indent: 0pt;line-height: 109%;text-align: justify;">与数据一致的所有假设（类似候选消除）。简单地说，我们希望应用候选消除算法搜索 决策树假设空间。写出经过表 <span class="s6">2-1 </span>的第一个训练样例后的 <span class="s21">S </span>和 <span class="s21">G </span>集合。注意 <span class="s21">S </span>必须包 含与数据一致的最特殊的决策树，而 <span class="s21">G </span>必须包含最一般的。说明遇到第二个训练样例 时 <span class="s21">S </span>和 <span class="s21">G </span>集合是如何被改进的（可以去掉描述同一个概念的语法不同的树）。在把候选 消除算法应用到决策树假设空间时，预计会碰到什么样的困难？</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s8" style="padding-left: 153pt;text-indent: 0pt;line-height: 24pt;text-align: left;">第<span class="h1">4</span>章 人工神经网络</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 47pt;text-indent: 21pt;line-height: 108%;text-align: left;">人工神经网络（<span class="s71">Artificial Neural Networks——ANNs</span>）提供了一种普遍而且实 用的方法，来从样例中学习值为实数、离散或向量的函数。 像反向传播 <span class="s71">BP</span></p><p style="padding-left: 47pt;text-indent: 0pt;text-align: left;">（<span class="s71">BackPropagation</span>）这样的算法使用梯度下降来调节网络参数以最佳拟合由输入</p><p class="s71" style="padding-top: 1pt;padding-left: 47pt;text-indent: 0pt;line-height: 108%;text-align: left;">-<span class="p">输出对组成的训练集合。</span>ANN <span class="p">学习对于训练数据中的错误鲁棒性很好，且已经成 功地应用到很多领域，例如视觉场景分析（</span>interpreting visual scenes<span class="p">）、语音识别、 以及机器人控制等。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 34pt;text-indent: 0pt;text-align: left;">4.1 <span class="s17">简介</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 112%;text-align: justify;">神经网络学习方法对于逼近实数值、离散值或向量值的目标函数提供了一种鲁棒性很强 的方法。对于某些类型的问题，如学习解释复杂的现实世界中的传感器数据，人工神经网络 是目前知道的最有效学习方法。例如，本章要描述的反向传播算法已在很多实际的问题中取 得了惊人的成功，比如学习识别手写字符（<span class="s6">LeCun et al. 1989</span>），学习识别口语（<span class="s6">Lang et al. 1990</span>）和学习识别人脸（<span class="s6">Cottrell 1990</span>）。<span class="s6">Rumelhart et al.</span>（<span class="s6">1994</span>）中概览了其实际的应用。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 30pt;text-indent: 0pt;text-align: left;">4.1.1 <span class="s25">生物学动机</span></h3><p style="padding-top: 10pt;padding-left: 6pt;text-indent: 21pt;line-height: 111%;text-align: justify;">人工神经网络的研究在一定程度上受到了生物学的启发，因为生物的学习系统是由相互 连接的神经元（<span class="s6">neuron</span>）组成的异常复杂的网络。而人工神经网络与此大体相似，它是由一 系列简单单元相互密集连接构成，其中每一个单元有一定数量的实值输入（可能是其他单元 的输出），并产生单一的实数值输出（可能成为其他很多单元的输入）。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 109%;text-align: left;">为了加深对这种类比的认识，让我们考虑一些来自生物学的事实。例如，据估计人类的 大脑是由大约 <span class="s6">10</span><span class="s46">11</span>个神经元相互连接组成的密集网络，平均每一个神经元与其他 <span class="s6">10</span><span class="s46">4</span>个神经 元相连。神经元的活性通常被通向其他神经元的连接激活或抑制。目前知道的最快的神经元 转换时间是在 <span class="s6">10</span><span class="s46">-3</span>秒级别<span class="s6">——</span>与计算机的转换时间 <span class="s6">10</span><span class="s46">-10</span>秒相比慢很多。然而人类能够以惊人 的速度做出复杂度惊人的决策。例如，你要通过视觉认出自己的母亲大约需要 <span class="s6">10</span><span class="s46">-1</span>秒。注意 在这 <span class="s6">10</span><span class="s46">-1</span>秒的间隔内，被激发的神经元序列不长于数百步，因为单个神经元的转换速度已知。 这个事实使很多人推测，生物神经系统的信息处理能力一定得益于对分布在大量神经元上的 信息表示的<span style=" color: #00F;">高度并行处理</span>。<span class="s6">ANN</span>系统的一个动机就是获得这种基于分布表示的高度并行算 法。大多数的<span class="s6">ANN</span>软件在串行机器上仿真分布处理，然而更快版本的算法也已经在高度并 行机和特别为<span class="s6">ANN</span>应用设计的专用硬件上实现。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 107%;text-align: justify;">由于 <span class="s6">ANN </span>只是一定程度地受生物神经系统的启发，所以 <span class="s6">ANN </span>并未模拟生物神经系统 中的很多复杂特征，而且已经知道 <span class="s6">ANN </span>的很多特征与生物系统也是不一致的。例如，对于 我们考虑的 <span class="s6">ANN</span>，每个单元输出单一的不变值，然而生物神经元输出的是复杂的时序脉冲。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 107%;text-align: justify;">长期以来，人工神经网络领域的研究者分为两个团体。一个团体的目标是使用 <span class="s6">ANN </span>研 究和模拟生物学习过程。另一个团体的目标是获得高效的机器学习算法，不管这种算法是否</p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 113%;text-align: justify;">反映了生物过程。在本书中我们的兴趣符合后一团体，所以我们不会再把注意力用在生物模 型上。若要获得关于使用 <span class="s6">ANN </span>模拟生物系统的更多信息请参考 <span class="s6">Churchland &amp; Sejnowski</span></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 14pt;text-align: justify;">（<span class="s6">1992</span>），<span class="s6">Zornetzer et al.</span>（<span class="s6">1994</span>），<span class="s6">Gabriel &amp; Moore</span>（<span class="s6">1990</span>）。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-top: 8pt;padding-left: 34pt;text-indent: 0pt;text-align: left;">4.2 <span class="s17">神经网络表示</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;"><span class="s6">Pomerleau</span>（<span class="s6">1993</span>）的 <span class="s6">ALVINN </span>系统是 <span class="s6">ANN </span>学习的一个典型实例，这个系统使用一个 学习到的 <span class="s6">ANN </span>以正常的速度在高速公路上驾驶汽车。<span class="s6">ANN </span>的<span style=" color: #00F;">输入</span>是一个 <span class="s6">30</span><span class="s10"></span><span class="s6">32 </span>像素的网 格，像素的亮度来自一个安装在车辆上的前向摄像机。<span class="s6">ANN </span>的<span style=" color: #00F;">输出</span>是车辆行进的方向。这 个 <span class="s6">ANN </span>通过观察人类驾驶时的操纵命令进行训练，训练过程大约 <span class="s6">5 </span>分钟。<span class="s6">ALVINN </span>用学习 到的网络在高速公路上以 <span class="s6">70 </span>英里时速成功地驾驶了 <span class="s6">90 </span>英里（在分行公路的左车道行驶，同 时有其他车辆）。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 5pt;text-indent: 21pt;line-height: 109%;text-align: justify;"><span class="p">图 </span>4-1 <span class="p">画出了 </span>ALVINN <span class="p">系统的一个版本中使用过的神经网络表示，这也是很多 </span>ANN <span class="p">系 统的典型表示方式。神经网络显示在图的左边，输入的摄像机图像在它的下边。网络图中每 个结点对应一个网络单元（</span>unit<span class="p">）的输出，而从下方进入结点的实线为其输入。可以看到， 共有四个单元直接从图像接收所有的 </span>30<span class="s10"></span>32 <span class="p">个像素。这四个单元被称为“隐藏”单元，因为 它们的输出仅在网络内部，不是整个网络输出的一部分。每个隐藏单元根据 </span>960 <span class="p">个输入的加</span></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: justify;">权和计算得到单一的实数值输出。然后这四个隐藏单元的输出被用作第二层 <span class="s6">30 </span>个“输出单 元”的输入。每个输出单元对应一个特定的驾驶方向，这些单元的输出决定哪一个驾驶方向 是最强烈推荐的。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 13pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="547" height="1" alt="image" src="机器学习/Image_072.png"/></span></p><p class="s48" style="padding-left: 15pt;text-indent: 0pt;text-align: left;">插图——原书页码： <span class="s21">84</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-top: 1pt;padding-left: 26pt;text-indent: 0pt;line-height: 190%;text-align: left;">sharp left-<span class="p">急剧左转 </span>sharp right-<span class="p">急剧右转 </span>straight ahead-<span class="p">正前方</span></p><p class="s6" style="padding-top: 2pt;padding-left: 26pt;text-indent: 0pt;line-height: 190%;text-align: left;">30 Output units-30 <span class="p">个输出单元 </span>4 Hidden units-4 <span class="p">个隐藏单元</span></p><p class="s6" style="padding-top: 2pt;padding-left: 26pt;text-indent: 0pt;text-align: left;">30<span class="s10"></span>32 sensor input retina-30<span class="s10"></span>32 <span class="p">传感器视网膜输入</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 14pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="531" height="1" alt="image" src="机器学习/Image_073.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 150pt;text-indent: 0pt;text-align: left;">图 <span class="h4">4-1 </span>学习驾驶汽车的神经网络</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s16" style="padding-left: 37pt;text-indent: 0pt;line-height: 125%;text-align: justify;">ALVINN <span class="s14">系统使用反向传播算法来学习驾驶汽车（上图），它的最高时速达到每小时 </span>70 <span class="s14">英里。左 图显示了来自车前摄像机的图像是如何被映射到 </span>960 <span class="s14">个神经网络输入的，这些输入又前馈到 </span>4 <span class="s14">个隐 藏单元，再连接到 </span>30 <span class="s14">个输出单元。网络输出编码了推荐的驾驶方向。右图显示了网络中一个隐藏 单元的权值。进入这个隐藏单元的 </span>30<span class="s57"></span>32 <span class="s14">个权值显示在大的矩阵中，白色的方框表示正权值而黑色 的方框表示负权值。从这个隐藏单元到 </span>30 <span class="s14">个输出单元的权值被画在这个大矩阵上方的较小矩形中。</span></p><p class="s14" style="padding-top: 1pt;padding-left: 37pt;text-indent: 0pt;text-align: left;">从这些输出权值可以看出，激活这个隐藏单元会促进向左转。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 5pt;text-indent: 21pt;line-height: 109%;text-align: justify;"><span class="p">图 </span>4-1 <span class="p">中的右侧部分描绘的是一些学习得到的权值，它们与这个 </span>ANN <span class="p">的四个隐藏单元 之一相联系。下面的黑白方格大矩阵描述的是从 </span>30<span class="s10"></span>32 <span class="p">像素输入到这个隐藏单元的权值。这 里，白方格表示正权值，黑方格表示负权值，方格的大小表示权的数量。大矩阵正上方的较 小的矩形表示从这个隐藏单元到 </span>30 <span class="p">个输出单元的权。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;"><span class="s6">ALVINN </span>的网络结构是很多 <span class="s6">ANN </span>中的典型结构。所有单元分层互连形成了一个有向无 环图。通常，<span class="s6">ANN </span>图的结构可以有很多种类型<span class="s6">——</span>无环的或有环的，有向的或无向的。本 章集中讨论以<span style=" color: #00F;">反向传播算法为基础的最常见和最实用的 </span><span class="s63">ANN </span><span style=" color: #00F;">方法</span>。<span style=" color: #00F;">反向传播算法假定网络 是一个固定结构，对应一个有向图，可能包含环</span>。<span class="s6">ANN </span>学习就是为图中的每一条边选取权 值。尽管某种类型的循环是允许的，大多数的实际应用都采用无环的前馈网络，与 <span class="s6">ALVINN </span>使用的网络结构相似。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 34pt;text-indent: 0pt;text-align: left;">4.3 <span class="s17">适合神经网络学习的问题</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;"><span class="s6">ANN </span>学习非常适合于这样的问题：<span style=" color: #00F;">训练集合为含有噪声的复杂传感器数据</span>，例如来自 摄像机和麦克风的数据。它也适用于<span style=" color: #00F;">需要更多符号表示的问题</span>，例如第 <span class="s6">3 </span>章讨论的决策树学 习任务。这种情况下 <span class="s6">ANN </span>和决策树学习经常产生精度大体相当的结果。可参见 <span class="s6">Shavlik et al.</span></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 107%;text-align: left;">（<span class="s6">1991</span>）和 <span class="s6">Weiss and Kapouleas</span>（<span class="s6">1989</span>）中关于决策树和 <span class="s6">ANN </span>学习的实验比较。反向传播 算法是最常用的 <span class="s6">ANN </span>学习技术。它适合具有以下特征的问题：</p><p style="padding-top: 5pt;padding-left: 66pt;text-indent: -21pt;line-height: 109%;text-align: left;"><span class="s10"> </span>实例是用很多“属性<span class="h4">-</span>值”对表示的。要学习的目标函数是定义在可以用向 量描述的实例之上的，向量由预先定义的特征组成，例如 <span class="s6">ALVINN </span>例子中 的像素值。这些输入属性之间可以高度相关，也可以相互独立。输入值可以 是任何实数。</p><p style="padding-left: 66pt;text-indent: -21pt;line-height: 109%;text-align: left;"><span class="s10"> </span>目标函数的输出可能是离散值、实数值或者由若干实数属性或离散属性组成 的向量。例如，在 <span class="s6">ALVINN </span>系统中输出的是 <span class="s6">30 </span>个属性的向量，每一个分量 对应一个建议的驾驶方向。每个输出值是 <span class="s6">0 </span>和 <span class="s6">1 </span>之间的某个实数，对应于在 预测相应驾驶方向时的置信度（<span class="s6">confidence</span>）。我们也可以训练一个单一网 络，同时输出行驶方向和建议的加速度，这只要简单地把编码这两种输出预 测的向量连接在一起就可以了。</p><p style="padding-left: 66pt;text-indent: -21pt;line-height: 107%;text-align: left;"><span class="s10"> </span>训练数据可能包含错误。<span class="s6">ANN </span>学习算法对于训练数据中的错误有非常好的 鲁棒性。</p><p class="s10" style="padding-top: 1pt;padding-left: 66pt;text-indent: -21pt;line-height: 110%;text-align: left;"> <span class="p">可容忍长时间的训练。网络训练算法通常比像决策树学习这样的算法需要更 长的训练时间。训练时间可能从几秒钟到几小时，这要看网络中权值的数量、 要考虑的训练实例的数量、以及不同学习算法参数的设置等因素。</span></p><p style="padding-left: 66pt;text-indent: -21pt;line-height: 109%;text-align: left;"><span class="s10"> </span>可能需要快速求出目标函数值。尽管 <span class="s6">ANN </span>的学习时间相对较长，但对学习 的网络求值，以便把网络应用到后续的实例，通常是非常快速的。例如， <span class="s6">ALVINN </span>在车辆向前行驶时，每秒应用它的神经网络若干次，以不断地更新 驾驶方向。</p><p class="s10" style="padding-left: 66pt;text-indent: -21pt;line-height: 107%;text-align: left;"> <span class="p">人类能否理解学到的目标函数是不重要的。神经网络方法学习到的权值经常 是人类难以解释的。学到的神经网络比学到的规则难于传达给人类。</span></p><p style="padding-top: 8pt;padding-left: 26pt;text-indent: 0pt;text-align: left;">这一章的其余部分是这样组织的：我们先讨论训练单个单元的学习算法，同时介绍组成</p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 109%;text-align: justify;">神经网络的几种主要单元，包括感知器（<span class="s6">perceptron</span>）、线性单元（<span class="s6">linear unit</span>）和 <span class="s6">sigmoid </span>单 元（<span class="s6">sigmoid unit</span>）。然后给出训练这些单元组成的多层网络的反向传播算法，并考虑几个一 般性的问题，比如 <span class="s6">ANN </span>的表征能力、假设空间搜索的本质特征、过度拟合问题、以及反向 传播算法的变体。本章也给出了一个应用反向传播算法识别人脸的详细例子，并指导读者如 何取得这个例子的数据和代码，并进一步实验这个应用。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 34pt;text-indent: 0pt;text-align: left;">4.4 <span class="s17">感知器</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 110%;text-align: left;">一种类型的<span class="s6">ANN</span>系统是以被称为感知器（<span class="s6">perceptron</span>）的单元为基础的，如图 <span class="s6">4-2 </span>所示。 <span style=" color: #00F;">感知器以一个实数值向量作为输入，计算这些输入的线性组合，然后如果结果大于某个阈值 就输出 </span><span class="s63">1</span><span style=" color: #00F;">，否则输出</span><span class="s63">-1</span><span style=" color: #00F;">。</span>更精确地，如果输入为<span class="s21">x</span><span class="s35">1</span>到<span class="s21">x</span><span class="s36">n</span>，那么感知器计算的输出为：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s38" style="padding-top: 3pt;text-indent: 0pt;line-height: 9pt;text-align: right;">⎧<span class="s100">1</span><span class="s33">   </span><span class="s30">if  w</span></p><ul id="l5"><li style="padding-top: 2pt;padding-left: 14pt;text-indent: -9pt;line-height: 9pt;text-align: left;"><p class="s30" style="display: inline;">w x</p></li><li style="padding-top: 2pt;padding-left: 13pt;text-indent: -9pt;line-height: 9pt;text-align: left;"><p class="s30" style="display: inline;">w x</p><p class="s38" style="padding-top: 2pt;padding-left: 5pt;text-indent: 0pt;line-height: 9pt;text-align: left;"><span class="s101">L</span> <span class="s30">w x </span> <span class="s33">0</span></p><p class="s33" style="text-indent: 0pt;line-height: 11pt;text-align: right;"><i>o</i>(<i>x</i><span class="s79">1 </span>,<span class="s101">L</span>, <i>x</i><span class="s52">n</span></p><p class="s33" style="text-indent: 0pt;line-height: 11pt;text-align: left;">) <span class="s38"> </span><span class="s102">⎨</span></p><p class="s42" style="padding-left: 33pt;text-indent: 0pt;line-height: 7pt;text-align: left;">0 1 1 2 2 <i>n n</i></p><p class="s103" style="text-indent: 0pt;line-height: 16pt;text-align: right;">⎩<span class="s38"></span><span class="s33"> 1</span></p><p class="s30" style="padding-left: 8pt;text-indent: 0pt;line-height: 13pt;text-align: left;">otherwise</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;text-align: left;">其中每一个<span class="s21">w</span><span class="s36">i</span>是一个实数常量，或叫做权值（<span class="s6">weight</span>），用来决定输入<span class="s21">x</span><span class="s36">i</span>对感知器输出的 贡献率。请注意， <span style=" color: #00F;">常量 </span><span class="s63">(-</span><span class="s58">w</span><span class="s104">0</span><span class="s63">) </span><span style=" color: #00F;">是一个阈值，它是为了使感知器输出 </span><span class="s63">1 </span><span style=" color: #00F;">，输入的加权和</span></p><p class="s30" style="padding-top: 6pt;padding-left: 7pt;text-indent: 0pt;text-align: left;">w<span class="s79">1</span><span class="s42"> </span>x<span class="s79">1 </span><span class="s38"> </span>w<span class="s79">2</span><span class="s42"> </span>x<span class="s79">2</span><span class="s42"> </span><span class="s38"></span><span class="s101">L </span><span class="s38"> </span>w<span class="s52">n</span><span class="s41"> </span>x<span class="s52">n</span><span class="s41"> </span><span class="s24">必须超过的阈值。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 13pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="547" height="1" alt="image" src="机器学习/Image_074.png"/></span></p><p class="s48" style="padding-left: 15pt;text-indent: 0pt;text-align: left;">插图——原书页码： <span class="s21">87 </span><i>上</i></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 14pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="531" height="1" alt="image" src="机器学习/Image_075.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 24pt;text-indent: 0pt;text-align: center;">图 <span class="h4">4-2 </span>感知器</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 24pt;text-indent: 0pt;text-align: center;">为了简化表示，我们假想有一个附加的常量输入<span class="s21">x</span><span class="s35">0</span><span class="s6">=1</span>，那么我们就可以把上边的不等式</p><p class="s41" style="padding-top: 5pt;padding-left: 41pt;text-indent: 0pt;line-height: 2pt;text-align: left;">n</p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 0pt;line-height: 20pt;text-align: left;"><span class="s105">写为</span> <span class="s106"></span><span class="s41">i</span><span class="s40"></span><span class="s42">0 </span>数写为：</p><p class="s30" style="text-indent: 0pt;line-height: 17pt;text-align: left;">w<span class="s52">i </span>x<span class="s52">i</span><span class="s41"> </span><span class="s38"> </span><span class="s33">0 </span><span class="p">，或以向量形式写为 </span>w <span class="s38"> </span>x <span class="s38"> </span><span class="s33">0 </span><span class="p">。为了简短起见，我们有时会把感知器函</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s107" style="padding-top: 3pt;padding-left: 24pt;text-indent: 0pt;text-align: center;">o<span class="s108">(</span>x<span class="s108">) </span><span class="s109"> </span><span class="s108">sgn(</span>w <span class="s109"> </span>x<span class="s108">)</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">其中，</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s38" style="padding-top: 3pt;text-indent: 0pt;line-height: 11pt;text-align: right;">⎧<span class="s100">1  </span><span class="s33"> </span><span class="s30">if</span></p><p class="s33" style="text-indent: 0pt;line-height: 10pt;text-align: right;">sgn( <i>y</i>) <span class="s38"> </span><span class="s102">⎨</span></p><p class="s103" style="text-indent: 0pt;line-height: 14pt;text-align: right;">⎩<span class="s38"></span><span class="s33"> 1</span></p><p class="s30" style="padding-top: 2pt;padding-left: 4pt;text-indent: 0pt;text-align: left;">y <span class="s38"> </span><span class="s33">0</span></p><p class="s30" style="padding-top: 4pt;text-indent: 0pt;text-align: left;">otherwise</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-top: 1pt;padding-left: 24pt;text-indent: 0pt;text-align: center;"><span class="p">学习一个感知器意味着选择权</span>w<span class="s35">0</span><span class="s6">, …, </span>w<span class="s36">n</span><span class="p">的值。所以感知器学习要考虑的候选假设空间</span>H</p><p style="padding-left: 6pt;text-indent: 0pt;text-align: left;">就是所有可能的实数值权向量的集合。</p><p class="s30" style="padding-top: 8pt;padding-left: 24pt;text-indent: 0pt;text-align: center;">H <span class="s38"> </span><span class="s33">{</span>w<span class="s110">r </span><span class="s33">| </span>w<span class="s110">r </span><span class="s38"> </span><span class="s38"></span><span class="s46">(</span><span class="s41">n</span><span class="s40"></span><span class="s42">1) </span><span class="s33">}</span></p><h3 style="padding-left: 30pt;text-indent: 0pt;text-align: left;">4.4.1 <span class="s25">感知器的表征能力</span></h3><p style="padding-top: 10pt;padding-left: 5pt;text-indent: 21pt;line-height: 106%;text-align: justify;">我们可以把<span style=" color: #00F;">感知器看作是 </span><span class="s58">n </span><span style=" color: #00F;">维实例空间（即点空间）中的超平面决策面</span>。对于超平面一 侧的实例，感知器输出 <span class="s6">1</span>，对于另一侧的实例输出<span class="s6">-1</span>，如图 <span class="s6">4-3 </span>所示。这个决策超平面方程 是 <span class="s30">w </span><span class="s38"> </span><span class="s30">x </span><span class="s38"> </span><span class="s33">0 </span>。当然，某些正反样例集合不可能被任一超平面分割。那些可以被分割的称为 线性可分（<span class="s6">linearly separable</span>）样例集合。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 13pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="547" height="1" alt="image" src="机器学习/Image_076.png"/></span></p><p class="s48" style="padding-left: 15pt;text-indent: 0pt;text-align: left;">插图——原书页码： <span class="s21">87 </span><i>下</i></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 14pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="531" height="1" alt="image" src="机器学习/Image_077.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 24pt;text-indent: 0pt;text-align: center;">图 <span class="h4">4-3 </span>两输入感知器表示的决策面</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-left: 37pt;text-indent: 0pt;text-align: left;">（<span class="s16">a</span>）一组训练样例和一个能正确分类这些样例的感知器决策面。（<span class="s16">b</span>）一组非线性可分的训练样例</p><p class="s14" style="padding-top: 3pt;padding-left: 37pt;text-indent: 0pt;line-height: 117%;text-align: left;">（也就是不能用任一直线正确分类的样例）。<span class="s56">x</span><span class="s64">1</span>和<span class="s56">x</span><span class="s64">2</span>是感知器的输入。“<span class="s16">+</span>”表示正例，“<span class="s16">-</span>”表示 反例。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 106%;text-align: justify;">单独的感知器可以用来表示很多布尔函数。例如，假定用 <span class="s6">1</span>（真）和<span class="s6">-1</span>（假）表示布尔 值，那么使用一个两输入的感知器来实现与函数（<span class="s6">AND</span>）的一种方法是设置权<span class="s21">w</span><span class="s35">0</span><span class="s6">= -0.8 </span>并且 <span class="s21">w</span><span class="s35">1</span><span class="s6">=</span><span class="s21">w</span><span class="s35">2</span><span class="s6">=0.5</span>。如果用这个感知器来表示或函数（<span class="s6">OR</span>），那么只要改变它的阈值<span class="s21">w</span><span class="s35">0</span><span class="s6">=-0.3</span>。事实 上，<span class="s6">AND</span>和<span class="s6">OR</span>可被看作<span class="s21">m</span><span class="s6">-of-</span><span class="s21">n</span>函数的特例：也就是要使函数输出为真，那么感知器的<span class="s21">n</span>个输 入中至少<span class="s21">m</span>个必须为真。<span class="s6">OR</span>函数对应于<span class="s21">m</span><span class="s6">=1</span>，<span class="s6">AND</span>函数对应于<span class="s21">m</span><span class="s6">=</span><span class="s21">n</span><span class="s6">.</span>。任意<span class="s21">m</span><span class="s6">-of-</span><span class="s21">n</span>函数可以很 容易地用感知器表示，只要设置所有输入的权为同样的值（如 <span class="s6">0.5</span>），然后据此恰当地设置阈 值。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 20pt;line-height: 107%;text-align: left;">感知器可以表示所有的原始布尔函数（<span class="s6">primitive boolean function</span>）：与、或、与非（<span class="s6">NAND</span>） 和或非（<span class="s6">NOR</span>）。然而不幸的是，一些布尔函数无法用单一的感知器表示，例如异或函数</p><p style="padding-left: 6pt;text-indent: 0pt;text-align: left;">（<span class="s6">XOR</span>），它当且仅当<span class="s21">x</span><span class="s35">1</span><span class="s111"></span><span class="s21">x</span><span class="s35">2</span>时输出为 <span class="s6">1</span>。请注意图 <span class="s6">4-3</span>（<span class="s6">b</span>）中线性不可分的训练样本集对应 于异或函数。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 111%;text-align: justify;">感知器表示与、或、与非、或非的能力是很重要的，因为所有的布尔函数都可表示为基 于这些原始函数的互连单元的某个网络。事实上，仅用两层深度的感知器网络就可以表示所 有的布尔函数，在这些网络中输入被送到多个单元，这些单元的输出被输入到第二级，也是 最后一级。一种方法是用<span style=" color: #00F;">析取范式（</span><span class="s63">disjunctive normal form</span><span style=" color: #00F;">）</span>（也就是对输入和它们的否定 的先进行合取，再对这组合取式进行析取）来表示布尔函数。注意，要把一个 <span class="s6">AND </span>感知器 的输入求否定，只要简单地改变相应输入权的符号。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 113%;text-align: justify;">因为阈值单元的网络可以表示大量的函数，而单独的单元不能做到这一点，所以通常我 们感兴趣的是学习阈值单元组成的多层网络。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 30pt;text-indent: 0pt;text-align: left;">4.4.2 <span class="s25">感知器训练法则</span></h3><p style="padding-top: 10pt;padding-left: 6pt;text-indent: 21pt;line-height: 113%;text-align: justify;">虽然我们的目的是学习由多个单元互连的网络，但我们还是从<span style=" color: #00F;">如何学习单个感知器的权 值开始</span>。准确地说，这里的学习任务是决定一个权向量，它可以使感知器对于给定的训练样 例输出正确的 <span class="s6">1 </span>或<span class="s6">-1</span>。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s24" style="padding-left: 27pt;text-indent: 0pt;text-align: left;"><span style=" color: #000;">已经知道有几种解决这个学习任务的算法。这里我们考虑两种：</span>感知器法则和 <span class="s63">delta </span>法</p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 107%;text-align: justify;"><span style=" color: #00F;">则（</span><span class="s63">delta rule</span><span style=" color: #00F;">）</span>（是第 <span class="s6">1 </span>章中用来学习评估函数的最小均方法 <span class="s6">LMS </span>的一个变体）。这两种算 法保证收敛到可接受的假设，在不同的条件下收敛到的假设略有不同。这两种方法对于 <span class="s6">ANN </span>是很重要的，因为它们提供了学习多个单元构成的网络的基础。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s24" style="padding-left: 5pt;text-indent: 21pt;line-height: 111%;text-align: justify;">为得到可接受的权向量，一种办法是从随机的权值开始，然后反复地应用这个感知器到 每个训练样例，只要它误分类样例就修改感知器的权值。重复这个过程，直到感知器正确分 类所有的训练样例。每一步根据感知器训练法则（<span class="s63">perceptron training rule</span>）来修改权值，也 就是根据下面的法则修改与输入<span class="s58">x</span><span class="s59">i</span>对应的权<span class="s58">w</span><span class="s59">i</span><span class="s63">:</span></p><p class="s58" style="padding-top: 5pt;padding-left: 24pt;text-indent: 0pt;text-align: center;">w<span class="s59">i</span><span class="s51"></span>w<span class="s59">i</span><span class="s63">+</span><span class="s51"></span>w<span class="s59">i</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s24" style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">其中</p><p class="s63" style="padding-top: 8pt;padding-left: 24pt;text-indent: 0pt;text-align: center;"><span class="s51"></span><i>w</i><span class="s59">i</span><span class="s62"> </span>=<span class="s112"></span>(<i>t</i>-<i>o</i>)<i>x</i><span class="s59">i</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">这里 <span class="s21">t </span>是当前训练样例的目标输出，<span class="s21">o </span>是感知器的输出，<span class="s113"></span>是一个正的常数称为<span style=" color: #00F;">学习速 率（</span><span class="s63">learning rate</span><span style=" color: #00F;">）</span>。<span style=" color: #00F;">学习速率的作用是缓和每一步调整权的程度。它通常被设为一个小的数 值（例如 </span><span class="s63">0.1</span><span style=" color: #00F;">），而且有时会使其随着权调整次数的增加而衰减。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 5pt;text-indent: 21pt;line-height: 108%;text-align: justify;"><span class="p">为什么这个更新法则会成功收敛到正确的权值呢？为了得到直观的感觉，考虑一些特 例。假定训练样本已被感知器正确分类。这时，</span>(<i>t</i>-<i>o</i>)<span class="p">是 </span>0<span class="p">，这使</span><span class="s111"></span><i>w</i><span class="s36">i</span><span class="p">为 </span>0<span class="p">，所以没有权值被修 改。而如果当目标输出是</span>+1 <span class="p">时感知器输出一个</span>-1<span class="p">，这种情况为使感知器输出一个</span>+1 <span class="p">而不是</span></p><p class="s21" style="padding-left: 5pt;text-indent: 0pt;text-align: justify;"><span class="s6">-1</span><span class="p">，权值必须被修改以增大 </span><span class="s30">w </span><span class="s38"> </span><span class="s30">x </span><span class="p">的值。例如，如果</span>x<span class="s36">i</span><span class="s6">&gt;0</span><span class="p">，那么增大</span>w<span class="s36">i</span><span class="p">会使感知器更接近正确 分类这个实例。注意这种情况下训练法则会增长</span>w<span class="s36">i</span><span class="p">，因为</span><span class="s6">(</span>t<span class="s6">-</span>o<span class="s6">)</span><span class="p">，</span><span class="s113"></span><span class="p">和</span>x<span class="s36">i</span><span class="p">都是正的。例如，如果 </span>x<span class="s36">i</span><span class="s6">=0.8</span><span class="p">，</span><span class="s113"></span>=<span class="s6">0</span>.<span class="s6">1</span><span class="p">，</span>t<span class="s6">=1</span><span class="p">，并且</span>o<span class="s6">= -1</span><span class="p">，那么权更新就是</span><span class="s113"></span>w<span class="s36">i</span><span class="s41"> </span>=<span class="s113"></span><span class="s6">(</span>t<span class="s6">-</span>o<span class="s6">)</span>x<span class="s36">i</span><span class="s6">=0.1(1-(-1))0.8=0.16</span><span class="p">。另一方 面，如果</span>t<span class="s6">=-1 </span><span class="p">而</span>o<span class="s6">=1</span><span class="p">，那么和正的</span>x<span class="s36">i</span><span class="p">关联的权值会被减小而不是增大。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 110%;text-align: justify;">事实上可以证明，在有限次使用感知器训练法则后，上面的训练过程会收敛到一个能正 确分类所有训练样例的权向量，前提是训练样例线性可分，并且使用了充分小的<span class="s113"></span>（参见 <span class="s6">Minskey &amp; Papert 1969</span>）。如果数据不是线性可分的，那么不能保证收敛。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 30pt;text-indent: 0pt;text-align: left;">4.4.3 <span class="s25">梯度下降和 </span>delta <span class="s25">法则</span></h3><p style="padding-top: 10pt;padding-left: 6pt;text-indent: 21pt;line-height: 109%;text-align: justify;">尽管当训练样例线性可分时，感知器法则可以成功地找到一个权向量，但如果样例不是 线性可分时它将不能收敛。因此，人们设计了另一个训练法则来克服这个不足，称为 <span class="s6">delta </span>法则（<span class="s6">delta rule</span>）。如果训练样本不是线性可分的，那么 <span class="s6">delta </span>法则会收敛到目标概念的最佳 近似。<span class="s63">(how to converge?)</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s63" style="padding-left: 6pt;text-indent: 21pt;line-height: 112%;text-align: left;">delta <span class="s24">法则的关键思想是使用梯度下降（</span>gradient descent<span class="s24">）来搜索可能权向量的假设空间， 以找到最佳拟合训练样例的权向量。</span><span class="s18">这个法则很重要，因为它提供了反向传播算法的基础， 而反向传播算法能够学习多个单元的互连网络。这个法则重要性的另一个原因是，对于包含 多种不同类型的连续参数化假设的假设空间，梯度下降是必须遍历这样的假设空间的所有学 习算法的基础。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 107%;text-align: justify;">最好把 <span class="s6">delta </span>训练法则理解为训练一个无阈值的感知器，也就是一个线性单元（<span class="s6">linear unit</span>），它的输出 <span class="s21">o </span>如下：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s107" style="padding-top: 3pt;text-indent: 0pt;text-align: right;">o<span class="s108">(</span>x<span class="s108">) </span><span class="s109"> </span>w <span class="s109"> </span>x</p><p class="s12" style="padding-top: 4pt;padding-left: 108pt;text-indent: 0pt;text-align: left;">(4.1)</p><p style="padding-left: 27pt;text-indent: 0pt;text-align: left;">于是，一个线性单元对应于感知器的第一阶段，不带有阈值。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 110%;text-align: justify;">为了推导线性单元的权值学习法则，先指定一个度量标准来衡量假设（权向量）相对于 训练样例的训练误差（<span class="s6">training error</span>）。尽管有很多办法定义这个误差，一个常用的特别方便 的度量标准为：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="padding-top: 3pt;text-indent: 0pt;line-height: 19pt;text-align: right;">E<span class="s33">(</span>w<span class="s110">r </span><span class="s33">) </span><span class="s38"></span></p><p class="s92" style="text-indent: 0pt;line-height: 12pt;text-align: left;">1</p><p style="text-indent: 0pt;text-align: left;"/><p class="s42" style="text-indent: 0pt;line-height: 7pt;text-align: left;">2</p><p style="text-indent: 0pt;text-align: left;"/><p class="s33" style="padding-top: 7pt;padding-left: 11pt;text-indent: 0pt;line-height: 15pt;text-align: left;"><span class="s39"></span>(<i>t</i><span class="s52">d</span><span class="s41">   </span><span class="s38"></span> <i>o</i><span class="s52">d</span><span class="s41"> </span>)</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s11" style="padding-left: 15pt;text-indent: 0pt;line-height: 12pt;text-align: center;">（<span class="s12">4.2</span>）</p><p class="s41" style="padding-left: 24pt;text-indent: 0pt;line-height: 13pt;text-align: center;"><span class="s84">2</span><span class="s33"> </span>d<span class="s40"></span>D</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;line-height: 142%;text-align: left;">其中<span class="s6">D</span>是训练样例集合，<span class="s21">t</span><span class="s36">d</span>是训练样例<span class="s21">d</span>的目标输出，<span class="s21">o</span><span class="s36">d</span>是线性单元对训练样例<span class="s21">d</span>的输出。 在这个定义中， <span class="s107">E</span><span class="s108">(</span><span class="s107">w</span><span class="s108">) </span>是目标输出<span class="s21">t</span><span class="s36">d</span>和线性单元输出<span class="s21">o</span><span class="s36">d</span>的差异的平方在所有的训练样例上求</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 107%;text-align: justify;">和后再除以 <span class="s6">2</span>。这里我们把<span class="s21">E</span>定为 <span class="s30">w </span>的函数，是因为线性单元的输出<span class="s21">o</span>依赖于这个权向量。当 然<span class="s21">E</span>也依赖于特定的训练样例集合，但我们认为它们在训练期间是固定的，所以不必麻烦地 把<span class="s21">E</span>写为训练样例的函数。第 <span class="s6">6 </span>章给出了选择这种<span class="s21">E</span>定义的一种贝叶斯论证。确切地讲，在 那里我们指出了在一定条件下，对于给定的训练数据使<span class="s21">E</span>最小化的假设也就是<span class="s21">H</span>中最可能的 假设。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s37" style="padding-left: 26pt;text-indent: 0pt;text-align: left;">4.4.3.1 <span class="s20">形象化假设空间</span></p><p style="padding-top: 8pt;padding-left: 5pt;text-indent: 21pt;line-height: 106%;text-align: justify;">为了理解梯度下降算法，形象地表示整个假设空间是有帮助的，图 <span class="s6">4-4 </span>画出了包含可能 权向量的整个假设空间和与与它们相关联的<span class="s21">E</span>值。这里，坐标轴<span class="s21">w</span><span class="s35">0</span>，<span class="s21">w</span><span class="s35">1</span>表示一个简单的线性 单元中两个权的可能的取值。纵轴指出相对于某固定的训练样例的误差<span class="s21">E</span>。因此图中的误差 曲面概括了假设空间中每一个权向量的企望度（<span class="s6">desirability</span>）（我们企望得到一个具有最小误 差的假设）。如果给定了用来定义<span class="s21">E</span>的方法，那么对于线性单元，这个误差曲面必然是具有 单一全局最小值的抛物面。当然，具体的抛物面形状依赖于具体的训练样例集合。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 13pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="547" height="1" alt="image" src="机器学习/Image_078.png"/></span></p><p class="s48" style="padding-left: 15pt;text-indent: 0pt;text-align: left;">插图——原书页码： <span class="s21">90</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 14pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="531" height="1" alt="image" src="机器学习/Image_079.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 37pt;text-indent: 133pt;text-align: left;">图 <span class="h4">4-4 </span>不同假设的误差</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s56" style="padding-left: 37pt;text-indent: 0pt;line-height: 117%;text-align: justify;"><span class="s14">对于有两个权值的线性单元，假设空间</span>H<span class="s14">就是</span>w<span class="s64">0</span><span class="s16">,</span>w<span class="s64">1</span><span class="s14">平面。纵轴表示与固定的训练样例集合相应的权 向量假设的误差。箭头显示了该点梯度的相反方向，指出了在</span>w<span class="s64">0</span><span class="s14">，</span>w<span class="s64">1</span><span class="s14">平面中沿误差曲面最陡峭下降 的方向。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 110%;text-align: justify;">梯度下降搜索确定一个使 <span class="s21">E </span>最小化的权向量的方法是从一个任意的初始权向量开始， 然后以很小的步伐反复修改这个向量。在每一步，按照沿误差曲面产生最陡峭下降的方向修 改权向量（参见图 <span class="s6">4-4</span>）。继续这个过程直到到达全局的最小误差。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s37" style="padding-left: 26pt;text-indent: 0pt;text-align: left;">4.4.3.2 <span class="s20">梯度下降法则的推导</span></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 20pt;text-align: justify;">我们怎样能计算出沿误差曲面最陡峭下降的方向呢？可以通过计算 <span class="s21">E </span>相对向量 <span class="s30">w</span><span class="s110">r</span><span class="s101"> </span>的每 个分量的导数来得到这个方向。这个向量导数被称为 <span class="s21">E </span>对于 <span class="s30">w </span>的梯度（<span class="s6">gradient</span>），记作</p><p class="s107" style="padding-top: 6pt;padding-left: 7pt;text-indent: 0pt;text-align: left;"><span class="s109"></span>E<span class="s108">(</span>w<span class="s108">) </span><span class="p">。</span></p><p class="s115" style="padding-top: 1pt;padding-left: 152pt;text-indent: 0pt;line-height: 14pt;text-align: left;"><span class="s114"></span><i>E</i><span class="s33">(</span><i>w</i><span class="s101">r </span>) <span class="s38"> </span><span class="s116">⎡ </span><span class="s117"></span><u><i>E </i></u>, <span class="s117"></span><u><i>E </i></u>,<span class="s101">L</span><span class="s33">, </span><span class="s117"></span><u><i>E </i></u><span class="s116">⎤</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s11" style="text-indent: 0pt;line-height: 6pt;text-align: center;">（<span class="s12">4.3</span>）</p><p class="s38" style="text-indent: 0pt;line-height: 12pt;text-align: left;"><span class="s30">w</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s38" style="text-indent: 0pt;line-height: 8pt;text-align: right;">⎢</p><p class="s103" style="text-indent: 0pt;line-height: 13pt;text-align: right;">⎣<span class="s38"></span><span class="s30">w</span><span class="s79">0</span></p><p class="s38" style="padding-left: 64pt;text-indent: 0pt;line-height: 8pt;text-align: left;">⎥</p><p class="s118" style="padding-left: 6pt;text-indent: 0pt;line-height: 13pt;text-align: left;"><span class="s30">w</span><span class="s42">1 </span><span class="s41">n </span><span class="s38">⎦</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 2pt;padding-left: 5pt;text-indent: 21pt;line-height: 157%;text-align: justify;">注意 <span class="s109"></span><span class="s107">E</span><span class="s108">(</span><span class="s107">w</span><span class="s108">) </span>本身是一个向量，它的成员是<span class="s21">E</span>对每个<span class="s21">w</span><span class="s36">i</span>的偏导数。当梯度被解释为权空间 的一个向量时，它确定了使<span class="s7">E</span>最陡峭上升的方向。所以这个向量的反方向给出了最陡峭下降 的方向。例如，图 <span class="s6">4-4 </span>中的箭头显示了<span class="s21">w</span><span class="s35">0</span>，<span class="s21">w</span><span class="s35">1</span>平面的一个特定点的负梯度 <span class="s109"> </span><span class="s109"></span><span class="s107">E</span><span class="s108">(</span><span class="s107">w</span><span class="s108">) </span>。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 26pt;text-indent: 0pt;text-align: left;">既然梯度确定了 <span class="s21">E </span>最陡峭上升的方向，那么梯度下降的训练法则是：</p><p class="s38" style="padding-top: 6pt;padding-left: 24pt;text-indent: 0pt;text-align: center;"><span class="s30">w </span> <span class="s30">w </span> <span class="s30">w</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">其中</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s109" style="padding-top: 2pt;text-indent: 0pt;text-align: right;"><span class="s107">w </span> <span class="s119"> </span><span class="s107">E</span><span class="s108">(</span><span class="s107">w</span><span class="s108">)</span></p><p class="s11" style="padding-top: 2pt;padding-left: 84pt;text-indent: 0pt;text-align: left;">（<span class="s12">4.4</span>）</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 6pt;text-indent: 21pt;line-height: 107%;text-align: left;">这里<span class="s113"></span>是一个正的常数叫做学习速率，它决定梯度下降搜索中的步长。其中的负号是因 为我们想要让权向量向 <span class="s21">E </span>下降的方向移动。这个训练法则也可以写成它的分量形式：</p><p class="s21" style="padding-top: 6pt;padding-left: 24pt;text-indent: 0pt;text-align: center;">w<span class="s36">i</span><span class="s10"></span>w<span class="s36">i</span><span class="s6">+</span><span class="s10"></span>w<span class="s36">i</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">其中</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s38" style="padding-top: 7pt;text-indent: 0pt;text-align: right;"><span class="s30">w</span><span class="s52">i</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s38" style="padding-left: 2pt;text-indent: 0pt;line-height: 20pt;text-align: left;"> <span class="s119"> </span><u></u><span class="s91">E </span></p><p class="s38" style="padding-left: 28pt;text-indent: 0pt;line-height: 14pt;text-align: left;"><span class="s30">w</span><span class="s52">i</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s11" style="padding-left: 27pt;text-indent: 0pt;text-align: left;">（<span class="s12">4.5</span>）</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 27pt;text-indent: 0pt;text-align: left;">这样很清楚，最陡峭的下降可以通过按比例</p><p class="s38" style="padding-top: 2pt;padding-left: 2pt;text-indent: 0pt;text-align: left;"><span class="s30">E</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="24" height="1" alt="image" src="机器学习/Image_080.png"/></span></p><p class="s38" style="text-indent: 0pt;text-align: left;"><span class="s30">w</span><span class="s52">i</span></p><p style="padding-top: 9pt;text-indent: 0pt;text-align: left;">改变 <span class="s30">w </span>的每一分量<span class="s21">w</span><span class="s36">i</span>来实现。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: left;">要形成一个根据等式（<span class="s6">4.5</span>）迭代更新权的实用算法，我们需要一个高效的方法在每一 步计算这个梯度。幸运的是，计算过程并不困难。我们可以从公式（<span class="s6">4.2</span>）中计算 <span class="s21">E </span>的微分，</p><p class="s38" style="padding-top: 5pt;padding-left: 1pt;text-indent: 0pt;line-height: 11pt;text-align: center;"><span class="s30">E</span></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 11pt;text-align: left;">从而得到组成这个梯度向量的分量</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="24" height="1" alt="image" src="机器学习/Image_081.png"/></span></p><p class="s38" style="text-indent: 0pt;text-align: left;"><span class="s30">w</span><span class="s52">i</span></p><p style="text-indent: 0pt;line-height: 11pt;text-align: left;">。过程如下：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s117" style="padding-top: 2pt;text-indent: 0pt;line-height: 8pt;text-align: right;"><span class="s91">E </span></p><p class="s92" style="padding-top: 2pt;padding-left: 11pt;text-indent: 0pt;line-height: 8pt;text-align: left;">  <span class="s117"> </span>1 <span class="s120">2</span></p><p class="s38" style="padding-top: 9pt;text-indent: 0pt;text-align: right;"><span class="s30">w</span><span class="s52">i</span></p><p class="s38" style="padding-left: 3pt;text-indent: 0pt;line-height: 12pt;text-align: left;"></p><p class="s38" style="padding-left: 14pt;text-indent: 0pt;line-height: 14pt;text-align: left;"><span class="s30">w</span><span class="s52">i</span></p><p class="s92" style="padding-top: 2pt;padding-left: 14pt;text-indent: 0pt;line-height: 7pt;text-align: left;">1</p><p class="s33" style="text-indent: 0pt;line-height: 12pt;text-align: left;">2</p><p style="text-indent: 0pt;text-align: left;"/><p class="s33" style="padding-left: 12pt;text-indent: 0pt;line-height: 18pt;text-align: left;"><span class="s39"></span>(<i>t</i><span class="s52">d  </span><span class="s41"> </span><span class="s38"></span> <i>o</i><span class="s52">d</span><span class="s41"> </span>)</p><p class="s41" style="padding-left: 12pt;text-indent: 0pt;line-height: 7pt;text-align: left;">d<span class="s40"></span>D</p><p class="s121" style="text-indent: 0pt;line-height: 18pt;text-align: left;"></p><p style="text-indent: 0pt;text-align: left;"/><p class="s92" style="padding-top: 2pt;text-indent: 0pt;line-height: 8pt;text-align: center;">  <span class="s117"> </span><span class="s120">2</span></p><p class="s38" style="text-indent: 0pt;line-height: 12pt;text-align: right;"></p><p class="s33" style="text-indent: 0pt;line-height: 6pt;text-align: right;">2 <span class="s38"></span><i>w</i></p><p class="s30" style="padding-left: 4pt;text-indent: 0pt;line-height: 17pt;text-align: left;"><span class="s33">(</span>t<span class="s52">d </span><span class="s38"> </span>o<span class="s52">d</span><span class="s41"> </span><span class="s33">)</span></p><p class="s122" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: center;">d<span class="s40"></span><span class="s41">D i</span></p><p class="s121" style="text-indent: 0pt;line-height: 18pt;text-align: left;"><span class="s89">   </span><span class="s41">d           d</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s33" style="padding-top: 1pt;padding-left: 24pt;text-indent: 0pt;line-height: 8pt;text-align: center;">1 <span class="s38"></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="10" height="1" alt="image" src="机器学习/Image_082.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="26" height="1" alt="image" src="机器学习/Image_083.png"/></span></p><p class="s38" style="padding-left: 141pt;text-indent: 0pt;line-height: 12pt;text-align: left;"> <span class="s33">2(</span><span class="s30">t </span> <span class="s30">o </span><span class="s33">)</span></p><p class="s33" style="padding-left: 152pt;text-indent: 0pt;line-height: 6pt;text-align: left;">2 <span class="s38"></span><i>w</i></p><p class="s30" style="text-indent: 0pt;line-height: 17pt;text-align: left;"><span class="s33">(</span>t<span class="s52">d </span><span class="s38"> </span>o<span class="s52">d</span><span class="s41"> </span><span class="s33">)</span></p><p class="s41" style="text-indent: 0pt;line-height: 7pt;text-align: right;">d<span class="s40"></span>D</p><p class="s41" style="text-indent: 0pt;text-align: center;">i</p><p class="s92" style="padding-top: 1pt;text-indent: 0pt;line-height: 8pt;text-align: center;">  <span class="s117"> </span><span class="s101">r r</span></p><p class="s33" style="padding-left: 141pt;text-indent: 0pt;line-height: 18pt;text-align: left;"><span class="s38"></span> <span class="s39"></span>(<i>t</i><span class="s52">d  </span><span class="s41"> </span><span class="s38"></span> <i>o</i><span class="s52">d</span><span class="s41"> </span>) <span class="s123"></span><i>w</i></p><p class="s30" style="padding-left: 4pt;text-indent: 0pt;line-height: 17pt;text-align: left;"><span class="s33">(</span>t<span class="s52">d </span><span class="s38"> </span>w <span class="s38"> </span>x<span class="s52">d</span><span class="s41"> </span><span class="s33">)</span></p><p class="s122" style="padding-left: 24pt;text-indent: 0pt;line-height: 8pt;text-align: center;">d<span class="s40"></span><span class="s41">D i</span></p><p class="s38" style="padding-top: 1pt;text-indent: 0pt;text-align: right;"><span class="s30">E</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 119pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="26" height="1" alt="image" src="机器学习/Image_084.png"/></span></p><p class="s38" style="text-indent: 0pt;text-align: right;"><span class="s30">w</span><span class="s52">i</span></p><p class="s33" style="padding-top: 6pt;padding-left: 1pt;text-indent: 0pt;line-height: 20pt;text-align: left;"><span class="s38"></span> <span class="s124"></span>(<i>t</i><span class="s52">d</span><span class="s41">   </span><span class="s38"></span> <i>o</i><span class="s52">d</span><span class="s41"> </span>)(<span class="s38"></span><i>x</i><span class="s52">id</span><span class="s41"> </span>)</p><p class="s41" style="padding-left: 11pt;text-indent: 0pt;line-height: 7pt;text-align: left;">d<span class="s40"></span>D</p><p class="s11" style="padding-top: 8pt;padding-left: 106pt;text-indent: 0pt;text-align: left;">（<span class="s12">4.6</span>）</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">其中<span class="s21">x</span><span class="s36">id</span>表示训练样例<span class="s21">d</span>的一个输入分量<span class="s21">x</span><span class="s36">i</span>。现在我们有了一个等式，能够用线性单元的</p><p class="s38" style="padding-top: 5pt;padding-left: 175pt;text-indent: 0pt;line-height: 11pt;text-align: center;"><span class="s30">E</span></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 12pt;text-align: left;">输入<span class="s21">x</span><span class="s36">id</span>、输出<span class="s21">o</span><span class="s36">d</span>、以及训练样例的目标值<span class="s21">t</span><span class="s36">d</span>表示</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="24" height="1" alt="image" src="机器学习/Image_085.png"/></span></p><p class="s38" style="text-indent: 0pt;text-align: left;"><span class="s30">w</span><span class="s52">i</span></p><p style="text-indent: 0pt;line-height: 11pt;text-align: left;">。把等式（<span class="s6">4.6</span>）代入等式（<span class="s6">4.5</span>）便得到</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">了梯度下降权值更新法则。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s33" style="padding-left: 5pt;text-indent: 0pt;line-height: 21pt;text-align: left;"><span class="s38"></span><i>w</i><span class="s52">i  </span><span class="s41"> </span><span class="s38"></span> <span class="s119"></span><span class="s125"> </span><span class="s39"></span>(<i>t</i><span class="s52">d  </span><span class="s41"> </span><span class="s38"></span> <i>o</i><span class="s52">d</span><span class="s41"> </span>)<i>x</i><span class="s52">id</span></p><p class="s41" style="text-indent: 0pt;line-height: 7pt;text-align: center;">d<span class="s40"></span>D</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s11" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">（<span class="s12">4.7</span>）</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;line-height: 110%;text-align: left;">概而言之，训练线性单元的梯度下降算法如下：选取一个初始的随机权向量；应用线性 单元到所有的训练样例，然后根据公式（<span class="s6">4.7</span>）计算每个权值的<span class="s111"></span><span class="s21">w</span><span class="s36">i</span>；通过加上<span class="s113"></span><span class="s21">w</span><span class="s36">i</span>来更新每 个权值，然后重复这个过程。这个算法被归纳在表（<span class="s6">4.1</span>）中。<span style=" color: #F00;">因为误差曲面仅包含一个全 局的最小值，所以无论训练样本是否线性可分，这个算法会收敛到具有最小误差的权向量， 条件是必须使用一个足够小的学习速率</span><span class="s126"></span><span style=" color: #F00;">。</span>如果<span class="s113"></span>太大，梯度下降搜索就有越过误差曲面最 小值的危险，而不是停留在那一点。因此，<span style=" color: #F00;">对此算法的一种常用的改进是随着梯度下降步数 的增加逐渐减小</span><span class="s126"></span><span style=" color: #F00;">的值。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="565" height="1" alt="image" src="机器学习/Image_086.png"/></span></p><p class="s16" style="padding-left: 32pt;text-indent: 105pt;line-height: 208%;text-align: left;"><span class="p">表 </span><span class="h4">4-1 </span><span class="p">训练线性单元的梯度下降算法 </span><span class="s14">要实现梯度下降的随机近似，删除式</span>(T4.2)<span class="s14">，并把式</span>(T4.1)<span class="s14">替换为</span><i>w</i><span class="s65">i </span><span class="s57"></span><i>w</i><span class="s65">i </span>+<span class="s127"></span>(<i>t</i>-<i>o</i>)<i>x</i><span class="s76">i</span><span class="s14">。 </span><span class="s6">Gradient-Descent(</span><span class="s21">training_examples</span><span class="s6">, </span><span class="s113"></span><span class="s12">)</span></p><p style="padding-left: 11pt;text-indent: 21pt;line-height: 13pt;text-align: left;"><span class="s21">training_examples </span>中每一个训练样例形式为序偶<span class="s6">&lt; </span><span class="s30">x </span><span class="s6">, </span><span class="s21">t</span><span class="s6">&gt;</span>，其中 <span class="s30">x </span>是输入值向量，<span class="s21">t </span>是目</p><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;">标输出值。<span class="s72"></span>是学习速率（例如 <span class="s6">0.05</span>）。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 53pt;text-indent: 0pt;text-align: left;"><span class="s128">· </span>初始化每个<span class="s21">w</span><span class="s36">i</span>为某个小的随机值</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s128" style="padding-left: 53pt;text-indent: 0pt;text-align: left;">· <span class="p">遇到终止条件之前，做以下操作：</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 81pt;text-indent: 0pt;text-align: left;"><span class="s128">· </span>初始化每个<span class="s10"></span><span class="s21">w</span><span class="s36">i</span>为 <span class="s6">0</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><ul id="l6"><li style="padding-left: 96pt;text-indent: -15pt;text-align: left;"><p class="s12" style="display: inline;"><span class="p">对于训练样例 </span><span class="s21">training_examples </span><span class="p">中的每个</span>&lt; <span class="s30">x </span>, <i>t</i>&gt;<span class="p">，做：</span></p></li></ul></li></ul><p style="padding-top: 6pt;padding-left: 80pt;text-indent: 0pt;text-align: left;"><span class="s128">· </span>把实例 <span class="s30">x</span><span class="s110">r </span>输入到此单元，计算输出 <span class="s21">o</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 80pt;text-indent: 0pt;text-align: left;"><span class="s128">· </span>对于线性单元的每个权<span class="s21">w</span><span class="s36">i</span>，做</p><p class="s74" style="padding-top: 4pt;padding-left: 187pt;text-indent: 0pt;text-align: left;"><span class="s111"></span>w<span class="s76">i </span><span class="s111"></span>w<span class="s76">i </span><span class="s12">+</span><span class="s113"></span><span class="s12">(</span>t<span class="s12">-</span>o<span class="s12">)</span>x<span class="s76">i</span><span class="s129"> </span><span class="s11">（</span><span class="s12">T4.1</span><span class="s11">）</span></p><p style="padding-top: 6pt;padding-left: 81pt;text-indent: 0pt;text-align: left;"><span class="s128">· </span>对于线性单元的每个权<span class="s21">w</span><span class="s36">i</span>，做</p><p class="s74" style="padding-top: 4pt;padding-left: 201pt;text-indent: 0pt;text-align: left;">w<span class="s76">i</span><span class="s111"> </span>w<span class="s76">i </span><span class="s12">+</span><span class="s111"></span>w<span class="s76">i</span><span class="s129"> </span><span class="s11">（</span><span class="s12">T4.2</span><span class="s11">）</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="566" height="1" alt="image" src="机器学习/Image_087.png"/></span></p><p class="s37" style="padding-top: 1pt;padding-left: 26pt;text-indent: 0pt;text-align: left;">4.4.3.3 <span class="s20">梯度下降的随机近似</span></p><p style="padding-top: 8pt;padding-left: 5pt;text-indent: 21pt;line-height: 110%;text-align: justify;">梯度下降是一种重要的通用学习范型。它是搜索庞大假设空间或无限假设空间的一种策 略，它可应用于满足以下条件的任何情况：（<span class="s6">1</span>）假设空间包含连续参数化的假设（例如，一 个线性单元的权值）；（<span class="s6">2</span>）误差对于这些假设参数可微。应用梯度下降的主要实践问题是：</p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 107%;text-align: left;">（<span class="s6">1</span>）有时收敛过程可能非常慢（它可能需要数千步的梯度下降）；（<span class="s6">2</span>）如果在误差曲面上有 多个局部极小值，那么不能保证这个过程会找到全局最小值。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s18" style="padding-left: 6pt;text-indent: 21pt;line-height: 107%;text-align: justify;"><span style=" color: #000;">缓解这些困难的一个常见的梯度下降变体被称为</span>增量梯度下降（<span class="s19">incremental gradient descent</span>）<span style=" color: #000;">，或</span>随机梯度下降（<span class="s19">stochastic gradient descent</span>）<span style=" color: #000;">。鉴于</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 109%;text-align: justify;">公式（<span class="s6">4.7</span>）给出的梯度下降训练法则在对 <span class="s21">D </span>中的所有训练样例求和后计算权值更新， <span style=" color: #F00;">随机梯度下降的思想是根据每个单独样例的误差增量地计算权值更新，得到近似的梯度下降 搜索</span>。修改后的训练法则与公式（<span class="s6">4.7</span>）给出的相似，<span style=" color: #F00;">只是在迭代计算每个训练样例时根据 下面的公式来更新权值</span></p><p class="s12" style="padding-top: 6pt;padding-left: 196pt;text-indent: 0pt;text-align: left;"><span class="s111"></span><i>w</i><span class="s76">i </span>=<span class="s113"></span>(<i>t</i>-<i>o</i>)<i>x</i><span class="s76">i</span><span class="s129"> </span><span class="s11">（</span>4.10<span class="s11">）</span></p><p class="s21" style="padding-top: 7pt;padding-left: 5pt;text-indent: 21pt;text-align: justify;"><span class="p">其中</span>t<span class="p">，</span>o<span class="p">，和</span>x<span class="s36">i</span><span class="p">分别是目标值、单元输出和第</span>i<span class="p">个训练样例的输入。要修改表 </span><span class="s6">4-1 </span><span class="p">的梯度 下降算法，只要简单地删除（</span><span class="s6">T4.2</span><span class="p">）式并把式（</span><span class="s6">T4.1</span><span class="p">）替换为</span>w<span class="s36">i</span><span class="s41"> </span><span class="s10"></span>w<span class="s36">i</span><span class="s41"> </span><span class="s6">+</span><span class="s72"></span><span class="s6">(</span>t<span class="s6">-</span>o<span class="s6">)</span>x<span class="s76">i</span><span class="p">。看待随机梯 度下降的一种方法是</span><span class="s18">考虑为每个单独的训练样例</span><span style=" color: #F00;">d</span><span class="s18">定义不同的误差函数</span><span style=" color: #F00;">E</span><span class="s130">d</span><span class="s19">( </span><span class="s30">w </span><span class="s19">)</span><span class="s18">：</span></p><p class="s33" style="padding-top: 6pt;text-indent: 0pt;line-height: 18pt;text-align: right;"><i>E </i>(<i>w</i><span class="s110">r</span>) <span class="s38"> </span><u>1 </u>(<i>t</i></p><p class="s41" style="text-indent: 0pt;line-height: 13pt;text-align: right;">d <span class="s131">2</span><span class="s33"> </span>d</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s42" style="text-indent: 0pt;line-height: 7pt;text-align: left;">2</p><p style="text-indent: 0pt;text-align: left;"/><ul id="l7"><li style="padding-left: 11pt;text-indent: -8pt;text-align: left;"><p class="s30" style="display: inline;">o<span class="s52">d</span><span class="s41"> </span><span class="s33">)</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s11" style="padding-left: 14pt;text-indent: 0pt;text-align: center;">（<span class="s12">4.11</span>）</p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 21pt;text-align: justify;">其中<span class="s21">t</span><span class="s36">d</span>和<span class="s21">o</span><span class="s36">d</span>是训练样例<span class="s21">d</span>的目标输出值和单元输出值。随机梯度下降迭代计算训练样例集 <span class="s21">D</span>的每个样例<span class="s21">d</span>，在每次迭代过程中按照关于<span class="s21">E</span><span class="s36">d</span><span class="s6">( </span><span class="s30">w </span><span class="s6">)</span>的梯度来改变权值。在迭代所有训练样例 时，这些权值更新的序列给出了对于原来的误差函数<span class="s21">E</span><span class="s6">( </span><span class="s30">w </span><span class="s6">)</span>的梯度下降的一个合理近似。通 过使<span class="s72"></span>（梯度下降的步长）的值足够小，可以使随机梯度下降以任意程度接近于真实梯度下 降。<span style=" color: #F00;">标准的梯度下降和随机的梯度下降之间的关键区别是：</span></p><p class="s28" style="padding-top: 6pt;padding-left: 66pt;text-indent: -21pt;line-height: 107%;text-align: left;"> <span class="s18">在标准的梯度下降中，是在权值更新前对所有样例汇总误差，然而在随机的 梯度下降中，权值是通过考查每个训练实例来更新的。</span></p><p class="s10" style="padding-top: 1pt;padding-left: 66pt;text-indent: -21pt;line-height: 110%;text-align: left;"> <span class="p">在标准的梯度下降中权值更新的每一步对多个样例求和，这需要更多的计 算。另一方面，因为使用真正的梯度，标准的梯度下降对于每一次权值更新 经常使用比随机梯度下降有较大的步长。</span></p><p style="padding-top: 1pt;padding-left: 66pt;text-indent: -21pt;text-align: left;"><span class="s10"> </span>如果<span class="s21">E</span><span class="s6">( </span><span class="s30">w </span><span class="s6">)</span>有多个局部极小值，随机的梯度下降有时可能避免陷入这些局部 极小值，因为它使用不同的<span class="s10"></span><span class="s21">E</span><span class="s36">d</span><span class="s6">( </span><span class="s30">w </span><span class="s6">)</span>而不是<span class="s10"></span><span class="s21">E</span>（ <span class="s30">w </span>）来引导搜索。</p><p style="padding-top: 6pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">在实践中，无论是随机的还是标准的梯度下降方法都被广泛应用。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s18" style="padding-left: 27pt;text-indent: 0pt;text-align: left;"><span style=" color: #000;">公式（ </span><span class="s6">4.10 </span><span style=" color: #000;">）中的训练法则被称为</span>增量法则（ <span class="s19">delta rule </span>）， 或有时叫 <span class="s19">LMS </span>法则 </p><p class="s6" style="padding-top: 1pt;padding-left: 5pt;text-indent: 0pt;line-height: 107%;text-align: left;"><span class="s18">（</span><span style=" color: #F00;">least-mean-square </span><span class="s18">最小均方）、</span><span style=" color: #F00;">Adaline </span><span class="s18">法则、或 </span><span style=" color: #F00;">Windrow-Hoff </span><span class="s18">法则</span><span class="p">（以它的发明者命名）。 在第 </span>1 <span class="p">章中描述了它在学习博弈问题的评估函数中的应用，当时我们称它为 </span>LMS <span class="p">权值更新 法则。注意公式（</span>4.10<span class="p">）的增量法则与 </span>4.4.2 <span class="p">节的感知器训练法则相似。事实上两个表达式 看起来完全一致。然而它们是不同的，因为在增量法则中 </span><i>o </i><span class="p">是指线性单元的输出 </span><i>o</i>( <span class="s30">x </span>)= <span class="s30">w </span><span class="s38"> </span><span class="s30">x </span><span class="p">， 而对于感知器法则，</span><i>o </i><span class="p">是指阈值输出 </span><i>o</i>( <span class="s30">x </span>)=<i>sgn</i>( <span class="s30">w </span><span class="s38"> </span><span class="s30">x </span>)<span class="p">。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 26pt;text-indent: 0pt;text-align: left;">尽管我们给出的<span style=" color: #F00;">增量法则可学习非阈值线性单元的权，但它也可以方便地用来训练有阈</span></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 0pt;line-height: 107%;text-align: justify;"><span style=" color: #F00;">值的感知器单元</span>。假定 <span class="s21">o</span><span class="s6">= </span><span class="s30">w </span><span class="s38"> </span><span class="s30">x </span>是上面的非阈值线性单元的输出，并且 <span class="s21">o</span><span class="s10"></span><span class="s6">=</span><span class="s21">sgn</span>（ <span class="s30">w </span><span class="s38"> </span><span class="s30">x </span>）是 <span class="s21">o </span>被阈值化的结果，与在感知器中一样。现在如果我们希望为 <span class="s21">o</span><span class="s10"></span>训练一个感知器使其拟合目标 值为<span class="s10"></span><span class="s6">1 </span>的训练样例，可以使用与训练 <span class="s21">o </span>一样的目标值和训练样例，不过使用增量法则。很 明显，如果非阈值输出 <span class="s21">o </span>能够被训练到完美拟合这些值，那么阈值输出 <span class="s21">o</span><span class="s72"> </span>也会拟合它们（因 为 <span class="s21">sgn</span><span class="s6">(1)=1</span>，和 <span class="s21">sgn</span><span class="s6">(-1)=-1</span>）。即使不能完美地拟合目标值，只要线性单元的输出具有正确的 符号，有阈值的 <span class="s21">o</span><span class="s10"></span>值会正确地拟合目标值<span class="s10"></span><span class="s6">1</span>。然而注意，由于这个过程会得到使线性单元输 出的误差最小化的权值，这些权值不能保证也使有阈值输出 <span class="s21">o</span><span class="s10"></span>的误分类样例数最小化。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 30pt;text-indent: 0pt;text-align: left;">4.4.4 <span class="s25">小结</span></h3><p class="s18" style="padding-top: 10pt;padding-left: 5pt;text-indent: 21pt;line-height: 110%;text-align: justify;"><span style=" color: #000;">我们已经研究了迭代学习感知器权值的两个相似的算法。</span>这两个算法间的关键差异是感 知器训练法则根据阈值化（<span class="s19">thresholded</span>）的感知器输出的误差更新权值<span style=" color: #00F;">（</span><span class="s63">4.4.2</span><span style=" color: #00F;">）</span>，然而增量 法则根据输入的非阈值化（<span class="s19">unthresholded</span>）线性组合的误差来更新权<span class="s63">(4.4.3)</span><span style=" color: #000;">。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 113%;text-align: justify;">这两个训练法则间的差异反映在不同的收敛特性上。感知器训练法则经过有限次的迭代 收敛到一个能理想分类训练数据的假设，但条件是训练样例线性可分。增量法则渐近收敛到 最小误差假设，可能需要无限的时间，但无论训练样例是否线性可分都会收敛。关于以上收 敛性的详细证明可以参考 <span class="s6">Hertz et al.</span>（<span class="s6">1991</span>）。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 109%;text-align: left;">学习权向量的第三种可能方法是线性规划（<span class="s6">linear programming</span>）。线性规划是解线性不 等式方程组的一种通用的有效方法。注意每个训练样例对应一个形式为 <span class="s30">w </span><span class="s38"> </span><span class="s30">x </span><span class="s6">&gt;0 </span>或 <span class="s30">w </span><span class="s38"> </span><span class="s30">x </span><span class="s10"></span><span class="s6">0 </span>的不等式，并且它们的解就是我们期望的权向量。不幸的是，这种方法仅当训练样例线性可 分时有解，但 <span class="s6">Duda &amp; Hart </span>（<span class="s6">1973</span>，<span class="s6">p.168</span>）建议了一种更巧妙的方法适合非线性可分的情 况。无论如何，这种线性规划的方法不能扩展到训练多层网络，这是我们最关心的。相反， 正如下一节所讨论的，基于增量法则的梯度下降方法可以简单地扩展到多层网络。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 34pt;text-indent: 0pt;text-align: left;">4.5 <span class="s17">多层网络和反向传播算法</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 108%;text-align: left;">正如 <span class="s6">4.4.1 </span>节所指出的，单个感知器仅能表示线性决策面。相反，反向传播算法所学习 的多层网络能够表示种类繁多的非线性曲面。例如，图 <span class="s6">4-5 </span>描述了一个典型的多层网络和它 的决策曲面。这个语音识别任务要区分出现在“<span class="s6">h_d</span>”上下文中的 <span class="s6">10 </span>种元音（例如，“<span class="s6">hid</span>”， “<span class="s6">had</span>”，“<span class="s6">head</span>”，“<span class="s6">hood</span>”等）。输入的语音信号用两个参数表示，它们是通过对声音的频谱 分析得到的，这样我们可以方便地在二维实例空间中显示出决策面。如图可见，多层网络能 够表示高度非线性的决策面，它比前面图 <span class="s6">4-3 </span>中画出的单个单元的线性决策面表征能力更 强。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 13pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="547" height="1" alt="image" src="机器学习/Image_088.png"/></span></p><p class="s48" style="padding-left: 15pt;text-indent: 0pt;text-align: left;">插图——原书页码： <span class="s21">96 </span><i>上</i></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 14pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="531" height="1" alt="image" src="机器学习/Image_089.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 150pt;text-indent: 0pt;text-align: left;">图 <span class="h4">4-5 </span>多层前馈网络的决策区域</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-left: 37pt;text-indent: 0pt;text-align: left;">这里显示的网络是用来训练识别 <span class="s16">10 </span>种出现在“<span class="s16">h_d</span>”（例如“<span class="s16">had</span>”，“<span class="s16">hid</span>”）间的元音。这个网</p><p class="s14" style="padding-top: 1pt;padding-left: 37pt;text-indent: 0pt;line-height: 128%;text-align: justify;">络的输入由两个参数 <span class="s16">F1 </span>和 <span class="s16">F2 </span>组成，它们是通过对声音的频谱分析得到的。网络的 <span class="s16">10 </span>个输出对应 于 <span class="s16">10 </span>个可能的元音。这个网络的预测是其中有最大值的输出。右图画出了学到的网络所代表的高 度非线性决策面。图中的点表示测试样例，它们与用来训练这个网络的样例是完全不同的。（经许 可摘自 <span class="s16">Haung &amp; Lippmann</span>（<span class="s16">1988</span>））</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 30pt;text-indent: -3pt;text-align: left;">本节讨论如何学习这样的多层网络，使用的算法和前面讨论的梯度下降方法相似。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 30pt;text-indent: 0pt;text-align: left;">4.5.1 <span class="s25">可微阈值单元</span></h3><p style="padding-top: 10pt;padding-left: 5pt;text-indent: 21pt;line-height: 111%;text-align: justify;">应该使用什么类型的单元来作为构建多层网络的基础？起初我们可以尝试选择前面讨 论的线性单元，因为我们已经为这种单元导出了一个梯度下降学习法则。然而，多个线性单 元的连接仍旧产生线性函数，而我们更希望选择能够表征非线性函数的网络。感知器单元是 另一种选择，但它的不连续阈值使它不可微，所以不适合梯度下降算法。我们所需要的是这 样的单元，它的输出是输入的非线性函数，并且输出是输入的可微函数。一种答案是 <span class="h4">sigmoid </span>单元（<span class="s6">sigmoid unit</span>），这是一种非常类似于感知器的单元，但它基于一个平滑的可微阈值函 数。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 13pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="547" height="1" alt="image" src="机器学习/Image_090.png"/></span></p><p class="s48" style="padding-left: 15pt;text-indent: 0pt;text-align: left;">插图——原书页码： <span class="s21">96 </span><i>下</i></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 14pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="531" height="1" alt="image" src="机器学习/Image_091.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 24pt;text-indent: 0pt;text-align: center;">图 <span class="h4">4-6 sigmoid </span>阈值单元</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: left;">图 <span class="s6">4-6 </span>画出了 <span class="s6">sigmoid </span>单元。与感知器相似，<span class="s6">sigmoid </span>单元先计算它的输入的线性组合， 然后应用一个阈值到此结果。然而，对于 <span class="s6">sigmoid </span>单元，阈值输出是输入的连续函数。更精 确地讲，<span class="s6">sigmoid </span>单元这样计算它的输出：</p><p class="s12" style="padding-top: 5pt;padding-left: 24pt;text-indent: 0pt;text-align: center;"><i>o</i>=<span class="s113"> </span>( <span class="s132">w</span><span class="s30"> </span><span class="s38"> </span><span class="s30">x </span>)</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">其中</p><p class="s33" style="padding-top: 8pt;text-indent: 0pt;line-height: 19pt;text-align: right;"><span class="s119"> </span>( <i>y</i>) <span class="s38"> </span><u>1    </u></p><p class="s33" style="text-indent: 0pt;line-height: 12pt;text-align: right;">1<span class="s38"> </span><i>e</i><span class="s133"></span><span class="s40"> </span><span class="s41">y</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s11" style="padding-top: 6pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">（<span class="s12">4.12</span>）</p><ul id="l8"><li style="padding-top: 6pt;padding-left: 6pt;text-indent: 21pt;line-height: 107%;text-align: justify;"><p style="display: inline;">经常被称为<span class="s6">sigmoid</span>函数或者也可以称为<span class="s6">logistic</span>函数（<span class="s6">logistic  function</span>）。注意它的输 出范围为 <span class="s6">0 </span>到 <span class="s6">1</span>，随输入单调递增（参见图 <span class="s6">4-6 </span>中的阈值函数曲线）。因为这个函数把非常 大的输入值域映射到一个小范围的输出，它经常被称为<span class="s6">sigmoid</span>单元的挤压函数（<span class="s6">squashing function</span>）。<span class="s6">sigmoid</span>函数有一个有用的特征，它的导数很容易以它的输出表示<span class="s6">[</span>确切地讲，</p><p class="s30" style="padding-top: 5pt;padding-left: 8pt;text-indent: 0pt;line-height: 11pt;text-align: left;">d<span class="s119"> </span><span class="s33">( </span>y<span class="s33">)</span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="43" height="1" alt="image" src="机器学习/Image_092.png"/></span></p><p class="s6" style="padding-left: 42pt;text-indent: 0pt;line-height: 9pt;text-align: left;">=<span class="s72"></span>(<i>y</i>)<span class="s10"></span>(1-<span class="s72"></span>(<i>y</i>))]<span class="p">。我们将看到，后面的梯度下降学习法则使用了这个导数。有时也可</span></p><p class="s30" style="padding-left: 18pt;text-indent: 0pt;line-height: 12pt;text-align: left;">dy</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 3pt;padding-left: 5pt;text-indent: 0pt;line-height: 107%;text-align: left;">以使用其他易计算导数的可微函数代替<span class="s72"></span>。例如，<span class="s6">sigmoid</span>函数定义的<span class="s21">e</span><span class="s83">-y</span>项有时被替换为<span class="s21">e</span><span class="s83">-k</span><span class="s40"></span><span class="s41">y</span>， 其中<span class="s21">k</span>为某个正常数，用来决定这个阈值函数的陡峭性。双曲正切函数<span class="s21">tanh</span>有时也用来代替 <span class="s6">sigmoid</span>函数（参见练习 <span class="s6">4.8</span>）。</p><h3 style="padding-left: 27pt;text-indent: 3pt;text-align: left;">4.5.2 <span class="s25">反向传播算法</span></h3><p style="padding-top: 10pt;padding-left: 6pt;text-indent: 21pt;line-height: 113%;text-align: justify;">对于由一系列确定的单元互连形成的多层网络，反向传播算法可用来学习这个网络的权 值。它采用梯度下降方法试图最小化网络输出值和目标值之间的误差平方。这一节给出反向 传播算法，下一节推导出反向传播算法使用的梯度下降权值更新法则。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 113%;text-align: justify;">因为我们要考虑多个输出单元的网络，而不是象以前只考虑单个单元，所以我们先重新 定义误差 <span class="s21">E</span>，以便对所有网络输出的误差求和。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s12" style="padding-top: 10pt;text-indent: 0pt;line-height: 12pt;text-align: right;"><i>E</i>( <span class="s132">w</span><span class="s30"> </span>) <span class="s134"></span></p><p class="s92" style="text-indent: 0pt;line-height: 12pt;text-align: left;">1</p><p style="text-indent: 0pt;text-align: left;"/><p class="s42" style="text-indent: 0pt;line-height: 7pt;text-align: left;">2</p><p style="text-indent: 0pt;text-align: left;"/><p class="s135" style="padding-top: 7pt;padding-left: 11pt;text-indent: 0pt;line-height: 14pt;text-align: left;"><span class="s136">  </span><span class="s31">(</span><span class="s30">t</span><span class="s41">kd   </span><span class="s118"></span><span class="s33"> </span><span class="s30">o</span><span class="s41">kd </span><span class="s31">)</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s11" style="padding-left: 2pt;text-indent: 0pt;line-height: 13pt;text-align: center;">（<span class="s12">4.13</span>）</p><p class="s41" style="padding-left: 121pt;text-indent: 0pt;line-height: 13pt;text-align: center;"><span class="s84">2 </span>d<span class="s40"></span>D k<span class="s40"></span>outputs</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 6pt;text-indent: 21pt;text-align: justify;">其中<span class="s21">outputs</span>是网络输出单元的集合，<span class="s21">t</span><span class="s36">kd</span>和<span class="s21">o</span><span class="s36">kd</span>是与训练样例<span class="s21">d</span>和第<span class="s21">k</span>个输出单元相关的输出 值。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 110%;text-align: justify;">反向传播算法面临的学习问题是搜索一个巨大的假设空间，这个空间由网络中所有单元 的所有可能的权值定义。这种情况可以用一个误差曲面来形象表示，与图 <span class="s6">4-4 </span>表示的线性单 元的误差曲面相似。那幅图中的误差被我们的新的误差定义 <span class="s21">E </span>所替代，并且空间中的其他 维现在对应网络中与所有单元相关的所有权值。和训练单个单元的情况一样，梯度下降可被 用来尝试寻找一个假设使 <span class="s21">E </span>最小化。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 111%;text-align: justify;">多层网络的一个主要不同是它的误差曲面可能有多个局部极小值，而图 <span class="s6">4-4 </span>表示的抛物 曲面仅有一个最小值。不幸的是，这意味着梯度下降仅能保证收敛到局部极小值，而未必得 到全局最小的误差。尽管有这个障碍，已经发现对于实践中很多应用反向传播算法都产生了 出色的结果。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 39pt;text-indent: 0pt;text-align: center;">表 <span class="h4">4-2 </span>包含两层 <span class="h4">sigmoid </span>单元的前馈网络的反向传播算法（随机梯度下降版本）</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="558" height="1" alt="image" src="机器学习/Image_093.png"/></span></p><p class="s6" style="padding-top: 8pt;padding-left: 32pt;text-indent: 0pt;text-align: left;">Backpropagation(<i>training</i>_<i>examples</i>, <span class="s72"></span>, <i>n</i><span class="s36">in</span>, <i>n</i><span class="s36">out</span>, <i>n</i><span class="s36">hidden</span>)</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="text-indent: 0pt;line-height: 12pt;text-align: left;">t</p><p style="text-indent: 0pt;text-align: left;"/><p class="s6" style="padding-left: 32pt;text-indent: 21pt;line-height: 48%;text-align: left;"><i>trainning</i>_<i>exaples </i><span class="p">中每一个训练样例是形式为</span>&lt; <span class="s30">x </span>, <span class="s30">t </span>&gt;<span class="p">的序偶，其中 </span><span class="s30">x </span><span class="p">是网络输 入值向量， </span><span class="s137">r</span><span class="s101"> </span><span class="p">是目标输出值。</span></p><p style="padding-top: 1pt;padding-left: 32pt;text-indent: 21pt;line-height: 14pt;text-align: left;"><span class="s72"></span>是学习速率（例如 <span class="s6">0.05</span>）。<span class="s21">n</span><span class="s36">in</span>是网络输入的数量，<span class="s21">n</span><span class="s36">hidden</span>是隐藏层单元数，<span class="s21">n</span><span class="s36">out</span>是 输出单元数。</p><p style="padding-left: 32pt;text-indent: 0pt;line-height: 13pt;text-align: left;">从单元<span class="s21">i</span>到单元<span class="s21">j</span>的输入表示为<span class="s21">x</span><span class="s36">ji</span>，单元<span class="s21">i</span>到单元<span class="s21">j</span>的权值表示为<span class="s21">w</span><span class="s36">ij</span>。</p><p style="padding-left: 74pt;text-indent: 0pt;line-height: 14pt;text-align: left;"><span class="s128">· </span>创建具有<span class="s21">n</span><span class="s36">in</span>个输入，<span class="s21">n</span><span class="s36">hidden</span>个隐藏单元，<span class="s21">n</span><span class="s36">out</span>个输出单元的网络</p><p style="padding-left: 74pt;text-indent: 0pt;line-height: 13pt;text-align: left;"><span class="s128">· </span>初始化所有的网络权值为小的随机值（例如<span class="s6">-0.05 </span>和 <span class="s6">0.05 </span>之间的数）</p><p class="s128" style="padding-left: 74pt;text-indent: 0pt;line-height: 14pt;text-align: left;">· <span class="p">在遇到终止条件前，做</span></p><ul id="l9"><li style="padding-top: 1pt;padding-left: 135pt;text-indent: -54pt;line-height: 14pt;text-align: left;"><p class="s12" style="display: inline;"><span class="p">对于训练样例 </span><span class="s21">training_examples </span><span class="p">中的每个</span>&lt; <span class="s30">x </span>, <span class="s30">t </span>&gt;<span class="p">，做 把输入沿网络前向传播</span></p></li></ul></li></ul><p style="padding-left: 153pt;text-indent: 0pt;line-height: 14pt;text-align: left;"><span class="s6">1</span>． 把实例 <span class="s30">x </span>输入网络，并计算网络中每个单元<span class="s21">u</span>的输出</p><p class="s21" style="padding-left: 134pt;text-indent: -3pt;line-height: 14pt;text-align: left;">o<span class="s36">u</span><span class="p">。 使误差沿网络反向传播</span></p><p style="padding-left: 152pt;text-indent: 0pt;line-height: 13pt;text-align: left;"><span class="s6">2</span>． 对于网络的每个输出单元<span class="s21">k</span>，计算它的误差项<span class="s72"></span><span class="s36">k</span></p><p class="s76" style="padding-left: 190pt;text-indent: 0pt;line-height: 13pt;text-align: left;"><span class="s113"></span>k <span class="s111"></span><span class="s74">o</span>k<span class="s12">(1-</span><span class="s74">o</span>k<span class="s12">)(</span><span class="s74">t</span>k<span class="s12">-</span><span class="s74">o</span>k<span class="s12">) </span><span class="s11">（</span><span class="s12">T4.3</span><span class="s11">）</span></p><p style="padding-left: 153pt;text-indent: 0pt;line-height: 15pt;text-align: left;"><span class="s6">3</span>． 对于网络的每个隐藏单元<span class="s21">h</span>，计算它的误差项<span class="s72"></span><span class="s36">h</span></p><p class="s76" style="text-indent: 0pt;line-height: 19pt;text-align: right;"><span class="s113"></span>h <span class="s111"></span><span class="s74">o</span>h<span class="s12">(1-</span><span class="s74">o</span>h<span class="s12">) </span><span class="s138"></span></p><p class="s41" style="text-indent: 0pt;line-height: 7pt;text-align: right;">k<span class="s40"></span>outputs</p><p class="s76" style="text-indent: 0pt;text-align: left;"><span class="s74">w</span>kh<span class="s113"></span>k<span class="s129"> </span><span class="s11">（</span><span class="s12">T4.4</span><span class="s11">）</span></p><p class="s140" style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><span class="s139">                                                        4</span>． 更新每个网络权值<span class="s141">w</span><span class="s142">ji                                                                                 </span><span class="s143"> </span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="553" height="1" alt="image" src="机器学习/Image_094.png"/></span></p><p class="s129" style="padding-left: 198pt;text-indent: 0pt;line-height: 11pt;text-align: center;"><span class="s144">w</span>ji<span class="s145"> </span><span class="s74">w</span>ji <span class="s146">+</span><span class="s111"></span><span class="s74">w</span>ji</p><p class="s11" style="padding-left: 124pt;text-indent: 0pt;line-height: 12pt;text-align: left;">其中</p><p class="s76" style="padding-left: 206pt;text-indent: 0pt;line-height: 15pt;text-align: left;"><span class="s111"></span><span class="s74">w</span>ji<span class="s12">=</span><span class="s113"></span>j<span class="s74">x</span>ji<span class="s129"> </span><span class="s11">（</span><span class="s12">T4.5</span><span class="s11">）</span></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="560" height="1" alt="image" src="机器学习/Image_095.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 7pt;text-indent: 21pt;line-height: 110%;text-align: justify;">表 <span class="s6">4-2 </span>给出了反向传播算法。这里描述的算法适用于包含两层 <span class="s6">sigmoid </span>单元的分层前馈 网络，并且每一层的单元与前一层的所有单元相连。这是反向传播算法的增量梯度下降（或 随机梯度下降）版本。这里使用的符号与前一节使用的一样，并进行了如下的扩展：</p><p class="s10" style="padding-top: 5pt;padding-left: 67pt;text-indent: -21pt;line-height: 107%;text-align: left;"> <span class="p">网络中每个结点被赋予一个序号（例如一个整数），这里的结点要么是网络 的输入，要么是网络中某个单元的输出。</span></p><p class="s21" style="padding-top: 1pt;padding-left: 46pt;text-indent: 0pt;text-align: left;"><span class="s10"> </span>x<span class="s36">ji</span><span class="p">表示结点</span>i<span class="p">到单元</span>j<span class="p">的输入，并且</span>w<span class="s36">ji</span><span class="p">表示对应的权值。</span></p><p style="padding-left: 46pt;text-indent: 0pt;text-align: left;"><span class="s10"> </span><span class="s72"></span><span class="s36">n</span>表示与单元<span class="s21">n</span>相关联的误差项。它的角色与前面讨论的<span class="s6">delta</span>训练法则中的</p><p class="s38" style="padding-top: 6pt;padding-left: 198pt;text-indent: 0pt;line-height: 11pt;text-align: center;"><span class="s30">E</span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="38" height="1" alt="image" src="机器学习/Image_096.png"/></span></p><p class="s6" style="padding-left: 67pt;text-indent: 0pt;line-height: 9pt;text-align: left;">(<i>t</i>-<i>o</i>)<span class="p">相似。后面我们可以看到</span><span class="s72"></span><span class="s36">n </span>= <span class="s38"> </span><span class="p">。</span></p><p class="s38" style="padding-left: 198pt;text-indent: 0pt;line-height: 14pt;text-align: center;"><span class="s30">net</span><span class="s52">n</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 7pt;text-indent: 21pt;line-height: 112%;text-align: justify;">在表 <span class="s6">4-2 </span>的算法的开始，建立一个具有期望数量的隐单元和输出单元的网络，并初始化 所有网络的权值为小的随机数。给定了这个固定的网络结构，算法的主循环就对训练样例进 行反复的迭代。对于每一个训练样例，它应用目前的网络到这个样例，计算对于这个样例网 络输出的误差，然后更新网络中所有的权值。对这样的梯度下降步骤进行迭代，直到网络的 性能达到可接受的精度（经常是上千次，多次使用同样的训练样例）。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;text-align: justify;">这里的梯度下降权更新法则（表 <span class="s6">4-2 </span>中的公式<span class="s6">[T4.5]</span>）与<span class="s6">delta</span>训练法则（公式<span class="s6">[4.10]</span>）相 似。就象<span class="s6">delta</span>法则，它依照以下三者的乘积来更新每一个权：学习速率<span class="s72"></span>、该权值应用的输 入值<span class="s21">x</span><span class="s36">ji</span>、和这个单元输出的误差。惟一的不同是<span class="s6">delta</span>法则中的误差项（<span class="s21">t</span><span class="s6">-</span><span class="s21">o</span>）被替换成一个更 复杂的误差项<span class="s72"></span><span class="s36">j</span>。在 <span class="s6">4.5.3 </span>节的对权更新法则的推导之后我们将给出<span class="s72"></span><span class="s36">j</span>的准确形式。为了直观 地理解它，先考虑网络的每一个输出单元<span class="s21">k</span>的<span class="s72"></span><span class="s36">k</span>（在算法的公式<span class="s6">[T4.3]</span>中））是怎样计算的。 很简单，<span class="s72"></span><span class="s36">k</span>与<span class="s6">delta</span>法则中的（<span class="s21">t</span><span class="s36">k</span><span class="s6">-</span><span class="s21">o</span><span class="s36">k</span>）相似，但乘上了<span class="s6">sigmoid</span>挤压函数的导数<span class="s21">o</span><span class="s36">k</span><span class="s6">(1-</span><span class="s21">o</span><span class="s36">k</span><span class="s6">)</span>。每个隐 藏单元<span class="s21">h</span>的<span class="s72"></span><span class="s36">h</span>的值具有相似的形式（算法的公式<span class="s6">[T4.4]</span>）。然而，因为训练样例仅对网络的输 出提供了目标值<span class="s21">t</span><span class="s36">k</span>，所以缺少直接的目标值来计算隐藏单元的误差值。因此采取以下间接办 法计算隐藏单元的误差项：对受隐藏单元<span class="s21">h</span>影响的每一个单元的误差<span class="s72"></span><span class="s36">k</span>进行加权求和，每个 误差<span class="s72"></span><span class="s36">k</span>权值为<span class="s21">w</span><span class="s36">kh</span>，<span class="s21">w</span><span class="s36">kh</span>就是从隐藏单元<span class="s21">h</span>到输出单元<span class="s21">k</span>的权值。这个权值刻画了隐藏单元<span class="s21">h</span>对于 输出单元<span class="s21">k</span>的误差应“负责”的程度。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 107%;text-align: justify;">表 <span class="s6">4-2 </span>中的算法随着每个训练样例的出现递增地更新权。这一点与梯度下降的随机近似 算法一致。要取得误差<span class="s21">E</span>的真实梯度，需要在修改权值之前对所有训练样例的<span class="s72"></span><span class="s36">j</span><span class="s21">x</span><span class="s36">ji</span>值求和。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 113%;text-align: justify;">在典型的应用中，反向传播算法的权值更新迭代会被重复上千次。有很多终止条件可以 用来停止这个过程。一种方法是在迭代的次数到了一个固定值时停止；或当在训练样例上的 误差降到某个阈值以下时；或在分离的验证样例集合上的误差符合某个标准时。终止判据的 选择是很重要的，因为太少的循环可能没有有效地降低误差，而太多的循环会导致对训练数 据的过度拟合。在 <span class="s6">4.6.5 </span>节中我们会更详细地讨论这个问题。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><ol id="l10"><ol id="l11"><ol id="l12"><ol id="l13"><li style="padding-left: 79pt;text-indent: -51pt;text-align: left;"><p class="s20" style="display: inline;">增加冲量（<span class="s37">Momentum</span>）项</p><p style="padding-top: 8pt;padding-left: 6pt;text-indent: 21pt;line-height: 110%;text-align: justify;">因为反向传播算法的应用如此广泛，所以已经开发出了很多反向传播算法的变体。其中 最常见的是修改算法中公式（<span class="s6">T4.5</span>）的权值更新法则，使第 <span class="s21">n </span>次迭代的权值更新部分地依赖 于发生在第 <span class="s21">n</span><span class="s6">-1 </span>次迭代时的更新，即把公式（<span class="s6">T4.5</span>）换为如下的形式：</p><p style="padding-top: 1pt;padding-left: 26pt;text-indent: 90pt;text-align: left;">       <span class="s10"></span><span class="s21">w</span><span class="s36">ji</span>(<span class="s21">n</span>)=<span class="s72"></span><span class="s36">j</span><span class="s21">x</span><span class="s36">ji </span>+ <span class="s72"></span><span class="s10"></span><span class="s21">w</span><span class="s36">ji</span>(<span class="s21">n </span>– 1) （4.18） </p><p class="s6" style="padding-top: 7pt;padding-left: 26pt;text-indent: 0pt;text-align: left;"><span class="p">这里</span><span class="s10"></span><i>w</i><span class="s36">ji</span>(<i>n</i>)<span class="p">是算法主循环中的第</span><i>n</i><span class="p">次迭代进行的权值更新，并且 </span>0<span class="s10"></span><span class="s72"></span>&lt;1 <span class="p">是一个称为冲量</span></p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 111%;text-align: justify;">（<span class="s6">momentum</span>）的常数。注意这个公式右侧的第一项就是反向传播算法的公式（<span class="s6">T4.5</span>）中的 权值更新。右边的第二项是新的，被称为冲量项。为了理解这个冲量项的作用，设想梯度下 降的搜索轨迹就好像一个（无冲量的）球滚下误差曲面。<span class="s10"></span>的作用是增加冲量使这个球从一 次迭代到下一次迭代时以同样的方向滚动。冲量有时会使这个球滚过误差曲面的局部极小 值；或使其滚过误差曲面上的平坦区域，如果没有冲量这个球有可能在这个区域停止。它也 具有在梯度不变的区域逐渐增大搜索步长的效果，从而可以加快收敛。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s37" style="padding-left: 27pt;text-indent: 0pt;text-align: left;">4.5.2.2 <span class="s20">学习任意的无环网络</span></p><p style="padding-top: 8pt;padding-left: 6pt;text-indent: 21pt;line-height: 107%;text-align: left;">表 <span class="s6">4-2 </span>给出的反向传播算法的定义仅适用于两层的网络。然而那里给出的算法可以简单 地推广到任意深度的前馈网络。公式（<span class="s6">T4.5</span>）的权值更新法则保持不变，惟一的变化是计算</p><p style="padding-left: 6pt;text-indent: 0pt;text-align: justify;"><span class="s72"></span>值的过程。概括地说，第<span class="s21">m</span>层的单元<span class="s21">r</span>的<span class="s72"></span><span class="s36">r</span>值是由更深的<span class="s21">m</span><span class="s6">+1 </span>层的<span class="s72"></span>值根据下式计算的：</p><p class="s76" style="padding-top: 5pt;text-indent: 0pt;line-height: 20pt;text-align: right;"><span class="s113"></span>r <span class="s12">=</span><span class="s74">o</span>r<span class="s12">(1- </span><span class="s74">o</span>r<span class="s12">) </span><span class="s138"></span></p><p class="s41" style="text-indent: 0pt;line-height: 8pt;text-align: right;">s<span class="s40"></span>m<span class="s40"></span><span class="s42">1</span><span class="s45">层</span></p><p class="s76" style="padding-top: 7pt;padding-left: 2pt;text-indent: 0pt;text-align: left;"><span class="s74">w</span>sr<span class="s113"></span>s<span class="s129"> </span><span class="s11">（</span><span class="s12">4.19</span><span class="s11">）</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">注意这个公式与表 <span class="s6">4-2 </span>算法的第 <span class="s6">3 </span>步相同，这里要说明的是对于网络中的任意数量的隐 藏单元，该步骤要被重复很多遍。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 113%;text-align: justify;">如果推广到任何有向无环结构也一样的简单，而不论网络中的单元是否象我们至此为止 假定的那样被统一地排列在层上。对于网络单元没有按此排列的情况，计算任意内部单元（也 就是所有非输出单元）的<span class="s72"></span>的法则是：</p><p class="s76" style="padding-top: 3pt;padding-left: 158pt;text-indent: 0pt;line-height: 21pt;text-align: left;"><span class="s113"></span>r <span class="s12">=</span><span class="s74">o</span>r<span class="s12">(1- </span><span class="s74">o</span>r<span class="s12">) </span><span class="s138"></span></p><p class="s41" style="text-indent: 0pt;line-height: 7pt;text-align: right;">s<span class="s40"></span>DownStream<span class="s42">(</span>r <span class="s42">)</span></p><p class="s76" style="padding-top: 6pt;padding-left: 1pt;text-indent: 0pt;text-align: left;"><span class="s74">w</span>sr<span class="s113"></span>s<span class="s129"> </span><span class="s11">（</span><span class="s12">4.20</span><span class="s11">）</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">其中 <span class="s21">DownStream</span><span class="s6">(</span><span class="s21">r</span><span class="s6">)</span>是在网络中单元 <span class="s6">r </span>的立即下游（<span class="s6">immediately downstream</span>）单元的集 合，或者说输入中包括 <span class="s21">r </span>的输出的所有单元。<span class="s6">4.5.3 </span>节我们要推导的就是这种权值更新法则 的一般形式。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 30pt;text-indent: 0pt;text-align: left;">4.5.3 <span class="s25">反向传播法则的推导</span></h3><p style="padding-top: 10pt;padding-left: 6pt;text-indent: 21pt;line-height: 113%;text-align: left;">这一节给出反向传播算法的权值调整法则的推导，如果是第一遍阅读可以跳过这一节， 而不失连续性。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 107%;text-align: left;">这里我们要解决的问题是推导出表 <span class="s6">4-2 </span>算法使用的随机梯度下降法则。回忆公式（<span class="s6">4.11</span>）， 随机的梯度下降算法迭代处理训练样例，每次处理一个。对于每个训练样例<span class="s21">d</span>，利用关于这 个样例的误差<span class="s21">E</span><span class="s36">d</span>的梯度修改权值。换句话说，对于每一个训练样例<span class="s21">d</span>，每个权<span class="s21">w</span><span class="s36">ji</span>被增加<span class="s10"></span><span class="s21">w</span><span class="s36">ji</span>。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s111" style="text-indent: 0pt;text-align: right;"><span class="s74">w</span><span class="s76">ji</span><span class="s12">=</span></p><p class="s94" style="padding-top: 2pt;padding-left: 4pt;text-indent: 0pt;line-height: 20pt;text-align: left;"> <span class="s119"> </span><span class="s118"></span><span class="s30">E</span><span class="s143">d  </span></p><p class="s38" style="padding-left: 22pt;text-indent: 0pt;line-height: 14pt;text-align: left;"><span class="s30">w</span><span class="s52">ji</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s11" style="padding-left: 84pt;text-indent: 0pt;text-align: left;">（<span class="s12">4.21</span>）</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">其中，<span class="s21">E</span><span class="s36">d</span>是训练样例<span class="s21">d</span>的误差，通过对网络中所有输出单元的求和得到</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s92" style="padding-top: 3pt;text-indent: 0pt;line-height: 10pt;text-align: right;">1</p><p class="s12" style="text-indent: 0pt;line-height: 8pt;text-align: right;"><i>E</i><span class="s76">d</span>( <span class="s132">w</span><span class="s30"> </span>) <span class="s134"></span></p><p class="s42" style="text-indent: 0pt;line-height: 7pt;text-align: left;">2</p><p style="text-indent: 0pt;text-align: left;"/><p class="s33" style="padding-top: 7pt;padding-left: 8pt;text-indent: 0pt;line-height: 15pt;text-align: left;"><span class="s39"></span>(<i>t</i><span class="s52">k</span><span class="s41">   </span><span class="s38"></span> <i>o</i><span class="s52">k</span><span class="s41"> </span>)</p><p class="s41" style="padding-left: 24pt;text-indent: 0pt;line-height: 13pt;text-align: center;"><span class="s84">2</span><span class="s33"> </span>k<span class="s40"></span>outputs</p><p style="padding-left: 6pt;text-indent: 21pt;text-align: left;">这里<span class="s21">outputs</span>是网络中输出单元的集合，<span class="s21">t</span><span class="s36">k</span>是单元<span class="s21">k</span>对于训练样例<span class="s21">d</span>的目标值，<span class="s21">o</span><span class="s36">k</span>是给定训 练样例<span class="s21">d</span>时单元<span class="s21">k</span>的输出值。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 27pt;text-indent: 0pt;text-align: left;">随机梯度下降法则的推导概念上是易懂的，但需要留意很多下标和变量。我们将遵循图</p><p style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;"><span class="s6">4-6 </span>中所画出的符号，增加一个下标 <span class="s21">j </span>用来表示网络中的第 <span class="s21">j </span>个单元，具体如下：</p><p class="s21" style="padding-top: 6pt;padding-left: 45pt;text-indent: 0pt;text-align: left;"><span class="s10"> </span>x<span class="s36">ji</span><span class="s6">=</span><span class="p">单元</span>j<span class="p">的第</span>i<span class="p">个输入</span></p><p class="s21" style="padding-left: 45pt;text-indent: 0pt;text-align: left;"><span class="s10"> </span>w<span class="s36">ji</span><span class="s6">=</span><span class="p">与单元</span>j<span class="p">的第</span>i<span class="p">个输入相关联的权值</span></p><p class="s36" style="padding-left: 45pt;text-indent: 0pt;text-align: left;"><span class="s10"> </span><span class="s21">net</span>j<span class="s6">=</span><span class="s10"></span>i<span class="s21">w</span>ji<span class="s21">x</span>ji<span class="p">（单元</span><span class="s21">j</span><span class="p">的输入的加权和）</span></p><p class="s21" style="padding-left: 45pt;text-indent: 0pt;text-align: left;"><span class="s10"> </span>o<span class="s36">j</span><span class="s6">=</span><span class="p">单元</span>j<span class="p">计算出的输出</span></p><p class="s21" style="padding-left: 45pt;text-indent: 0pt;text-align: left;"><span class="s10"> </span>t<span class="s36">j</span><span class="s6">=</span><span class="p">单元</span>j<span class="p">的目标输出</span></p><ul id="l14"><li style="padding-left: 66pt;text-indent: -20pt;text-align: left;"><p class="s72" style="display: inline;"><span class="s6">=sigmoid </span><span class="p">函数</span></p><p class="s10" style="padding-left: 45pt;text-indent: 0pt;text-align: left;"> <span class="s21">outputs</span><span class="s6">=</span><span class="p">网络的最后一层的单元集合</span></p></li><li style="padding-top: 1pt;padding-left: 66pt;text-indent: -20pt;line-height: 107%;text-align: left;"><p class="s6" style="display: inline;"><i>DownStream</i>(<i>j</i>)=<span class="p">单元的立即输入（</span>immediate inputs<span class="p">）中包含单元 </span><i>j </i><span class="p">输出的单 元集合</span></p></li></ul></li></ol></ol></ol></ol><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s38" style="padding-top: 2pt;text-indent: 0pt;line-height: 11pt;text-align: right;"><span class="s30">E</span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="30" height="1" alt="image" src="机器学习/Image_097.png"/></span></p><p style="text-indent: 0pt;line-height: 8pt;text-align: right;">现在我们导出 <span class="s83">d</span></p><p class="s38" style="text-indent: 0pt;line-height: 15pt;text-align: right;"><span class="s30">w</span><span class="s52">ji</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;">的一个表示，以便实现公式（<span class="s6">4.21</span>）中出现的随机的梯度下降法则。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">首先，注意权值<span class="s21">w</span><span class="s36">ji</span>仅能通过<span class="s21">net</span><span class="s36">j</span>影响网络的其他部分。所以，我们可以使用链式规则（<span class="s6">chain rule</span>）得到</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s38" style="padding-top: 4pt;text-indent: 0pt;text-align: right;"><span class="s30">E</span><span class="s52">d</span></p><p style="padding-left: 175pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="30" height="1" alt="image" src="机器学习/Image_098.png"/></span></p><p class="s38" style="text-indent: 0pt;text-align: right;"><span class="s30">w</span><span class="s52">ji</span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="37" height="1" alt="image" src="机器学习/Image_099.png"/></span></p><p class="s147" style="padding-top: 4pt;padding-left: 1pt;text-indent: 0pt;line-height: 19pt;text-align: center;">=<span class="s12"> </span><span class="s38"></span><span class="s30">E</span><span class="s52">d</span></p><p class="s38" style="padding-left: 9pt;text-indent: 0pt;line-height: 15pt;text-align: left;"><span class="s30">net </span><span class="s52">j</span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="37" height="1" alt="image" src="机器学习/Image_100.png"/></span></p><p class="s147" style="padding-top: 12pt;text-indent: 0pt;line-height: 19pt;text-align: left;">=<span class="s12"> </span><span class="s38"></span><span class="s30">E</span><span class="s52">d</span></p><p class="s38" style="padding-left: 6pt;text-indent: 0pt;line-height: 15pt;text-align: center;"><span class="s30">net </span><span class="s52">j</span></p><p class="s38" style="padding-top: 2pt;padding-left: 2pt;text-indent: 0pt;text-align: left;"><span class="s30">net </span><span class="s52">j</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 1pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="38" height="1" alt="image" src="机器学习/Image_101.png"/></span></p><p class="s38" style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><span class="s30">w</span><span class="s52">ji</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s144" style="text-indent: 0pt;text-align: left;">x<span class="s129">ji</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s11" style="padding-left: 70pt;text-indent: 0pt;text-align: left;">（<span class="s12">4.22</span>）</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 27pt;text-indent: 0pt;text-align: left;">已知等式（<span class="s6">4.22</span>），我们剩下的任务就是为</p><p class="s38" style="padding-top: 2pt;padding-left: 4pt;text-indent: 0pt;text-align: left;"><span class="s30">E</span><span class="s52">d</span></p><p style="text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="38" height="1" alt="image" src="机器学习/Image_102.png"/></span></p><p class="s38" style="text-indent: 0pt;text-align: left;"><span class="s30">net </span><span class="s52">j</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;">导出一个方便的表示。我们依次考虑</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 26pt;text-indent: -21pt;text-align: left;">两种情况：一种情况是单元 <span class="s21">j </span>是网络的一个输出单元，另一种情况是 <span class="s21">j </span>是一个内部单元。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;text-align: left;">情况 <span class="h4">1</span>：输出单元的权值训练法则。就象<span class="s21">w</span><span class="s36">ji</span>仅能通过<span class="s21">net</span><span class="s36">j</span>影响其余的网络一样，<span class="s21">net</span><span class="s36">j</span>仅能 通过<span class="s21">o</span><span class="s36">j</span>影响其余的网络。所以我们可以再次使用链式规则得出</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s38" style="padding-top: 4pt;text-indent: 0pt;text-align: right;"><span class="s30">E</span><span class="s52">d</span></p><p style="padding-left: 176pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="38" height="1" alt="image" src="机器学习/Image_103.png"/></span></p><p class="s38" style="text-indent: 0pt;text-align: right;"><span class="s30">net </span><span class="s52">j</span></p><p class="s38" style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 12pt;text-align: center;"><span class="s30">E</span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="28" height="1" alt="image" src="机器学习/Image_104.png"/></span></p><p class="s148" style="padding-left: 3pt;text-indent: 0pt;line-height: 8pt;text-align: center;">=<span class="s12"> </span><span class="s41">d</span></p><p class="s38" style="padding-left: 8pt;text-indent: 0pt;line-height: 15pt;text-align: center;"><span class="s30">o </span><span class="s52">j</span></p><p class="s38" style="padding-top: 2pt;padding-left: 7pt;text-indent: 0pt;text-align: left;"><span class="s30">o </span><span class="s52">j</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 1pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="38" height="1" alt="image" src="机器学习/Image_105.png"/></span></p><p class="s38" style="padding-left: 2pt;text-indent: 0pt;text-align: left;"><span class="s30">net </span><span class="s52">j</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s11" style="padding-left: 71pt;text-indent: 0pt;text-align: left;">（<span class="s12">4.23</span>）</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">首先仅考虑等式（<span class="s6">4.23</span>）的第一项</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="28" height="1" alt="image" src="机器学习/Image_106.png"/></span></p><p class="s38" style="padding-top: 2pt;text-indent: 0pt;text-align: right;"><span class="s30">E</span><span class="s52">d</span></p><p class="s149" style="padding-top: 3pt;text-indent: 0pt;line-height: 19pt;text-align: left;">= <span class="s117"> </span><span class="s92">1</span></p><p class="s39" style="padding-top: 7pt;padding-left: 8pt;text-indent: 0pt;line-height: 15pt;text-align: left;"><span class="s33">(</span><span class="s30">t</span><span class="s52">k</span></p><p class="s42" style="text-indent: 0pt;line-height: 7pt;text-align: left;">2</p><p style="text-indent: 0pt;text-align: left;"/></li><li style="padding-top: 10pt;padding-left: 11pt;text-indent: -8pt;line-height: 12pt;text-align: left;"><p class="s30" style="display: inline;">o<span class="s52">k</span><span class="s41"> </span><span class="s33">)</span></p><p class="s38" style="text-indent: 0pt;line-height: 14pt;text-align: right;"><span class="s30">o </span><span class="s52">j</span></p><p class="s38" style="padding-left: 12pt;text-indent: 0pt;line-height: 14pt;text-align: left;"><span class="s30">o </span><span class="s52">j</span></p><p class="s41" style="padding-left: 3pt;text-indent: 0pt;line-height: 14pt;text-align: left;"><span class="s84">2</span><span class="s33"> </span>k<span class="s40"></span>outputs</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s92" style="padding-top: 2pt;text-indent: 0pt;line-height: 11pt;text-align: right;">  <span class="s117"></span>  </p><p class="s21" style="padding-left: 27pt;text-indent: 0pt;line-height: 10pt;text-align: left;"><span class="p">除了当 </span>k<span class="s6">=</span>j <span class="p">时，所有输出单元 </span>k <span class="p">的导数 </span><span class="s33">(</span><span class="s30">t</span><span class="s52">k</span></p><p class="s38" style="text-indent: 0pt;line-height: 13pt;text-align: right;"><span class="s30">o </span><span class="s52">j</span></p></li><li style="padding-top: 10pt;padding-left: 11pt;text-indent: -8pt;text-align: left;"><p class="s30" style="display: inline;">o<span class="s52">k</span></p><p style="padding-top: 10pt;text-indent: 0pt;text-align: left;"><span class="s33">)</span><span class="s46">2 </span>为 <span class="s6">0</span>。所以我们不必对多个输出</p><p class="s21" style="padding-left: 6pt;text-indent: 0pt;text-align: left;"><span class="p">单元求和，只需令 </span>k<span class="s6">=</span>j<span class="p">。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s38" style="padding-left: 6pt;text-indent: 0pt;text-align: left;"><span class="s30">E</span><span class="s52">d</span></p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="29" height="1" alt="image" src="机器学习/Image_107.png"/></span></p><p class="s38" style="padding-left: 8pt;text-indent: 0pt;text-align: left;"><span class="s30">o </span><span class="s52">j</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s114" style="padding-left: 1pt;text-indent: 0pt;line-height: 20pt;text-align: left;"><span class="s38"> </span><u></u></p><p class="s38" style="padding-left: 11pt;text-indent: 0pt;line-height: 14pt;text-align: left;"><span class="s30">o </span><span class="s52">j</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><ol id="l15"><li style="padding-left: 11pt;text-indent: -8pt;line-height: 18pt;text-align: left;"><p class="s33" style="display: inline;">(<i>t</i></p></li><li style="padding-left: 21pt;text-indent: -17pt;line-height: 13pt;text-align: left;"><p class="s41" style="display: inline;">j</p></li></ol><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s42" style="text-indent: 0pt;line-height: 7pt;text-align: left;">2</p><p style="text-indent: 0pt;text-align: left;"/></li><li style="padding-left: 11pt;text-indent: -8pt;text-align: left;"><p class="s30" style="display: inline;">o <span class="s52">j</span><span class="s41"> </span><span class="s33">)</span></p><p class="s33" style="padding-top: 5pt;text-indent: 0pt;line-height: 10pt;text-align: right;">1</p><p style="text-indent: 0pt;text-align: left;"><span><img width="10" height="1" alt="image" src="机器学习/Image_108.png"/></span></p><p class="s38" style="padding-top: 1pt;padding-left: 187pt;text-indent: -10pt;line-height: 62%;text-align: left;"> <span class="s33">2(</span><span class="s30">t </span><span class="s52">j </span> <span class="s30">o </span><span class="s52">j </span><span class="s33">) 2</span></p><p class="s38" style="padding-top: 3pt;text-indent: 0pt;text-align: center;"><span class="s33">(</span><span class="s30">t </span><span class="s52">j</span><span class="s41"> </span> <span class="s30">o </span><span class="s52">j</span><span class="s41"> </span><span class="s33">)</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="64" height="1" alt="image" src="机器学习/Image_109.png"/></span></p><p class="s38" style="text-indent: 0pt;text-align: center;"><span class="s30">o </span><span class="s52">j</span></p><p class="s12" style="padding-top: 3pt;padding-left: 177pt;text-indent: 0pt;text-align: left;">= (-<i>t</i><span class="s76">j</span>-<i>o</i><span class="s76">j</span>) <span class="s11">（</span>4.24<span class="s11">）</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s38" style="text-indent: 0pt;line-height: 13pt;text-align: right;"><span class="s30">o </span><span class="s52">j</span></p><p style="padding-left: 27pt;text-indent: 0pt;line-height: 12pt;text-align: left;">接下来考虑等式（<span class="s6">4.23</span>）的第二项。既然<span class="s21">o</span><span class="s36">j</span><span class="s6">=</span><span class="s72"></span>（<span class="s21">net</span><span class="s36">j</span>），导数</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="38" height="1" alt="image" src="机器学习/Image_110.png"/></span></p><p class="s38" style="text-indent: 0pt;text-align: left;"><span class="s30">net </span><span class="s52">j</span></p><p style="text-indent: 0pt;line-height: 11pt;text-align: left;">就是<span class="s6">sigmoid</span>函数的导</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;"><span class="p">数，而我们已经指出过</span>sigmoid<span class="p">函数的导数为</span><span class="s72"></span>(<i>net</i><span class="s36">j</span>)(1-<span class="s72"></span>(<i>net</i><span class="s36">j</span>))<span class="p">。所以，</span></p><p class="s38" style="padding-top: 8pt;text-indent: 0pt;text-align: right;"><span class="s30">o </span><span class="s52">j</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 178pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="37" height="1" alt="image" src="机器学习/Image_111.png"/></span></p><p class="s38" style="text-indent: 0pt;text-align: right;"><span class="s30">net </span><span class="s52">j</span></p><p class="s33" style="padding-top: 7pt;padding-left: 11pt;text-indent: 0pt;line-height: 13pt;text-align: center;"><span class="s38"></span><span class="s119"> </span>(<i>net </i><span class="s52">j</span><span class="s41"> </span>)</p><p style="text-indent: 0pt;text-align: left;"><span><img width="61" height="1" alt="image" src="机器学习/Image_112.png"/></span></p><p class="s38" style="padding-left: 1pt;text-indent: 0pt;line-height: 9pt;text-align: left;"></p><p class="s38" style="padding-left: 8pt;text-indent: 0pt;line-height: 14pt;text-align: center;"><span class="s30">net </span><span class="s52">j</span></p><p class="s38" style="padding-top: 3pt;padding-left: 1pt;text-indent: 0pt;text-align: left;"><span class="s30">o </span><span class="s52">j</span><span class="s41"> </span><span class="s33">(1 </span> <span class="s30">o </span><span class="s52">j</span><span class="s41"> </span><span class="s33">)</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s11" style="padding-left: 73pt;text-indent: 0pt;text-align: left;">（<span class="s12">4.25</span>）</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">把表达式（<span class="s6">4.24</span>）和（<span class="s6">4.25</span>）代入（<span class="s6">4.23</span>），我们得到</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s38" style="padding-top: 2pt;text-indent: 0pt;line-height: 15pt;text-align: right;"><span class="s30">E</span><span class="s52">d</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s12" style="text-indent: 0pt;line-height: 8pt;text-align: left;">= -(<i>t </i>-<i>o </i>)<i>o </i>(1-<i>o </i>) <span class="s11">（</span>4.26<span class="s11">）</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 176pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="37" height="1" alt="image" src="机器学习/Image_113.png"/></span></p><p class="s38" style="text-indent: 0pt;text-align: right;"><span class="s30">net </span><span class="s52">j</span></p><p class="s129" style="padding-left: 17pt;text-indent: 0pt;line-height: 7pt;text-align: left;">j j j j</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">然后与等式（<span class="s6">4.21</span>）和（<span class="s6">4.22</span>）合并，我们便推导出了输出单元的随机梯度下降法则：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s111" style="text-indent: 0pt;text-align: right;"><span class="s74">w</span><span class="s76">ji</span><span class="s12">=</span></p><p class="s129" style="text-indent: 0pt;line-height: 7pt;text-align: left;">j     j         j              j         ji</p><p style="text-indent: 0pt;text-align: left;"/><p class="s11" style="padding-top: 2pt;padding-left: 4pt;text-indent: 0pt;line-height: 20pt;text-align: left;"><span class="s134"> </span><span class="s119"> </span><span class="s150"></span><span class="s30">E</span><span class="s143">d </span><span class="s12">=</span><span class="s113"></span>（<span class="s74">t </span><span class="s12">-</span><span class="s74">o </span>）<span class="s74">o </span>（<span class="s12">1-</span><span class="s74">o </span>）<span class="s74">x </span>（<span class="s12">4.27</span>）</p><p class="s38" style="padding-left: 22pt;text-indent: 0pt;line-height: 14pt;text-align: left;"><span class="s30">w</span><span class="s52">ji</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">注意这个训练法则恰恰是表 <span class="s6">4-2 </span>算法中的（<span class="s6">T4.3</span>）和（<span class="s6">T4.5</span>）的权值更新法则。此外，</p><p class="s38" style="padding-top: 6pt;padding-left: 55pt;text-indent: 0pt;line-height: 11pt;text-align: center;"><span class="s30">E</span></p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 9pt;text-align: left;">我们可以发现式（<span class="s6">T4.3</span>）中的<span class="s72"></span><span class="s36">k</span>与 <span class="s38"> </span><span class="s143">d </span>值相等。在这一节的其余部分我们将使用<span class="s72"></span><span class="s36">i</span>来表</p><p class="s38" style="padding-left: 60pt;text-indent: 0pt;line-height: 14pt;text-align: center;"><span class="s30">net</span><span class="s52">k</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 10pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">示任意单元<span class="s21">i</span>的 <span class="s38"></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="35" height="1" alt="image" src="机器学习/Image_114.png"/></span></p><p class="s38" style="padding-top: 2pt;padding-left: 3pt;text-indent: 0pt;line-height: 19pt;text-align: left;"><span class="s30">E</span><span class="s52">d</span><span class="s41"> </span><span class="s151">。</span></p><p class="s38" style="padding-left: 1pt;text-indent: 0pt;line-height: 14pt;text-align: left;"><span class="s30">net</span><span class="s52">i</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 7pt;padding-left: 5pt;text-indent: 21pt;text-align: justify;">情况 <span class="h4">2</span>：隐藏单元的权值训练法则。对于网络中的内部单元或者说隐藏单元的情况，推 导<span class="s21">w</span><span class="s36">ji</span>必须考虑<span class="s21">w</span><span class="s36">ji</span>间接地影响网络输出，从而影响<span class="s21">E</span><span class="s36">d</span>。由于这个原因，我们发现定义网络中单 元<span class="s21">j</span>的所有立即下游（<span class="s6">immediately downstream</span>）单元的集合（也就是立即输入中包含单元<span class="s21">j </span>的输出的所有单元）是有用的。我们用<span class="s21">DownStream</span><span class="s6">(</span><span class="s21">j</span><span class="s6">)</span>表示这样的单元集合。注意<span class="s21">net</span><span class="s36">j</span>只能通 过<span class="s21">Downstream</span><span class="s6">(</span><span class="s21">j</span><span class="s6">)</span>中的单元影响网络输出（再影响<span class="s21">E</span><span class="s36">d</span>）。所以可以如下推导</p><p style="text-indent: 0pt;text-align: left;"><span><img width="37" height="1" alt="image" src="机器学习/Image_115.png"/></span></p><p class="s38" style="padding-top: 1pt;padding-left: 136pt;text-indent: 0pt;line-height: 20pt;text-align: left;"><span class="s30">E</span><span class="s52">d </span><span class="s152"></span> <span class="s153"></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="77" height="1" alt="image" src="机器学习/Image_116.png"/></span></p><p class="s38" style="padding-top: 1pt;padding-left: 24pt;text-indent: 0pt;text-align: left;"><span class="s30">E</span><span class="s52">d</span></p><p class="s38" style="padding-top: 1pt;padding-left: 7pt;text-indent: 0pt;text-align: left;"><span class="s30">net</span><span class="s52">k</span></p><p class="s38" style="text-indent: 0pt;line-height: 14pt;text-align: right;"><span class="s30">net </span><span class="s52">j</span></p><p class="s41" style="padding-left: 13pt;text-indent: 0pt;line-height: 14pt;text-align: left;"><span class="s122">k</span><span class="s40"></span>DownStream<span class="s42">( </span>j <span class="s42">) </span><span class="s118"></span><span class="s30">net </span>j</p><p class="s38" style="padding-left: 3pt;text-indent: 0pt;line-height: 14pt;text-align: left;"><span class="s30">net </span><span class="s52">j</span></p><p class="s38" style="padding-top: 8pt;text-indent: 0pt;line-height: 21pt;text-align: right;"> <span class="s39"></span></p><p class="s41" style="text-indent: 0pt;line-height: 7pt;text-align: right;">k<span class="s40"></span>DownStream<span class="s42">( </span>j <span class="s42">)</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s38" style="text-indent: 0pt;line-height: 21pt;text-align: right;"> <span class="s39"></span></p><p class="s41" style="text-indent: 0pt;line-height: 7pt;text-align: right;">k<span class="s40"></span>DownStream<span class="s42">( </span>j <span class="s42">)</span></p></li><li style="padding-top: 10pt;padding-left: 8pt;text-indent: -8pt;text-align: left;"><p class="s119" style="display: inline;"> <span class="s52">k</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li style="padding-left: 8pt;text-indent: -8pt;text-align: left;"><p class="s119" style="display: inline;"> <span class="s52">k</span></p><p class="s38" style="padding-top: 3pt;padding-left: 2pt;text-indent: 0pt;text-align: left;"><span class="s30">net</span><span class="s52">k</span></p><p style="padding-left: 1pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="38" height="1" alt="image" src="机器学习/Image_117.png"/></span></p><p class="s38" style="padding-left: 2pt;text-indent: 0pt;text-align: left;"><span class="s30">net </span><span class="s52">j</span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="77" height="1" alt="image" src="机器学习/Image_118.png"/></span></p><p class="s38" style="padding-top: 4pt;padding-left: 2pt;text-indent: 0pt;text-align: left;"><span class="s30">net</span><span class="s52">k</span></p><p class="s38" style="padding-left: 7pt;text-indent: 0pt;text-align: left;"><span class="s30">o </span><span class="s52">j</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s38" style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><span class="s30">o </span><span class="s52">j</span></p><p class="s38" style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><span class="s30">net </span><span class="s52">j</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s12" style="text-indent: 0pt;text-align: center;">(4.28)</p><p class="s38" style="padding-top: 9pt;text-indent: 0pt;line-height: 21pt;text-align: right;"> <span class="s39"></span></p><p class="s41" style="text-indent: 0pt;line-height: 7pt;text-align: right;">k<span class="s40"></span>DownStream<span class="s42">( </span>j <span class="s42">)</span></p></li><li style="padding-top: 11pt;padding-left: 8pt;text-indent: -8pt;text-align: left;"><p class="s41" style="display: inline;"><span class="s154"></span><span class="s119"> </span>k <span class="s49">w</span>kj</p><p class="s38" style="padding-top: 3pt;padding-left: 6pt;text-indent: 0pt;text-align: left;"><span class="s30">o </span><span class="s52">j</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 1pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="38" height="1" alt="image" src="机器学习/Image_119.png"/></span></p><p class="s38" style="padding-left: 2pt;text-indent: 0pt;text-align: left;"><span class="s30">net </span><span class="s52">j</span></p><p class="s38" style="padding-top: 1pt;text-indent: 0pt;line-height: 21pt;text-align: right;"> <span class="s39"></span></p><p class="s41" style="text-indent: 0pt;line-height: 7pt;text-align: right;">k<span class="s40"></span>DownStream<span class="s42">( </span>j <span class="s42">)</span></p></li><li style="padding-top: 3pt;padding-left: 8pt;text-indent: -8pt;text-align: left;"><p class="s52" style="display: inline;"><span class="s119"> </span>k<span class="s41"> </span><span class="s30">w</span>kj<span class="s41"> </span><span class="s30">o </span>j<span class="s41"> </span><span class="s33">(1 </span><span class="s38"> </span><span class="s30">o </span>j<span class="s41"> </span><span class="s33">)</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s38" style="padding-top: 2pt;padding-left: 24pt;text-indent: 0pt;line-height: 11pt;text-align: center;"><span class="s30">E</span></p><p style="padding-left: 27pt;text-indent: 0pt;line-height: 9pt;text-align: left;">重新组织各项并使用<span class="s72"></span><span class="s36">j</span>表示 <span class="s38"> </span><span class="s143">d </span>，我们得到</p><p class="s38" style="text-indent: 0pt;line-height: 14pt;text-align: center;"><span class="s30">net </span><span class="s52">j</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s52" style="padding-top: 4pt;text-indent: 0pt;text-align: right;"><span class="s119"> </span>j<span class="s41"> </span><span class="s38"> </span><span class="s30">o </span>j<span class="s41"> </span><span class="s33">(1 </span><span class="s38"> </span><span class="s30">o </span>j<span class="s41"> </span><span class="s33">)</span></p><p class="s41" style="padding-top: 2pt;padding-left: 18pt;text-indent: 0pt;line-height: 21pt;text-align: left;"><span class="s121"></span><span class="s154"></span><span class="s119"> </span>k <span class="s49">w</span>kj</p><p class="s41" style="text-indent: 0pt;line-height: 7pt;text-align: left;">k<span class="s40"></span>Downstream<span class="s42">( </span>j <span class="s42">)</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">和</p><p class="s113" style="padding-top: 8pt;padding-left: 24pt;text-indent: 0pt;text-align: center;"><span class="s74">w</span><span class="s76">ji </span><span class="s74">= </span> <span class="s76">j</span><span class="s129"> </span><span class="s74">x</span><span class="s76">ji</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;"><span class="p">上式就是由公式（</span>4.20<span class="p">）得到的一般法则，用来更新任意有向无环网络结构内部单元的 权值。注意表 </span>4-2 <span class="p">的式（</span>T4.4<span class="p">）仅是这个法则当 </span><i>Downstream</i>(<i>j</i>)=<i>outputs </i><span class="p">时的一个特例。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-top: 7pt;padding-left: 34pt;text-indent: 0pt;text-align: left;">4.6 <span class="s17">反向传播算法的说明</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-top: 11pt;padding-left: 30pt;text-indent: 0pt;text-align: left;">4.6.1 <span class="s25">收敛性和局部极小值</span></h3><p style="padding-top: 10pt;padding-left: 6pt;text-indent: 21pt;line-height: 112%;text-align: left;">正如前面所描述的，反向传播算法实现了一种对可能的网络权值空间的梯度下降搜索， 它迭代地减小训练样例的目标值和网络输出间的误差。因为对于多层网络，误差曲面可能含 有多个不同的局部极小值，梯度下降可能陷入这些局部极小值中的一个。因此，对于多层网 络，反向传播算法仅能保证收敛到误差 <span class="s21">E </span>的某个局部极小值，不一定收敛到全局的最小误 差。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 113%;text-align: justify;">尽管缺乏对收敛到全局最小误差的保证，反向传播算法在实践中是非常有效的函数逼近 算法。对于很多实际的应用，人们发现局部极小值的问题没有想象的那么严重。为了对这个 问题有一些直观的认识，考虑含有大量权值的网络，它对应着维数非常高的空间中的误差曲 面（每个权值一维）。当梯度下降陷入相对某个权的局部极小值时，相对其他的权这里未必 是局部极小值。事实上，网络的权越多，误差曲面的维数越多，也就越可能为梯度下降提供 更多的“逃逸路线”，让梯度下降离开相对该单个权值的局部极小值处。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 110%;text-align: justify;">对局部极小值的第二种观点是，考虑随着训练中迭代次数的增加网络权值的演化方式。 注意在算法中，如果把网络的权值初始化为接近于 <span class="s6">0 </span>的值，那么在早期的梯度下降步骤中， 网络将表现为一个非常平滑的函数，近似为输入的线性函数。这是因为 <span class="s6">sigmoid </span>函数本身在</p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 111%;text-align: justify;">权值靠近 <span class="s6">0 </span>时接近线性（见图 <span class="s6">4-6 </span>中的 <span class="s6">sigmoid </span>函数曲线）。仅当权值已经增长了一定时间 之后，它们才会到达可以表示高度非线性网络函数的程度。或许可以期待在权空间的这个区 域存在更多的局部极小值，这样可以表示更复杂的函数。也可希望当权到达这一点时它们已 经足够靠近全局最小值，即便它是这个区域的局部极小值也是可以接受的。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 110%;text-align: justify;">尽管有上面的评论，人们对用 <span class="s6">ANN </span>表示的复杂误差曲面的梯度下降理解得还不够，还 不知道有何方法能确切地预测局部极小值什么时候会导致困难。用来缓解局部极小值问题的 一些常见的启发式规则包括：</p><p style="padding-top: 5pt;padding-left: 66pt;text-indent: -21pt;line-height: 110%;text-align: justify;"><span class="s10"> </span>象公式（<span class="s6">4.18</span>）描述的那样为梯度更新法则加一个冲量项。冲量有时可以带 动梯度下降过程，冲过狭窄的局部最下值（然而原则上它也可以带动梯度下 降过程冲过狭窄的全局最小值到其他局部极小值！）。</p><p style="padding-left: 66pt;text-indent: -21pt;line-height: 111%;text-align: justify;"><span class="s10"> </span>使用随机的梯度下降而不是真正的梯度下降。根据 <span class="s6">4.4.3.3 </span>小节讨论的，梯度 下降的随机近似对于每个训练样例沿一个不同的误差曲面有效下降，它依靠 这些梯度的平均来逼近对于整个训练集合的梯度。这些不同的误差曲面通常 有不同的局部极小值，这使得下降过程不太可能陷入任一个局部极小值。</p><p class="s10" style="padding-left: 66pt;text-indent: -21pt;line-height: 111%;text-align: justify;"> <span class="p">使用同样的数据训练多个网络，但用不同的随机权值初始化每个网络。如果 不同的训练过程产生不同的局部极小值，那么对分离的验证集合性能最好的 网络被选择。或者保留所有的网络，并且把它们当作一个网络“委员会”， 它们的输出是每个网络输出的平均值（可能加权）。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 30pt;text-indent: 0pt;text-align: left;">4.6.2 <span class="s25">前馈网络的表征能力</span></h3><p style="padding-top: 10pt;padding-left: 6pt;text-indent: 21pt;line-height: 113%;text-align: justify;">什么类型的函数可以使用前馈网络来表示呢？当然这个问题的答案依赖于网络的宽度 和深度。尽管目前对哪一族函数可以用哪种类型的网络描述还知道得很少，但已经知道了三 个一般性的结论：</p><p class="s10" style="padding-top: 5pt;padding-left: 66pt;text-indent: -21pt;line-height: 112%;text-align: justify;"> <span class="p">布尔函数。任何布尔函数可以被具有两层单元的网络准确表示，尽管对于最 坏的情况，所需隐藏单元的数量随着网络输入数量的增加指数级增长。为了 说明这是如何实现的，考虑下面表示任何布尔函数的通用方案：对于每一个 可能的输入向量，创建不同的隐藏单元，并设置它的权值使当且仅当这个特 定的向量输入到网络时该单元被激活。这样就产生了一个对于任何输入仅有 一个单元被激活的隐藏层。接下来把输出单元实现为一个或门，仅由所希望 的输入模式激活。</span></p><p style="padding-left: 66pt;text-indent: -21pt;line-height: 107%;text-align: justify;"><span class="s10"> </span>连续函数。任何有界的连续函数可以由一个两层的网络以任意小的误差（在 有限的范数下）逼近（<span class="s6">Cybenko 1989</span>；<span class="s6">Hornik et al. 1989</span>）。这个理论适用于 隐藏层使用 <span class="s6">sigmoid </span>单元、输出层使用（非阈值的）线性单元的网络。所需 的隐藏单元数量依赖于要逼近的函数。</p><p style="padding-top: 1pt;padding-left: 66pt;text-indent: -21pt;line-height: 110%;text-align: left;"><span class="s10"> </span>任意函数。任意函数可以被一个有三层单元的网络以任意精度逼近（<span class="s6">Cybenko 1988</span>）。与前面相同，输出层使用线性单元，两个隐藏层使用 <span class="s6">sigmoid </span>单元， 每一层所需的单元数量一般不确定。这一结论的证明方法为：首先说明任何 函数可以被许多局部化函数的线性组合逼近，这些局部函数的值除了某个小 范围外都为 <span class="s6">0</span>；然后说明两层的 <span class="s6">sigmoid </span>单元足以产生良好的局部逼近。</p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 21pt;line-height: 113%;text-align: justify;">这些结论表明有限深度的前馈网络为反向传播算法提供了非常有表征力的假设空间。然 而记住下面一点是重要的：梯度下降是从一个初始的权值开始的，因此搜索范围里的网络权 向量可能不包含所有的权向量。<span class="s6">Hertz et al.</span>（<span class="s6">1991</span>）提供了上面结论的更详细的讨论。</p><h3 style="padding-left: 27pt;text-indent: 3pt;text-align: left;">4.6.3 <span class="s25">假设空间搜索和归纳偏置</span></h3><p style="padding-top: 10pt;padding-left: 6pt;text-indent: 21pt;line-height: 111%;text-align: justify;">把反向传播算法的假设空间搜索和其他学习算法采取的搜索相比较很有意义。对于反向 传播算法，网络权的每一种可能赋值都表示了一个句法不同的假设，原则上都在学习器的考 虑范围内。换句话说，这个假设空间是 <span class="s21">n </span>个网络权值的 <span class="s21">n </span>维欧氏空间。注意这个空间是连续 的，这与决策树学习和其他基于离散表示的方法的假设空间完全不同。假设空间的连续性以 及误差 <span class="s21">E </span>关于假设的连续参数可微这两个事实，导致了一个良定义的误差梯度，为最佳假 设的搜索提供了一个非常有用的结构。这个结构与基于符号的概念学习算法的“一般到特殊 序”搜索的结构，或 <span class="s6">ID3 </span>和 <span class="s6">C4.5 </span>算法中对决策树的简单到复杂序搜索所用的结构都完全不 同。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 110%;text-align: justify;">反向传播算法从观测数据中泛化的归纳偏置是什么呢？精确地刻画反向传播学习的归 纳偏置是有难度的，因为它依赖于梯度下降搜索和权空间覆盖可表征函数空间的方式的相互 作用性。然而，可以把这一偏置粗略地刻画为在数据点之间平滑插值（<span class="s6">smooth interpolation between data points</span>）。如果给定两个正例，它们之间没有反例，反向传播算法会倾向于把这 两点之间的点也标记为正例。例如，在图 <span class="s6">4-5 </span>画出的决策面中可以看到这一点，训练样例的 特定样本产生了平滑变化的决策区域。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 30pt;text-indent: 0pt;text-align: left;">4.6.4 <span class="s25">隐藏层表示</span></h3><p style="padding-top: 10pt;padding-left: 6pt;text-indent: 21pt;line-height: 112%;text-align: left;">反向传播算法的一个迷人的特性是，它能够在网络内部的隐藏层发现有用的中间表示。 因为训练样例仅包含网络输入和输出，权值调节的过程可以自由地设置权值，来定义在最小 化误差平方 <span class="s21">E </span>中最有效的任何隐藏单元表示。这能够引导反向传播算法定义新的隐藏层特 征，这些特征在输入中没有明确表示出来，但却能捕捉输入实例中与学习目标函数最相关的 特征。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 20pt;line-height: 109%;text-align: justify;">例如，考虑图 <span class="s6">4-7 </span>所示的网络。这里，<span class="s6">8 </span>个网络输入与 <span class="s6">3 </span>个隐藏单元相连，<span class="s6">3 </span>个隐藏单 元又依次连接到 <span class="s6">8 </span>个输出单元。由于这样的结构，<span class="s6">3 </span>个隐藏单元必须重新表示 <span class="s6">8 </span>个输入值， 以某种方式捕捉输入的相关特征，以便这个隐藏层的表示可以被输出单元用来计算正确的目 标值。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 13pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="547" height="1" alt="image" src="机器学习/Image_120.png"/></span></p><p class="s48" style="padding-left: 5pt;text-indent: 0pt;text-align: center;">插图——原书页码： <span class="s21">107</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;line-height: 190%;text-align: left;">Inputs-<span class="p">输入 </span>Outputs-<span class="p">输出 </span>Input-<span class="p">输入值 </span>Output-<span class="p">输出值</span></p><p class="s6" style="padding-top: 2pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">Hidden Values-<span class="p">隐藏值</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 14pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="531" height="1" alt="image" src="机器学习/Image_121.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 24pt;text-indent: 0pt;text-align: center;">图 <span class="h4">4-7 </span>学习到的隐藏层表示</p><p class="s16" style="padding-top: 1pt;padding-left: 37pt;text-indent: 0pt;line-height: 125%;text-align: justify;"><span class="s14">这个 </span>8<span class="s57"></span>3<span class="s57"></span>8 <span class="s14">的网络被训练以学习恒等函数，使用图中所示的 </span>8 <span class="s14">个训练样例。在 </span>5000 <span class="s14">轮（</span>epochs<span class="s14">） 训练之后，</span>3 <span class="s14">个隐藏单元使用图右侧的编码方式来编码 </span>8 <span class="s14">个相互不同的输入。注意如果把编码后的 值四舍五入为 </span>0 <span class="s14">和 </span>1<span class="s14">，那么结果是 </span>8 <span class="s14">个不同值的标准二进值编码。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;text-align: justify;">考虑训练图 <span class="s6">4-7 </span>所示的网络，来学习简单的目标函数 <span class="s21">f</span><span class="s6">( </span><span class="s30">x </span><span class="s6">)= </span><span class="s30">x </span>，其中 <span class="s30">x </span>是含有七个 <span class="s6">0 </span>和 一个 <span class="s6">1 </span>的向量。网络必须学会在 <span class="s6">8 </span>个输出单元重现这 <span class="s6">8 </span>个输入。尽管这是一个简单的函数，</p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 107%;text-align: justify;">但现在限制网络只能使用 <span class="s6">3 </span>个隐单元。所以，学习到的 <span class="s6">3 </span>个隐藏单元必须捕捉住来自 <span class="s6">8 </span>个输 入单元的所有关键信息。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 109%;text-align: justify;">当反向传播算法被用来完成这个任务时，使用 <span class="s6">8 </span>个可能向量作为训练样例，它成功地学 会了目标函数。梯度下降的反向传播算法产生的隐藏层表示是什么呢？通过分析学习到的网 络对于 <span class="s6">8 </span>个可能输入向量产生的隐藏单元的值，可以看出学到的编码和熟知的对 <span class="s6">8 </span>个值使用 <span class="s6">3 </span>位标准二进制编码相同（也就是 <span class="s6">000</span>，<span class="s6">001</span>，<span class="s6">010</span>， ，<span class="s6">111</span>）。图 <span class="s6">4-7 </span>显示了反向传播算</p><p style="padding-left: 27pt;text-indent: -21pt;text-align: left;">法的一次运行中计算出的这 <span class="s6">3 </span>个隐藏单元的确切值。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 110%;text-align: justify;">多层网络在隐藏层自动发现有用表示的能力是 <span class="s6">ANN </span>学习的一个关键特性。与那些仅限 于使用人类设计者提供的预定义特征的学习方法相比，它提供了一种相当重要的灵活性—— 允许学习器创造出设计者没有明确引入的特征。当然这些创造出的特征一定是网络输入的 <span class="s6">sigmoid </span>单元函数可以计算出的。注意网络中使用的单元层越多，就可以创造出越复杂的特 征。<span class="s6">4.7 </span>节要讨论的人脸识别应用提供了隐藏单元特征的另一个例子。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 110%;text-align: justify;">为了增强对这个例子中反向传播算法操作的直观理解，让我们更详细地分析梯度下降过 程中的具体操作<span class="s9">①</span>。使用表 <span class="s6">4-2 </span>中的算法训练图 <span class="s6">4-7 </span>中的网络，设置初始的权值为区间（<span class="s6">-0.1, 0.1</span>）中的随机数，学习速率<span class="s72"></span><span class="s6">=0.3</span>，没有权冲量（即<span class="s72"></span><span class="s6">=0</span>）。使用其他的学习速率和使用非 <span class="s6">0</span></p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 107%;text-align: justify;">的冲量得到的结果相似。图 <span class="s6">4-7 </span>中显示的隐藏单元编码是在执行了算法的外层训练迭代 <span class="s6">5000 </span>次后得到的（也就是对 <span class="s6">8 </span>个训练样例的每一个迭代 <span class="s6">5000 </span>次）。然而吸引我们注意的大多数权 值变化是发生在前 <span class="s6">2500 </span>次的。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 113%;text-align: justify;">我们可以描绘出输出误差的平方相对梯度下降搜索步数的函数曲线，这样就可以直接观 察反向传播算法的梯度下降搜索的效果。它显示在图 <span class="s6">4-8 </span>中最上面的曲线图中。这幅图的 <span class="s6">8</span></p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 110%;text-align: justify;">条曲线对应 <span class="s6">8 </span>个网络输出，每一条曲线都显示了相应的网络输出对所有训练样例的误差平方 和。横轴表示反向传播算法的最外层迭代的次数。如图中所显示的，每个输出的误差平方和 随着梯度下降过程而下降，某些单元快一些，某些单元较慢。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 107%;text-align: justify;">隐藏单元表示的演变过程可以在图 <span class="s6">4-8 </span>的第二幅图中看到。这幅图显示了对于一个可能 的输入（这幅图对应的是 <span class="s6">01000000</span>）网络计算出的三个隐藏单元值。和前面一样，横轴表 示训练循环的次数。如图中所显示的，这个网络收敛到图 <span class="s6">4-7 </span>中给出的最终的编码之前经历 了很多不同的编码。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 20pt;line-height: 107%;text-align: left;">最后，图 <span class="s6">4-8 </span>中的第 <span class="s6">3 </span>幅图画出了网络中各个权值的演变过程。这幅图显示了连接 <span class="s6">8 </span>个 输入单元（和一个常量偏置输入（<span class="s6">constant bias input</span>））到 <span class="s6">3 </span>个隐单元之一的权值的演变过程。 注意这个隐藏单元权值的显著变化与隐藏层编码和输出误差平方的显著变化一致。这里收敛</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 26pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="193" height="1" alt="image" src="机器学习/Image_122.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s13" style="padding-top: 2pt;padding-left: 7pt;text-indent: 0pt;text-align: left;">①<span class="s155"> </span><a href="http://www.cs.cmu.edu/%7Etom/mlbook.html%E5%BE%97%E5%88%B0" class="s156" target="_blank">这个例子的源代码可以从</a><a href="http://www.cs.cmu.edu/%7Etom/mlbook.html%E5%BE%97%E5%88%B0" class="s87" target="_blank">http://www.cs.cmu.edu/~tom/mlbook.html</a><a href="http://www.cs.cmu.edu/%7Etom/mlbook.html%E5%BE%97%E5%88%B0" class="s156" target="_blank">得到。</a></p><p style="padding-left: 2pt;text-indent: 0pt;text-align: center;">接近 <span class="s6">0 </span>的权值是偏置权<span class="s21">w</span><span class="s35">0</span>。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 13pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="547" height="1" alt="image" src="机器学习/Image_123.png"/></span></p><p class="s48" style="padding-left: 5pt;text-indent: 0pt;text-align: center;">插图——原书页码： <span class="s21">109</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-top: 1pt;padding-left: 26pt;text-indent: 0pt;line-height: 190%;text-align: left;">Sum of squared errors for each output unit-<span class="p">每个输出单元的误差平方和 </span>Hidden unit encoding for input 01000000-<span class="p">输入 </span>01000000 <span class="p">的隐藏单元编码 </span>Weights from inputs to one hidden unit-<span class="p">输入到一个隐藏单元的权</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 14pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="531" height="1" alt="image" src="机器学习/Image_124.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><h4 style="padding-top: 1pt;padding-left: 37pt;text-indent: 133pt;text-align: left;"><span class="p">图 </span>4-8 <span class="p">学习 </span>8<span class="s10"></span>3<span class="s10"></span>8 <span class="p">网络</span></h4><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-left: 37pt;text-indent: 0pt;line-height: 125%;text-align: left;">最上图显示了随着训练迭代次数（轮数）的增加，<span class="s16">8 </span>个输入的误差平方和的演变。中图显示了对于 输入串“<span class="s16">01000000</span>”的隐藏层表示的演变。下图显示了 <span class="s16">3 </span>个隐藏单元之一的权值演变过程。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 30pt;text-indent: 0pt;text-align: left;">4.6.5 <span class="s25">泛化，过度拟合和停止判据</span></h3><p style="padding-top: 10pt;padding-left: 5pt;text-indent: 21pt;line-height: 109%;text-align: justify;">在表 <span class="s6">4-2 </span>对反向传播算法的描述中，没有指定算法使用的终止条件。终止权值更新循环 的合适条件是什么呢？很明显，一种选择是继续训练直到对训练样例的误差 <span class="s21">E </span>降低至某个 预先定义的阈值之下。事实上，这不是一个好的策略，因为反向传播算法容易过度拟合训练 样例，降低了对于其他未见过实例的泛化精度。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">为了看出使训练数据上误差最小化的危险，考虑误差 <span class="s21">E </span>是如何随着权值迭代次数变化 的。图 <span class="s6">4-9 </span>显示了两个相当典型的反向传播算法应用中的这种变化。首先考虑图中上面一幅 曲线图。两条曲线中较低的一条显示了在训练集合上的误差 <span class="s21">E </span>随着梯度下降迭代次数的增 加而单调下降。较高的曲线是在一个与训练样例不同的验证集合的实例上测到的误差 <span class="s21">E </span>的 情况。这条线测量了网络的泛化精度（<span class="s6">generalization accuracy</span>）——网络拟合训练数据外的 实例的精度。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 107%;text-align: left;">注意在验证样例上测量到的的误差<span class="s21">E</span><span class="s9">①</span>先下降，然后上升，尽管在训练样例上的误差持 续下降。为什么会发生这种现象呢？这是因为这些权值拟合了训练样例的“特异性”</p><p style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;line-height: 107%;text-align: left;">（<span class="s6">idiosyncrasy</span>），而这个“特异性”对于样例的一般分布没有代表性。<span class="s6">ANN</span>中大量的权值参 数为拟合这样的“特异性”提供了很大的自由度。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 113%;text-align: left;">为什么过度拟合往往是发生在迭代的后期，而不是迭代的早期呢？设想网络的权值是被 初始化为小随机值的。使用这些几乎一样的权值仅能描述非常平滑的决策面。随着训练的进 行，一些权值开始增长，以降低在训练数据上的误差，同时学习到的决策面的复杂度也在提 高。于是，随着权值调整迭代次数的增加，反向传播算法获得的假设的有效复杂度也在增加。 如果权值调整迭代次数足够多，反向传播算法经常会产生过度复杂的决策面，拟合了训练数 据中的噪声和训练样例中没有代表性的特征。这个过度拟合问题与决策树学习中的过度拟合</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 26pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="193" height="1" alt="image" src="机器学习/Image_125.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-top: 2pt;padding-left: 6pt;text-indent: 1pt;line-height: 125%;text-align: left;"><span class="s13">① </span>译注：原书此处有误，原句为<span class="s56">generalization accuracy</span>先下降后上升，显然这里的<span class="s16">generalization accuracy</span>应 为<span class="s16">error E</span>）。</p><p style="padding-left: 27pt;text-indent: -21pt;text-align: left;">问题相似（见第 <span class="s6">3 </span>章）。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 27pt;text-indent: 0pt;text-align: left;">有几种技术可以用于解决反向传播中的过度拟合问题。一种方法被称为权值衰减</p><p style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;line-height: 110%;text-align: left;">（<span class="s6">weight decay</span>），它在每次迭代过程中以某个小因子降低每个权值。这等效于修改 <span class="s21">E </span>的定义， 加入一个与网络权值的总量相应的惩罚项。此方法的动机在于保持权值较小，从而使学习过 程向着复杂决策面的反方向偏置。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 27pt;text-indent: 0pt;text-align: left;">克服过度拟合问题的一个最成功的方法，就是在训练数据外再为算法提供一套验证数据</p><p style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;line-height: 111%;text-align: left;">（<span class="s6">validation data</span>）。算法在使用训练集合驱动梯度下降搜索的同时，监视对于这个验证集合 的误差。本质上，这相当于允许算法本身画出图 <span class="s6">4-9 </span>中显示的两条曲线。算法应该进行多少 次权值调整迭代呢？显然，应该使用在验证集合上产生最小误差的迭代次数，因为这是网络 性能对于未见过实例的最好表征。在这种方法的典型实现中，网络的权值被保留两份拷贝： 一份用来训练，而另一份拷贝作为目前为止性能最好的权，衡量的标准是它们对于验证集合 的误差。一旦训练到的权值在验证集合上的误差比保存的权值的误差高，训练被终止，并且 返回保存的权值作为最终的假设。当这个过程被应用到图 <span class="s6">4-9 </span>中最上图的情况时，它将输出</p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 110%;text-align: justify;">在 <span class="s6">9100 </span>次迭代后网络得到的权值。图 <span class="s6">4-9 </span>的第二幅曲线图显示，不是总能明显确定验证集 合何时达到最小误差。在这幅图中，验证集合的误差先下降，然后上升，然后再下降。所以 必须注意避免错误的结论：在 <span class="s6">850 </span>次迭代后网络到达了它的最小验证集合误差。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 13pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="547" height="1" alt="image" src="机器学习/Image_126.png"/></span></p><p class="s48" style="padding-left: 15pt;text-indent: 0pt;text-align: left;">插图——原书页码： <span class="s21">110</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;line-height: 190%;text-align: left;">Error versus weight updates(example 1)-<span class="p">误差相对权值更新次数变化曲线（例 </span>1<span class="p">） </span>Error versus weight updates(example 2)- <span class="p">误差相对权值更新次数变化曲线（例 </span>2<span class="p">） </span>Error-<span class="p">误差</span></p><p class="s6" style="padding-top: 2pt;padding-left: 27pt;text-indent: 0pt;line-height: 190%;text-align: left;">Number of weight updates-<span class="p">权值更新次数 </span>Training set error-<span class="p">训练集合的误差 </span>Validation set error-<span class="p">验证集合的误差</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 14pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="531" height="1" alt="image" src="机器学习/Image_127.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 37pt;text-indent: 22pt;text-align: left;">图 <span class="h4">4-9 </span>两个不同机器人感知任务的误差 <span class="s7">E </span>相对权值更新次数的变化曲线</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-left: 37pt;text-indent: 0pt;line-height: 128%;text-align: justify;">两种情况下，在训练样例上的误差 <span class="s56">E </span>都单调下降，因为梯度下降的目标是最小化这个误差。对于单 独的验证集合中的样例，误差 <span class="s56">E </span>通常先下降，然后误差可能因为过度拟合训练样例而上升。最有可 能正确泛化到未见过数据的网络是对于验证集合有最小误差的网络。注意在第二幅曲线图中，必须 小心不要过早停止训练，因为在验证集合上的误差 <span class="s56">E </span>在迭代到 <span class="s16">850 </span>次时开始上升而后又下降。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 110%;text-align: justify;">一般而言，过度拟合问题以及克服它的方法是一个棘手的问题。上面的交叉验证方法在 可获得额外的数据提供验证集合时工作得最好。然而不幸的是，过度拟合的问题对小训练集 合最严重。在这种情况下，有时使用一种称为“<span class="s21">k</span><span class="s6">-fold</span>交叉验证（<span class="s21">k</span><span class="s6">-fold cross-validation</span>）”的 方法，这种方法进行<span class="s21">k</span>次不同的交叉验证，每次使用数据的不同分割作为训练集合和验证集 合，然后对结果进行平均。在这种方法的一个版本中，把可供使用的<span class="s21">m</span>个实例分割成<span class="s21">k</span>个不</p><p style="text-indent: 0pt;text-align: left;"><span><img width="5" height="1" alt="image" src="机器学习/Image_128.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="5" height="1" alt="image" src="机器学习/Image_129.png"/></span></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: justify;">相交的子集，每个子集有<span class="s21">m</span><span class="s6">/</span><span class="s21">k</span>个实例。然后，运行<span class="s21">k</span>次交叉验证过程，每一次使用不同的子集 作为验证集合，并合并其他的子集作为训练集合。于是，每一个样例会在一次实验中被用作 验证集合的成员，在<span class="s21">k</span><span class="s6">-1 </span>次实验中用作训练集合的成员。在每次试验中，都使用上面讨论的 交叉验证过程，来决定在验证集合上取得最佳性能的迭代次数<span class="s21">i</span>。然后计算这些<span class="s21">i</span>的均值 <span class="s30">i </span>， 最后运行一次反向传播算法，训练所有<span class="s21">m</span>个<span class="s9">①</span>实例并迭代 <span class="s30">i </span>次，此时没有验证集合。这个过程 与第 <span class="s6">5 </span>章描述的基于有限数据比较两种学习方法的过程很相近。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-top: 7pt;padding-left: 34pt;text-indent: 0pt;text-align: left;">4.7 <span class="s17">示例：人脸识别</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 6pt;text-indent: 21pt;line-height: 111%;text-align: justify;"><a href="http://www.cs.cmu.edu//%7Etom/mlbook.html" class="s223" target="_blank">为了说明反向传播算法应用中的一些实际的设计问题，这一节讨论把这个算法应用到人 脸识别的学习任务。这一节用来产生这个例子的所有图像数据和代码都可以从以下网址得 到：</a>http://www.cs.cmu.edu//~tom/mlbook.html<span class="p">，同时还有如何使用这些代码的完整文档。读 者可以自己进行试验。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 30pt;text-indent: 0pt;text-align: left;">4.7.1 <span class="s25">任务</span></h3><p style="padding-top: 10pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">这里的学习任务是分类不同人的不同姿态的摄影图像。我们收集了 <span class="s6">20 </span>个不同的人的摄</p><p style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: justify;">影图像，每个人大约有 <span class="s6">32 </span>张图像，对应这个人不同的表情（快乐，沮丧，愤怒，中性）；他</p><p style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: justify;">们看的不同方向（左，右，正前，上）；和他们是否戴太阳镜。从图 <span class="s6">4-10 </span>的示例图像中可以</p><p class="s6" style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;line-height: 107%;text-align: justify;"><span class="p">看到，人后面的背景、穿的衣服、和人脸在图像中的位置也都有差异。我们共收集了 </span>624 <span class="p">幅灰度图像，每一幅的分辨率为 </span>120<span class="s10"></span>128<span class="p">，图像的每个像素使用 </span>0<span class="p">（黑色）到 </span>255<span class="p">（白色） 的灰度值描述。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 109%;text-align: left;">从这些图像数据中可以学习很多不同的目标函数。例如，我们可以训练一个 <span class="s6">ANN</span>，使 给定一幅图像输入时输出这个人的惟一标识（<span class="s6">identity</span>）、脸的朝向、性别、是否带太阳镜等。 所有这些目标函数可以以很高的精度从这些数据中学习到，鼓励读者们自行试验。在本节后 面的部分，我们考虑一个特定的任务：学习图像中人脸的朝向（左，右，正前，还是上）。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 13pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="547" height="1" alt="image" src="机器学习/Image_130.png"/></span></p><p class="s48" style="padding-left: 15pt;text-indent: 0pt;text-align: left;">插图——原书页码： <span class="s21">113</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">30<span class="s10"></span>32resolution input images- 30<span class="s10"></span>32 <span class="p">分辨率的输入图像</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 27pt;text-indent: 0pt;text-align: left;">Network weights after 1 iteration through each training example- <span class="p">对每个训练样例迭代</span></p><p class="s6" style="padding-top: 1pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">1 <span class="p">次后的网络权值</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 26pt;text-indent: 0pt;text-align: left;">Network weights after 100 iteration through each training example- <span class="p">对每个训练样例迭代</span></p><p class="s6" style="padding-top: 1pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">100 <span class="p">次后的网络权值</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 26pt;text-indent: 0pt;text-align: left;">left: <span class="p">左</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 26pt;text-indent: 0pt;text-align: left;">straight: <span class="p">前</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 26pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="193" height="1" alt="image" src="机器学习/Image_131.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s13" style="padding-top: 2pt;padding-left: 7pt;text-indent: 0pt;text-align: left;">① <span class="s14">译注：原书此处误为</span><span class="s16">n</span></p><p class="s6" style="padding-left: 27pt;text-indent: 0pt;text-align: left;">right: <span class="p">右</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 27pt;text-indent: 0pt;text-align: left;">up: <span class="p">上</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 14pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="531" height="1" alt="image" src="机器学习/Image_132.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 37pt;text-indent: 88pt;text-align: left;">图 <span class="h4">4-10 </span>学习识别人脸朝向的人工神经网络</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s16" style="padding-left: 37pt;text-indent: 0pt;line-height: 125%;text-align: left;"><span class="s14">这里使用人脸的灰度图像（见最上一行）训练一个 </span>960<span class="s57"></span>3<span class="s57"></span>4 <span class="s14">的网络，来预测一个人是在向左、向右、 向前还是向上看。在使用了 </span>260 <span class="s14">幅这样的图像训练后，这个网络对于独立的验证集合达到了 </span>90% <span class="s14">的精度。图中也显示了使用训练样例迭代 </span>1 <span class="s14">次后和迭代 </span>100 <span class="s14">次后的网络权值。每个输出单元（左， 前，右，上）有四个权值，用暗（负）和明（正）的方块显示。最左侧的方块对应权</span><i>w</i><span class="s64">0</span><span class="s14">，它决定单 元的阈值，右面的三个方块对应从三个隐藏单元输入的权。图中也显示了每个像素输入到每个隐藏 单元的权值，被画在对应像素的位置。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 30pt;text-indent: 0pt;text-align: left;">4.7.2 <span class="s25">设计要素</span></h3><p style="padding-top: 10pt;padding-left: 5pt;text-indent: 21pt;line-height: 111%;text-align: justify;">应用反向传播算法到一个给定任务时，必须决定几个设计要素。下面我们归纳出了学习 人脸朝向这个学习任务的一些设计要素。尽管我们没有打算去选择精确的最优设计，但这里 描述的设计对目标函数学习得相当好。在训练了 <span class="s6">260 </span>幅图像样例之后，对于独立测试集合的 精度达到 <span class="s6">90%</span>。相对而言，如果随机猜测四个脸朝向中的一个，只能达到 <span class="s6">25%</span>的正确率。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 6pt;text-indent: 26pt;line-height: 110%;text-align: justify;"><span class="p">输入编码。已经知道 </span>ANN <span class="p">的输入必然是图像的某种表示，那么设计的关键是如何编 码这幅图像。例如我们可以对图像进行预处理，来分解出边缘、亮度一致的区域或其他局部 图像特征，然后把这些特征输入网络。这种设计的一个问题是会导致每幅图像有不同数量的 特征参数（例如边缘的数量），然而 </span>ANN <span class="p">具有固定数量的输入单元。对于这种情况，我们 的设计是把图像编码成固定的 </span>30<span class="s10"></span>32 <span class="p">像素的亮度值，每个像素对应一个网络输入。并且把范 围是 </span>0 <span class="p">到 </span>255 <span class="p">的亮度值按比例线性缩放到 </span>0 <span class="p">到 </span>1 <span class="p">的区间内，以使网络输入与隐单元和输出单 元在同样的区间取值。实际上这里的 </span>30<span class="s10"></span>32 <span class="p">像素图像就是原来 </span>120<span class="s10"></span>128 <span class="p">像素的图像的低分 辨率概括，每个低分辨率像素根据对应的若干高分辨率像素亮度的均值计算得到。使用这样 的低分辨率图像，把输入个数和权值的数量减少到了一个更易于处理的规模，从而降低了运 算要求，但同时也保留了足够的分辨率以正确分类图像。回忆图 </span>4-1 <span class="p">中 </span>ALVINN <span class="p">系统使用 了相似的的分辨率图像作为网络的输入。一个有趣的差别是，在 </span>ALVINN <span class="p">中，每一个低分 辨率像素的亮度等于从高分辨率图像对应的区域中随机取一个像素的亮度，而不是取这个区 域中所有像素亮度的均值。其动机是为了明显地减少从高分辨率图像产生低分辨率图像所需 的运算。这个效率对于 </span>ALVINN <span class="p">系统是特别重要的，因为在自动驾驶车辆的过程中，</span>ALVINN <span class="p">系统的网络必须在每秒钟处理很多幅图像。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 107%;text-align: left;">输出编码。<span class="s6">ANN </span>必须输出四个值中的一个来表示输入图像中人脸的朝向（左，右，上， 前）。注意我们可以使用单一的输出单元来编码这四种情况的分类，例如指定输出值 <span class="s6">0.2</span>，<span class="s6">0.4</span>， <span class="s6">0.6 </span>和 <span class="s6">0.8 </span>来编码这四个可能值。不过这里我们使用 <span class="s6">4 </span>个不同的输出单元，每一个对应四种 可能朝向中的一种，取具有最高值的输出作为网络的预测值。这种方法经常被称为 <span class="s21">n </span>取 <span class="s6">1</span></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: justify;">（<span class="s6">1-of-</span><span class="s21">n</span>）输出编码。选择 <span class="s21">n </span>取 <span class="s6">1 </span>输出编码而不用单个单元有两个动机。第一，这为网络表 示目标函数提供了更大的自由度（即在输出层单元中有 <span class="s21">n </span>倍的可用权值）。第二，在 <span class="s21">n </span>取 <span class="s6">1 </span>编码中，最高值输出和次高值输出间的差异可以作为对网络预测的置信度（不明确的分类可 能导致结果相近或相等）。进一步的设计问题是“这 <span class="s6">4 </span>个输出单元的目标值应该是什么？”</p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 107%;text-align: justify;">一个显而易见的办法是用 <span class="s6">4 </span>个目标值<span class="s6">&lt;1</span>，<span class="s6">0</span>，<span class="s6">0</span>，<span class="s6">0&gt;</span>来编码脸朝向左，<span class="s6">&lt;0</span>，<span class="s6">1</span>，<span class="s6">0</span>，<span class="s6">0&gt;</span>来编码 脸朝向正前，依此类推。我们这里使用 <span class="s6">0.1 </span>和 <span class="s6">0.9</span>，而不是 <span class="s6">0 </span>和 <span class="s6">1</span>，即<span class="s6">&lt;0.9</span>，<span class="s6">0.1</span>，<span class="s6">0.1</span>，<span class="s6">0.1&gt; </span>表示脸朝向左的目标输出向量。避免使用 <span class="s6">0 </span>和 <span class="s6">1 </span>作为目标值的原因是 <span class="s6">sigmoid </span>单元对于有限 权值不能产生这样的输出。如果我们企图训练网络来准确匹配目标值 <span class="s6">0 </span>和 <span class="s6">1</span>，梯度下降将会 迫使权值无界增长。另一方面，值 <span class="s6">0.1 </span>和 <span class="s6">0.9 </span>是 <span class="s6">sigmoid </span>单元在有限权值情况下可以完成的。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 109%;text-align: left;">网络结构图。正如前面所描述的，反向传播算法可以被应用到任何有向无环 <span class="s6">sigmoid </span>单 元的网络。所以，我们面临的另一设计问题是，这个网络包含多少个单元以及如何互连。最 普遍的一种网络结构是分层网络，一层的每个单元向前连接到下一层的每一个单元。目前的 设计选择这样的标准结构，使用两层 <span class="s6">sigmoid </span>单元（一个隐藏层和一个输出层）。使用一或 两层 <span class="s6">sigmoid </span>单元是很普遍的，偶尔使用三层。使用更多的层是不常见的，因为训练时间会 变得很长，而且三层 <span class="s6">sigmoid </span>单元的网络已经能够表示数量相当大的目标函数（见 <span class="s6">4.6.2 </span>节）。 我们已经确定选择一个分层的前馈网络，那么其中应该包含多少个隐藏单元呢？在图 <span class="s6">4-10</span></p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 110%;text-align: justify;">报告的结果中，仅使用了三个隐藏单元，达到了对测试集合 <span class="s6">90%</span>的精度。在另一个使用 <span class="s6">30 </span>个隐藏单元的实验中，得到的精度提高了一到两个百分点。尽管这两个实验得到的泛化精度 相差很小，但后一个试验明显需要更多的训练时间。使用 <span class="s6">260 </span>幅图像的训练样例，<span class="s6">30 </span>个隐 单元的网络在 <span class="s6">Sun Sparc5 </span>工作站上的训练时间大约是一个小时。相对而言，三个隐藏单元 的网络大约是 <span class="s6">5 </span>分钟。人们已经发现在很多应用中需要某个最小数量的隐单元来精确地学习 目标函数，并且超过这个数量的多余的隐单元不会显著地提高泛化精度，条件是使用交叉验 证方法来决定应该进行多少次梯度下降迭代。如果没有使用交叉验证，那么增加隐藏单元数 量经常会增加过度拟合训练数据的倾向，从而降低泛化精度。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 110%;text-align: justify;">学习算法的其他参数。在这个实验中，学习速率<span class="s10"></span>被设定为 <span class="s6">0.3</span>，冲量<span class="s10"></span>被设定为 <span class="s6">0.3</span>。 赋予这两个参数更低的值会产生大体相当的泛化精度，但需要更长的训练时间。如果这两个 值被设定得太高，训练将不能收敛到一个具有可接受误差（在训练集合上）的网络。在整个 试验中我们使用完全的梯度下降（和表 <span class="s6">4-2 </span>算法中随机近似的梯度下降不同）。输出单元的 网络权值被初始化为小的随机值。然而输入单元的权值被初始化为 <span class="s6">0</span>，因为这样可以使学习 到的权值的图像化（见图 <span class="s6">4-10</span>）更易于理解，而对泛化精度没有明显的影响。训练的迭代 次数的选择可以通过分割可用的数据为训练集合和独立的验证集合。梯度下降方法被用于最 小化训练集合上的误差，并且每隔 <span class="s6">50 </span>次梯度下降迭代根据验证集合评估一次网络的性能。</p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 107%;text-align: justify;">最终选择的网络是对验证集合精度最高的网络。可以参见 <span class="s6">4.6.5 </span>节得到关于这个过程的解释 和依据。最终报告的精度（也就是 <span class="s6">90%</span>，对于图 <span class="s6">4-10 </span>中的网络）是在没有对训练产生任何 影响的第三个集合——测试集合上测量得到的。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 30pt;text-indent: 0pt;text-align: left;">4.7.3 <span class="s25">学习到的隐藏层表示</span></h3><p style="padding-top: 10pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">有必要分析一下网络中学习得到的 <span class="s6">2899 </span>个<span class="s9">①</span>权值。图 <span class="s6">4-10 </span>描绘了对所有训练样例进行</p><p style="padding-top: 1pt;padding-left: 26pt;text-indent: -21pt;text-align: left;">一次权值更新后的每个权值，和 <span class="s6">100 </span>次更新后的权值。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 113%;text-align: left;">为了理解这些图像，先考虑图中紧邻人脸图像下的四个矩形。每一个矩形描绘了网络中 四个输出单元（编码了左、前、右和上）中的一个权值。每个矩形中的四个小方形表示和这</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 26pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="193" height="1" alt="image" src="机器学习/Image_133.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s16" style="padding-top: 2pt;padding-left: 5pt;text-indent: 1pt;line-height: 125%;text-align: left;"><span class="s13">① </span><span class="s14">译注：</span>2899=<span class="s14">输入单元与三个隐单元间连接对应的权（</span>960<span class="s57"></span>3<span class="s14">）</span>+<span class="s14">三个隐单元与四个输出单元间连接对应 的权（</span>3<span class="s57"></span>4<span class="s14">）</span>+<span class="s14">三个隐单元和四个输出单元的</span><i>w</i><span class="s64">0</span><span class="s14">权（</span>3+4<span class="s14">）</span></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 106%;text-align: justify;">个输出单元关联的四个权值——最左边是权<span class="s21">w</span><span class="s35">0</span>，它决定单元的阈值，然后是连接三个隐藏单 元到这个输出的三个权值。方形的亮度表示权值，亮白表示较大的正权值，暗黑表示较大的 负权值，介于中间的灰色阴影表示中等的权值。例如，标为“上”的输出单元的阈值权<span class="s21">w</span><span class="s35">0</span>接 近 <span class="s6">0</span>，从第一个隐藏单元来的权值为较大的正值，从第二个隐藏单元来的权值为较大的负值。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 5pt;text-indent: 21pt;line-height: 108%;text-align: justify;"><span class="p">隐藏单元的权值显示在输出单元的下边。回忆一下，每个隐藏单元接受所有 </span>30<span class="s10"></span>32 <span class="p">个像 素输入。与这些输入关联的 </span>30<span class="s10"></span>32 <span class="p">个权值被显示在它们对应的像素的位置（阈值权</span><i>w</i><span class="s35">0</span><span class="p">被重叠 显示在图像阵列的左上角）。非常有趣的是，可以看到权的取值通常对人脸和身体出现的图 像区域的特别敏感。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 112%;text-align: justify;">针对每一个训练样例梯度下降迭代 <span class="s6">100 </span>次后的网络权值显示在图的下部。注意最左边的 隐藏单元的权值和迭代一次时的权值有很大不同，另两个隐藏单元的权值也有所变化。现在 可以分析一下这个最终权值集合中的编码。例如，考虑输出单元指出一个人是在向右看。这 个单元与第二个隐藏单元间具有一个较大的正权值，与第三个隐单元间具有一个大的负权 值。分析这两个隐单元的权值，容易看到如果一个人的脸是转向他的右面（也就是我们的左 面），那么他的亮度高的皮肤会大致与这个隐藏单元中的较大正值对齐，同时他的亮度低的 头发会大致与负权值对齐，这导致此单元输出一个较大的值。同样的图像会使第三个隐单元 输出一个接近 <span class="s6">0 </span>的值，因为亮度高的脸部倾向于与大的负权对齐。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 34pt;text-indent: 0pt;text-align: left;">4.8 <span class="s17">人工神经网络的高级话题</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-top: 11pt;padding-left: 30pt;text-indent: 0pt;text-align: left;">4.8.1 <span class="s25">其他可选的误差函数</span></h3><p style="padding-top: 10pt;padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">正如前面所指出的，只要函数 <span class="s21">E </span>相对参数化的假设空间可微，那么就可以执行梯度下 降。虽然基本的反向传播算法以网络误差平方和的形式定义 <span class="s21">E</span>，但也有人提出其他的定义， 以便把其他的约束引入权值调整法则。如果定义了一个新的 <span class="s21">E</span>，那么就必须推导出一个新的 权值调整法则供梯度下降使用。<span class="s21">E </span>的其他可选定义包括：</p><p style="padding-top: 5pt;padding-left: 49pt;text-indent: -21pt;line-height: 107%;text-align: justify;"><span class="s10"> </span>为权值增加一个惩罚项。如同前面讨论的，我们可以加入一个随着向量幅度增 长的项到 <span class="s21">E </span>中。这导致梯度下降搜寻较小的权值向量，从而减小过度拟合的风 险。一种办法是按照下面的等式重新定义 <span class="s21">E</span>：</p><p class="s42" style="padding-top: 7pt;padding-left: 137pt;text-indent: 0pt;line-height: 7pt;text-align: left;"><span class="s157">r </span><span class="s92">1 </span>2 2</p><p class="s30" style="padding-left: 122pt;text-indent: 0pt;line-height: 15pt;text-align: left;">E<span class="s33">(</span>w<span class="s33">) </span><span class="s38"> </span><span class="s39"></span><span class="s121"> </span><span class="s121"></span></p><p class="s41" style="text-indent: 0pt;line-height: 10pt;text-align: right;"><span class="s84">2 </span>d<span class="s40"></span>D k<span class="s40"></span>outputs</p><p class="s30" style="text-indent: 0pt;line-height: 16pt;text-align: left;"><span class="s33">(</span>t<span class="s52">kd </span><span class="s38"> </span>o<span class="s52">kd</span><span class="s41"> </span><span class="s33">)</span></p><ul id="l16"><li style="padding-left: 14pt;text-indent: -8pt;line-height: 18pt;text-align: left;"><p class="s119" style="display: inline;"> <span class="s39"></span><span class="s121"> </span><span class="s30">w </span><span class="s52">ji</span></p><p class="s41" style="padding-left: 24pt;text-indent: 0pt;line-height: 7pt;text-align: left;">i<span class="s42">, </span>j</p><p style="padding-top: 7pt;padding-left: 50pt;text-indent: 0pt;line-height: 110%;text-align: left;">这得到了一个与反向传播法则基本一致的权更新法则，只是在每次迭代时为每 个权乘以常量（<span class="s6">1-2</span><span class="s10"></span>）。因此选择这种 <span class="s21">E </span>的定义和使用权衰减策略（见练习 <span class="s6">4.10</span>） 是等价的。</p><p style="padding-left: 49pt;text-indent: -21pt;line-height: 109%;text-align: left;"><span class="s10"> </span>对误差增加一项目标函数的斜率（<span class="s6">slope</span>）或导数。某些情况下，训练信息中不 仅有目标值，而且还有关于目标函数的导数。例如，<span class="s6">Simard et al.</span>（<span class="s6">1992</span>）描述 了一个字符识别的应用，在这个应用中使用了一些训练导数来强迫网络学习那 些在图像平移中不变的字符识别函数。<span class="s6">Mitchell and Thrun</span>（<span class="s6">1993</span>）描述了根据学 习器以前的知识计算训练导数的方法。在这两个系统中（在第 <span class="s6">12 </span>章中描述）， 误差函数都被增加了一项，用来衡量这些训练导数和网络的实际导数间的差异。 这样的误差函数的一个例子是</p><p class="s101" style="padding-top: 7pt;text-indent: 0pt;line-height: 7pt;text-align: right;">r <span class="s33">1</span></p><p class="s150" style="padding-top: 2pt;padding-left: 45pt;text-indent: 0pt;line-height: 12pt;text-align: left;">⎡ <span class="s158">2 </span><span class="s159">⎛</span><span class="s38"> </span><span class="s118"></span><span class="s30">t</span><span class="s143">kd  </span></p><p class="s42" style="text-indent: 0pt;line-height: 7pt;text-align: left;">2</p><p style="text-indent: 0pt;text-align: left;"/><p class="s143" style="padding-top: 2pt;padding-left: 9pt;text-indent: 0pt;line-height: 12pt;text-align: left;"> <span class="s118"></span><span class="s30">o</span>kd <span class="s159">⎞</span><span class="s38"> </span><span class="s150">⎤</span></p><p class="s30" style="text-indent: 0pt;line-height: 12pt;text-align: right;">E<span class="s33">(</span>w<span class="s33">) </span><span class="s38"></span></p><p class="s121" style="padding-left: 1pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><span class="s131">2 </span> </p><p class="s38" style="padding-left: 7pt;text-indent: 0pt;line-height: 12pt;text-align: left;">⎢<span class="s33">(</span><span class="s30">t</span><span class="s52">kd</span></p></li></ul></li><li style="padding-left: 10pt;text-indent: -8pt;line-height: 12pt;text-align: left;"><p class="s30" style="display: inline;">o<span class="s52">kd</span><span class="s41"> </span><span class="s33">)</span></p></li></ul><p class="s38" style="padding-left: 5pt;text-indent: 0pt;line-height: 12pt;text-align: left;"> <span class="s119"> </span><span class="s39"> </span><span class="s94">⎜</span>⎜ <span class="s160">x </span><span class="s69">j</span><span class="s41"> </span></p><p class="s38" style="padding-left: 8pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><span class="s160">x </span><span class="s69">j</span><span class="s41"> </span><span class="s94">⎟</span>⎟ ⎥</p><p class="s41" style="padding-left: 90pt;text-indent: 75pt;line-height: 19pt;text-align: left;">d<span class="s40"></span>D k<span class="s40"></span>outputs <span class="s38">⎢</span><span class="s161">⎣</span></p><p class="s41" style="padding-top: 23pt;text-indent: 0pt;line-height: 2pt;text-align: center;">j</p><p class="s41" style="padding-left: 69pt;text-indent: 0pt;line-height: 16pt;text-align: center;">j<span class="s40"></span>inputs <span class="s134">⎝ </span><span class="s162"></span><span class="s38"> </span><span class="s36">d</span></p><p class="s118" style="padding-top: 9pt;text-indent: 0pt;text-align: right;"><span class="s30">t</span><span class="s41">kd</span></p><p style="padding-left: 85pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="27" height="1" alt="image" src="机器学习/Image_134.png"/></span></p><p class="s41" style="text-indent: 0pt;line-height: 2pt;text-align: right;">j</p><p class="s118" style="padding-left: 14pt;text-indent: 0pt;line-height: 19pt;text-align: left;"> <span class="s41">d </span><span class="s38">⎠ </span><span class="s116">⎥</span><span class="s103">⎦</span></p><p style="padding-left: 49pt;text-indent: 0pt;line-height: 18pt;text-align: left;">这里， <span class="s163">x</span><span class="s164">d</span><span class="s41"> </span>表示对于训练实例<span class="s21">d</span>第<span class="s21">j</span>个输入单元的值。于是 <span class="s165"></span><span class="s30">x</span><span class="s166">d</span></p><p class="s118" style="padding-top: 9pt;text-indent: 0pt;text-align: right;"><span class="s30">o</span><span class="s41">kd</span></p><p style="padding-top: 3pt;padding-left: 4pt;text-indent: 0pt;text-align: left;">是描述目标输出值</p><p style="padding-left: 286pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="31" height="1" alt="image" src="机器学习/Image_135.png"/></span></p><p class="s41" style="padding-left: 153pt;text-indent: 0pt;line-height: 2pt;text-align: left;">j j</p><p style="padding-left: 49pt;text-indent: 0pt;line-height: 19pt;text-align: left;"><span class="s21">t</span><span class="s36">kd</span>应该如何随输入值 <span class="s163">x</span><span class="s164">d </span>变化的训练导数。类似的， <span class="s165"></span><span class="s30">x</span><span class="s166">d</span></p><p style="padding-top: 3pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">表示实际的学习网络</p><p style="padding-top: 3pt;padding-left: 49pt;text-indent: 0pt;text-align: left;">的对应导数。常数<span class="s10"></span>决定匹配训练值对于匹配训练导数的相对权值。</p><p style="padding-top: 1pt;padding-left: 49pt;text-indent: -21pt;line-height: 109%;text-align: left;"><span class="s10"> </span>使网络对目标值的交叉熵（<span class="s6">cross entropy</span>）最小化。考虑学习一个概率函数，比 如预测一个借贷申请者会否还贷，根据是这个申请者的年龄和存款余额。尽管 这里的训练样例仅提供了布尔型的目标值（要么是 <span class="s6">1</span>，要么是 <span class="s6">0</span>，根据这个申请 者是否还贷），但基本的目标函数最好以申请者还贷的概率的形式输出，而不 是对每个输入实例都企图输出明确的 <span class="s6">0 </span>或 <span class="s6">1 </span>值。在这种情况下，我们希望网络 输出一个概率估计，可以证明最小化交叉熵（<span class="s6">cross entropy</span>）的网络可以给出最 好的（也就是最大似然）概率估计，交叉熵的定义如下：</p><ul id="l17"><li style="padding-top: 1pt;padding-left: 148pt;text-indent: -9pt;line-height: 21pt;text-align: left;"><p class="s33" style="display: inline;"><span class="s39"></span><i>t</i><span class="s52">d</span><span class="s41">  </span>log <i>o</i><span class="s52">d</span><span class="s41">   </span><span class="s38"></span> (1 <span class="s38"></span> <i>t</i><span class="s52">d</span><span class="s41"> </span>) log(1 <span class="s38"></span> <i>o</i><span class="s52">d</span><span class="s41"> </span>)</p></li></ul><p class="s41" style="text-indent: 0pt;line-height: 7pt;text-align: center;">d<span class="s40"></span>D</p><p style="padding-top: 2pt;padding-left: 49pt;text-indent: 0pt;line-height: 106%;text-align: left;">这里<span class="s21">o</span><span class="s36">d</span>是网络对于训练样例<span class="s21">d</span>输出的概率估计，<span class="s21">t</span><span class="s36">d</span>是对于训练样例<span class="s21">d</span>的目标值（<span class="s6">0 </span>或 <span class="s6">1</span>）。第 <span class="s6">6 </span>章讨论了何时及为什么最可能的网络假设就是使交叉熵最小化的假 设，并推导了相应的<span class="s6">sigmoid</span>单元的梯度下降权值调整法则。第 <span class="s6">6 </span>章也描述了在 什么条件下最可能的假设就是使误差平方和最小化的假设。</p><p style="padding-top: 1pt;padding-left: 49pt;text-indent: -21pt;line-height: 110%;text-align: left;"><span class="s10"> </span>改变有效误差函数也可以通过权值共享（<span class="s6">weight sharing</span>）完成，也就是把与不 同单元或输入相关联的权“捆绑在一起”。这里的想法是强迫不同的网络权值 取一致的值，通常是为了实施人类设计者事先知道的某个约束。例如，<span class="s6">Waibel et al.</span>（<span class="s6">1989</span>）和 <span class="s6">Lang et al.</span>（<span class="s6">1990</span>）描述了神经网络在语音识别方面的一个应用 ， 其中网络的输入是在一个 <span class="s6">144 </span>毫秒的时间窗中不同时间的语音频率分量。在这 个应用中可以做的一个假定是：一个特定语音（例如“<span class="s6">eee</span>”）的频率分量的识 别是与这个语音在 <span class="s6">144 </span>毫秒时间窗中出现的确切时间无关的。为了实施这个约 束，必须强迫接收这个时间窗不同部分的不同单元共享权值。这样做的效果是 约束了假设的潜在空间，从而减小了过度拟合的风险，提高了准确泛化到未见 过情形的可能性。权值共享通常这样实现：首先在共享权值的每个单元分别更 新各个权值，然后取这些权值的平均，再用这个平均值替换每个需共享的权值。 这个过程的结果是被共享的权值与没有被共享的权值相比使用了不同的误差函 数。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 30pt;text-indent: 0pt;text-align: left;">4.8.2 <span class="s25">其他可选的误差最小化过程</span></h3><p style="padding-top: 10pt;padding-left: 6pt;text-indent: 21pt;line-height: 113%;text-align: justify;">虽然梯度下降是搜寻使误差函数最小化的假设的最通用的搜索方法之一，但它不总是最 高效的。当训练复杂的网络时，不难见到反向传播算法要进行上万次的权值更新迭代。由于 这个原因，人们探索并提出了很多其他的权值优化算法。为了领会其他的可能方法，我们不 妨把权值更新方法就看作是要决定两个问题：选择一个改变当前权值向量的方向；选择要移 动的距离。在反向传播算法中，这个方向是通过取梯度的负值来选择的，距离是通过常量的 学习速率<span class="s72"></span>决定的。</p><p style="padding-left: 6pt;text-indent: 20pt;line-height: 111%;text-align: justify;">一种被称为“线搜索（<span class="s6">line search</span>）”的优化方法，采用了不同的方法选择权值更新的距 离。确切地讲，每当选定了一条确定权值更新方向的路线，那么权更新的距离是通过寻找沿 这条线的误差函数的最小值来选择的。注意这可能导致很大幅度也可能是很小幅度的权值更 新，要看沿这条线的最小误差点的位置。另一种方法，是根据“线搜索”的思想建立的，被 称为共轭梯度（<span class="s6">conjugate gradient</span>）法。这种方法进行一系列线搜索来搜索误差曲面的最小 值。这一系列搜索的第一步仍然使用梯度的反方向作为方向。在后来的每一步，选择使误差 梯度分量刚好为 <span class="s6">0 </span>并保持为 <span class="s6">0 </span>的方向。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 111%;text-align: justify;">虽然其他的误差最小化方法提高了训练网络的效率，但象共轭梯度这样的方法对于最终 网络的泛化误差没有明显的影响。对最终误差惟一可能的影响是，不同的误差最小化过程会 陷入不同的局部极小值。<span class="s6">Bishop</span>（<span class="s6">1996</span>）包含了关于训练网络的几种参数优化方法的一般性 讨论。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 30pt;text-indent: 0pt;text-align: left;">4.8.3 <span class="s25">递归网络（</span>Recurrent Networks<span class="s25">）</span></h3><p class="s6" style="padding-top: 10pt;padding-left: 5pt;text-indent: 21pt;line-height: 109%;text-align: justify;"><span class="p">直到现在我们考虑的只是有向无环的网络拓扑结构。递归网络是有如下特征的人工神经 网络：适用于时序数据；使用网络单元在时间 </span>t <span class="p">的输出作为其他单元在时间 </span><i>t</i>+1 <span class="p">的输入。以 这种方式，递归网络支持在网络中使用某种形式的有向环（</span>directed cycles<span class="p">）。为了演示递归 网络，考虑一个时序预测任务——根据当天的经济指标 </span><i>x</i>(<i>t</i>)<span class="p">，预测下一天的股票平均市值 </span><i>y</i>(<i>t</i>+1)<span class="p">。给定了这样的时序数据，一个显而易见的办法是根据输入值 </span><i>x</i>(<i>t</i>)<span class="p">训练一个前馈网络 预测输出 </span><i>y</i>(<i>t</i>+1)<span class="p">。一个这样的网络显示在图 </span>4-11<span class="p">（</span>a<span class="p">）中。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 5pt;text-indent: 21pt;line-height: 108%;text-align: justify;"><span class="p">这样的网络的缺点是仅依赖 </span>x<span class="s6">(</span>t<span class="s6">)</span><span class="p">作出对 </span>y<span class="s6">(</span>t<span class="s6">+1)</span><span class="p">预测，而不能捕捉 </span>y<span class="s6">(</span>t<span class="s6">+1)</span><span class="p">对 </span>x <span class="p">的以前值的依 赖性。而这可能是必需的，例如，明天的股票平均市值可能依赖于今天的经济指标和昨天的 经济指标的差异。当然我们可以通过把 </span>x<span class="s6">(</span>t<span class="s6">)</span><span class="p">和 </span>x<span class="s6">(</span>t-<span class="s6">1)</span><span class="p">都作为前馈网络的输入，来弥补这个不 足。但是如果我们希望这个网络预测 </span>y<span class="s6">(</span>t<span class="s6">+1)</span><span class="p">时考虑任意过去的时间窗内的信息呢？那么就需 要用不同的解决方案了。图 </span><span class="s6">4-11</span><span class="p">（</span><span class="s6">b</span><span class="p">）显示的递归网络提供了一个这样的解决方案。这里我 们向隐藏层加了一个新的单元 </span>b <span class="p">和新的输入单元 </span>c<span class="s6">(</span>t<span class="s6">)</span><span class="p">。</span>c<span class="s6">(</span>t<span class="s6">)</span><span class="p">的值被定义为单元 </span>b <span class="p">在时间 </span>t<span class="s6">-1 </span><span class="p">的 值；也就是说，网络在某一个时间步（</span><span class="s6">time step</span><span class="p">）的输入值 </span>c<span class="s6">(</span>t<span class="s6">)</span><span class="p">拷贝自单元 </span>b <span class="p">在前一时间步 的值。注意这实现了一种递归关系，其中 </span>b <span class="p">表示关于网络输入的历史信息。因为 </span>b <span class="p">既依赖于 </span>x<span class="s6">(</span>t<span class="s6">)</span><span class="p">又依赖于 </span>c<span class="s6">(</span>t<span class="s6">)</span><span class="p">，所以 </span>b <span class="p">可能概括了 </span>x <span class="p">以前任意时间距离的值。很多其他的网络拓扑也可以 用来表示递归网络。例如，我们可以在输入和单元 </span>b <span class="p">间插入若干层单元，也可以在加入单元 </span>b <span class="p">和输入单元 </span>c <span class="p">的地方再并行插入几个单元。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 13pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="547" height="1" alt="image" src="机器学习/Image_136.png"/></span></p><p class="s48" style="padding-left: 15pt;text-indent: 0pt;text-align: left;">插图——原书页码： <span class="s21">120</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;line-height: 190%;text-align: left;">Feedforward network-<span class="p">前馈网络 </span>Recurrent network-<span class="p">递归网络</span></p><p class="s6" style="padding-top: 2pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">Recurrent network unfolded in time-<span class="p">按时间展开的递归网络</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 14pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="531" height="1" alt="image" src="机器学习/Image_137.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 157pt;text-indent: 0pt;text-align: center;">图 <span class="h4">4-11 </span>递归网络</p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 109%;text-align: justify;">如何训练这样的递归网络呢？递归网络有多种变体，因此人们也分别提出了不同的训练 方法（例如参见<span class="s6">Jordan 1986; Elman 1990; Mozer 1995; Williams &amp; Zipser 1995</span>）。有趣的是， 象图 <span class="s6">4-11</span>（<span class="s6">b</span>）那样的递归网络可以简单使用反向传播算法的变体来训练。为了理解如何实 施，考虑图 <span class="s6">4-11</span>（<span class="s6">c</span>），显示了递归网络按照时间展开的数据流。这里我们把递归网络拷贝成 几份，用不同拷贝间的连接替换掉反馈环。注意这个大的网络不再包含回路。所以展开网络 的权值可以直接使用反向传播算法来训练。当然实践中我们希望仅保留一份递归网络和权值 集合的拷贝。所以，在训练了展开的网络后，可以取不同拷贝中权值<span class="s21">w</span><span class="s36">ji</span>的平均值作为最终网 络的对应的权值<span class="s21">w</span><span class="s36">ji</span>。<span class="s6">Mozer</span>（<span class="s6">1995</span>）非常详细地描述了这个训练过程。实践中，递归网络比 没有反馈环的网络难以训练，泛化的可靠性也不如后者。然而它们仍然因较强的表征力保持 着重要性。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 30pt;text-indent: 0pt;text-align: left;">4.8.4 <span class="s25">动态修改网络结构</span></h3><p style="padding-top: 10pt;padding-left: 6pt;text-indent: 21pt;line-height: 113%;text-align: justify;">直到现在我们考虑的神经网络学习问题是调整一个固定网络结构中的权值。为了改善泛 化精度和训练效率，人们提出了很多动态增长或压缩网络单元和单元间连接数量的方法。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 5pt;text-indent: 21pt;line-height: 112%;text-align: left;"><span class="p">一种想法是从一个不包含隐藏单元的网络开始，然后根据需要增加隐单元增长网络，直 到训练误差下降到某个可接受的水平。级联相关（</span>Cascade-Correlation<span class="p">）算法（</span>Fahlman &amp; Lebiere 1990<span class="p">）就是这样一种算法。级联相关算法从创建一个没有隐单元的网络开始。例如， 对于我们的人脸朝向的学习任务，它会建立一个仅包含四个输出单元全连接到 </span>30<span class="s10"></span>32 <span class="p">个输入 结点的网络。在这个网络被训练了一段时间后，我们可以很容易地发现还有较大的残留误差， 因为事实上这个目标函数不可能被一个单层结构的网络理想地表示。在这种情况下，算法增 加一个隐藏单元，选择它的权值使这个隐藏单元的值和整个网络的残留误差的相关性最大 化。现在一个新的单元被安装进了网络，它的权值保持不变，并且增加这个新单元到每一个 输出单元间的连接。重复这个过程。原始的权值被再次训练（保持隐藏单元的权值不变）， 检查残留误差，如果残留误差还高于阈值就加入第二个隐单元。每当加入一个新的隐藏单元， 它的输入包括所有原始的网络输入和已经存在的隐藏单元的输出。网络以这种方式增长，积 聚隐藏单元，直到网络的残余误差下降到某个可接受的水平。</span>Fahlman &amp; Lebiere<span class="p">（</span>1990<span class="p">）报 告了级联相关算法显著减少训练时间的例子，原因是每一步仅有一层网络在被训练。这个算 法的一个实际困难是因为算法可以无限制地增加单元，它就很容易过度拟合训练数据，所以 必须采取避免过度拟合的预防措施。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 113%;text-align: justify;">动态修改网络结构的第二个想法是使用相反的途径。不再从可能的最简单网络开始增加 复杂性，而是从一个复杂的网络开始修剪掉某些无关紧要的连接。判断某个权是否无关紧要 的一种方法是看它的值是否接近 <span class="s6">0</span>。第二种看来在实践中更加成功的方法是考虑这个权值的</p><p class="s38" style="text-indent: 0pt;line-height: 9pt;text-align: right;"><span class="s30">E</span></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 11pt;text-align: left;">一个小的变化对误差 <span class="s21">E </span>的影响。变化 <span class="s21">w </span>对 <span class="s21">E </span>的影响（也就是</p><p style="text-indent: 0pt;text-align: left;"><span><img width="21" height="1" alt="image" src="机器学习/Image_138.png"/></span></p><p style="padding-left: 17pt;text-indent: 0pt;line-height: 8pt;text-align: left;">）可以被看作衡量这个连</p><p class="s38" style="text-indent: 0pt;line-height: 13pt;text-align: left;"><span class="s30">w</span></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 107%;text-align: justify;">接的显著性（<span class="s6">salient</span>）的尺度。<span class="s6">LeCun et al.</span>（<span class="s6">1990</span>）描述了一个网络被训练的过程，最不显 著的连接被拆除，重复这个过程直到遇到某个终止条件。他们称这种方法为“最优脑损伤</p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: justify;">（<span class="s6">optimal brain damage</span>）”法，因为在每一步算法都试图去除最没有用的连接。他们报告了 在一个字符识别应用中这种方法将一个大的网络中权值减少到四分之一，对泛化精度有微小 的改善，并且大大改善了后来的训练效率。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 113%;text-align: left;">一般而言，动态修改网络结构的方法已经取得了一些成功，但也有不足。这种方法是否 能稳定地提高反向传播算法的泛化精度还有待研究。然而已经证明在一些情形下它可以显著</p><p style="padding-left: 6pt;text-indent: 0pt;text-align: left;">地降低训练时间。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 34pt;text-indent: 0pt;text-align: left;">4.9 <span class="s17">小结和补充读物</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 27pt;text-indent: 0pt;text-align: left;">这一章的要点包括：</p><p class="s10" style="padding-top: 6pt;padding-left: 66pt;text-indent: -21pt;line-height: 111%;text-align: left;"> <span class="p">人工神经网络学习为学习实数值和向量值函数提供了一种实际的方法，对于 连续的和离散值的属性都可以使用，并且对训练数据中的噪声有很好的鲁棒 性。反向传播算法是最常见的网络学习算法，已经成功应用到很多学习任务， 比如手写识别和机器人控制。</span></p><p class="s10" style="padding-left: 66pt;text-indent: -21pt;line-height: 112%;text-align: left;"> <span class="p">反向传播算法考虑的假设空间是固定连接的有权网络所能表示的所有函数 空间。包含三层单元的前馈网络能够以任意精度逼近任意函数，只要每一层 有足够数量（可能非常多）的单元。即使是一个实际大小的网络也能够表示 很大范围的高度非线性的函数，这使得前馈网络成为学习预先未知的一般形 式的离散和连续函数的很好选择。</span></p><p class="s10" style="padding-left: 66pt;text-indent: -21pt;line-height: 111%;text-align: justify;"> <span class="p">反向传播算法使用梯度下降方法搜索可能假设的空间，迭代减小网络的误差 以拟合训练数据。梯度下降收敛到训练误差相对网络权值的局部极小值。更 一般的，梯度下降是一种有应用潜力的方法，它可用来搜索很多连续参数的 假设空间，只要训练误差是假设参数的可微函数。</span></p><p class="s6" style="padding-left: 66pt;text-indent: -21pt;line-height: 109%;text-align: justify;"><span class="s10"> </span><span class="p">反向传播算法最令人感兴趣的特征之一是，它能够创造出网络输入中没有明 确出现的特征。确切地讲，多层网络的内部（隐藏）层能够表示对学习目标 函数有用的但隐含在网络输入中的中间特征。这种能力被例子如 </span>4.6.4 <span class="p">节的 </span>8<span class="s10"></span>3<span class="s10"></span>8 <span class="p">网络中创造的数字 </span>1 <span class="p">到 </span>8 <span class="p">的布尔编码；以及 </span>4.7 <span class="p">节人脸识别应用中隐 藏层表示的图像特征。</span></p><p style="padding-left: 66pt;text-indent: -21pt;line-height: 110%;text-align: justify;"><span class="s10"> </span>过度拟合训练数据是 <span class="s6">ANN </span>学习中的一个重要问题。过度拟合导致网络泛化 到新的数据时性能很差，尽管网络对于训练数据表现非常好。交叉验证方法 可以用来估计梯度下降搜索的合适终止点，从而最小化过度拟合的风险。</p><p style="padding-left: 66pt;text-indent: -21pt;line-height: 110%;text-align: justify;"><span class="s10"> </span>尽管反向传播算法是最常见的 <span class="s6">ANN </span>学习算法，人们也提出很多其他的算法， 包括对于特殊任务的一些算法。例如，递归网络方法训练包含有向环的网络， 类似级联相关的算法改变权的同时也改变网络结构。</p><p style="padding-top: 7pt;padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">本书的其他章节也介绍了一些关于 <span class="s6">ANN </span>学习的其他信息。第 <span class="s6">6 </span>章给出了选择最小化误 差平方和的贝叶斯论证，以及在其他情况下用最小化交叉熵（<span class="s6">cross entropy</span>）代替最小化误 差平方和的方法。第 <span class="s6">7 </span>章讨论了为可靠学习布尔函数所需要的训练实例数量的理论结果，以 及某些类型网络的 <span class="s6">Vapnik-Chervonenkis </span>维。关于过度拟合以及如何避免的讨论可以在第 <span class="s6">5 </span>章中找到。第 <span class="s6">12 </span>章讨论了使用以前的知识来提高泛化精度的方法。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: left;">对人工神经网络的研究可以追溯到计算机科学的早期。<span class="s6">McCulloch &amp; Pitts</span>（<span class="s6">1943</span>）提出 了一个相当于感知器的神经元模型，<span class="s6">60 </span>年代的大量工作探索了这个模型的很多变体。<span class="s6">60 </span>年 代早期 <span class="s6">Widrow &amp; Hoff</span>（<span class="s6">1960</span>）探索了感知器网络（他们称为“<span class="s6">adelines</span>”）和 <span class="s6">delta </span>法则， <span class="s6">Rosenblatt</span>（<span class="s6">1962</span>）证明了感知器训练法则的收敛性。然而，直到 <span class="s6">60 </span>年代晚期，人们开始清 楚单层的感知器网络的表征能力很有限，而且找不到训练多层网络的有效方法。<span class="s6">Minsky &amp; Papert</span>（<span class="s6">1969</span>）说明即使是象 <span class="s6">XOR </span>这样简单的函数也不能用单层的感知器网络表示或学习， 在整个 <span class="s6">70 </span>年代 <span class="s6">ANN </span>的研究衰退了。</p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 107%;text-align: justify;">在 <span class="s6">80 </span>年代中期 <span class="s6">ANN </span>的研究经历了一次复兴，主要是因为训练多层网络的反向传播算 法的发明（<span class="s6">Rumelhart &amp; McClelland 1986</span>；<span class="s6">Parker 1985</span>）。这些思想可以被追溯到有关的早期 研究（例如 <span class="s6">Werbos 1975</span>）。自从 <span class="s6">80 </span>年代，反向传播算法就成为应用最广泛的学习方法，而 且人们也积极探索出了很多其他的 <span class="s6">ANN </span>方法。在同一时期，计算机变得不再贵重，这允许 人们试验那些在 <span class="s6">60 </span>年代不可能被完全探索的计算密集性的算法。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 109%;text-align: justify;">很多教科书专门论述了神经网络学习。一本早期的但仍有用的关于模式识别的参数学习 方法的书是 <span class="s6">Duda &amp; Hart</span>（<span class="s6">1973</span>）。<span class="s6">Windrow &amp; Stearns</span>（<span class="s6">1985</span>）的教科书覆盖了感知器和相关 的单层网络以及它们的应用。<span class="s6">Rumelhart &amp; McClelland</span>（<span class="s6">1986</span>）收编了 <span class="s6">80 </span>年代中期开始的重 新激发起人们对神经网络方法兴趣的论文。关于神经网络最近出版的书籍包括 <span class="s6">Bishop</span></p><p style="padding-left: 6pt;text-indent: 0pt;text-align: left;">（<span class="s6">1996</span>）；<span class="s6">Chauvin &amp; Rumelhar</span>（<span class="s6">t</span></p><p class="s6" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">1995<span class="p">）；</span>Freeman &amp; Skapina<span class="p">（</span>1991<span class="p">）；</span>Fu<span class="p">（</span>1994<span class="p">）；</span>Hecht-Nielson</p><p style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">（<span class="s6">1990</span>）和 <span class="s6">Hertz et al.</span>（<span class="s6">1991</span>）。</p><p style="padding-left: 27pt;text-indent: 0pt;text-align: left;">习题</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;text-align: left;"><span class="s6">4.1 </span>对图 <span class="s6">4-3 </span>画出的误差曲面，感知器的权<span class="s21">w</span><span class="s35">0</span>，<span class="s21">w</span><span class="s35">1</span>和<span class="s21">w</span><span class="s35">2</span>的值是什么？假定这个误差曲面 与<span class="s21">x</span><span class="s35">1</span>轴相交在<span class="s21">x</span><span class="s35">1</span><span class="s6">= -1</span>，并与<span class="s21">x</span><span class="s35">2</span>轴相交在<span class="s21">x</span><span class="s35">2 </span><span class="s6">= 2</span>。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: left;"><span class="s6">4.2 </span><span class="p">设计一个两输入的感知器来实现布尔函数 </span>A<span class="s10"></span>B<span class="p">。设计一个两层的感知器网络来实 现布尔函数 </span>A XOR B<span class="p">。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 26pt;text-indent: 0pt;text-align: left;"><span class="s6">4.3 </span><span class="p">考虑使用阈值表达式</span>w<span class="s35">0 </span><span class="s6">+ </span>w<span class="s35">1</span>x<span class="s35">1 </span><span class="s6">+ </span>w<span class="s35">2</span>x<span class="s35">2 </span><span class="s6">&gt; 0 </span><span class="p">定义的两个感知器。感知器</span>A<span class="p">的权值为</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 169pt;text-indent: 0pt;text-align: center;">w<span class="s35">0</span><span class="s6">=1</span><span class="p">，</span>w<span class="s35">1</span><span class="s6">=2</span><span class="p">，</span>w<span class="s35">2</span><span class="s6">=1</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 48pt;text-indent: 0pt;text-align: left;">感知器 <span class="s21">B </span>的权值为</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 175pt;text-indent: 0pt;text-align: center;">w<span class="s35">0</span><span class="s6">=0</span><span class="p">，</span>w<span class="s35">1</span><span class="s6">=2</span><span class="p">，</span>w<span class="s35">2</span><span class="s6">=1</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 27pt;text-indent: 0pt;text-align: left;">请 判 断以下 表 达对或 错 。感知 器 <span class="s21">A </span>是 <span class="s21">more_general_than </span>感知器 <span class="s21">B </span>的。 </p><p style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">（<span class="s21">more_general_than </span>在第 <span class="s6">2 </span>章中定义）</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 6pt;text-indent: 21pt;text-align: left;">4.4 <span class="p">实现一个两输入线性单元的</span>delta<span class="p">训练法则。训练它来拟合目标概念</span>-2+<i>x</i><span class="s35">1</span>+2<i>x</i><span class="s35">2</span>&gt;0<span class="p">。画 出误差</span><i>E</i><span class="p">相对训练迭代次数的函数曲线。画出 </span>5<span class="p">，</span>10<span class="p">，</span>50<span class="p">，</span>100<span class="p">， 次迭代后的决策面。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 52pt;text-indent: 20pt;line-height: 106%;text-align: left;">（<span class="s6">a</span>） 为<span class="s72"></span>选取不同的常量值，并使用衰减的学习速率——也就是第<span class="s21">i</span>次迭代 使用<span class="s72"></span><span class="s35">0</span><span class="s6">/</span><span class="s21">i</span>，再进行试验。哪一个效果更好？</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 52pt;text-indent: 21pt;line-height: 107%;text-align: left;">（<span class="s6">b</span>） 试验增量（<span class="s6">incremental</span>）和批量（<span class="s6">batch</span>）学习。那个收敛得更快？考 虑权值更新次数和总执行时间。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 26pt;text-indent: 0pt;text-align: left;"><span class="s6">4.5 </span>推导输出为 <span class="s21">o </span>的单个单元的梯度下降训练法则，其中</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s42" style="text-indent: 0pt;line-height: 7pt;text-align: left;">0            1   1           1   1</p><p style="text-indent: 0pt;text-align: left;"/><p class="s30" style="padding-top: 4pt;padding-left: 125pt;text-indent: 0pt;text-align: left;">o <span class="s38"> </span>w <span class="s38"> </span>w x <span class="s38"> </span>w x <span class="s46">2</span></p><p class="s41" style="text-indent: 0pt;line-height: 7pt;text-align: left;">n    n            n    n</p><p style="text-indent: 0pt;text-align: left;"/><p class="s38" style="padding-top: 4pt;padding-left: 1pt;text-indent: 0pt;text-align: left;"><span class="s101">L</span> <span class="s30">w x </span> <span class="s30">w x </span><span class="s46">2</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-top: 1pt;padding-left: 6pt;text-indent: 21pt;line-height: 107%;text-align: left;">4.6 <span class="p">简略的解释为什么公式（</span>4.10<span class="p">）中的 </span>delta <span class="p">法则仅是公式（</span>4.7<span class="p">）表示的真正梯度下降 法则的近似？</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 106%;text-align: left;"><span class="s6">4.7 </span>考虑一个两层的前馈<span class="s6">ANN</span>，它具有两个输入<span class="s21">a</span>和<span class="s21">b</span>，一个隐单元<span class="s21">c</span>，和一个输出单元<span class="s21">d</span>。 这个网络有五个权值（<span class="s21">w</span><span class="s36">ca</span>，<span class="s21">w</span><span class="s36">cb</span>，<span class="s21">w</span><span class="s36">c</span><span class="s42">0</span>，<span class="s21">w</span><span class="s36">dc</span>，<span class="s21">w</span><span class="s36">d</span><span class="s42">0</span>），其中<span class="s21">w</span><span class="s36">x</span><span class="s42">0</span>表示单元<span class="s21">x</span>的阈值权。先把这些权 的值初始化为（<span class="s6">0.1</span>，<span class="s6">0.1</span>，<span class="s6">0.1</span>，<span class="s6">0.1</span>，<span class="s6">0.1</span>），然后给出使用反向传播算法训练这个网络的前两 次迭代中每一次这些权值的值。假定学习速率<span class="s72"></span><span class="s6">=0.3</span>，冲量<span class="s72"></span><span class="s6">=0.9</span>，采用增量的权值更新，和 以下训练样例：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><table style="border-collapse:collapse;margin-left:119.9pt" cellspacing="0"><tr style="height:23pt"><td style="width:37pt"><p class="s98" style="padding-top: 1pt;padding-left: 11pt;text-indent: 0pt;text-align: left;">a</p></td><td style="width:46pt"><p class="s98" style="padding-top: 1pt;text-indent: 0pt;text-align: center;">b</p></td><td style="width:37pt"><p class="s98" style="padding-top: 1pt;padding-left: 20pt;text-indent: 0pt;text-align: left;">d</p></td></tr><tr style="height:28pt"><td style="width:37pt"><p class="s98" style="padding-top: 7pt;padding-left: 11pt;text-indent: 0pt;text-align: left;">1</p></td><td style="width:46pt"><p class="s98" style="padding-top: 7pt;text-indent: 0pt;text-align: center;">0</p></td><td style="width:37pt"><p class="s98" style="padding-top: 7pt;padding-left: 20pt;text-indent: 0pt;text-align: left;">1</p></td></tr><tr style="height:23pt"><td style="width:37pt"><p class="s98" style="padding-top: 7pt;padding-left: 11pt;text-indent: 0pt;text-align: left;">0</p></td><td style="width:46pt"><p class="s98" style="padding-top: 7pt;text-indent: 0pt;text-align: center;">1</p></td><td style="width:37pt"><p class="s98" style="padding-top: 7pt;padding-left: 20pt;text-indent: 0pt;text-align: left;">0</p></td></tr></table><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 26pt;text-indent: 0pt;text-align: left;"><span class="s6">4.8 </span>修改表 <span class="s6">4-2 </span>中的反向传播算法，使用双曲正切<span class="s21">tanh</span>函数取代<span class="s6">sigmoid</span>函数作为挤压函</p><p class="s21" style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;"><span class="p">数。也就是说，假定单个单元的输出是</span>o<span class="s6">=</span>tanh<span class="p">（ </span><span class="s30">w </span><span class="s38"> </span><span class="s30">x </span><span class="p">）。给出输出层权值和隐藏层权值的权 更新法则。提示：</span>tanh<span class="s10"></span><span class="s6">(</span>x<span class="s6">)=1-</span>tanh<span class="s46">2</span><span class="s6">(</span>x<span class="s6">)</span><span class="p">。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 5pt;text-indent: 21pt;line-height: 110%;text-align: justify;">4.9 <span class="p">回忆图 </span>4-7 <span class="p">描述的 </span>8<span class="s10"></span>3<span class="s10"></span>8 <span class="p">网络。考虑训练一个 </span>8<span class="s10"></span>1<span class="s10"></span>8 <span class="p">的网络来完成同样的任务；也 就是仅有一个隐藏单元的网络。注意，图 </span>4-7 <span class="p">中的 </span>8 <span class="p">个训练样例可以被表示为单个隐单元的 </span>8 <span class="p">个不同的值（例如 </span>0.1<span class="p">，</span>0.2<span class="p">， ，</span>0.8<span class="p">）。那么仅有一个隐单元的网络能够根据这些训练 样例学习恒等函数吗？提示：考虑类似这样的问题“是否存在这样的隐藏单元权值，能产生 上面建议的隐藏单元编码？”，“是否存在这样的输出单元权值，能正确解码这样的输入编 码？”和“梯度下降搜索可能发现这样的权值吗？”</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 26pt;text-indent: 0pt;text-align: left;">4.10 <span class="p">考虑 </span>4.8.1 <span class="p">小节中描述的另一种误差函数：</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s167" style="padding-top: 3pt;padding-left: 137pt;text-indent: 0pt;line-height: 7pt;text-align: left;">r <span class="s92">1 </span><span class="s42">2</span></p><p class="s30" style="padding-left: 122pt;text-indent: 0pt;line-height: 15pt;text-align: left;">E<span class="s33">(</span>w<span class="s33">) </span><span class="s38"> </span><span class="s39"></span><span class="s121"> </span><span class="s121"></span></p><p class="s41" style="text-indent: 0pt;line-height: 10pt;text-align: right;"><span class="s84">2 </span>d<span class="s40"></span>D k<span class="s40"></span>outputs</p><p class="s30" style="text-indent: 0pt;line-height: 18pt;text-align: left;"><span class="s33">(</span>t<span class="s52">kd</span><span class="s41"> </span><span class="s38"> </span>o<span class="s52">kd</span><span class="s41"> </span><span class="s33">)2 </span><span class="s38"> </span><span class="s119"> </span><span class="s39"></span><span class="s121"> </span>w <span class="s52">ji</span></p><p class="s41" style="text-indent: 0pt;line-height: 7pt;text-align: center;">i<span class="s42">, </span>j</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 107%;text-align: left;">为这个误差 <span class="s21">E </span>推导出梯度下降权更新法则。证明这个权值更新法则的实现可通过在进 行表 <span class="s6">4-2 </span>的标准梯度下降权更新前把每个权值乘以一个常数。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: left;">4.11 <a href="http://www.cs.cmu.edu/%7Etom/mlbook.html" class="s223" target="_blank">应 用 反向传 播算法 来完成 人脸识 别任务 。参见 互联网页 </a>http://www.cs.cmu.edu/~tom/mlbook.html <span class="p">来获得其细节，包括人脸图像数据，反向传播程序 源代码和具体的任务。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: left;"><span class="s6">4.12 </span><span class="p">推导出学习 </span>x<span class="p">，</span>y <span class="p">平面上的矩形这一目标概念的梯度下降算法。使用 </span>x<span class="p">，</span>y <span class="p">的坐标描 述每一个假设，矩形的左下角和右上角分别表示为 </span>llx<span class="p">，</span>lly<span class="p">，</span>urx <span class="p">和 </span>ury<span class="p">。实例</span><span class="s6">&lt;</span>x<span class="s6">,</span>y<span class="s6">&gt;</span><span class="p">被假设</span><span class="s6">&lt;</span>llx<span class="p">， </span>lly<span class="p">，</span>urx<span class="p">，</span>ury<span class="s6">&gt;</span><span class="p">标记为正例的充要条件是点</span><span class="s6">&lt;</span>x<span class="s6">,</span>y<span class="s6">&gt;</span><span class="p">位于对应的矩形内部。按本章中的办法定义 误差 </span>E<span class="p">。试设计一个梯度下降算法来学习这样的矩形假设。注意误差 </span>E <span class="p">不是 </span>llx<span class="p">，</span>lly<span class="p">，</span>urx <span class="p">和 </span>ury <span class="p">的连续函数，这与感知器学习的情况一样。（提示：考虑感知器中使用的两个解决办法：</span></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: justify;">（<span class="s6">1</span>）改变分类法则来使输出预测成为输入的连续函数；（<span class="s6">2</span>）另外定义一个误差——比如到 矩形中心的距离——就像训练感知器的 <span class="s6">delta </span>法则。）当正例和反例可被矩形分割时，设计的 算法会收敛到最小误差假设吗？何时不会？该算法有局部极小值的问题吗？该算法与学习 特征约束合取的符号方法相比如何？</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 26pt;text-indent: 0pt;text-align: left;">参考文献</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s8" style="padding-left: 24pt;text-indent: 0pt;line-height: 24pt;text-align: center;">第<span class="h1">5</span>章 评估假设</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 113%;text-align: left;">对假设的精度进行经验的评估是机器学习中的基本问题。本章介绍了用统计方法估计假 设精度，主要为解决以下三个问题：首先，已知一个假设在有限数据样本上观察到的精度， 怎样估计它在其他实例上的精度。其次，如果一个假设在某些数据样本上好于另一个，那么 一般情况下是否该假设更准确。第三，当数据有限时，怎样高效地利用这些数据，通过它们 既能学习到假设，还能估计其精度？由于有限的数据样本可能不代表数据的一般分布，所以 从这些数据上估计出的假设精度可能有误差。统计的方法，结合有关数据基准分布的假定， 使我们可以用有限数据样本上的观察精度来逼近整个数据分布上的真实精度。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">5.1 <span class="s17">动机</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 113%;text-align: left;">多数情况下，对学习到的假设进行尽可能准确的性能评估十分重要。原因之一很简单， 是为了知道是否可以使用该假设。例如，从一个长度有限的数据库中学习，以了解不同医疗 手段的效果，就有必要尽可能准确地知道学习结果的正确性。另一原因在于，对假设的评估 是许多学习方法的重要组成部分。例如在决策树学习中，为避免过度拟合问题必须进行后修 剪，这时我们必须评估每一步修剪对树的精度产生的影响。因此，有必要了解已修剪和未修 剪树的精度估计中固有的可能误差。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 113%;text-align: left;">当数据十分充足时，假设精度的估计相对容易。然而当给定的数据集非常有限时，要学 习一个概念并估计其将来的精度，存在两个很关键的困难：</p><p style="padding-top: 4pt;padding-left: 49pt;text-indent: -21pt;text-align: left;"><span class="s34">• </span>估计的偏差<span class="s6">(Bias in the estimate)</span>。首先，学习到的概念在训练样例上的观察精度 通常不能很好地用于估计在将来样例上的精度。因为假设是从这些样例中得出 的，因此对将来样例的精度估计通常偏于乐观。尤其在学习器采用了很大的假 设空间，并过度拟合训练样例时，这一情况更可能出现。要对将来的精度进行 无偏估计，典型的方法是选择与训练样例和假设无关的检验样例，在这个样例 集合上检验假设。</p><p style="padding-left: 49pt;text-indent: -21pt;text-align: left;"><span class="s34">• </span>估计的方差<span class="s6">(Variance in the estimate)</span>。其次，即使假设精度在独立的无偏检验样 例上测量，得到的精度仍可能与真实精度不同，这取决于特定检验样例集合的 组成。检验样例越少，产生的方差越大。</p><p style="padding-top: 7pt;padding-left: 6pt;text-indent: 21pt;line-height: 113%;text-align: justify;">本章讨论了对学到的假设的评估、对两个假设精度的比较、和有限数据样本情况下两个 学习算法精度的比较。其中的讨论多数集中在统计和采样理论的基本定律，而本章假定读者 在统计学方面没有背景知识。假设的统计检验需要较多的理论知识。本章提供了介绍性的综 述，集中讨论那些与假设的学习、评估和比较相关的问题。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">5.2 <span class="s17">估计假设精度</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 113%;text-align: left;">在评估一个假设时，我们一般更感兴趣于估计其对未来实例的分类精度。同时，也需要 知道这一精度估计中的可能的误差（即与此估计相联系的误差门限）。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 107%;text-align: left;">本章使用的学习问题的框架如下。有一所有可能实例的空间 <span class="s21">X</span>（如所有人的集合），其 上定义了多个目标函数（如计划本年购买滑雪板者）。我们假定 <span class="s21">X </span>中不同实例具有不同的出</p><p style="padding-left: 5pt;text-indent: 0pt;text-align: justify;">现频率，对此，一种合适的建模方式是，假定存在一未知的概率分布 <span class="s68">D</span>，它定义了 <span class="s21">X </span>中每一 实例出现的概率（如 <span class="s6">19 </span>岁的人的概率比 <span class="s6">109 </span>岁的人概率高）。注意 <span class="s68">D </span>并没有说明 <span class="s21">x </span>是一正例 还是一反例，只确定了其出现概率。学习任务是在假设空间 <span class="s21">H </span>上学习一个目标概念（即目 标函数）<span class="s21">f</span>。目标函数 <span class="s21">f </span>的训练样例由施教者提供给学习器：每一个实例按照分布 <span class="s68">D </span>被独立 地抽取，然后它连同其正确的目标值 <span class="s21">f</span><span class="s6">(</span><span class="s21">x</span><span class="s6">)</span>被提供给学习器。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">为说明这一点，考虑目标函数“计划本年购买滑雪板者”，可以调查去滑雪板商店的顾 客，通过此调查来收集训练样例。在这里实例空间 <span class="s21">X </span>为所有人组成的集合，每个实例可由 人的各种属性描述，如年龄、职业、每年滑雪次数等。分布情况 <span class="s68">D </span>指定了在滑雪板商店中 遇到的每个人的概率。目标函数 <span class="s21">f</span><span class="s6">:</span><span class="s21">X</span>→<span class="s6">{0,1}</span>将每个人进行分类，判断它是否会在本年内购买 滑雪板。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 26pt;text-indent: 0pt;text-align: left;">在这个一般的框架中，我们感兴趣的是以下两个问题：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 26pt;text-indent: -21pt;text-align: left;"><span class="s6">1. </span>给定假设 <span class="s21">h </span>和包含若干按 <span class="s68">D </span>分布随机抽取的样例的数据集，如何针对将来按同样分布抽 取的实例，得到对 <span class="s21">h </span>的精度的最好估计。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 5pt;text-indent: 0pt;text-align: justify;">2. <span class="p">这一精度估计的可能的误差是多少？</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 6pt;text-indent: 0pt;text-align: justify;">5.2.1 <span class="s25">样本错误率和真实错误率</span></h3><p style="padding-top: 10pt;padding-left: 6pt;text-indent: 21pt;line-height: 107%;text-align: justify;">为解决上述的两个问题，需要确切地区分出两种精度（或两种错误率）。其一是可用数 据样本上该假设的错误率。其二是在分布为 <span class="s68">D </span>的整个实例集合上该假设的错误率。它们分 别被称为样本错误率和真实错误率。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">对于于从 <span class="s21">X </span>中抽取的样本 <span class="s21">S</span>，某假设关于 <span class="s21">S </span>的样本错误率（<span class="s6">sample error</span>），是该假设错 误分类的实例在 <span class="s21">S </span>中所占比例：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 26pt;text-indent: 0pt;text-align: left;"><span class="p">定义： 假设</span>h<span class="p">关于目标函数</span>f<span class="p">和数据样本</span>S<span class="p">的样本错误率（标记为</span>error<span class="s36">S</span><span class="s6">(</span>h<span class="s6">)</span><span class="p">）为：</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="11" height="1" alt="image" src="机器学习/Image_139.png"/></span></p><p class="s41" style="text-indent: 0pt;line-height: 24pt;text-align: left;">S                  <span class="s168">n</span><span class="s30"> </span><span class="s121"></span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s33" style="padding-top: 3pt;padding-left: 134pt;text-indent: 0pt;text-align: center;"><i>error </i>(<i>h</i>) <span class="s38"> </span><span class="s169">1 </span><span class="s119"> </span>( <i>f </i>(<i>x</i>), <i>h</i>(<i>x</i>))</p><p class="s41" style="padding-top: 1pt;padding-left: 134pt;text-indent: 0pt;text-align: center;">x<span class="s40"></span>S</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s108" style="padding-top: 2pt;padding-left: 26pt;text-indent: 0pt;line-height: 194%;text-align: left;"><span class="p">其中 </span><span class="s21">n </span><span class="p">为 </span><span class="s21">S </span><span class="p">中样例的数量，而 </span><span class="s119"> </span>( <i>f </i>(<i>x</i>), <i>h</i>(<i>x</i>)) <span class="p">在 </span><i>f </i>(<i>x</i>) <span class="s109"> </span><i>h</i>(<i>x</i>) <span class="p">时为 </span><span class="s6">1</span><span class="p">，否则为 </span><span class="s6">0</span><span class="p">。 真实错误率</span><span class="s6">(true error)</span><span class="p">是对于按 </span><span class="s68">D </span><span class="p">分布随机抽取的实例，该假设对它错误分类的概率。</span></p><p style="padding-left: 48pt;text-indent: -21pt;line-height: 16pt;text-align: left;">定义： 假设<span class="s21">h</span>关于目标函数<span class="s21">f</span>和分布<span class="s68">D</span>的真实错误率（由<span class="s21">error</span><span class="s170">D</span><span class="s6">(</span><span class="s21">h</span><span class="s6">)</span>表示），为<span class="s21">h</span>误分类按<span class="s68">D </span>分布随机抽取实例的概率：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s107" style="padding-top: 4pt;text-indent: 0pt;text-align: right;">error<span class="s171">D</span></p><p class="s108" style="padding-top: 3pt;text-indent: 0pt;line-height: 13pt;text-align: left;">(<i>h</i>) <span class="s109"> </span>Pr[ <i>f </i>(<i>x</i>) <span class="s109"> </span><i>h</i>(<i>x</i>)]</p><p class="s41" style="padding-left: 26pt;text-indent: 0pt;line-height: 7pt;text-align: left;">x<span class="s40"></span><span class="s172">D</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 2pt;padding-left: 26pt;text-indent: 0pt;line-height: 14pt;text-align: left;">这里，记号 <span class="s108">Pr </span>表示概率在实例分布 <span class="s68">D </span>上计算。</p><p class="s41" style="padding-left: 81pt;text-indent: 0pt;line-height: 7pt;text-align: left;">x<span class="s40"></span><span class="s172">D</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;line-height: 16pt;text-align: justify;"><span class="p">我们通常想知道的是假设的真实错误率</span>error<span class="s170">D</span><span class="s6">(</span>h<span class="s6">)</span><span class="p">，因为这是在分类未来样例时出现错误 的可能性。然而我们所能测量的只是样本错误率</span>error<span class="s36">S</span><span class="s6">(</span>h<span class="s6">)</span><span class="p">，它所要求的数据样本</span>S<span class="p">是我们所 拥有的。本节所要考虑的主要问题就是“</span>error<span class="s36">S</span><span class="s6">(</span>h<span class="s6">)</span><span class="p">在何种程度上提供了对</span>error<span class="s170">D</span><span class="s6">(</span>h<span class="s6">) </span><span class="p">的估</span></p><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;">计？”。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 11pt;text-indent: 0pt;text-align: left;">5.2.2 <span class="s25">离散值假设的置信区间</span></h3><p class="s21" style="padding-top: 10pt;padding-left: 11pt;text-indent: 21pt;text-align: justify;"><span class="p">为解决“</span>error<span class="s36">S</span><span class="s6">(</span>h<span class="s6">)</span><span class="p">在何种程度上提供了对</span>error<span class="s170">D</span><span class="s6">(</span>h<span class="s6">) </span><span class="p">的估计”的问题，先考虑</span>h<span class="p">为离散值 假设的情况。具体地说，比如要基于某离散值假设</span>h<span class="p">在样本</span>S<span class="p">上观察到的样本错误率，估计它 的真实错误率，其中：</span></p><p style="padding-top: 7pt;padding-left: 54pt;text-indent: -21pt;line-height: 14pt;text-align: left;"><span class="s34">• </span>样本 <span class="s21">S </span>包含 <span class="s21">n </span>个样例，它们的抽取按照概率分布 <span class="s68">D</span>，抽取过程是相互独立的，并 且不依赖于 <span class="s21">h</span></p><p class="s34" style="padding-left: 33pt;text-indent: 0pt;line-height: 13pt;text-align: left;">• <span class="s21">n</span><span class="p">≥</span><span class="s6">30</span></p><p class="s21" style="padding-left: 31pt;text-indent: 1pt;line-height: 141%;text-align: left;"><span class="s34">• </span><span class="p">假设</span>h<span class="p">在这</span>n<span class="p">个样例上犯了</span>r<span class="p">个错误（</span>error<span class="s36">S</span><span class="s6">(</span>h<span class="s6">)=</span>r<span class="s6">/</span>n<span class="p">） 已知这些条件，统计理论可给出以下断言：</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 31pt;text-indent: 0pt;text-align: left;">1.<span class="p">没有其他信息的话，</span><i>error</i><span class="s170">D</span>(<i>h</i>)<span class="p">最可能的值为</span><i>error</i><span class="s36">S</span>(<i>h</i>)</p><p class="s6" style="padding-top: 11pt;padding-left: 31pt;text-indent: 0pt;text-align: left;">2.<span class="p">有大约 </span>95<span class="p">％的可能性，真实错误率</span><i>error</i><span class="s170">D</span>(<i>h</i>)<span class="p">处于下面的区间内：</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="padding-top: 11pt;text-indent: 0pt;text-align: right;">error<span class="s52">S</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s33" style="text-indent: 0pt;text-align: left;">(<i>h</i>) <span class="s38"> </span>1.96</p><p style="text-indent: 0pt;text-align: left;"><span><img width="165" height="41" alt="image" src="机器学习/Image_140.png"/></span></p><p class="s30" style="padding-top: 2pt;padding-left: 6pt;text-indent: 0pt;text-align: center;">error<span class="s52">S</span><span class="s41"> </span><span class="s33">(</span>h<span class="s33">)(1 </span><span class="s38"> </span>error<span class="s52">S</span><span class="s41"> </span><span class="s33">(</span>h<span class="s33">))</span></p><p class="s30" style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: center;">n</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-top: 1pt;padding-left: 10pt;text-indent: 21pt;text-align: justify;"><span class="p">举例说明，假如数据样本</span><i>S</i><span class="p">包含</span><i>n</i>=40 <span class="p">个样例，并且假设</span><i>h</i><span class="p">在这些数据上产生了</span><i>r</i>=12 <span class="p">个错 误。这样，样本错误率为</span><i>error</i><span class="s36">S</span>(<i>h</i>)=12/40<span class="p">＝</span>0.3<span class="p">。如果没有更多的信息，对真实错误率</span><i>error</i><span class="s170">D</span>(<i>h</i>) <span class="p">的最好的估计即为样本错误率 </span>0.3<span class="p">。然而我们不能期望这是对真实错误率的完美估计。如果 另外搜集 </span>40 <span class="p">个随机抽取的样例</span><i>S</i>´<span class="p">，样本错误率</span><i>error</i><span class="s36">S</span><span class="s42">´</span>(<i>h</i>)<span class="p">将与原来的</span><i>error</i><span class="s36">S</span>(<i>h</i>)<span class="p">存在些许不同。 这种不同是由</span><i>S</i>´<span class="p">和</span><i>S</i><span class="p">组成上的随机差异所产生的。实际上，如果不断重复这一实验，每次抽 取一个包含 </span>40 <span class="p">样例的样本</span><i>S</i><span class="s36">i</span><span class="p">，将会发现约 </span>95%<span class="p">的实验中计算所得的区间包含真实错误率。 因此，我们将此区间称为</span><i>error</i><span class="s170">D</span>(<i>h</i>)<span class="p">的 </span>95%<span class="p">置信区间估计。在本例中，</span><i>r</i>=12 <span class="p">和</span><i>n</i>=40<span class="p">，根据上式， </span>95%<span class="p">置信区间为 </span>0.30<span class="p">±</span>(1.96<span class="p">×</span>0.07)<span class="p">＝</span>0.30<span class="p">±</span>0.14<span class="p">。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">上面的 <span class="s6">95</span>％置信区间表达式可推广到一般情形以计算任意置信度。常数 <span class="s6">1.96 </span>是由 <span class="s6">95% </span>这一置信度确定的。定义<span class="s21">z</span><span class="s36">N</span>为计算<span class="s21">N</span><span class="s6">%</span>置信区间时的常数。计算<span class="s21">error</span><span class="s170">D</span><span class="s6">(</span><span class="s21">h</span><span class="s6">)</span>的<span class="s21">N</span><span class="s6">%</span>置信区间的一 般表达式为：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="padding-top: 11pt;text-indent: 0pt;text-align: right;">error<span class="s52">S</span></p><p class="s33" style="padding-top: 10pt;text-indent: 0pt;text-align: left;">(<i>h</i>) <span class="s38"> </span><i>z </i><span class="s52">N</span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="165" height="41" alt="image" src="机器学习/Image_141.png"/></span></p><p class="s30" style="padding-top: 2pt;padding-left: 9pt;text-indent: 0pt;text-align: center;">error<span class="s52">S</span><span class="s41"> </span><span class="s33">(</span>h<span class="s33">)(1 </span><span class="s38"> </span>error<span class="s52">S</span><span class="s41"> </span><span class="s33">(</span>h<span class="s33">))</span></p><p class="s30" style="padding-top: 1pt;padding-left: 9pt;text-indent: 0pt;text-align: center;">n</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 20pt;text-indent: 0pt;text-align: center;">(5.1)</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 31pt;text-indent: 0pt;text-align: left;">其中<span class="s21">z</span><span class="s36">N</span>的值依赖于所需的置信度，参见表 <span class="s6">5-1 </span>中的取值。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 153pt;text-indent: 0pt;text-align: left;">表 <span class="h4">5-1 </span>双侧的<span class="s7">N</span>％置信区间的<span class="s7">z</span><span class="s173">N</span>值</p><p style="text-indent: 0pt;text-align: left;"><br/></p><table style="border-collapse:collapse;margin-left:5.60001pt" cellspacing="0"><tr style="height:17pt"><td style="width:75pt;border-top-style:solid;border-top-width:2pt"><p class="s174" style="padding-left: 16pt;text-indent: 0pt;text-align: left;">置信度 <span class="s54">N</span><span class="s53">%</span></p></td><td style="width:49pt;border-top-style:solid;border-top-width:2pt"><p class="s53" style="padding-top: 1pt;padding-left: 16pt;text-indent: 0pt;text-align: left;">50%</p></td><td style="width:49pt;border-top-style:solid;border-top-width:2pt"><p class="s53" style="padding-top: 1pt;padding-left: 16pt;text-indent: 0pt;text-align: left;">68%</p></td><td style="width:50pt;border-top-style:solid;border-top-width:2pt"><p class="s53" style="padding-top: 1pt;padding-left: 16pt;text-indent: 0pt;text-align: left;">80%</p></td><td style="width:49pt;border-top-style:solid;border-top-width:2pt"><p class="s53" style="padding-top: 1pt;padding-left: 16pt;text-indent: 0pt;text-align: left;">90%</p></td><td style="width:49pt;border-top-style:solid;border-top-width:2pt"><p class="s53" style="padding-top: 1pt;padding-left: 16pt;text-indent: 0pt;text-align: left;">95%</p></td><td style="width:49pt;border-top-style:solid;border-top-width:2pt"><p class="s53" style="padding-top: 1pt;padding-left: 16pt;text-indent: 0pt;text-align: left;">98%</p></td><td style="width:49pt;border-top-style:solid;border-top-width:2pt"><p class="s53" style="padding-top: 1pt;padding-left: 16pt;text-indent: 0pt;text-align: left;">99%</p></td></tr><tr style="height:17pt"><td style="width:75pt;border-bottom-style:solid;border-bottom-width:2pt"><p class="s174" style="padding-left: 24pt;text-indent: 0pt;text-align: left;">常量<span class="s54">z</span><span class="s175">N</span></p></td><td style="width:49pt;border-bottom-style:solid;border-bottom-width:2pt"><p class="s53" style="padding-top: 1pt;text-indent: 0pt;text-align: center;">0.67</p></td><td style="width:49pt;border-bottom-style:solid;border-bottom-width:2pt"><p class="s53" style="padding-top: 1pt;text-indent: 0pt;text-align: center;">1.00</p></td><td style="width:50pt;border-bottom-style:solid;border-bottom-width:2pt"><p class="s53" style="padding-top: 1pt;text-indent: 0pt;text-align: center;">1.28</p></td><td style="width:49pt;border-bottom-style:solid;border-bottom-width:2pt"><p class="s53" style="padding-top: 1pt;text-indent: 0pt;text-align: center;">1.64</p></td><td style="width:49pt;border-bottom-style:solid;border-bottom-width:2pt"><p class="s53" style="padding-top: 1pt;text-indent: 0pt;text-align: center;">1.96</p></td><td style="width:49pt;border-bottom-style:solid;border-bottom-width:2pt"><p class="s53" style="padding-top: 1pt;text-indent: 0pt;text-align: center;">2.33</p></td><td style="width:49pt;border-bottom-style:solid;border-bottom-width:2pt"><p class="s53" style="padding-top: 1pt;text-indent: 0pt;text-align: center;">2.58</p></td></tr></table><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-top: 1pt;padding-left: 11pt;text-indent: 21pt;text-align: justify;"><span class="p">因此，正如</span><i>error</i><span class="s170">D</span>(<i>h</i>)<span class="p">的 </span>95<span class="p">％置信区间为 </span>0.30<span class="p">±</span>(1.96<span class="p">• </span>0.07)<span class="p">（其中</span><i>r</i>=12<span class="p">，</span><i>n</i>=40<span class="p">），可以求 得同样情况下 </span>68%<span class="p">置信区间为 </span>0.30<span class="p">±（</span>1.0<span class="p">• </span>0.07<span class="p">）。从直觉上我们也可以看出 </span>68<span class="p">％置信区间 要小于 </span>95<span class="p">％置信区间，因为我们减小了要求</span><i>error</i><span class="s170">D</span>(<i>h</i>)<span class="p">落入此区间的概率。</span></p><p class="s6" style="padding-left: 11pt;text-indent: 21pt;text-align: left;"><span class="p">等式 </span>5.1 <span class="p">描述了为了在</span><i>error</i><span class="s36">S</span>(<i>h</i>)<span class="p">基础上估计</span><i>error</i><span class="s170">D</span>(<i>h</i>)<span class="p">，如何计算置信区间（即误差门限）。 这一表达式时只能应用于离散值假设。它假定样本</span><i>S</i><span class="p">抽取的分布与将来的数据抽取的分布相 同，并且假定数据不依赖于所检验的假设。还有，该表达式只提供了近似的置信区间，不过 这一近似在至少包含 </span>30 <span class="p">个样例并且</span><i>error</i><span class="s36">S</span>(<i>h</i>)<span class="p">不太靠近 </span>0 <span class="p">或 </span>1 <span class="p">时很接近真实情况。判断这种 近似是否接近真实，更精确的规则为：</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="padding-top: 2pt;padding-left: 159pt;text-indent: 0pt;text-align: left;">n<span class="s38"> </span>error<span class="s52">S</span><span class="s41"> </span><span class="s33">(</span>h<span class="s33">)(1 </span><span class="s38"> </span>error<span class="s52">S</span><span class="s41"> </span><span class="s33">(</span>h<span class="s33">)) </span><span class="s38"> </span><span class="s33">5</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 11pt;text-indent: 21pt;line-height: 113%;text-align: justify;">上面我们概述了计算离散值假设的置信区间的过程，下一节将给出这一过程的统计学基 础。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 12pt;text-indent: 0pt;text-align: left;">5.3 <span class="s17">采样理论基础</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 12pt;text-indent: 21pt;line-height: 113%;text-align: justify;">本节介绍了统计学和采样理论的几个基本概念，包括概率分布、期望值、方差、二项分 布和正态分布、以及双侧和单侧区间。对于这些概念的基本了解将有助于理解假设评估和算 法评估。更为重要的，它们提供了一种重要的概念框架，以便于理解相关的机器学习问题（如 过度拟合问题）以及理解在成功的泛化和训练样例数目之间的关系。已经熟悉这些概念的读 者可以跳过本节。其中介绍的关键概念在表 <span class="s6">5-2 </span>中列出。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 31pt;text-indent: 0pt;text-align: center;">表 <span class="h4">5-2 </span>统计学中的基本定义和概念</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 2pt;text-align: left;"><span><img width="570" height="2" alt="image" src="机器学习/Image_142.png"/></span></p><p class="s14" style="padding-left: 30pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span>随机变量<span class="s16">(random variable)</span>可被看作是有概率输出的一个实验。它的值为实验的输出结果。</p><p class="s14" style="padding-top: 3pt;padding-left: 29pt;text-indent: 0pt;line-height: 106%;text-align: left;"><span class="s55">n      </span>某随机变量的概率分布<span class="s16">(probability distribution)</span>指定了<span class="s56">Y</span>取值为任一可能的值<span class="s56">y</span><span class="s65">i</span>的可能性<span class="s16">Pr(</span><span class="s56">Y</span><span class="s16">=</span><span class="s56">y</span><span class="s65">i</span><span class="s16">) </span><span class="s55">n      </span>随机变量<span class="s56">Y</span>的期望值<span class="s16">(expected value)</span>或均值<span class="s16">(mean)</span>为 <span class="s39"></span><span class="s176">i </span><span class="s41"> </span><span class="s30">y</span><span class="s52">i  </span><span class="s33">Pr(</span><span class="s30">Y  </span><span class="s38"></span><span class="s33"> </span><span class="s30">y</span><span class="s52">i</span><span class="s41"> </span><span class="s33">) </span>。通常用符号<span class="s177">μ</span><span class="s65">Y</span>来表示 <span class="s56">E</span><span class="s16">[</span><span class="s56">Y</span><span class="s16">]</span>。</p><p class="s16" style="padding-top: 2pt;padding-left: 30pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span><span class="s14">随机变量的方差</span>(Variance)<span class="s14">为</span>Var(<i>Y</i>)=<i>E</i>[(<i>Y</i>-<span class="s177">μ</span><span class="s65">Y</span>)<span class="s70">2</span>]<span class="s14">。它描述了</span><i>Y</i><span class="s14">关于其均值分布的宽度或分散度。</span></p><p class="s14" style="padding-top: 7pt;padding-left: 30pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span><span class="s56">Y</span>的标准差<span class="s16">(Standard deviation)</span>为</p><p style="text-indent: 0pt;text-align: left;"><span><img width="56" height="21" alt="image" src="机器学习/Image_143.png"/></span></p><p class="s30" style="padding-top: 6pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">Var<span class="s33">(</span>Y <span class="s33">) </span><span class="s14">。通常用符号</span><span class="s177">σ</span><span class="s65">Y</span><span class="s14">来代表。</span></p><p class="s14" style="padding-top: 6pt;padding-left: 33pt;text-indent: -3pt;line-height: 12pt;text-align: left;"><span class="s55">n </span>二项分布<span class="s16">(Binomial distribution)</span>是在硬币投掷问题中，若出现正面的概率为 <span class="s56">p</span>，那么在 <span class="s56">n </span>个独立 的实验中出现 <span class="s56">r </span>次正面的分布情况。</p><p class="s14" style="padding-top: 2pt;padding-left: 30pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span>正态分布<span class="s16">(Normal distribution)</span>是一钟形的概率分布，它在许多自然现象中都会出现。</p><p class="s14" style="padding-top: 4pt;padding-left: 33pt;text-indent: -3pt;line-height: 12pt;text-align: left;"><span class="s55">n </span>中心极限定理<span class="s16">(Central Limit Theorem)</span>说明独立同分布的随机变量在大量实验中的和遵循正态分 布。</p><p class="s14" style="padding-top: 2pt;padding-left: 30pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span>估计量<span class="s16">(estimator)</span>为一随机变量 <span class="s56">Y</span>，它用来估计一基准总体的某一参数 <span class="s56">p</span>。</p><p class="s16" style="padding-top: 3pt;padding-left: 30pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span><i>P </i><span class="s14">的估计量 </span><i>Y </i><span class="s14">的估计偏差</span>(estimation bias)<span class="s14">为</span>(<i>E</i>[<i>Y</i>]<span class="s14">－</span><i>p</i>)<span class="s14">。无偏估计量是指该偏差为 </span>0<span class="s14">。</span></p><p class="s14" style="padding-top: 3pt;padding-left: 30pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span><span class="s56">N</span><span class="s16">%</span>置信区间<span class="s16">(confidence interval)</span>用于估计参数 <span class="s56">p</span>，该区间以 <span class="s56">N</span><span class="s16">%</span>的概率包含 <span class="s56">p</span>。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 2pt;text-align: left;"><span><img width="570" height="2" alt="image" src="机器学习/Image_144.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 12pt;text-indent: 0pt;text-align: left;">5.3.1 <span class="s25">错误率估计和二项比例估计</span></h3><p style="padding-top: 10pt;padding-left: 12pt;text-indent: 21pt;line-height: 113%;text-align: justify;">在样本错误率和真实错误率之间的差异与数据样本大小的依赖关系如何？这一问题在 统计学中已透彻研究。它可表述为：给定一总体中随机抽取的部分样本的观察频率，估计整 个总体的概率。在这里，我们感兴趣的观察量为 <span class="s21">h </span>是否误分类样例。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 12pt;text-indent: 21pt;text-align: left;">解决该问题首先要注意到，测量样本错误率相当于在作一个有随机输出的实验。我们先</p><p class="s6" style="text-indent: 0pt;line-height: 11pt;text-align: left;">(</p><p style="text-indent: 0pt;text-align: left;"/><p class="s21" style="padding-top: 3pt;padding-left: 12pt;text-indent: 0pt;line-height: 88%;text-align: left;"><span class="p">从分布</span><span class="s68">D</span><span class="p">中随机抽取出</span>n<span class="p">个独立的实例，形成样本</span>S<span class="p">，然后测量样本错误率</span>error<span class="s36">S</span><span class="s6">(</span>h<span class="s6">)</span><span class="p">，如前一 节所述，如果将实验重复多次，每次抽取大小为</span>n<span class="p">的不同的样本</span>S<span class="s36">i</span><span class="p">，将可以得到不同的</span>error<span class="s36">S</span><span class="s69">i</span><span class="s41"> </span>h<span class="s6">)</span></p><p class="s6" style="text-indent: 0pt;line-height: 11pt;text-align: left;">(</p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-top: 1pt;padding-left: 11pt;text-indent: 0pt;text-align: justify;">的值，它取决于不同<span class="s21">S</span><span class="s36">i</span>的组成中的随机差异。这种情况下，第<span class="s21">i</span>个这样的实验的输出<span class="s21">error</span><span class="s36">S</span><span class="s69">i </span><span class="s21">h</span><span class="s6">) </span>被称为一随机变量（<span class="s6">random variable</span>）。一般情况下，可以将随机变量看成一个有随机输出的 实验。随机变量值即为随机实验的观察输出。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 32pt;text-indent: 0pt;line-height: 4pt;text-align: left;"><span class="p">设想要运行</span>k<span class="p">个这样的随机实验，测量随机变量</span>error<span class="s36">S</span><span class="s178">1 </span>h<span class="s6">) </span><span class="p">，</span>error<span class="s36">S</span><span class="s178">2 </span>h<span class="s6">)</span><span class="p">，⋯⋯， </span>error<span class="s36">S</span><span class="s69">k</span><span class="s41"> </span>h<span class="s6">)</span><span class="p">。</span></p><p class="s6" style="padding-left: 273pt;text-indent: 0pt;line-height: 11pt;text-align: left;">( ( (</p><p style="padding-top: 3pt;padding-left: 12pt;text-indent: 0pt;line-height: 107%;text-align: left;">然后我们以图表的形式显示出观察到的每个错误率值的频率。当<span class="s21">k</span>不断增长，该图表将呈现 如表 <span class="s6">5-3 </span>那样的分布。该表描述的概率分布称为二项分布（<span class="s6">Binomial distribution</span>）。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 21pt;text-indent: 173pt;text-align: left;">表 <span class="h4">5-3 </span>二项分布</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 2pt;text-align: left;"><span><img width="570" height="2" alt="image" src="机器学习/Image_145.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 19pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="547" height="1" alt="image" src="机器学习/Image_146.png"/></span></p><p class="s48" style="padding-left: 21pt;text-indent: 0pt;text-align: left;">插图——原书页码： <span class="s21">25</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-top: 1pt;padding-left: 33pt;text-indent: 0pt;text-align: left;">Binomial distribution for n=40, p=0.3: n=40<span class="p">，</span>p=0.3 <span class="p">时的二项分布</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 20pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="531" height="1" alt="image" src="机器学习/Image_147.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-top: 3pt;padding-left: 12pt;text-indent: 18pt;line-height: 12pt;text-align: left;">一个二项分布（<span class="s16">Binomial distribution</span>）给出了当单个硬币投掷出现正面的概率为 <span class="s56">p </span>时，在 <span class="s56">n </span>个独立硬币 投掷的样本中观察到 <span class="s56">r </span>次正面的概率。它由以下的概率函数定义：</p><p class="s30" style="padding-top: 4pt;padding-left: 9pt;text-indent: 0pt;line-height: 19pt;text-align: center;">P<span class="s33">(</span>r<span class="s33">) </span><span class="s38"> </span><u>n</u><u>! </u>p<span class="s83">r </span><span class="s33">(1 </span><span class="s38"> </span>p<span class="s33">)</span><span class="s83">n</span><span class="s40"></span><span class="s41">r</span></p><p class="s30" style="padding-left: 32pt;text-indent: 0pt;line-height: 12pt;text-align: center;">r<span class="s33">!(</span>n <span class="s38"> </span>r<span class="s33">)!</span></p><p class="s14" style="padding-top: 4pt;padding-left: 29pt;text-indent: 0pt;text-align: left;">如果随机变量 <span class="s56">X </span>遵循二项分布，则：</p><p class="s56" style="padding-top: 3pt;padding-left: 30pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span>X <span class="s14">取值为 </span>r <span class="s14">的概率 </span><span class="s16">Pr(</span>X<span class="s16">=</span>r<span class="s16">)</span><span class="s14">由 </span>P<span class="s16">(</span>r<span class="s16">)</span><span class="s14">给出。</span></p><p class="s56" style="padding-top: 3pt;padding-left: 29pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span>X <span class="s14">的期望值或均值 </span>E<span class="s16">[</span>X<span class="s16">]</span><span class="s14">为：</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s56" style="padding-left: 29pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span>X <span class="s14">的方差 </span>Var<span class="s16">(</span>X<span class="s16">)</span><span class="s14">为</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s56" style="padding-left: 3pt;text-indent: 0pt;text-align: left;">E<span class="s16">[</span>X<span class="s16">]=</span>np</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-left: 29pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span><span class="s56">X</span>的标准差为<span class="s177">σ</span><span class="s65">X</span>为：</p><p class="s56" style="padding-top: 4pt;padding-left: 29pt;text-indent: 0pt;text-align: left;">Var<span class="s16">(</span>X<span class="s16">)=</span>np<span class="s16">(1-</span>p<span class="s16">)</span></p><p class="s119" style="padding-top: 5pt;text-indent: 0pt;text-align: right;"> <span class="s52">X</span><span class="s41"> </span><span class="s38"></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="70" height="21" alt="image" src="机器学习/Image_148.png"/></span></p><p class="s30" style="padding-top: 5pt;padding-left: 9pt;text-indent: 0pt;text-align: left;">np<span class="s33">(1 </span><span class="s38"> </span>p<span class="s33">)</span></p><p class="s14" style="padding-top: 5pt;padding-left: 12pt;text-indent: 18pt;line-height: 12pt;text-align: left;">对于足够大的 <span class="s56">n </span>值，二项分布很接近于有同样均值和方差的正态分布（见表 <span class="s16">5-4</span>）。多数统计学家建议 只在 <span class="s56">np</span><span class="s16">(1-</span><span class="s56">p</span><span class="s16">)</span>≥<span class="s16">5 </span>时使用正态分布来近似二项分布。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 2pt;text-align: left;"><span><img width="570" height="2" alt="image" src="机器学习/Image_149.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 12pt;text-indent: 0pt;text-align: left;">5.3.2 <span class="s25">二项分布</span></h3><p style="padding-top: 10pt;padding-left: 12pt;text-indent: 21pt;line-height: 109%;text-align: left;">为较好地理解二项分布，考虑以下的问题。有一磨损并弯曲了的硬币，要估计在抛硬币 时出现正面的概率。令此未知概率为 <span class="s21">p</span>。投掷该硬币 <span class="s21">n </span>次并计算出现正面的次数 <span class="s21">r</span>。对于 <span class="s21">p </span>的一合理的估计为 <span class="s21">r</span><span class="s6">/</span><span class="s21">n</span>。注意，如果重新进行一次该实验，生成一个新的 <span class="s21">n </span>次抛硬币的集合， 其出现正面次数 <span class="s21">r </span>将与第一次实验有稍许不同，从而得到对 <span class="s21">p </span>的另一个估计。二项分布描述 的是对任一可能的 <span class="s21">r </span>值（从 <span class="s6">0 </span>到 <span class="s21">n</span>），这个正面概率为 <span class="s21">p </span>的硬币抛掷 <span class="s21">n </span>次恰好出现 <span class="s21">r </span>次正面的 概率。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 11pt;text-indent: 21pt;line-height: 16pt;text-align: justify;"><span class="p">有趣的是，从抛掷硬币的随机样本中估计</span>p<span class="p">，与在实例的随机样本上测试</span>h<span class="p">以估计</span>error<span class="s170">D</span><span class="s6">(</span>h<span class="s6">) </span><span class="p">是相同的问题。一次硬币抛掷对应于从</span><span class="s68">D</span><span class="p">中抽取一个实例并测试它是否被</span>h<span class="p">误分类。一次随 机抛掷出现正面的概率</span>p<span class="p">对应于随机抽取的实例被误分类的概率（即</span>p<span class="p">对应</span>error<span class="s170">D</span><span class="s6">(</span>h<span class="s6">)</span><span class="p">）。</span>n<span class="p">次抛 掷的样本观察到</span>r<span class="p">次正面，对应</span>n<span class="p">个抽取的实例被误分类的数目。因此</span>r<span class="s6">/</span>n<span class="p">对应</span>error<span class="s36">S</span><span class="s6">(</span>h<span class="s6">)</span><span class="p">。估计</span></p><p class="s21" style="padding-left: 6pt;text-indent: 0pt;text-align: justify;">p<span class="p">的问题等效于估计</span>error<span class="s170">D</span><span class="s6">(</span>h<span class="s6">)</span><span class="p">。二项分布给出了一个一般形式的概率分布，无论用于表示</span>n<span class="p">次 硬币出现正面的次数还是在</span>n<span class="p">个样例中假设出错的次数。二项分布的详细形式依赖于样本大 小</span>n<span class="p">以及概率</span>p<span class="p">或</span>error<span class="s170">D</span><span class="s6">(</span>h<span class="s6">)</span><span class="p">。</span></p><p style="padding-top: 11pt;padding-left: 26pt;text-indent: 0pt;text-align: left;">一般来说应用二项分布的条件包括：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: left;"><span class="s6">1.</span>有一基准实验（如投掷硬币），其输出可被描述为一随机变量 <span class="s21">Y</span>。随机变量 <span class="s21">Y </span>有两种 取值（如 <span class="s21">Y</span>＝<span class="s6">1 </span>为正面，<span class="s21">Y</span>＝<span class="s6">0 </span>反面）。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 20pt;line-height: 107%;text-align: left;"><span class="s6">2.</span>在实验的任一次尝试中 <span class="s21">Y</span><span class="s6">=1 </span>的概率为常数 <span class="s21">p</span>。它与其他的实验尝试无关。因此 <span class="s21">Y</span><span class="s6">=0 </span>的 概率为 <span class="s6">1-</span><span class="s21">p</span>。一般 <span class="s21">p </span>为预先未知的，面临的问题就在于估计它。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 27pt;text-indent: 0pt;text-align: left;"><span class="s6">3.</span>基准实验的<span class="s21">n</span>次独立尝试按序列执行，生成一个独立同分布的随机变量序列<span class="s21">Y</span><span class="s35">1</span>，<span class="s21">Y</span><span class="s35">2</span>，⋯⋯</p><p style="padding-left: 6pt;text-indent: 0pt;text-align: justify;"><span class="s21">Y</span><span class="s36">n</span>。令<span class="s21">R</span>代表<span class="s21">n</span>次试验中出现<span class="s21">Y</span><span class="s36">i</span>＝<span class="s6">1 </span>的次数：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s41" style="padding-top: 4pt;padding-left: 134pt;text-indent: 0pt;line-height: 6pt;text-align: center;">n</p><p class="s30" style="padding-left: 134pt;text-indent: 0pt;line-height: 18pt;text-align: center;">R <span class="s38"></span><span class="s33"> </span><span class="s124"></span>Y<span class="s52">i</span></p><p class="s41" style="padding-left: 134pt;text-indent: 0pt;line-height: 7pt;text-align: center;">i<span class="s40"></span><span class="s42">1</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 5pt;padding-left: 26pt;text-indent: 0pt;text-align: left;"><span class="s6">4.</span>随机变量 <span class="s21">R </span>取特定值 <span class="s21">r </span>的概率（如观察到 <span class="s21">r </span>次正面的概率）由二项分布给出：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="padding-top: 3pt;padding-left: 119pt;text-indent: 0pt;line-height: 19pt;text-align: center;"><span class="s33">Pr(</span>R <span class="s38"> </span>r<span class="s33">) </span><span class="s38"> </span><u>n</u><u>! </u>p<span class="s83">r </span><span class="s33">(1 </span><span class="s38"> </span>p<span class="s33">)</span><span class="s83">n</span><span class="s40"></span><span class="s41">r</span></p><p class="s30" style="padding-left: 119pt;text-indent: 0pt;line-height: 12pt;text-align: center;">r<span class="s33">!(</span>n <span class="s38"> </span>r<span class="s33">)!</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 48pt;text-indent: 0pt;text-align: left;">（<span class="s6">5.2</span>）</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">此概率分布的一个图表在表 <span class="s6">5-3 </span>中给出。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 107%;text-align: left;">二项分布刻画了 <span class="s21">n </span>次硬币投掷出现 <span class="s21">r </span>次正面的概率，也刻画了包含 <span class="s21">n </span>个随机样例的数据 样本出现 <span class="s21">r </span>次误分类错误的概率。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">5.3.3 <span class="s25">均值和方差</span></h3><p style="padding-top: 10pt;padding-left: 6pt;text-indent: 21pt;line-height: 113%;text-align: left;">随机变量的两个最常用到的属性为其期望值（也称为均值）和方差。期望值是重复采样 随机变量得到的值的平均。更精确的定义如下：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 27pt;text-indent: 0pt;text-align: left;"><span class="p">定义： 考虑随机变量</span>Y<span class="p">可能的取值为</span>y<span class="s35">1</span><span class="s6">…</span>y<span class="s36">n</span><span class="p">，</span>Y<span class="p">的期望值</span><span class="s6">(expected value)</span>E<span class="s6">(</span>Y<span class="s6">)</span><span class="p">为：</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s41" style="padding-top: 4pt;text-indent: 0pt;line-height: 6pt;text-align: right;">n</p><p class="s30" style="padding-left: 134pt;text-indent: 0pt;line-height: 18pt;text-align: left;">E<span class="s33">[</span>Y <span class="s33">] </span><span class="s38"> </span><span class="s124"> </span>y<span class="s52">i </span><span class="s33">Pr(</span>Y <span class="s38"> </span>y<span class="s52">i</span><span class="s41"> </span><span class="s33">)</span></p><p class="s41" style="text-indent: 0pt;line-height: 7pt;text-align: right;">i<span class="s40"></span><span class="s42">1</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 32pt;text-indent: 0pt;text-align: left;">（<span class="s6">5.3</span>）</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 26pt;text-indent: 0pt;text-align: left;">例如，如果 <span class="s21">Y </span>取值 <span class="s6">1 </span>的概率为 <span class="s6">0.7</span>，取值 <span class="s6">2 </span>的概率 <span class="s6">0.3</span>，那么期望值为（<span class="s6">1</span>·<span class="s6">0.7</span>＋<span class="s6">2</span>·<span class="s6">0.3</span></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">＝<span class="s6">1.3</span>）。如果随机变量 <span class="s21">Y </span>服从二项分布，那么可得：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s107" style="padding-top: 3pt;text-indent: 0pt;text-align: right;">E<span class="s108">[</span>Y <span class="s108">] </span><span class="s109"> </span>np</p><p style="padding-top: 2pt;padding-left: 76pt;text-indent: 0pt;text-align: left;">（<span class="s6">5.4</span>）</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 26pt;text-indent: 0pt;text-align: left;">其中 <span class="s21">n </span>和 <span class="s21">p </span>为式 <span class="s6">5.2 </span>中定义的二项分布的参数。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 113%;text-align: left;">另一重要属性方差描述的是概率分布的宽度或散度，即它描述了随机变量与其均值之间 的差有多大。</p><p style="padding-left: 27pt;text-indent: 0pt;text-align: left;">定义： 随机变量 <span class="s21">Y </span>的方差（<span class="s6">variance</span>）<span class="s21">Var</span><span class="s6">[</span><span class="s21">Y</span><span class="s6">]</span>为：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="padding-top: 3pt;padding-left: 133pt;text-indent: 0pt;text-align: left;">Var<span class="s33">[</span>Y <span class="s33">] </span><span class="s38"> </span>E<span class="s33">[(</span>Y <span class="s38"> </span>E<span class="s33">[</span>Y <span class="s33">])</span><span class="s46">2</span><span class="s42"> </span><span class="s33">]</span></p><p style="padding-top: 3pt;padding-left: 28pt;text-indent: 0pt;text-align: left;">（<span class="s6">5.5</span>）</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;text-align: left;">方差描述的是从<span class="s21">Y</span>的一个观察去估计其均值<span class="s21">E</span><span class="s6">(</span><span class="s21">Y</span><span class="s6">)</span>的误差平方的期望。方差的平方根被称 为<span class="s21">Y</span>的标准差，记为<span class="s47">σ</span><span class="s36">Y</span>。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 27pt;text-indent: 0pt;text-align: left;">定义： 随机变量<span class="s21">Y</span>的标准差（<span class="s6">standard deviation</span>）<span class="s47">σ</span><span class="s36">Y</span>为：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s119" style="padding-top: 3pt;text-indent: 0pt;text-align: right;"> <span class="s52">Y</span><span class="s41"> </span><span class="s109"></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="107" height="22" alt="image" src="机器学习/Image_150.png"/></span></p><p class="s107" style="padding-top: 3pt;padding-left: 9pt;text-indent: 0pt;text-align: left;">E<span class="s108">[(</span>Y <span class="s109"> </span>E<span class="s108">[</span>Y <span class="s108">])</span><span class="s46">2</span><span class="s42"> </span><span class="s108">]</span></p><p style="padding-top: 3pt;padding-left: 16pt;text-indent: 0pt;text-align: left;">（<span class="s6">5.6</span>）</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 26pt;text-indent: 0pt;text-align: left;">若随机变量 <span class="s21">Y </span>服从二项分布，则方差和标准差分别为：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s107" style="padding-top: 3pt;padding-left: 134pt;text-indent: 0pt;text-align: center;">Var<span class="s108">[</span>Y <span class="s108">] </span><span class="s109"> </span>np<span class="s108">(1 </span><span class="s109"> </span>p<span class="s108">)</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s119" style="padding-top: 2pt;text-indent: 0pt;text-align: right;"> <span class="s52">Y</span><span class="s41"> </span><span class="s38"></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="70" height="21" alt="image" src="机器学习/Image_151.png"/></span></p><p class="s30" style="padding-top: 3pt;padding-left: 9pt;text-indent: 0pt;text-align: left;">np<span class="s33">(1 </span><span class="s38"> </span>p<span class="s33">)</span></p><p style="padding-top: 3pt;padding-left: 23pt;text-indent: 0pt;text-align: left;">（<span class="s6">5.7</span>）</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-top: 1pt;padding-left: 27pt;text-indent: -21pt;text-align: left;">5.3.4 <span class="s25">估计量，偏差和方差</span></h3><p class="s21" style="padding-top: 10pt;padding-left: 6pt;text-indent: 21pt;text-align: left;"><span class="p">我们已得出随机变量</span>error<span class="s36">S</span><span class="s6">(</span>h<span class="s6">)</span><span class="p">服从二项分布，现在回到前面的问题：</span>error<span class="s36">S</span><span class="s6">(</span>h<span class="s6">)</span><span class="p">和真实错 误率</span>error<span class="s170">D</span><span class="s6">(</span>h<span class="s6">)</span><span class="p">之间可能的差异是多少？</span></p><p class="s6" style="padding-top: 10pt;padding-left: 26pt;text-indent: 0pt;text-align: left;"><span class="p">用式 </span>5.2 <span class="p">中二项分布的定义来描述</span><i>error</i><span class="s36">S</span>(<i>h</i>)<span class="p">和</span><i>error</i><span class="s170">D</span>(<i>h</i>)<span class="p">，可得：</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="padding-top: 10pt;text-indent: 0pt;text-align: right;">error<span class="s52">S</span></p><p class="s33" style="padding-top: 3pt;text-indent: 0pt;line-height: 19pt;text-align: left;">(<i>h</i>) <span class="s38"> </span><u><i>r</i></u></p><p class="s30" style="padding-left: 28pt;text-indent: 0pt;line-height: 12pt;text-align: left;">n</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="padding-top: 2pt;padding-left: 134pt;text-indent: 0pt;text-align: center;">error<span class="s171">D </span><span class="s33">(</span>h<span class="s33">) </span><span class="s38"> </span>p</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;text-align: justify;">其中 <span class="s21">n </span>为样本 <span class="s21">S </span>中实例数，<span class="s21">r </span>是 <span class="s21">S </span>中被 <span class="s21">h </span>误分类的实例数，<span class="s21">p </span>为从 <span class="s68">D </span>中抽取一实例被误 分类的概率。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 6pt;text-indent: 20pt;line-height: 16pt;text-align: justify;"><span class="p">统计学中将</span><i>error</i><span class="s36">S</span>(<i>h</i>)<span class="p">称为真实错误率</span><i>error</i><span class="s170">D</span>(<i>h</i>)<span class="p">的一个估计量 </span>(<i>estimator</i>)<span class="p">。一般地，估计 量是用来估计某基准总体的某一参数的随机变量。对于估计量，显然最关心的是它平均来说 是否能产生正确估计。下面定义估计偏差</span>(<i>estimation bias</i>)<span class="p">为估计量的期望值同真实参数值之 间的差异。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 27pt;text-indent: 0pt;text-align: left;">定义： 针对任意参数 <span class="s21">p </span>的估计量 <span class="s21">Y </span>的估计偏差为：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 134pt;text-indent: 0pt;text-align: center;">E<span class="s6">[</span>Y<span class="s6">]-</span>p</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 107%;text-align: justify;">如果估计偏差为 <span class="s6">0</span>，我们称 <span class="s21">Y </span>为 <span class="s21">p </span>的无偏估计量（<span class="s6">unbiased estimator</span>）。注意，在此情况 下由多次重复实验生成的 <span class="s21">Y </span>的多个随机值的平均（即 <span class="s21">E</span><span class="s6">[</span><span class="s21">Y</span><span class="s6">]</span>）将收敛于 <span class="s21">p</span>。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 6pt;text-indent: 20pt;line-height: 16pt;text-align: justify;">error<span class="s36">S</span><span class="s6">(</span>h<span class="s6">)</span><span class="p">是否为</span>error<span class="s170">D</span><span class="s6">(</span>h<span class="s6">)</span><span class="p">的一个无偏估计量？确实如此，因为对于二项分布，</span>r<span class="p">的期望值 为</span>np<span class="p">（等式</span><span class="s6">[5.4]</span><span class="p">）。由此，并且因为</span>n<span class="p">为一常数，那么</span>r<span class="s6">/</span>n<span class="p">的期望值为</span>p<span class="p">。</span></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 16pt;text-align: justify;">对估计偏差还需要作两点说明。首先，在本章开始我们提到，在训练样例上测试假设得 到的对假设错误率的估计偏于乐观化，所指的正是估计偏差。要使<span class="s21">error</span><span class="s36">S</span><span class="s6">(</span><span class="s21">h</span><span class="s6">)</span>对<span class="s21">error</span><span class="s170">D</span><span class="s6">(</span><span class="s21">h</span><span class="s6">)</span>无偏 估计，假设<span class="s21">h</span>和样本<span class="s21">S</span>必须独立选取。第二，估计偏差<span class="s6">(estimation bias)</span>这一概念不能与第二章 介绍的学习器的归纳偏置<span class="s6">(inductive bias)</span>相混淆。估计偏差为一数字量，而归纳偏置为断言 集合。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 113%;text-align: left;">估计量的另一重要属性为其方差。给定多个无偏估计量，直观上应选取其中方差最小的。 由方差的定义，所选择的应为参数值和估计值之间期望平方误差最小的。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 5pt;text-indent: 21pt;line-height: 16pt;text-align: left;"><span class="p">假如在测试一假设时，它对</span>n<span class="p">＝</span><span class="s6">40 </span><span class="p">个随机样例的样本产生</span>r<span class="p">＝</span><span class="s6">12 </span><span class="p">个错误，那么对</span>error<span class="s170">D</span><span class="s6">(</span>h<span class="s6">) </span><span class="p">的无偏估计为</span>error<span class="s36">S</span><span class="s6">(</span>h<span class="s6">)</span><span class="p">＝</span>r<span class="s6">/</span>n<span class="p">＝</span><span class="s6">0.3</span><span class="p">。估计中产生的方差完全来源于</span>r<span class="p">中的方差，因为</span>n<span class="p">为一常数。 由于</span>r<span class="p">是二项分布，它的方差由式（</span><span class="s6">5.7</span><span class="p">）为</span>np<span class="s6">(1-</span>p<span class="s6">)</span><span class="p">。然而</span>p<span class="p">未知，我们可以用估计量</span>r<span class="s6">/</span>n<span class="p">来代</span></p><p style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">替<span class="s21">p</span>。由此得出<span class="s21">r</span>的的估计方差为 <span class="s6">40</span>·<span class="s6">0.3(1-0.3)</span>＝<span class="s6">8.4</span>，或相应的标准差</p><p style="text-indent: 0pt;text-align: left;"><span><img width="31" height="17" alt="image" src="机器学习/Image_152.png"/></span></p><p style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;"><span class="s33">8.4 </span>≈<span class="s6">2.9</span>。这表示</p><p class="s6" style="padding-top: 1pt;padding-left: 5pt;text-indent: 0pt;text-align: left;"><i>error</i><span class="s36">S</span>(<i>h</i>)<span class="p">＝</span><i>r</i>/<i>n</i><span class="p">中的标准差约为 </span>2.9/40<span class="p">＝</span>0.07<span class="p">。概而言之，观察到的</span><i>error</i><span class="s36">S</span>(<i>h</i>)<span class="p">为 </span>0.3<span class="p">，标准差约 为 </span>0.07<span class="p">。（见习题 </span>5.1<span class="p">）。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 27pt;text-indent: 0pt;text-align: left;"><span class="p">一般来说，若在</span>n<span class="p">个随机选取的样本中有</span>r<span class="p">个错误，</span>error<span class="s36">S</span><span class="s41"> </span><span class="s6">(</span>h<span class="s6">)</span><span class="p">的标准差为：</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s41" style="padding-top: 10pt;text-indent: 0pt;text-align: right;"><span class="s154"></span><span class="s119"> </span>error<span class="s43">S</span><span class="s44"> </span><span class="s42">(</span>h<span class="s42">)</span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="20" height="1" alt="image" src="机器学习/Image_153.png"/></span></p><p class="s38" style="padding-top: 2pt;padding-left: 2pt;text-indent: 0pt;line-height: 21pt;text-align: center;"> <span class="s179"> </span><span class="s83">r</span><span class="s41"> </span></p><p class="s30" style="padding-left: 2pt;text-indent: 0pt;line-height: 12pt;text-align: center;">n</p><p style="text-indent: 0pt;text-align: left;"><span><img width="67" height="40" alt="image" src="机器学习/Image_154.png"/></span></p><p class="s91" style="padding-top: 3pt;padding-left: 26pt;text-indent: -17pt;line-height: 122%;text-align: left;"> p<span class="s92">(1 </span><span class="s117"> </span>p<span class="s92">) </span><span class="s30">n</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 39pt;text-indent: 0pt;text-align: left;">（<span class="s6">5.8</span>）</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-top: 1pt;padding-left: 26pt;text-indent: 0pt;text-align: left;"><span class="p">它约等于用</span>r<span class="s6">/</span>n<span class="p">＝</span>error<span class="s36">S</span><span class="s41"> </span><span class="s6">(</span>h<span class="s6">)</span><span class="p">来代替</span>p<span class="p">：</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s41" style="padding-top: 10pt;text-indent: 0pt;text-align: right;"><span class="s154"> </span>error<span class="s180">S </span><span class="s42">(</span>h<span class="s42">) </span><span class="s118"></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="166" height="41" alt="image" src="机器学习/Image_155.png"/></span></p><p class="s30" style="padding-top: 2pt;padding-left: 10pt;text-indent: 0pt;line-height: 20pt;text-align: left;">error<span class="s52">S </span><span class="s33">(</span>h<span class="s33">)(1 </span><span class="s38"> </span>error<span class="s52">S </span><span class="s33">(</span>h<span class="s33">)) </span><span class="s151">（</span><span class="s6">5.9</span><span class="p">）</span></p><p class="s30" style="padding-left: 63pt;text-indent: 0pt;line-height: 12pt;text-align: left;">n</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-top: 1pt;padding-left: 27pt;text-indent: -21pt;text-align: left;">5.3.5 <span class="s25">置信区间</span></h3><p style="padding-top: 10pt;padding-left: 6pt;text-indent: 21pt;line-height: 113%;text-align: left;">通常描述某估计的不确定性的方法是使用一置信区间，真实的值以一定的概率落入该区 间中。这样的估计称为置信区间（<span class="s6">confidence interval</span>）估计。</p><p style="padding-top: 1pt;padding-left: 26pt;text-indent: 0pt;line-height: 28pt;text-align: left;">定义： 某个参数 <span class="s21">p </span>的 <span class="s21">N</span>％置信区间是一个以 <span class="s21">N</span>％的概率包含 <span class="s21">p </span>的区间。 例如，如果在<span class="s21">n</span>＝<span class="s6">40 </span>个独立抽取的样例的样本中有<span class="s21">r</span>＝<span class="s6">12 </span>个错误，可以称区间 <span class="s6">0.3</span>±<span class="s6">0.14</span></p><p class="s6" style="padding-left: 27pt;text-indent: -21pt;line-height: 14pt;text-align: left;"><span class="p">有 </span>95<span class="p">％的可能性包含真实错误率</span><i>error</i><span class="s170">D</span>(<i>h</i>)<span class="p">。</span></p><p class="s6" style="padding-top: 10pt;padding-left: 5pt;text-indent: 21pt;line-height: 16pt;text-align: justify;"><span class="p">如何获得</span><i>error</i><span class="s170">D</span>(<i>h</i>)<span class="p">的置信区间？答案在于估计量</span><i>error</i><span class="s36">S</span>(<i>h</i>)<span class="p">服从二项分布。这一分布的均 值为</span><i>error</i><span class="s170">D</span>(<i>h</i>)<span class="p">，标准差可由式 </span>5.9 <span class="p">计算。因此，为计算 </span>95<span class="p">％置信区间，只需要找到一个以均 值</span><i>error</i><span class="s170">D</span>(<i>h</i>)<span class="p">为中心的区间，它的宽度足以包含该分布下全部概率的 </span>95<span class="p">％。等价地，它指定了 </span><i>error</i><span class="s170">D</span>(<i>h</i>)<span class="p">有 </span>95<span class="p">％的机会落入</span><i>error</i><span class="s36">S</span>(<i>h</i>)<span class="p">周围的某区间的大小。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 108%;text-align: left;">对于给定的 <span class="s21">N </span>值，如何计算区间大小以使其包含 <span class="s21">N</span>％的概率质量？对于二项分布来说 这一计算十分烦琐。然而多数情况下可以进行一近似，使计算过程更容易。这基于如下事实： 即对于足够大的样本，二项分布可以很好地由正态分布来近似。正态分布（在表 <span class="s6">5-4 </span>中概述） 是统计学中研究得最透彻的概率分布之一。如表 <span class="s6">5-4 </span>所示，正态分布是一钟形分布，由其均 值<span class="s47">μ</span>和标准差<span class="s47">σ</span>完全定义。对于大的 <span class="s21">n</span>，二项分布非常近似于一个同样均值和方差的正态分</p><p style="padding-left: 12pt;text-indent: 0pt;text-align: justify;">布。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 33pt;text-indent: 0pt;text-align: left;">之所以使用正态分布来代替，一个原因是多数统计参考都列表给出了正态分布下包含<span class="s21">N</span></p><p style="padding-top: 1pt;padding-left: 12pt;text-indent: 0pt;text-align: justify;">％的概率质量的均值周围的区间的大小。这就是计算<span class="s21">N</span>％置信区间所需的信息。实际上表 <span class="s6">5-1</span></p><p style="padding-top: 1pt;padding-left: 12pt;text-indent: 0pt;text-align: justify;">正是这样一个表。表 <span class="s6">5-1 </span>中给定的常数<span class="s21">z</span><span class="s36">N</span>定义的是在钟形正态分布下，包含<span class="s21">N</span>％概率质量的 均值周围的最小区间的宽度。更精确地说，<span class="s21">z</span><span class="s36">N</span>以标准差给定了区间的半宽度（即在任一方向 距均值的距离），图 <span class="s6">5-1(a)</span>给出了针对<span class="s21">z</span><span class="s35">80</span>的一个区间。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 21pt;text-indent: 157pt;text-align: left;">表 <span class="h4">5-4 </span>正态或高斯分布</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 2pt;text-align: left;"><span><img width="570" height="2" alt="image" src="机器学习/Image_156.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 19pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="547" height="1" alt="image" src="机器学习/Image_157.png"/></span></p><p class="s48" style="padding-left: 21pt;text-indent: 0pt;text-align: left;">插图——原书页码： <span class="s21">139</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-top: 1pt;padding-left: 33pt;text-indent: 0pt;text-align: left;">Normal distribution with mean 0, standard deviation 1<span class="p">：均值为 </span>0<span class="p">，标准差为 </span>1 <span class="p">的正态分布</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 20pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="531" height="1" alt="image" src="机器学习/Image_158.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-top: 2pt;padding-left: 30pt;text-indent: 0pt;text-align: left;">一个正态分布（也被称为高斯分布）是一钟型分布，它定义为下面的概率密度函数：</p><p class="s40" style="padding-top: 7pt;padding-left: 95pt;text-indent: 0pt;line-height: 7pt;text-align: center;"><span class="s42">1 </span>⎛<span class="s42"> </span><span class="s41">x</span><i></i><span class="s41"> </span>⎞<span class="s182">2</span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="48" height="19" alt="image" src="机器学习/Image_159.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="6" height="0" alt="image" src="机器学习/Image_160.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="18" height="0" alt="image" src="机器学习/Image_161.png"/></span></p><p class="s40" style="text-indent: 0pt;line-height: 7pt;text-align: left;">⎝</p><p style="text-indent: 0pt;text-align: left;"/><p class="s40" style="text-indent: 0pt;line-height: 7pt;text-align: left;">⎠</p><p style="text-indent: 0pt;text-align: left;"/><p class="s30" style="padding-left: 8pt;text-indent: 0pt;line-height: 18pt;text-align: center;">p<span class="s33">(</span>x<span class="s33">) </span><span class="s38"> </span><u>1 </u>e<span class="s183"> </span><span class="s46">2 </span><span class="s183">⎜ </span><span class="s184"></span><span class="s181"> </span><span class="s183">⎟</span></p><p class="s33" style="padding-left: 9pt;text-indent: 0pt;line-height: 14pt;text-align: center;">2<span class="s119"> </span><span class="s46">2</span></p><p class="s14" style="padding-top: 3pt;padding-left: 30pt;text-indent: 0pt;line-height: 131%;text-align: left;">一个正态分布由上面公式中的两个参数完全确定：<span class="s177">μ</span>和<span class="s177">σ</span>。 如果随机变量 <span class="s56">X </span>遵循正态分布，则：</p><p class="s56" style="padding-left: 30pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span>X <span class="s14">落入到</span><span class="s16">(</span>a<span class="s16">, </span>b<span class="s16">)</span><span class="s14">的概率为：</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s56" style="padding-left: 30pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span>X <span class="s14">的期望值或均值 </span>E<span class="s16">[</span>X<span class="s16">]</span><span class="s14">为：</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s41" style="padding-left: 30pt;text-indent: 0pt;line-height: 7pt;text-align: left;">b</p><p class="s30" style="padding-left: 30pt;text-indent: 0pt;line-height: 20pt;text-align: left;"><span class="s138"></span><span class="s121"> </span>p<span class="s33">(</span>x<span class="s33">)</span>dx</p><p class="s41" style="padding-left: 30pt;text-indent: 0pt;line-height: 7pt;text-align: left;">a</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s56" style="padding-left: 29pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span>X <span class="s14">的方差 </span>Var<span class="s16">(</span>X<span class="s16">)</span><span class="s14">为</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-left: 30pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span><span class="s56">X</span>的标准差为<span class="s177">σ</span><span class="s65">X</span>为：</p><p class="s56" style="padding-top: 2pt;padding-left: 33pt;text-indent: 0pt;text-align: left;">E<span class="s16">[</span>X<span class="s16">]= </span><span class="s177">μ</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s56" style="padding-left: 28pt;text-indent: 0pt;text-align: center;">Var<span class="s16">(</span>X<span class="s16">)=</span><span class="s177">σ</span><span class="s70">2</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s177" style="padding-top: 6pt;padding-left: 28pt;text-indent: 0pt;text-align: center;">σ<span class="s65">X</span><span class="s16">=</span>σ</p><p class="s14" style="padding-top: 2pt;padding-left: 30pt;text-indent: 0pt;text-align: left;">中心极限定理（<span class="s16">5.4.1 </span>节）说明大量独立同分布的随机变量的和遵循的分布近似为正态分布。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 2pt;text-align: left;"><span><img width="570" height="2" alt="image" src="机器学习/Image_162.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 19pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="547" height="1" alt="image" src="机器学习/Image_163.png"/></span></p><p class="s48" style="padding-left: 21pt;text-indent: 0pt;text-align: left;">插图——原书页码： <span class="s21">140</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 20pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="531" height="1" alt="image" src="机器学习/Image_164.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 121pt;text-indent: 0pt;text-align: left;">图 <span class="h4">5-1 </span>一个均值为 <span class="h4">0</span>，标准差为 <span class="h4">1 </span>的正态分布。</p><p class="s14" style="padding-top: 1pt;padding-left: 37pt;text-indent: 0pt;line-height: 117%;text-align: left;"><span class="s16">(a)</span>在 <span class="s16">80%</span>置信度下，随机变量值位于双侧区间<span class="s16">[-1.28, 1.28]</span>之间。注意<span class="s56">z</span><span class="s64">80</span>＝<span class="s16">1.28</span>。有 <span class="s16">10%</span>置信度其落 入区间左侧，<span class="s16">10%</span>落入区间右侧。<span class="s16">(b)</span>在 <span class="s16">90%</span>置信度下，随机变量位于单侧区间<span class="s16">[-</span>∞<span class="s16">, 1.28]</span>上。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: left;">概而言之，如果随机变量 <span class="s21">Y </span>服从正态分布，均值为<span class="s47">μ</span>，标准差为<span class="s47">σ</span>，那么 <span class="s21">Y </span>的任一观 察值 <span class="s21">y </span>有 <span class="s21">N</span><span class="s6">%</span>的机会落入下面的区间：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 27pt;text-indent: 145pt;line-height: 174%;text-align: left;"><span class="s47">μ</span>±<span class="s21">z</span><span class="s36">N</span><span class="s47">σ </span>（<span class="s6">5.10</span>） 相似地，均值<span class="s47">μ</span>有 <span class="s21">N</span><span class="s6">%</span>的机会落入下面的区间：</p><p style="padding-top: 3pt;padding-left: 26pt;text-indent: 145pt;text-align: left;"><span class="s21">y</span>±<span class="s21">z</span><span class="s36">N</span><span class="s47">σ </span>（<span class="s6">5.11</span>）</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;text-align: left;">很容易将此结论和前面的结论结合起来推导式 <span class="s6">5.1 </span>的离散值假设的<span class="s21">N</span>％置信区间的一般 表达式。首先，由于<span class="s21">error</span><span class="s36">S</span><span class="s6">(</span><span class="s21">h</span><span class="s6">)</span>遵从二项分布，其均值为<span class="s21">error</span><span class="s170">D</span><span class="s6">(</span><span class="s21">h</span><span class="s6">)</span>，标准差如式 <span class="s6">5.9 </span>所示。其次， 我们知道对于足够大的样本大小<span class="s21">n</span>，二项分布非常近似于正态分布。第三，式 <span class="s6">5.11 </span>告诉我们 如何为估计正态分布的均值求出<span class="s21">N</span>％置信区间。因此，将<span class="s21">error</span><span class="s36">S</span><span class="s6">(</span><span class="s21">h</span><span class="s6">)</span>的均值和标准差代入到式 <span class="s6">5.11 </span>中将得到式 <span class="s6">5.1 </span>中对离散值假设的<span class="s21">N</span>％置信区间为：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="padding-top: 11pt;text-indent: 0pt;text-align: right;">error<span class="s52">S</span></p><p class="s33" style="padding-top: 10pt;text-indent: 0pt;text-align: left;">(<i>h</i>) <span class="s38"> </span><i>z </i><span class="s52">N</span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="166" height="41" alt="image" src="机器学习/Image_165.png"/></span></p><p class="s30" style="padding-top: 2pt;padding-left: 9pt;text-indent: 0pt;text-align: center;">error<span class="s52">S</span><span class="s41"> </span><span class="s33">(</span>h<span class="s33">)(1 </span><span class="s38"> </span>error<span class="s52">S</span><span class="s41"> </span><span class="s33">(</span>h<span class="s33">))</span></p><p class="s30" style="padding-top: 1pt;padding-left: 9pt;text-indent: 0pt;text-align: center;">n</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">回忆一下，在表达式的推导中有两个近似化：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 6pt;text-indent: 21pt;line-height: 16pt;text-align: justify;">1.<span class="p">估计</span><i>error</i><span class="s36">S</span>(<i>h</i>)<span class="p">的标准差</span><span class="s47">σ</span><span class="p">时，我们将</span><i>error</i><span class="s170">D</span>(<i>h</i>)<span class="p">近似为</span><i>error</i><span class="s36">S</span>(<i>h</i>)<span class="p">（即从式 </span>5.8 <span class="p">到式 </span>5.9 <span class="p">的推 导）。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 27pt;text-indent: 0pt;text-align: left;">2.<span class="p">二项分布由正态分布近似。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 107%;text-align: justify;">统计学中的一般规则表明，这两个近似在 <span class="s21">n</span>≥<span class="s6">30 </span>或 <span class="s21">np</span><span class="s6">(1-</span><span class="s21">p</span><span class="s6">)</span>≥<span class="s6">5 </span>时工作得很好。对于较小 的 <span class="s21">n </span>值，最好使用列表的形式给出二项分布的具体值。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">5.3.6 <span class="s25">双侧和单侧边界</span></h3><p class="s21" style="padding-top: 10pt;padding-left: 6pt;text-indent: 21pt;text-align: justify;"><span class="p">上述的置信区间是双侧的，即它规定了估计量的上界和下界。在某些情况下，可能要用 到单侧边界。例如，提出问题“</span>error<span class="s170">D</span><span class="s6">(</span>h<span class="s6">)</span><span class="p">至多为</span>U<span class="p">的概率”。在只要限定</span>h<span class="p">的最大错误率，而 不在乎真实错误率是否小于估计错误率时，很自然会提出这种问题。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 106%;text-align: right;">只要对上述的过程作一小的修改就可计算单侧错误率边界。它所基于的事实为正态分布 关于其均值对称。因此，任意正态分布上的双侧置信区间能够转换为相应的单侧区间，置信 度为原来的两倍。（见图 <span class="s6">5-1(b)</span>）。换言之，由一个有下界 <span class="s21">L </span>和上界 <span class="s21">U </span>的 <span class="s6">100(1-</span><span class="s47">α</span><span class="s6">)%</span>置信区 间，可得到一个下界为 <span class="s21">L </span>无上界的 <span class="s6">100(1-</span><span class="s47">α</span><span class="s6">/2)%</span>置信区间，同时也可得出一个有上界 <span class="s21">U </span>无 下界的 <span class="s6">100(1-</span><span class="s47">α</span><span class="s6">/2)%</span>置信区间。这里<span class="s47">α</span>对应于真实值落在指定区间外的概率。换句话说，<span class="s47">α </span>是真实值落入图 <span class="s6">5-1(a)</span>中无阴影部分的概率，<span class="s47">α</span><span class="s6">/2 </span>是落入图 <span class="s6">5-1</span>（<span class="s6">b</span>）的无阴影部分的概率。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s185" style="text-indent: 0pt;line-height: 6pt;text-align: left;">D</p><p style="text-indent: 0pt;text-align: left;"/><p class="s6" style="padding-left: 5pt;text-indent: 21pt;text-align: justify;"><span class="p">为说明这一点，再次考虑</span><i>h</i><span class="p">产生</span><i>r</i>=12 <span class="p">个错误且样本大小</span><i>n</i>=40 <span class="p">的这个例子。如上所述，它 导致一个双侧的 </span>95<span class="p">％置信区间 </span>0.3<span class="p">±</span>0.14<span class="p">。其中 </span>100(1-<span class="s47">α</span>)=95<span class="p">％，所以</span><span class="s47">α</span><span class="p">＝</span>0.05<span class="p">。因此，应 用以上规则，可得有 </span>100(1-<span class="s47">α</span>/2)<span class="p">＝</span>97.5<span class="p">％的置信度</span><i>error </i>(<i>h</i>)<span class="p">最多为 </span>0.30<span class="p">＋</span>0.14<span class="p">＝</span>0.44<span class="p">，而不管</span></p><p class="s6" style="padding-left: 5pt;text-indent: 0pt;line-height: 16pt;text-align: left;"><i>error</i><span class="s170">D</span>(<i>h</i>)<span class="p">的下界。因此在</span><i>error</i><span class="s170">D</span>(<i>h</i>)<span class="p">上的单侧错误率边界比相应的双侧边界有双倍的置信度（见 习题 </span>5.3<span class="p">）。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">5.4 <span class="s17">推导置信区间的一般方法</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 5pt;text-indent: 21pt;text-align: justify;"><span class="p">前一节介绍的是针对一特定情况推导置信区间估计：基于独立抽取的</span>n<span class="p">样本，估计离散 值假设的</span>error<span class="s170">D</span><span class="s6">(</span>h<span class="s6">)</span><span class="p">。本节介绍的方法是在许多估计问题中用到的通用的方法。确切地讲，我 们可以将此看作是基于大小为</span>n<span class="p">的随机抽取样本的均值，来估计总体均值的问题。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 27pt;text-indent: 0pt;text-align: left;">通用的过程包含以下步骤：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 27pt;text-indent: 0pt;text-align: left;"><span class="s6">1.</span><span class="p">确定基准总体中要估计的参数</span>p<span class="p">，例如</span>error<span class="s170">D</span><span class="s6">(</span>h<span class="s6">)</span><span class="p">。</span></p><p class="s21" style="padding-top: 11pt;padding-left: 26pt;text-indent: 0pt;text-align: left;"><span class="s6">2.</span><span class="p">定义一个估计量</span>Y<span class="p">（如</span>error<span class="s36">S</span><span class="s6">(</span>h<span class="s6">)</span><span class="p">）它的选择应为最小方差的无偏估计量。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 26pt;text-indent: 0pt;text-align: left;"><span class="s6">3.</span>确定估计量所服从的概率分布<span class="s68">D</span><span class="s36">Y</span>，包括其均值和方差。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 26pt;text-indent: 0pt;text-align: left;"><span class="s6">4.</span>确定<span class="s21">N</span>％置信区间，通过寻找阈值<span class="s21">L</span>和<span class="s21">U</span>以使这个按<span class="s68">D</span><span class="s36">Y</span>分布的随机变量有<span class="s21">N</span>％机会落入<span class="s21">L</span></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">和<span class="s21">U</span>之间。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 113%;text-align: justify;">后面的几节将应用该通用的方法到其他几种机器学习中常见的估计问题。首先我们需要 讨论估计理论的一个基本成果，称为中心极限定理<span class="s6">(Central Limit Theorem)</span>。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">5.4.1 <span class="s25">中心极限定理</span></h3><p style="padding-top: 10pt;padding-left: 6pt;text-indent: 21pt;text-align: justify;">中心极限定理是简化置信区间的推导的一个基本根据。考虑如下的一般框架：在<span class="s21">n</span>个独 立抽取的且服从同样概率分布的随机变量<span class="s21">Y</span><span class="s35">1</span>⋯<span class="s21">Y</span><span class="s36">n</span>中观察实验值（如同一硬币的<span class="s21">n</span>次抛掷）。令 <span class="s47">μ</span>代表每一变量<span class="s21">Y</span><span class="s36">i</span>服从的未知分布的均值，并令<span class="s47">σ</span>代表标准差。称这些变量<span class="s21">Y</span><span class="s36">i</span>为独立同分布 <span class="s6">(independent, identically distributed)</span>随机变量，因为它们描述的是各自独立并且服从同样概率</p><p class="s41" style="text-indent: 0pt;line-height: 18pt;text-align: left;">n              <span class="s135"></span><span class="s136">    </span>i</p><p style="text-indent: 0pt;text-align: left;"/><p class="s108" style="padding-top: 1pt;text-indent: 0pt;line-height: 6pt;text-align: right;">1 <span class="s41">n</span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="9" height="1" alt="image" src="机器学习/Image_166.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="11" height="1" alt="image" src="机器学习/Image_167.png"/></span></p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 12pt;text-align: left;">分布的实验。为估计<span class="s21">Y</span><span class="s36">i</span>服从的分布的均值<span class="s47">μ</span>，我们计算样本的值 <span class="s107">Y </span><span class="s109"> </span><span class="s107">Y </span>（如<span class="s21">n</span>次投掷</p><p class="s186" style="text-indent: 0pt;line-height: 12pt;text-align: right;">n<span class="s107"> </span><span class="s41">i</span><span class="s40"></span><span class="s42">1</span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="9" height="1" alt="image" src="机器学习/Image_168.png"/></span></p><p style="padding-left: 6pt;text-indent: 0pt;text-align: left;">硬币中出现正面的比例）。中心极限定理说明在<span class="s21">n</span>→∞时 <span class="s107">Y</span><span class="s52">n</span><span class="s41"> </span>所服从的概率分布为一正态分布，</p><p style="text-indent: 0pt;text-align: left;"><span><img width="9" height="1" alt="image" src="机器学习/Image_169.png"/></span></p><p class="s119" style="text-indent: 0pt;line-height: 11pt;text-align: right;"></p><p style="text-indent: 0pt;text-align: left;"><span><img width="23" height="20" alt="image" src="机器学习/Image_170.png"/></span></p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 12pt;text-align: left;">而不论<span class="s21">Y</span><span class="s36">i</span>本身服从什么样的分布。更进一步，<span class="s107">Y</span><span class="s52">n </span>服从的分布均值为<span class="s47">μ</span>而且标准差为 ，精</p><p class="s30" style="padding-left: 6pt;text-indent: 385pt;line-height: 11pt;text-align: left;">n</p><p style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">确的定义如下：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="9" height="1" alt="image" src="机器学习/Image_171.png"/></span></p><p class="s14" style="padding-top: 2pt;padding-left: 48pt;text-indent: 0pt;text-align: left;">定理 <span class="s187">5.1</span>：中心极限定理。考虑独立同分布的随机变量<span class="s56">Y</span><span class="s64">1</span><span class="s16">…</span><span class="s56">Y</span><span class="s65">n</span>的集合，它们服从一任意的概率分</p><p class="s41" style="text-indent: 0pt;line-height: 7pt;text-align: left;">n</p><p style="text-indent: 0pt;text-align: left;"/><p class="s14" style="padding-top: 7pt;padding-left: 26pt;text-indent: 0pt;text-align: left;">布，均值为<span class="s177">μ</span>，有限方差<span class="s177">σ</span><span class="s70">2</span>。定义样本均值 <span class="s107">Y</span></p><p class="s135" style="text-indent: 0pt;line-height: 18pt;text-align: left;"></p><p style="text-indent: 0pt;text-align: left;"/><p class="s108" style="padding-left: 13pt;text-indent: 0pt;line-height: 10pt;text-align: left;">1 <span class="s41">n</span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="11" height="1" alt="image" src="机器学习/Image_172.png"/></span></p><p class="s109" style="padding-left: 2pt;text-indent: 0pt;line-height: 8pt;text-align: left;"> <span class="s107">Y</span></p><p class="s186" style="padding-left: 13pt;text-indent: 0pt;line-height: 13pt;text-align: left;">n <span class="s41">i</span><span class="s40"></span><span class="s42">1 </span><span class="s166">i</span></p><p class="s14" style="padding-top: 8pt;padding-left: 1pt;text-indent: 0pt;text-align: left;">。则当<span class="s56">n</span>→∞时下面的式子</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 220pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="9" height="1" alt="image" src="机器学习/Image_173.png"/></span></p><p class="s30" style="padding-left: 121pt;text-indent: 0pt;line-height: 13pt;text-align: center;">Y<span class="s52">n </span><span class="s38"> </span><span class="s119"></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="22" height="20" alt="image" src="机器学习/Image_174.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="43" height="1" alt="image" src="机器学习/Image_175.png"/></span></p><p class="s119" style="padding-left: 120pt;text-indent: 0pt;line-height: 15pt;text-align: center;"></p><p class="s30" style="padding-top: 4pt;padding-left: 129pt;text-indent: 0pt;text-align: center;">n</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-top: 2pt;padding-left: 47pt;text-indent: 0pt;text-align: left;">服从一正态分布，均值为 <span class="s16">0 </span>且标准差为 <span class="s16">1</span>。</p><p style="text-indent: 0pt;text-align: left;"><span><img width="9" height="1" alt="image" src="机器学习/Image_176.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="9" height="1" alt="image" src="机器学习/Image_177.png"/></span></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: left;">这一结论非常令人吃惊，因为它说明在不知道独立的<span class="s21">Y</span><span class="s36">i</span>所服从的基准分布的情况下，我 们可以得知样本均值 <span class="s30">Y </span>的分布形式。更进一步，中心极限定理说明了怎样使用 <span class="s30">Y </span>的均值和</p><p style="padding-top: 3pt;padding-left: 26pt;text-indent: -21pt;text-align: left;">方差来确定单独的<span class="s21">Y</span><span class="s36">i</span>的均值和方差。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 20pt;line-height: 106%;text-align: left;">中心极限定理是一个非常有用的结论，因为它表示任意样本均值的估计量（如<span class="s21">error</span><span class="s36">S</span><span class="s6">(</span><span class="s21">h</span><span class="s6">) </span>为均值错误率）服从的分布在<span class="s21">n</span>足够大时可近似为正态分布。如果还知道这一近似的正态分 布的方差，就可用式 <span class="s6">5.11 </span>来计算置信区间。一个通常的规则是在<span class="s21">n</span>≥<span class="s6">30 </span>时可使用这一近似。 前面的章节我们正是使用了正态分布来近似地描述<span class="s21">error</span><span class="s36">S</span><span class="s6">(</span><span class="s21">h</span><span class="s6">)</span>服从的二项分布。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 5pt;text-indent: 0pt;text-align: left;">5.5 <span class="s17">两假设错误率间的差异</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;text-align: justify;">现考虑对某离散目标函数有两个假设<span class="s21">h</span><span class="s35">1</span>和<span class="s21">h</span><span class="s35">2</span>。假设<span class="s21">h</span><span class="s35">1</span>在一拥有<span class="s21">n</span><span class="s35">1</span>个独立抽取样例的样本 <span class="s21">S</span><span class="s35">1</span>上测试，且<span class="s21">h</span><span class="s35">2</span>在<span class="s21">n</span><span class="s35">2</span>个同样抽取的样例的样本<span class="s21">S</span><span class="s35">2</span>上测试。假定要估计这两个假设的真实错误 率间的差异：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="padding-top: 2pt;padding-left: 157pt;text-indent: 0pt;text-align: left;">d <span class="s38"> </span>error<span class="s171">D </span><span class="s33">(</span>h<span class="s79">1 </span><span class="s33">) </span><span class="s38"> </span>error<span class="s171">D </span><span class="s33">(</span>h<span class="s79">2</span><span class="s42"> </span><span class="s33">)</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;text-align: left;">可使用节 <span class="s6">5.4 </span>中描述的四步骤来推导 <span class="s21">d </span>的置信区间估计。在确定 <span class="s21">d </span>为待估计的参数后， 下面要定义一估计量。很显然，这里可选择样本错误率之间的差异作为估计量，标记为 <span class="s30">d</span><span class="s31">ˆ</span><span class="s33"> </span>：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="padding-top: 3pt;text-indent: 0pt;line-height: 12pt;text-align: right;">d<span class="s31">ˆ </span><span class="s38"> </span>error</p><p class="s33" style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;line-height: 9pt;text-align: left;">(<i>h </i>) <span class="s38"> </span><i>error</i></p><p class="s33" style="padding-top: 7pt;padding-left: 6pt;text-indent: 0pt;line-height: 9pt;text-align: left;">(<i>h </i>)</p><p class="s41" style="text-indent: 0pt;line-height: 9pt;text-align: right;">S<span class="s188">1</span><span class="s189"> </span><span class="s42">1</span></p><p class="s41" style="padding-left: 39pt;text-indent: 0pt;line-height: 9pt;text-align: left;">S<span class="s188">2</span><span class="s189"> </span><span class="s42">2</span></p><p class="s30" style="padding-top: 13pt;padding-left: 26pt;text-indent: 0pt;text-align: left;"><span class="p">在此不加证明地使用 </span>d<span class="s31">ˆ</span><span class="s33"> </span><span class="p">即为 </span><span class="s21">d </span><span class="p">的无偏估计量，即 </span>E<span class="s33">[</span>d<span class="s31">ˆ</span><span class="s33">] </span><span class="s38"> </span>d <span class="p">。</span></p><p style="padding-top: 13pt;padding-left: 5pt;text-indent: 21pt;line-height: 17pt;text-align: left;">随机变量 <span class="s30">d</span><span class="s31">ˆ</span><span class="s33"> </span>服从的概率分布是什么？从前面的章节中，我们知道对于较大的<span class="s21">n</span><span class="s35">1</span>和<span class="s21">n</span><span class="s35">2</span>（比</p><p class="s21" style="padding-left: 5pt;text-indent: 0pt;line-height: 3pt;text-align: left;"><span class="p">如都≥</span><span class="s6">30</span><span class="p">），</span>error<span class="s36">S</span><span class="s178">1 </span>h<span class="s35">1</span><span class="s6">)</span><span class="p">和</span>error<span class="s36">S</span><span class="s178">2</span><span class="s42"> </span>h<span class="s35">2</span><span class="s6">)</span><span class="p">都近似遵从正态分布。由于两正态分布的差仍为一正态分</span></p><p class="s6" style="padding-left: 90pt;text-indent: 0pt;line-height: 11pt;text-align: left;">( (</p><p class="s21" style="padding-top: 2pt;padding-left: 5pt;text-indent: 0pt;line-height: 14pt;text-align: left;"><span class="p">布，因此 </span><span class="s30">d</span><span class="s31">ˆ </span><span class="p">也近似遵从正态分布，均值为</span>d<span class="p">。同时，可得该分布的方差为</span>error<span class="s36">S </span><span class="s6">(</span>h<span class="s35">1</span><span class="s6">)</span><span class="p">和</span>error<span class="s36">S</span><span class="s41"> </span><span class="s6">(</span>h<span class="s35">2</span><span class="s6">)</span></p><p class="s42" style="text-indent: 0pt;line-height: 7pt;text-align: right;">1 2</p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 14pt;text-align: left;">的方差的和。使用式 <span class="s6">5.9 </span>获得这两个分布的近似方差，有：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="padding-top: 2pt;padding-left: 63pt;text-indent: 0pt;line-height: 12pt;text-align: left;">error <span class="s33">(</span>h <span class="s33">)(1 </span><span class="s38"> </span>error <span class="s33">(</span>h <span class="s33">)) </span>error</p><p class="s41" style="padding-left: 35pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span class="s190"> </span><span class="s35">2 </span><span class="s191"> </span>S <span class="s42">1 </span>S <span class="s42">1 </span><span class="s191"></span><span class="s38"> </span>S</p><p class="s33" style="padding-top: 2pt;padding-left: 3pt;text-indent: 0pt;line-height: 13pt;text-align: left;">(<i>h</i><span class="s79">2 </span>)(1 <span class="s38"> </span><i>error</i><span class="s52">S</span></p><p class="s33" style="padding-top: 3pt;padding-left: 3pt;text-indent: 0pt;line-height: 12pt;text-align: left;">(<i>h</i><span class="s79">2</span><span class="s42"> </span>))</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 35pt;text-indent: 0pt;line-height: 3pt;text-align: left;">（<span class="s6">5.12</span>）</p><p class="s189" style="padding-left: 24pt;text-indent: 0pt;line-height: 5pt;text-align: center;">1 1 2 2</p><p style="text-indent: 0pt;text-align: left;"><span><img width="169" height="1" alt="image" src="机器学习/Image_178.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="175" height="1" alt="image" src="机器学习/Image_179.png"/></span></p><p class="s30" style="text-indent: 0pt;line-height: 12pt;text-align: left;">n</p><p style="text-indent: 0pt;text-align: left;"/><p class="s30" style="text-indent: 0pt;line-height: 12pt;text-align: left;">n</p><p style="text-indent: 0pt;text-align: left;"/><p class="s192" style="padding-left: 44pt;text-indent: 0pt;line-height: 10pt;text-align: left;">d<span class="s42">ˆ</span></p><p class="s42" style="padding-left: 24pt;text-indent: 0pt;line-height: 8pt;text-align: center;">1 2</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 3pt;padding-left: 26pt;text-indent: 0pt;text-align: left;">现在已确定了估计量 <span class="s30">d</span><span class="s31">ˆ</span><span class="s33"> </span>所服从的概率分布，很容易导出置信区间以说明使用 <span class="s30">d</span><span class="s31">ˆ</span><span class="s33"> </span>来估计<span class="s21">d</span></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">的可能误差。随机变量 <span class="s30">d</span><span class="s31">ˆ</span><span class="s33"> </span>服从均值<span class="s21">d</span>方差<span class="s47">σ</span><span class="s46">2</span>的正态分布，其<span class="s21">N</span>％置信区间估计为 <span class="s30">d</span><span class="s31">ˆ</span><span class="s33"> </span><span class="s38"> </span><span class="s30">z</span></p><p class="s42" style="text-indent: 0pt;line-height: 7pt;text-align: left;">ˆ</p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 13pt;text-align: left;">使用上面给出的方差<span class="s119"> </span><span class="s46">2</span><span class="s42"> </span>的近似值，<span class="s21">d</span>的近似的<span class="s21">N</span>％置信区间估计为：</p><p class="s41" style="padding-left: 110pt;text-indent: 0pt;line-height: 6pt;text-align: left;">d</p><p class="s52" style="padding-top: 2pt;text-indent: 0pt;text-align: left;">N <span class="s119"> </span><span class="p">。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s41" style="text-indent: 0pt;line-height: 7pt;text-align: left;">N</p><p style="text-indent: 0pt;text-align: left;"/><p class="s30" style="padding-top: 9pt;padding-left: 43pt;text-indent: 0pt;line-height: 14pt;text-align: left;">d<span class="s31">ˆ </span><span class="s38"> </span>z</p><p style="text-indent: 0pt;text-align: left;"><span><img width="372" height="46" alt="image" src="机器学习/Image_180.png"/></span></p><p class="s30" style="padding-top: 2pt;padding-left: 17pt;text-indent: 0pt;line-height: 13pt;text-align: center;">error<span class="s52">S </span><span class="s33">(</span>h<span class="s79">1 </span><span class="s33">)(1 </span><span class="s38"> </span>error<span class="s52">S </span><span class="s33">(</span>h<span class="s79">1 </span><span class="s33">)) </span>error<span class="s52">S </span><span class="s33">(</span>h<span class="s79">2 </span><span class="s33">)(1 </span><span class="s38"> </span>error<span class="s52">S </span><span class="s33">(</span>h<span class="s79">2</span><span class="s42"> </span><span class="s33">))</span></p><p class="s189" style="padding-left: 17pt;text-indent: 0pt;line-height: 8pt;text-align: center;">1 1 <span class="s94"> </span>2 2</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 27pt;text-indent: 0pt;line-height: 10pt;text-align: left;">(5.13)</p><p class="s30" style="padding-left: 142pt;text-indent: 0pt;line-height: 14pt;text-align: left;">n<span class="s79">1</span><span class="s42"> </span>n<span class="s79">2</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;line-height: 108%;text-align: justify;">其中<span class="s21">z</span><span class="s36">N</span>是表 <span class="s6">5-1 </span>中描述的常数。上式给出了一般的双侧置信区间，以估计两个假设错误 率之间的差异。有时可能需要某一置信度下的单侧的边界——要么界定最大可能差异，要么 为最小的。单侧置信区间可以用 <span class="s6">5.3.6 </span>节中描述的方法来修改上式而得到。</p><p style="padding-left: 5pt;text-indent: 21pt;text-align: left;">虽然上面的分析考虑到了<span class="s21">h</span><span class="s35">1</span>和<span class="s21">h</span><span class="s35">2</span>在相互独立的数据样本上测试，更通常的情况是在一个 样本<span class="s21">S</span>（<span class="s21">S</span>仍然独立于<span class="s21">h</span><span class="s35">1</span>和<span class="s21">h</span><span class="s35">2</span>）。这样， <span class="s30">d</span><span class="s31">ˆ</span><span class="s33"> </span>被重新定义为：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="padding-top: 3pt;text-indent: 0pt;line-height: 12pt;text-align: right;">d<span class="s31">ˆ </span><span class="s38"> </span>error</p><p class="s33" style="padding-top: 6pt;padding-left: 3pt;text-indent: 0pt;line-height: 9pt;text-align: left;">(<i>h </i>) <span class="s38"> </span><i>error </i>(<i>h </i>)</p><p class="s41" style="padding-left: 140pt;text-indent: 0pt;line-height: 7pt;text-align: center;">S <span class="s42">1 </span>S <span class="s42">2</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 3pt;padding-left: 5pt;text-indent: 21pt;text-align: justify;">当使用<span class="s21">S</span>来代替<span class="s21">S</span><span class="s35">1</span>和<span class="s21">S</span><span class="s35">2</span>时，新的 <span class="s30">d</span><span class="s31">ˆ</span><span class="s33"> </span>中的方差通常小于 <span class="s6">5.12 </span>式给出的方差。这是因为，使 用单个的样本<span class="s21">S</span>消除了由<span class="s21">S</span><span class="s35">1</span>和<span class="s21">S</span><span class="s35">2</span>的组合带来的随机差异。这样，由式 <span class="s6">5.13 </span>给出的置信区间一 般说来会过于保守，但仍然是正确的。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">5.5.1 <span class="s25">假设检验</span></h3><p class="s21" style="padding-top: 10pt;padding-left: 6pt;text-indent: 21pt;line-height: 113%;text-align: justify;"><span class="p">有时我们感兴趣的是某特定的猜想正确的概率，而不是对某参数的区间估计。比如下面 的问题“</span>error<span class="s170">D</span><span class="s6">(</span>h<span class="s35">1</span><span class="s6">)&gt;</span>error<span class="s170">D</span><span class="s6">(</span>h<span class="s35">2</span><span class="s6">)</span><span class="p">的可能性有多大？”。仍使用前一节的条件设定，假定要测量</span>h<span class="s35">1</span></p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 1pt;text-align: left;">和<span class="s21">h</span><span class="s35">2</span>的样本错误率，使用大小为 <span class="s6">100 </span>的独立样本<span class="s21">S</span><span class="s35">1</span>和<span class="s21">S</span><span class="s35">2</span>，并且知道<span class="s21">error</span><span class="s36">S</span><span class="s178">1</span><span class="s42"> </span><span class="s21">h</span><span class="s35">1</span><span class="s6">)</span>＝<span class="s6">0.30 </span>且<span class="s21">error</span><span class="s36">S</span><span class="s178">2</span><span class="s42"> </span><span class="s21">h</span><span class="s35">2</span><span class="s6">)</span></p><p class="s6" style="text-indent: 0pt;line-height: 10pt;text-align: right;">( (</p><p class="s6" style="padding-top: 2pt;padding-left: 5pt;text-indent: 0pt;line-height: 13pt;text-align: left;"><span class="p">＝</span>0.20<span class="p">，因此差异 </span><span class="s30">d</span><span class="s31">ˆ</span><span class="s33"> </span><span class="p">为 </span>0.10<span class="p">。当然，由于数据样本的随机性，即使</span><i>error </i>(<i>h</i><span class="s35">1</span>)<span class="p">≤ </span><i>error </i>(<i>h</i><span class="s35">2</span>)<span class="p">，</span></p><p class="s185" style="text-indent: 0pt;line-height: 5pt;text-align: right;">D</p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 12pt;text-align: left;">仍有可能得到这样的差异。在这里，给定样本错误率 <span class="s30">d</span><span class="s31">ˆ</span><span class="s33"> </span>＝<span class="s6">0.10</span>，<span class="s21">error </span><span class="s6">(</span><span class="s21">h</span><span class="s35">1</span><span class="s6">)&gt;</span><span class="s21">error</span></p><p class="s185" style="padding-left: 4pt;text-indent: 0pt;line-height: 6pt;text-align: center;">D</p><p class="s6" style="padding-left: 4pt;text-indent: 0pt;line-height: 11pt;text-align: center;">(<i>h</i><span class="s35">2</span>)<span class="p">的概率</span></p><p class="s185" style="text-indent: 0pt;line-height: 5pt;text-align: right;">D D</p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 17pt;text-align: left;">是多少？等价地，如何计算在 <span class="s30">d</span><span class="s31">ˆ</span><span class="s33"> </span>＝<span class="s6">0.10 </span>时<span class="s21">d</span><span class="s6">&gt;0 </span>的概率？</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s42" style="text-indent: 0pt;line-height: 7pt;text-align: left;">ˆ</p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-top: 3pt;padding-left: 5pt;text-indent: 21pt;text-align: left;">注意概率 <span class="s6">Pr(</span><span class="s21">d</span>＞<span class="s6">0)</span>等于 <span class="s30">d</span><span class="s31">ˆ</span><span class="s33"> </span>过高估计 <span class="s21">d </span>不多于 <span class="s6">0.1 </span>的概率。也即，这个概率为 <span class="s30">d</span><span class="s31">ˆ</span><span class="s33"> </span>落入单侧 区间 <span class="s30">d</span><span class="s193">ˆ</span><span class="s33"> </span><span class="s6">&lt;</span><span class="s21">d</span><span class="s6">+0.10 </span>的概率。由于 <span class="s21">d </span>是 <span class="s30">d</span><span class="s193">ˆ</span><span class="s33"> </span>所服从分布的均值，上式等价于 <span class="s30">d</span><span class="s31">ˆ</span><span class="s33"> </span><span class="s38"> </span><span class="s119"> </span><span class="s38"> </span><span class="s33">0.10 </span>。</p><p class="s41" style="text-indent: 0pt;line-height: 3pt;text-align: right;">d</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s42" style="text-indent: 0pt;line-height: 7pt;text-align: left;">ˆ</p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-top: 4pt;padding-left: 27pt;text-indent: 0pt;line-height: 16pt;text-align: left;">概括地说，概率 <span class="s6">Pr(</span><span class="s21">d</span>＞<span class="s6">0)</span>等于 <span class="s30">d</span><span class="s193">ˆ</span><span class="s33"> </span>落入单侧区间 <span class="s30">d</span><span class="s31">ˆ</span><span class="s33"> </span><span class="s38"> </span><span class="s119"> </span><span class="s38"> </span><span class="s33">0.10 </span>的概率。由于前一节我们</p><p class="s41" style="padding-left: 160pt;text-indent: 0pt;line-height: 6pt;text-align: center;">d</p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">已计算出 <span class="s30">d</span><span class="s31">ˆ</span><span class="s33"> </span>的大致分布，就可以通过 <span class="s30">d</span><span class="s31">ˆ</span><span class="s33"> </span>分布在该区间的概率质量来确定 <span class="s30">d</span><span class="s31">ˆ</span><span class="s33"> </span>落入这个单侧区 间的概率。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s42" style="text-indent: 0pt;line-height: 7pt;text-align: left;">ˆ</p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-left: 26pt;text-indent: 0pt;line-height: 15pt;text-align: left;">首先将区间 <span class="s30">d</span><span class="s31">ˆ </span><span class="s38"> </span><span class="s119"> </span><span class="s38"> </span><span class="s33">0.10 </span>表示为允许从均值偏离的标准差数。使用式 <span class="s6">5.12 </span>可得</p><p class="s41" style="padding-left: 113pt;text-indent: 0pt;line-height: 6pt;text-align: left;">d</p><p class="s194" style="text-indent: 0pt;line-height: 7pt;text-align: left;">ˆ</p><p style="text-indent: 0pt;text-align: left;"/><p class="s119" style="padding-left: 6pt;text-indent: 0pt;line-height: 13pt;text-align: left;"> <span class="s109"> </span><span class="s108">0.061 </span><span class="p">，所以这一区间可近似表示为</span></p><p class="s129" style="padding-left: 16pt;text-indent: 0pt;line-height: 5pt;text-align: left;">d</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s38" style="padding-top: 4pt;padding-left: 24pt;text-indent: 0pt;line-height: 14pt;text-align: center;"><span class="s30">d</span><span class="s31">ˆ </span> <span class="s119"> </span><span class="s120">ˆ </span> <span class="s33">1.64</span><span class="s119"> </span><span class="s120">ˆ</span></p><p class="s41" style="padding-left: 128pt;text-indent: 0pt;line-height: 7pt;text-align: center;">d d</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: left;">与此正态分布的单侧区间相关联的置信度是多少？查表 <span class="s6">5-1</span>，可得均值周围的 <span class="s6">1.64 </span>标准 差对应置信度 <span class="s6">90</span>％的双侧区间。因此这个单侧区间具有置信度 <span class="s6">95</span>％。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 26pt;text-indent: 0pt;line-height: 13pt;text-align: left;"><span class="p">因此，给定观察到的 </span><span class="s30">d</span><span class="s31">ˆ </span><span class="p">＝</span>0.1<span class="p">，</span><i>error </i>(<i>h</i><span class="s35">1</span>)&gt;<i>error </i>(<i>h</i><span class="s35">2</span>)<span class="p">的概率约为 </span>0.95<span class="p">。根据统计学的术语，</span></p><p class="s185" style="padding-left: 24pt;text-indent: 0pt;line-height: 6pt;text-align: center;">D D</p><p class="s6" style="padding-left: 5pt;text-indent: 0pt;line-height: 15pt;text-align: left;"><span class="p">可表述为：接受（</span>accept<span class="p">）“</span><i>error</i><span class="s170">D</span>(<i>h</i><span class="s35">1</span>)&gt;<i>error</i><span class="s170">D</span>(<i>h</i><span class="s35">2</span>)<span class="p">”这一假设，置信度为 </span>0.95<span class="p">。换一种说法，</span></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 107%;text-align: left;">可表述为我们拒绝（<span class="s6">reject</span>）对立假设（常称为零假设），以<span class="s6">(1-0.95)=0.05 </span>的效度（<span class="s6">significance level</span>）。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">5.6 <span class="s17">学习算法比较</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 108%;text-align: justify;">有时我们更感兴趣于比较两个学习算法<span class="s21">L</span><span class="s36">A</span>和<span class="s21">L</span><span class="s36">B</span>的性能，而不是两个特定假设。怎样近似 地检验多个学习算法，如何确定两个算法之间的差异在统计上是有意义的？虽然，在机器学 习研究领域，对于比较的方法仍在争论中，不过这里介绍了一个合理的途径。关于不同方法</p><p style="padding-left: 33pt;text-indent: -21pt;text-align: left;">的讨论见<span class="s6">Dietterich</span>（<span class="s6">1996</span>）。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 12pt;text-indent: 21pt;text-align: justify;">开始先指定要估计的参数。假定有<span class="s21">L</span><span class="s36">A</span>和<span class="s21">L</span><span class="s36">B</span>两个算法，要确定为了学习一特定目标函数<span class="s21">f </span>平均来说那个算法更优。定义“平均”的一种合理方法是，从一基准实例分布<span class="s68">D</span>中抽取所有 包含<span class="s21">n</span>个样例的训练集合，在所有这样的集合中测量两个算法的平均性能。换句话说，需要 估计假设错误率之间差异的期望值：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s107" style="padding-top: 3pt;padding-left: 116pt;text-indent: 0pt;line-height: 14pt;text-align: left;">E <span class="s108">[</span>error<span class="s171">D</span><span class="s172"> </span><span class="s108">(</span>L <span class="s52">A</span><span class="s41"> </span><span class="s108">(</span>S <span class="s108">)) </span><span class="s109"> </span>error<span class="s171">D</span><span class="s172"> </span><span class="s108">(</span>L<span class="s52">B</span><span class="s41"> </span><span class="s108">(</span>S <span class="s108">))]</span></p><p class="s41" style="text-indent: 0pt;line-height: 6pt;text-align: center;">S <span class="s40"></span><span class="s172">D</span></p><p class="s6" style="padding-top: 4pt;padding-left: 34pt;text-indent: 0pt;text-align: left;">(5.14)</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 12pt;text-indent: 20pt;text-align: left;">其中<span class="s21">L</span><span class="s6">(</span><span class="s21">S</span><span class="s6">)</span>代表给定训练样本<span class="s21">S</span>时学习算法<span class="s21">L</span>输出的假设，下标<span class="s21">S</span><span class="s10"></span><span class="s68">D</span>表示期望值是在基准分 布<span class="s68">D</span>中抽取的样本<span class="s21">S</span>上计算。上述表达式描述的是学习算法<span class="s21">L</span><span class="s36">A</span>和<span class="s21">L</span><span class="s36">B</span>的差的期望值。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 11pt;text-indent: 21pt;text-align: justify;">在实际的学习算法比较中，我们只有一个有限的样本<span class="s21">D</span><span class="s35">0</span>。在这种情况下，很显然，要 估计上述的量需要将<span class="s21">D</span><span class="s35">0</span>分割成训练集合<span class="s21">S</span><span class="s35">0</span>和不相交的测试集合<span class="s21">T</span><span class="s35">0</span>。训练数据可以用来既训练 <span class="s21">L</span><span class="s36">A</span>又训练<span class="s21">L</span><span class="s36">B</span>，而测试数据则用来比较两个学习到的假设的准确度，也就是，使用下式来计算：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s107" style="padding-top: 3pt;padding-left: 116pt;text-indent: 0pt;line-height: 12pt;text-align: left;">error<span class="s52">T </span><span class="s108">(</span>L<span class="s52">A </span><span class="s108">(</span>S<span class="s79">0 </span><span class="s108">)) </span><span class="s109"> </span>error<span class="s52">T </span><span class="s108">(</span>L<span class="s52">B </span><span class="s108">(</span>S<span class="s79">0</span><span class="s42"> </span><span class="s108">))</span></p><p style="padding-top: 2pt;padding-left: 26pt;text-indent: 0pt;line-height: 13pt;text-align: left;">（<span class="s6">5.15</span>）</p><p class="s189" style="padding-left: 144pt;text-indent: 0pt;line-height: 5pt;text-align: left;">0 0</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="text-indent: 0pt;line-height: 11pt;text-align: left;">(</p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-top: 1pt;padding-left: 11pt;text-indent: 21pt;text-align: justify;">上式与 <span class="s6">5.14 </span>式的计算有两个关键的不同。首先我们使用<span class="s21">error</span><span class="s36">T</span><span class="s178">0 </span><span class="s21">h</span><span class="s6">)</span>来近似 <span class="s21">error</span><span class="s170">D</span><span class="s6">(</span><span class="s21">h</span><span class="s6">)</span>。第 二，错误率的差异测量是在一个训练集合<span class="s21">S</span><span class="s35">0</span>上而不是在从分布<span class="s68">D</span>中抽取的所有的样本<span class="s21">S</span>上计算 期望值。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 31pt;text-indent: 0pt;text-align: center;">改进 <span class="s6">5.15 </span>式的一种方法是将数据<span class="s21">D</span><span class="s35">0</span>多次分割为不相交的训练和测试集合，然后在其中</p><p style="text-indent: 0pt;text-align: left;"><span><img width="9" height="1" alt="image" src="机器学习/Image_181.png"/></span></p><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;">计算错误率的平均值。这一过程在表 <span class="s6">5-5 </span>中列出，它在一可用数据的固定样本<span class="s21">D</span><span class="s35">0</span>上估计两个 学习算法错误率之间的差异。该过程首先将数据拆分为<span class="s21">k</span>个不相交的相等子集，子集大小至 少为 <span class="s6">30</span>。然后训练和测试算法<span class="s21">k</span>次，每次使用其中一个子集作为测试数据集，其他<span class="s21">k</span><span class="s6">-1 </span>个子 集为训练集。使用这种办法，学习算法在<span class="s21">k</span>个独立测试集上测试，而错误率的差异的均值 <span class="s119"> </span>作为两个学习算法间差异的估计。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 31pt;text-indent: 0pt;text-align: center;">表 <span class="h4">5-5 </span>估计两学习算法<span class="s7">L</span><span class="s173">A</span>和<span class="s7">L</span><span class="s173">B</span>错误率差异的一种方法</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-left: 43pt;text-indent: 0pt;text-align: left;">近似的置信区间将在正文中给出。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 2pt;text-align: left;"><span><img width="570" height="2" alt="image" src="机器学习/Image_182.png"/></span></p><p class="s56" style="padding-left: 12pt;text-indent: 0pt;text-align: left;"><span class="s16">1.</span><span class="s14">将可用数据</span>D<span class="s64">0</span><span class="s14">分割成</span>k<span class="s14">个相同大小的不相交子集</span>T<span class="s64">1</span><span class="s16">, </span>T<span class="s64">2</span><span class="s16">, …, </span>T<span class="s65">k</span><span class="s14">。其大小至少为 </span><span class="s16">30</span><span class="s14">。</span></p><p class="s14" style="padding-top: 2pt;padding-left: 12pt;text-indent: 0pt;line-height: 126%;text-align: left;"><span class="s16">2.</span>令 <span class="s56">i </span>从 <span class="s16">1 </span>到 <span class="s56">k </span>循环，做下面的操作： 使用<span class="s56">T</span><span class="s65">i</span>作为测试集合，而剩余的数据作为训练集合<span class="s56">S</span><span class="s65">i</span></p><p class="s30" style="padding-left: 30pt;text-indent: 0pt;line-height: 133%;text-align: left;"><span class="s55">n </span>S<span class="s52">i </span><span class="s38"> </span><span class="s33">{</span>D<span class="s79">0 </span><span class="s38"> </span>T<span class="s52">i </span><span class="s33">} </span><span class="s55">n </span>h<span class="s52">A </span><span class="s38"> </span>L<span class="s52">A </span><span class="s33">(</span>S<span class="s52">i </span><span class="s33">) </span><span class="s55">n </span>h<span class="s52">B </span><span class="s38"> </span>L<span class="s52">B </span><span class="s33">(</span>S<span class="s52">i</span><span class="s41"> </span><span class="s33">)</span></p><p class="s52" style="padding-left: 30pt;text-indent: 0pt;line-height: 13pt;text-align: left;"><span class="s55">n </span><span class="s119"></span>i <span class="s109"> </span><span class="s107">error</span>T <span class="s108">(</span><span class="s107">h</span>A <span class="s108">) </span><span class="s109"> </span><span class="s107">error</span>T <span class="s108">(</span><span class="s107">h</span>B<span class="s41"> </span><span class="s108">)</span></p><p class="s44" style="padding-left: 110pt;text-indent: 0pt;line-height: 5pt;text-align: left;">i i</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="9" height="1" alt="image" src="机器学习/Image_183.png"/></span></p><p class="s14" style="padding-left: 11pt;text-indent: 0pt;text-align: left;"><span class="s16">3.</span>返回值 <span class="s119"> </span>，其中</p><p class="s195" style="padding-top: 5pt;padding-left: 213pt;text-indent: 0pt;line-height: 7pt;text-align: left;">1<span class="s33"> </span><span class="s41">k</span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="9" height="1" alt="image" src="机器学习/Image_184.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="11" height="1" alt="image" src="机器学习/Image_185.png"/></span></p><p class="s119" style="padding-left: 7pt;text-indent: 0pt;line-height: 14pt;text-align: center;"> <span class="s38"> </span><span class="s124"></span> <span class="s52">i</span></p><p class="s196" style="padding-left: 18pt;text-indent: 0pt;line-height: 10pt;text-align: center;">k<span class="s30"> </span><span class="s41">i</span><span class="s40"></span><span class="s42">1</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 2pt;text-align: left;"><span><img width="570" height="2" alt="image" src="机器学习/Image_186.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="9" height="1" alt="image" src="机器学习/Image_187.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="9" height="1" alt="image" src="机器学习/Image_188.png"/></span></p><p style="padding-top: 2pt;padding-left: 10pt;text-indent: 21pt;text-align: left;">表 <span class="s6">5-5 </span>返回的 <span class="s119"> </span>可被用作对式 <span class="s6">5.14 </span>所需结果的一个估计。更合适的说法是把 <span class="s119"> </span>看作下 式的估计：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="padding-top: 3pt;text-indent: 0pt;line-height: 13pt;text-align: right;">E</p><p class="s41" style="text-indent: 0pt;line-height: 8pt;text-align: right;">S <span class="s40"></span>D<span class="s197">0</span></p><p class="s33" style="padding-top: 2pt;text-indent: 0pt;text-align: left;">[<i>error</i><span class="s171">D</span><span class="s172"> </span>(<i>L</i><span class="s52">A</span><span class="s41"> </span>(<i>S </i>)) <span class="s38"> </span><i>error</i><span class="s171">D</span><span class="s172"> </span>(<i>L</i><span class="s52">B</span><span class="s41"> </span>(<i>S </i>))]</p><p style="padding-top: 2pt;padding-left: 52pt;text-indent: 0pt;text-align: left;">（<span class="s6">5.16</span>）</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 32pt;text-indent: 0pt;text-align: left;">其中<span class="s21">S</span>代表一个大小为</p><p style="text-indent: 0pt;text-align: left;"><span><img width="34" height="20" alt="image" src="机器学习/Image_189.png"/></span></p><p class="s30" style="padding-top: 2pt;padding-left: 3pt;text-indent: 0pt;text-align: center;">k <span class="s38"> </span><span class="s33">1</span></p><p class="s30" style="padding-top: 3pt;padding-left: 1pt;text-indent: 0pt;text-align: center;">k</p><p style="text-indent: 0pt;text-align: left;"><span><img width="1" height="20" alt="image" src="机器学习/Image_190.png"/></span></p><p style="padding-top: 10pt;padding-left: 1pt;text-indent: 0pt;text-align: left;"><span class="s30">D</span><span class="s79">0 </span>，从<span class="s21">D</span><span class="s35">0</span>中一致抽取的随机样本。在该式和 <span class="s6">5.14 </span>中原来</p><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;">的表达式之间，惟一的差别在于其期望值的计算是在可用数据的子集<span class="s21">D</span><span class="s35">0</span>上计算，而不是在 从整个分布<span class="s68">D</span>上抽取的子集上计算。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="9" height="1" alt="image" src="机器学习/Image_191.png"/></span></p><p style="padding-left: 32pt;text-indent: 0pt;text-align: left;">估计 <span class="s6">5.16 </span>式的近似的 <span class="s21">N</span>％置信区间可使用 <span class="s119"> </span>表示为：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 170pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="9" height="1" alt="image" src="机器学习/Image_192.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="5" height="0" alt="image" src="机器学习/Image_193.png"/></span></p><p class="s42" style="text-indent: 0pt;line-height: 15pt;text-align: right;"><span class="s119"> </span><span class="s38"> </span><span class="s30">t</span><i>N </i>,<i>k </i><span class="s40"></span>1 <span class="s38"> </span><span class="s30">s</span><span class="s198"></span></p><p style="padding-left: 21pt;text-indent: 0pt;line-height: 12pt;text-align: left;">（<span class="s6">5.17</span>）</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 385pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="9" height="1" alt="image" src="机器学习/Image_194.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="5" height="0" alt="image" src="机器学习/Image_195.png"/></span></p><p style="padding-left: 11pt;text-indent: 20pt;line-height: 15pt;text-align: left;">其中<span class="s21">t</span><span class="s36">N</span><span class="s42">, </span><span class="s41">k</span><span class="s42">-1</span>是一常数，其意义类似于前面置信区间表达式中的<span class="s21">z</span><span class="s36">N</span>，而 <span class="s107">s</span><span class="s199"></span><span class="s181"> </span>代表对 <span class="s119"> </span>所服从</p><p style="text-indent: 0pt;text-align: left;"><span><img width="5" height="0" alt="image" src="机器学习/Image_196.png"/></span></p><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;">的概率分布的标准差的估计，确切的讲， <span class="s107">s</span><span class="s199"></span><span class="s181"> </span>定义为：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="5" height="0" alt="image" src="机器学习/Image_197.png"/></span></p><p class="s30" style="padding-top: 10pt;text-indent: 0pt;text-align: right;">s<span class="s198"></span><span class="s200"> </span><span class="s38"></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="143" height="44" alt="image" src="机器学习/Image_198.png"/></span></p><p class="s33" style="padding-top: 4pt;text-indent: 0pt;text-align: right;">1</p><p class="s30" style="padding-top: 2pt;padding-left: 10pt;text-indent: 0pt;text-align: center;">k<span class="s33">(</span>k <span class="s38"></span></p><p class="s41" style="padding-top: 4pt;padding-left: 15pt;text-indent: 0pt;line-height: 6pt;text-align: left;">k                    <u>   </u></p><p class="s33" style="text-indent: 0pt;line-height: 12pt;text-align: left;">1)</p><p style="text-indent: 0pt;text-align: left;"/><p class="s42" style="text-indent: 0pt;line-height: 7pt;text-align: left;">2</p><p style="text-indent: 0pt;text-align: left;"/><p class="s119" style="padding-left: 10pt;text-indent: 0pt;line-height: 19pt;text-align: left;"><span class="s39"></span><span class="s33">(</span> <span class="s52">i</span><span class="s41"> </span><span class="s38"> </span> <span class="s33">)</span></p><p class="s41" style="padding-left: 12pt;text-indent: 0pt;line-height: 7pt;text-align: left;">i<span class="s40"></span><span class="s42">1</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 2pt;text-indent: 0pt;text-align: left;">（<span class="s6">5.18</span>）</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="9" height="1" alt="image" src="机器学习/Image_199.png"/></span></p><p style="padding-top: 1pt;padding-left: 11pt;text-indent: 21pt;text-align: left;">注意 <span class="s6">5.17 </span>中的常量<span class="s21">t</span><span class="s36">N</span><span class="s42">, </span><span class="s41">k</span><span class="s42">-1</span>有两个下标。第一个代表所需的置信度，如前面的常数<span class="s21">z</span><span class="s36">N</span>中那样。 第二个参数称为自由度（<span class="s6">degree of freedom</span>），常被记作<span class="s21">v</span>，它与生成随机变量 <span class="s119"> </span>的值时独立 的随机事件数目相关。在当前的条件下，自由度数值为<span class="s21">k</span><span class="s6">-1</span>。参数<span class="s21">t</span>的几种取值在表 <span class="s6">5-6 </span>中列 出。注意当<span class="s21">k</span>→∞时，<span class="s21">t</span><span class="s36">N</span><span class="s42">, </span><span class="s41">k</span><span class="s42">-1</span>的值趋于常数<span class="s21">z</span><span class="s36">N</span>。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 11pt;text-indent: 21pt;line-height: 110%;text-align: justify;">注意这里描述的比较学习算法的过程要在同样的测试集合上测试两个假设。这与 <span class="s6">5.5 </span>节 中描述的比较两个用独立测试集合评估过的假设不同。使用相同样本来测试假设被称为配对 测试<span class="s6">(paired test)</span>。配对测试通常会产生更紧密的置信区间。因为在配对测试中任意的差异都 来源于假设之间的差异。相反，若假设在分开的数据样本上的测试，两个样本错误率之间的 差异也可能部分来源于两个样本组成上的不同。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 99pt;text-indent: 0pt;text-align: left;">表 <span class="h4">5-6 </span>双侧置信区间<span class="s7">t</span><span class="s173">N</span><span class="s201">,</span><span class="s202">v</span>的值。当<span class="s7">v</span>→∞时，<span class="s7">t</span><span class="s173">N</span><span class="s201">,</span><span class="s202">v</span>趋近于<span class="s7">z</span><span class="s173">N</span>。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><table style="border-collapse:collapse;margin-left:5.60001pt" cellspacing="0"><tr style="height:17pt"><td style="width:266pt;border-top-style:solid;border-top-width:2pt" colspan="5"><p class="s174" style="text-indent: 0pt;text-align: center;">置信度 <span class="s54">N</span></p></td></tr><tr style="height:15pt"><td style="width:55pt;border-bottom-style:solid;border-bottom-width:1pt"/><td style="width:52pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s53" style="padding-top: 1pt;padding-left: 16pt;text-indent: 0pt;text-align: left;">90%</p></td><td style="width:53pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s53" style="padding-top: 1pt;text-indent: 0pt;text-align: center;">95%</p></td><td style="width:53pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s53" style="padding-top: 1pt;text-indent: 0pt;text-align: center;">98%</p></td><td style="width:53pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s53" style="padding-top: 1pt;text-indent: 0pt;text-align: center;">99%</p></td></tr><tr style="height:16pt"><td style="width:55pt;border-top-style:solid;border-top-width:1pt"><p class="s54" style="padding-top: 1pt;padding-right: 1pt;text-indent: 0pt;text-align: center;">v<span class="s53">=2</span></p></td><td style="width:52pt;border-top-style:solid;border-top-width:1pt"><p class="s53" style="padding-top: 1pt;padding-left: 17pt;text-indent: 0pt;text-align: left;">2.92</p></td><td style="width:53pt;border-top-style:solid;border-top-width:1pt"><p class="s53" style="padding-top: 1pt;text-indent: 0pt;text-align: center;">4.30</p></td><td style="width:53pt;border-top-style:solid;border-top-width:1pt"><p class="s53" style="padding-top: 1pt;text-indent: 0pt;text-align: center;">6.96</p></td><td style="width:53pt;border-top-style:solid;border-top-width:1pt"><p class="s53" style="padding-top: 1pt;text-indent: 0pt;text-align: center;">9.92</p></td></tr><tr style="height:15pt"><td style="width:55pt"><p class="s54" style="padding-top: 1pt;padding-right: 1pt;text-indent: 0pt;text-align: center;">v<span class="s53">=5</span></p></td><td style="width:52pt"><p class="s53" style="padding-top: 1pt;padding-left: 17pt;text-indent: 0pt;text-align: left;">2.02</p></td><td style="width:53pt"><p class="s53" style="padding-top: 1pt;text-indent: 0pt;text-align: center;">2.57</p></td><td style="width:53pt"><p class="s53" style="padding-top: 1pt;text-indent: 0pt;text-align: center;">3.36</p></td><td style="width:53pt"><p class="s53" style="padding-top: 1pt;text-indent: 0pt;text-align: center;">4.03</p></td></tr><tr style="height:15pt"><td style="width:55pt"><p class="s54" style="padding-top: 1pt;padding-left: 17pt;text-indent: 0pt;text-align: left;">v<span class="s53">=10</span></p></td><td style="width:52pt"><p class="s53" style="padding-top: 1pt;padding-left: 17pt;text-indent: 0pt;text-align: left;">1.81</p></td><td style="width:53pt"><p class="s53" style="padding-top: 1pt;text-indent: 0pt;text-align: center;">2.23</p></td><td style="width:53pt"><p class="s53" style="padding-top: 1pt;text-indent: 0pt;text-align: center;">2.76</p></td><td style="width:53pt"><p class="s53" style="padding-top: 1pt;text-indent: 0pt;text-align: center;">3.17</p></td></tr><tr style="height:15pt"><td style="width:55pt"><p class="s54" style="padding-top: 1pt;padding-left: 17pt;text-indent: 0pt;text-align: left;">v<span class="s53">=20</span></p></td><td style="width:52pt"><p class="s53" style="padding-top: 1pt;padding-left: 17pt;text-indent: 0pt;text-align: left;">1.72</p></td><td style="width:53pt"><p class="s53" style="padding-top: 1pt;text-indent: 0pt;text-align: center;">2.09</p></td><td style="width:53pt"><p class="s53" style="padding-top: 1pt;text-indent: 0pt;text-align: center;">2.53</p></td><td style="width:53pt"><p class="s53" style="padding-top: 1pt;text-indent: 0pt;text-align: center;">2.84</p></td></tr><tr style="height:15pt"><td style="width:55pt"><p class="s54" style="padding-top: 1pt;padding-left: 17pt;text-indent: 0pt;text-align: left;">v<span class="s53">=30</span></p></td><td style="width:52pt"><p class="s53" style="padding-top: 1pt;padding-left: 17pt;text-indent: 0pt;text-align: left;">1.70</p></td><td style="width:53pt"><p class="s53" style="padding-top: 1pt;text-indent: 0pt;text-align: center;">2.04</p></td><td style="width:53pt"><p class="s53" style="padding-top: 1pt;text-indent: 0pt;text-align: center;">2.46</p></td><td style="width:53pt"><p class="s53" style="padding-top: 1pt;text-indent: 0pt;text-align: center;">2.75</p></td></tr><tr style="height:15pt"><td style="width:55pt"><p class="s54" style="padding-top: 1pt;padding-left: 15pt;text-indent: 0pt;text-align: left;">v<span class="s53">=120</span></p></td><td style="width:52pt"><p class="s53" style="padding-top: 1pt;padding-left: 17pt;text-indent: 0pt;text-align: left;">1.66</p></td><td style="width:53pt"><p class="s53" style="padding-top: 1pt;text-indent: 0pt;text-align: center;">1.98</p></td><td style="width:53pt"><p class="s53" style="padding-top: 1pt;text-indent: 0pt;text-align: center;">2.36</p></td><td style="width:53pt"><p class="s53" style="padding-top: 1pt;text-indent: 0pt;text-align: center;">2.62</p></td></tr><tr style="height:17pt"><td style="width:55pt;border-bottom-style:solid;border-bottom-width:2pt"><p class="s54" style="padding-left: 17pt;text-indent: 0pt;text-align: left;">v<span class="s53">=</span><span class="s174">∞</span></p></td><td style="width:52pt;border-bottom-style:solid;border-bottom-width:2pt"><p class="s53" style="padding-top: 1pt;padding-left: 17pt;text-indent: 0pt;text-align: left;">1.64</p></td><td style="width:53pt;border-bottom-style:solid;border-bottom-width:2pt"><p class="s53" style="padding-top: 1pt;text-indent: 0pt;text-align: center;">1.96</p></td><td style="width:53pt;border-bottom-style:solid;border-bottom-width:2pt"><p class="s53" style="padding-top: 1pt;text-indent: 0pt;text-align: center;">2.33</p></td><td style="width:53pt;border-bottom-style:solid;border-bottom-width:2pt"><p class="s53" style="padding-top: 1pt;text-indent: 0pt;text-align: center;">2.58</p></td></tr></table><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s25" style="padding-top: 1pt;padding-left: 11pt;text-indent: 0pt;text-align: left;"><span class="h3">5.6.1 </span>配对 <span class="s203">t </span>测试</p><p style="padding-top: 10pt;padding-left: 32pt;text-indent: 0pt;text-align: left;">上面描述了在给定固定数据集时比较两个学习算法的过程。本节讨论这一过程以及 <span class="s6">5.17</span></p><p style="padding-left: 6pt;text-indent: 0pt;text-align: left;">和 <span class="s6">5.18 </span>式中置信区间的统计学论证。如果第一次阅读，可以跳过它而不失连续性。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 27pt;text-indent: 0pt;text-align: left;">为了理解 <span class="s6">5.17 </span>式中的置信区间，考虑以下的估计问题：</p><p class="s21" style="padding-top: 5pt;padding-left: 28pt;text-indent: 0pt;line-height: 14pt;text-align: left;"><span class="s34">• </span><span class="p">给定一系列独立同分布的随机变量</span>Y<span class="s35">1</span><span class="s6">,</span>Y<span class="s35">2</span><span class="s6">…</span>Y<span class="s36">k</span><span class="p">的观察值。</span></p><p style="padding-left: 28pt;text-indent: 0pt;line-height: 15pt;text-align: left;"><span class="s34">• </span>要估计这些<span class="s21">Y</span><span class="s36">i</span>所服从的概率分布的均值<span class="s47">μ</span>。</p><p style="text-indent: 0pt;text-align: left;"><span><img width="9" height="1" alt="image" src="机器学习/Image_200.png"/></span></p><p class="s34" style="padding-left: 28pt;text-indent: 0pt;text-align: left;">• <span class="p">使用的估计量为样本均值 </span><span class="s30">Y</span></p><p class="s195" style="padding-top: 1pt;padding-left: 202pt;text-indent: 0pt;line-height: 7pt;text-align: left;">1<span class="s33"> </span><span class="s41">k</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 181pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="9" height="1" alt="image" src="机器学习/Image_201.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="11" height="1" alt="image" src="机器学习/Image_202.png"/></span></p><p class="s30" style="padding-left: 202pt;text-indent: -22pt;line-height: 60%;text-align: left;">Y  <span class="s38"></span><span class="s33">    </span><span class="s124"></span>Y<span class="s52">i</span><span class="s41"> </span><span class="s196">k</span>  <span class="s41">i</span><span class="s40"></span><span class="s42">1</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 113pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="9" height="1" alt="image" src="机器学习/Image_203.png"/></span></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 12pt;text-align: justify;">这一基于样本均值 <span class="s30">Y </span>估计分布均值<span class="s47">μ</span>的问题非常常见。例如，它覆盖了早先用<span class="s21">error</span><span class="s36">S</span><span class="s6">(</span><span class="s21">h</span><span class="s6">)</span></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 16pt;text-align: justify;">来估计<span class="s21">error</span><span class="s170">D</span><span class="s6">(</span><span class="s21">h</span><span class="s6">)</span>的问题。（其中，<span class="s21">Y</span><span class="s36">i</span>为 <span class="s6">0 </span>或 <span class="s6">1 </span>表示<span class="s21">h</span>是否对一单独的<span class="s21">S</span>样例产生误分类，而<span class="s21">error</span><span class="s170">D</span><span class="s6">(</span><span class="s21">h</span><span class="s6">) </span>为基准分布的均值<span class="s47">μ</span>。）由式子 <span class="s6">5.17 </span>和 <span class="s6">5.18 </span>描述的<span class="s21">t</span>测试应用于该问题的一特殊情形——即 每个单独的<span class="s21">Y</span><span class="s36">i</span>遵循正态分布。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 26pt;text-indent: 0pt;text-align: left;">现考虑比较学习算法的表 <span class="s6">5-5 </span>过程的一个理想化条件。假定不是拥有固定样本数据<span class="s21">D</span><span class="s35">0</span>，</p><p style="padding-left: 5pt;text-indent: 0pt;text-align: justify;">而是从基准实例分布中抽取新的训练样例。在这里我们修改表 <span class="s6">5-5 </span>中的过程，使每一次循环 生成一个新的随机训练集<span class="s21">S</span><span class="s36">i</span>和新的随机测试集<span class="s21">T</span><span class="s36">i</span>，生成方法是从基准分布中抽取而不是从固 定样本<span class="s21">D</span><span class="s35">0</span>中抽取。这一理想化方法能很好地匹配上面的估计问题。特别地，该过程所测量 的<span class="s47">δ</span><span class="s36">i</span>现对应到独立同分步的随机变量<span class="s21">Y</span><span class="s36">i</span>。其分布的均值<span class="s47">μ</span>对应两学习算法错误率的期望差异</p><p style="text-indent: 0pt;text-align: left;"><span><img width="9" height="1" alt="image" src="机器学习/Image_204.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="9" height="1" alt="image" src="机器学习/Image_205.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="9" height="1" alt="image" src="机器学习/Image_206.png"/></span></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: justify;">（即式 <span class="s6">5.14</span>）。样本均值 <span class="s30">Y </span>为这一理想化方法计算出的 <span class="s119"> </span>。现希望回答：“ <span class="s119"> </span>是否能较好地 估计<span class="s47">μ</span>”。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="9" height="1" alt="image" src="机器学习/Image_207.png"/></span></p><p style="padding-left: 5pt;text-indent: 21pt;text-align: justify;">首先，注意到测试集<span class="s21">T</span><span class="s36">i</span>的大小至少包含 <span class="s6">30 </span>个样例。因此，单独的<span class="s47">δ</span><span class="s36">i</span>将近似遵循正态分 布（由中心极限定理）。因此，我们有一特殊条件即<span class="s21">Y</span><span class="s36">i</span>服从近似的正态分布。可以得到，一 般地，当每个<span class="s21">Y</span><span class="s36">i</span>遵循正态分布时，样本均值 <span class="s30">Y </span>也遵循正态分布。由此，可以考虑使用前面计 算置信区间的表达式（等式 <span class="s6">5.11</span>），其中的估计量正是遵循了正态分布。然而，该等式要求 知道分布的标准差，但这里未知。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;"><span class="s21">t </span>测试正好用于这样的情形，即估计一系列独立同正态分布的随机变量的样本均值。在 这里，可使用式 <span class="s6">5.17 </span>和 <span class="s6">5.18 </span>中的置信区间，它可被重新表述为：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="9" height="1" alt="image" src="机器学习/Image_208.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="5" height="0" alt="image" src="机器学习/Image_209.png"/></span></p><p class="s38" style="padding-left: 24pt;text-indent: 0pt;text-align: center;"><span class="s119"> </span> <span class="s30">Y </span> <span class="s30">t </span><span class="s52">N</span><span class="s41"> </span><span class="s42">,</span><span class="s41">k </span><span class="s40"></span><span class="s42">1 </span> <span class="s30">s</span><span class="s69">Y</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="5" height="0" alt="image" src="机器学习/Image_210.png"/></span></p><p class="s30" style="text-indent: 0pt;line-height: 12pt;text-align: left;">s</p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-top: 2pt;padding-left: 27pt;text-indent: 0pt;line-height: 12pt;text-align: left;">其中 为估计的样本均值的标准差：</p><p class="s41" style="padding-left: 54pt;text-indent: 0pt;line-height: 6pt;text-align: left;">Y</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="5" height="0" alt="image" src="机器学习/Image_211.png"/></span></p><p class="s30" style="padding-top: 10pt;text-indent: 0pt;text-align: right;">s<span class="s69">Y</span><span class="s41"> </span><span class="s38"></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="138" height="44" alt="image" src="机器学习/Image_212.png"/></span></p><p class="s33" style="padding-top: 4pt;text-indent: 0pt;text-align: right;">1</p><p class="s30" style="padding-top: 2pt;padding-left: 10pt;text-indent: 0pt;text-align: center;">k<span class="s33">(</span>k <span class="s38"></span></p><p class="s41" style="padding-top: 4pt;padding-left: 15pt;text-indent: 0pt;line-height: 6pt;text-align: left;">k                  <u>    </u></p><p class="s33" style="text-indent: 0pt;line-height: 12pt;text-align: left;">1)</p><p style="text-indent: 0pt;text-align: left;"/><p class="s42" style="text-indent: 0pt;line-height: 7pt;text-align: left;">2</p><p style="text-indent: 0pt;text-align: left;"/><p class="s33" style="padding-left: 10pt;text-indent: 0pt;line-height: 19pt;text-align: left;"><span class="s39"></span>(<i>Y</i><span class="s52">i</span><span class="s41">  </span><span class="s38"></span> <i>Y </i>)</p><p class="s41" style="padding-left: 12pt;text-indent: 0pt;line-height: 7pt;text-align: left;">i <span class="s40"></span><span class="s42">1</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="5" height="0" alt="image" src="机器学习/Image_213.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="5" height="0" alt="image" src="机器学习/Image_214.png"/></span></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;text-align: justify;">而<span class="s21">t</span><span class="s36">N</span><span class="s42">, </span><span class="s41">k</span><span class="s42">-1</span>类似于前面的<span class="s21">z</span><span class="s36">N</span>的常量。实际上，常量<span class="s21">t</span><span class="s36">N</span><span class="s42">, </span><span class="s41">k</span><span class="s42">-1</span>描述的是称为<span class="s21">t</span>分布的概率分布下的区 域，正如常数<span class="s21">z</span><span class="s36">N</span>描述了正态分布下的区域。<span class="s21">t</span>分布是一类似于正态分布的钟形分布，但更宽 且更短，以反映由于使用 <span class="s30">s </span>来近似真实标准差<span class="s119"> </span>时带来的更大的方差。当<span class="s21">k</span>趋近于无穷时，</p><p class="s41" style="padding-left: 126pt;text-indent: 0pt;line-height: 3pt;text-align: left;">Y Y</p><p class="s21" style="padding-left: 5pt;text-indent: 0pt;line-height: 15pt;text-align: left;">t<span class="p">分布趋近于正态分布（因此</span>t<span class="s36">N</span><span class="s42">, </span><span class="s41">k</span><span class="s42">-1</span><span class="p">趋近于</span>z<span class="s36">N</span><span class="p">）。这在直觉上是正确的，因为我们希望样本大小</span>k</p><p style="text-indent: 0pt;text-align: left;"><span><img width="5" height="0" alt="image" src="机器学习/Image_215.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="5" height="0" alt="image" src="机器学习/Image_216.png"/></span></p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 11pt;text-align: left;">增加时 <span class="s30">s </span>收敛到真实的标准差<span class="s119"> </span>，且因为当标准差确切已知时可使用<span class="s21">z</span><span class="s36">N</span>。</p><p class="s41" style="padding-left: 44pt;text-indent: 0pt;line-height: 7pt;text-align: left;">Y Y</p><h3 style="padding-left: 6pt;text-indent: 0pt;text-align: justify;">5.6.2 <span class="s25">实际的考虑</span></h3><p style="text-indent: 0pt;text-align: left;"><span><img width="9" height="1" alt="image" src="机器学习/Image_217.png"/></span></p><p style="padding-top: 10pt;padding-left: 6pt;text-indent: 21pt;text-align: left;">上面的讨论证明了在使用样本均值 <span class="s30">Y </span>来估计一个包含<span class="s21">k</span>个独立同正态分布的随机变量 的样本均值时，使用式 <span class="s6">5.17 </span>来估计置信区间。这匹配了我们的理想的条件，即假定对于目</p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 16pt;text-align: justify;">标函数的样例可进行无限存取。在实际中，若数据集<span class="s21">D</span><span class="s35">0</span>有限，且算法使用表 <span class="s6">5-5 </span>描述的实际 方法，这一证明并不严格适用。实际的问题是，为产生<span class="s47">δ</span><span class="s36">i</span>只有重新采样<span class="s21">D</span><span class="s35">0</span>，以另外的方法 把它分割为测试集和训练集。<span class="s47">δ</span><span class="s36">i</span>此时相互并不独立，因为它们基于从有限子集<span class="s21">D</span><span class="s35">0</span>中抽取的 相互重叠的训练样例，而不是从整个分布<span class="s68">D</span>中抽取。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;text-align: left;">当只有一个有限的数据样本<span class="s21">D</span><span class="s35">0</span>可用时，有几种方法用来重采样<span class="s21">D</span><span class="s35">0</span>。表 <span class="s6">5-5 </span>描述的是<span class="s21">k</span><span class="s6">-fold </span>方法，其中<span class="s21">D</span><span class="s35">0</span>被分为<span class="s21">k</span>个不相交的等大小的子集，在这种<span class="s21">k</span><span class="s6">-fold</span>方法中，<span class="s21">D</span><span class="s35">0</span>中每一样例都有一 次用于测试，而<span class="s21">k</span><span class="s6">-1 </span>次用于训练。另一种常用的方法是从<span class="s21">D</span><span class="s35">0</span>中随机抽取至少 <span class="s6">30 </span>个样例的集 合，再用剩余的样例来训练，重复这一过程直到足够的次数。这种随机方法的好处是能够重 复无限次，以减小置信区间到需要的宽度。相反，<span class="s21">k</span><span class="s6">-fold</span>方法受限于样例的总数，这是因为 每个样例只有一次用于测试，且希望样本大小至少为 <span class="s6">30</span>。然而，随机方法的缺点是，测试 集合不再能看作是从基准分布<span class="s68">D</span>独立抽取。相反，<span class="s21">k</span><span class="s6">-fold</span>交叉验证生成的测试集合是独立的， 因为一实例只在测试集合中出现一次。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 113%;text-align: left;">概括地说，基于有限数据的学习算法的比较中没有一个单独的方法能满足我们希望的所 有约束。有必要记住统计学模型在数据有限时很少能完美地匹配学习算法验证的所有约束。 然而它们确实提供了近似的置信区间，有助于解释学习算法的实验性比较。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 6pt;text-indent: 0pt;text-align: justify;">5.7 <span class="s17">小结和补充读物</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 27pt;text-indent: 0pt;text-align: left;">本章的要点包括：</p><p class="s21" style="padding-top: 7pt;padding-left: 49pt;text-indent: -21pt;line-height: 86%;text-align: justify;"><span class="s34">• </span><span class="p">统计理论提供了一个基础，从而基于在数据样本</span>S<span class="p">上的观察错误率</span>error<span class="s36">S</span><span class="s6">(</span>h<span class="s6">)</span><span class="p">，估 计假设</span>h<span class="p">的真实错误率</span>error<span class="s170">D</span><span class="s6">(</span>h<span class="s6">)</span><span class="p">。例如，如果</span>h<span class="p">为一离散值假设，而且数据样本包 括</span>n<span class="p">≥</span><span class="s6">30 </span><span class="p">个不依赖</span>h<span class="p">且相互独立的样例时，那么</span>error<span class="s170">D</span><span class="s6">(</span>h<span class="s6">)</span><span class="p">的</span>N<span class="p">％置信区间近似为：</span></p><p class="s30" style="padding-top: 10pt;text-indent: 0pt;text-align: right;">error<span class="s52">S</span></p><p class="s33" style="padding-top: 9pt;text-indent: 0pt;text-align: left;">(<i>h</i>) <span class="s38"> </span><i>z </i><span class="s52">N</span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="166" height="41" alt="image" src="机器学习/Image_218.png"/></span></p><p class="s30" style="padding-top: 1pt;padding-left: 9pt;text-indent: 0pt;text-align: center;">error<span class="s52">S</span><span class="s41"> </span><span class="s33">(</span>h<span class="s33">)(1 </span><span class="s38"> </span>error<span class="s52">S</span><span class="s41"> </span><span class="s33">(</span>h<span class="s33">))</span></p><p class="s30" style="padding-top: 1pt;padding-left: 9pt;text-indent: 0pt;text-align: center;">n</p><p style="padding-left: 51pt;text-indent: 0pt;line-height: 14pt;text-align: left;">其中<span class="s21">z</span><span class="s36">N</span>的值由表 <span class="s6">5-1 </span>给出。</p><p class="s21" style="padding-left: 49pt;text-indent: -21pt;line-height: 89%;text-align: justify;"><span class="s34">• </span><span class="p">一般地，估计置信区间的问题可通过确定一待估计的参数（如</span>error<span class="s170">D </span><span class="s6">(</span>h<span class="s6">)</span><span class="p">）以及相 对应的估计量（</span>error<span class="s36">S </span><span class="s6">(</span>h<span class="s6">)</span><span class="p">）来完成。由于估计量是一随机变量（如</span>error<span class="s36">S</span><span class="s6">(</span>h<span class="s6">)</span><span class="p">依赖 于随机样本</span>S<span class="p">），它可由其服从的概率分布来描述。置信区间的计算可通过确定 该分布下包含所需概率质量的区间来描述。</span></p><p class="s21" style="padding-top: 1pt;padding-left: 49pt;text-indent: -21pt;line-height: 90%;text-align: left;"><span class="s34">• </span><span class="p">估计假设精度的一种误差可能为估计偏差（</span><span class="s6">estimation bias</span><span class="p">）。如果</span>Y<span class="p">为对某参数 </span>p<span class="p">的估计量，</span>Y<span class="p">的估计偏差为</span>Y<span class="p">的期望值和</span>p<span class="p">之间的差。例如，如果</span>S<span class="p">是用来形成假 设</span>h<span class="p">的训练数据，则</span>error<span class="s36">S</span><span class="s6">(</span>h<span class="s6">)</span><span class="p">给出了真实错误率</span>error<span class="s170">D</span><span class="s6">(</span>h<span class="s6">)</span><span class="p">的一个偏于乐观化的估 计。</span></p><p style="padding-left: 49pt;text-indent: -21pt;line-height: 94%;text-align: justify;"><span class="s34">• </span>估计产生误差的第二种原因是估计方差（<span class="s6">variance</span>）。即使对于无偏估计，估计 量的观察值也有可能在各实验中不同。估计量分布的方差<span class="s47">σ</span><span class="s46">2</span>描述了该估计与真 实值的不同有多大。该方差在数据样本增大时降低。</p><p class="s34" style="padding-left: 49pt;text-indent: -21pt;text-align: justify;">• <span class="p">比较两学习算法效果的问题在数据和时间无限时是一个相对容易的估计问题， 但在资源有限时要困难得多。本章描述的一种途径是在可用数据的不同子集上 运行学习算法，在剩余数据上测试学到的假设，然后将这些实验的结果平均。</span></p><p class="s21" style="padding-top: 1pt;padding-left: 49pt;text-indent: -21pt;line-height: 92%;text-align: left;"><span class="s34">• </span><span class="p">这里所考虑的多数情况下，推导置信区间需要进行多个假定和近似。例如上面 的</span>error<span class="s170">D </span><span class="s6">(</span>h<span class="s6">)</span><span class="p">的置信区间需要将二项分布近似为正态分布；近似计算分布的方差； 以及假定实例从一固定不变的概率分布中生成。基于这些近似得到的区间只是 近似置信区间，但它们仍提供了设计和解释机器学习实验结果的有效指导。</span></p><p style="padding-top: 8pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">本章介绍的关键统计学定义在表 <span class="s6">5-2 </span>中列出。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 109%;text-align: justify;">使用统计的方法来估计和测试假设这一主题有大量的文献。本章只介绍了基本概念，细 节的问题可在许多书籍和文章中找到。<span class="s6">Billingsley et al.</span>（<span class="s6">1986</span>）提供了对统计学的一个很简 明的介绍，详尽描述了这里所讨论的一些问题。其他文献包括 <span class="s6">DeGroot</span>（<span class="s6">1986</span>）； <span class="s6">Casella &amp; Berger</span>（<span class="s6">1990</span>）。<span class="s6">Duda &amp; Hart</span>（<span class="s6">1973</span>）在数值模式识别领域提出了这些问题的解决。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 6pt;text-indent: 20pt;line-height: 107%;text-align: justify;">Segre et al.<span class="p">（</span>1991<span class="p">，</span>1996<span class="p">），</span>Etzioni &amp; Etzioni<span class="p">（</span>1994<span class="p">），以及 </span>Gordon &amp; Segre<span class="p">（</span>1996<span class="p">）讨 论了评估学习算法的统计意义测试，算法的性能根据其改进计算效率的能力来评测。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 107%;text-align: justify;"><span class="s6">Geman et al.</span>（<span class="s6">1992</span>）讨论了在同时最小化偏差和最小化方差之间作出的折中。这一从 有限数据中学习和比较假设的主题仍在争论中。例如，<span class="s6">Dietterich</span>（<span class="s6">1996</span>）讨论了在不同的训 练<span class="s6">-</span>测试数据分割下使用配对差异 <span class="s21">t </span>测试带来的风险。</p><p style="padding-left: 27pt;text-indent: 0pt;text-align: left;">习题</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 27pt;text-indent: 0pt;text-align: left;"><span class="s6">5.1 </span>假定检验一假设<span class="s21">h</span>，并发现在一包含<span class="s21">n</span><span class="s6">=1000 </span>个随机抽取样例的样本<span class="s21">S</span>上，它出现<span class="s21">r</span><span class="s6">=300</span></p><p class="s6" style="padding-top: 1pt;padding-left: 5pt;text-indent: 0pt;text-align: left;"><span class="p">个错误。</span><i>error</i><span class="s36">S</span>(<i>h</i>)<span class="p">的标准差是什么？将此结果与 </span>5.3.4 <span class="p">节末尾的例子中标准差相比较会得出 什么结论？</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: left;"><span class="s6">5.2 </span>考虑某布尔值概念中学到的假设<span class="s21">h</span>。当<span class="s21">h</span>在 <span class="s6">100 </span>个样例的集合上测试时，有 <span class="s6">83 </span>个分类 正确。那么真实错误率<span class="s21">error</span><span class="s170">D</span><span class="s6">(</span><span class="s21">h</span><span class="s6">)</span>的标准差和 <span class="s6">95</span>％置信区间是多少？</p><p style="padding-top: 10pt;padding-left: 26pt;text-indent: 0pt;text-align: left;"><span class="s6">5.3 </span>如果假设<span class="s21">h</span>在<span class="s21">n</span><span class="s6">=65 </span>的独立抽取样本上出现<span class="s21">r</span><span class="s6">=10 </span>个错误。真实错误率的 <span class="s6">90</span>％置信区间</p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 16pt;text-align: left;">（双侧的）是多少。<span class="s6">95</span>％单侧置信区间（即一个上界<span class="s21">U</span>，使得有 <span class="s6">95</span>％置信度<span class="s21">error</span><span class="s170">D</span><span class="s6">(</span><span class="s21">h</span><span class="s6">)</span>≤<span class="s21">U</span>） 是多少？<span class="s6">90</span>％单侧区间是多少？</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 6pt;text-indent: 20pt;line-height: 16pt;text-align: left;">5.4 <span class="p">要测试－假设</span><i>h</i><span class="p">，其</span><i>error</i><span class="s170">D</span>(<i>h</i>)<span class="p">已知在 </span>0.2 <span class="p">和 </span>0.6 <span class="p">范围内。要保证 </span>95<span class="p">％双侧置信区间的 宽度小于 </span>0.1<span class="p">，最少应搜集的样例数是多少。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 27pt;text-indent: 0pt;text-align: left;">5.5 <span class="p">对于在不同数据样本上测试的两假设错误率的差，给出计算单侧上界和单侧下界的</span></p><p class="s21" style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">N<span class="p">％置信区间的通用表达式。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 27pt;text-indent: 0pt;text-align: left;">5.6 <span class="p">解释为什么式 </span>5.17 <span class="p">给出的置信区间估计可用于估计式 </span>5.16<span class="p">，而不能估计式 </span>5.14<span class="p">。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s8" style="padding-left: 136pt;text-indent: 0pt;line-height: 24pt;text-align: left;">第<span class="h1">6</span>章 贝叶斯学习</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 113%;text-align: justify;">贝叶斯推理提供了推理的一种概率手段。它基于如下的假定，即<span style=" color: #00F;">待考查的量遵循某概率 分布</span>，且可根据这些概率及已观察到的数据进行推理，以作出最优的决策。贝叶斯推理对机 器学习十分重要，因为它为衡量多个假设的置信度提供了定量的方法。贝叶斯推理为直接操 作概率的学习算法提供了基础，而且它也为其他算法的分析提供了理论框架。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">6.1 <span class="s17">介绍</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 112%;text-align: left;">贝叶斯学习同我们的机器学习研究相关，有两个原因。首先，贝叶斯学习算法能够计算 显式的假设概率，如朴素贝叶斯分类器，它是解决相应学习问题的最有实际价值的方法之一。 例如，<span class="s6">Michie et al.</span>（<span class="s6">1994</span>）详细研究比较了<span style=" color: #00F;">朴素贝叶斯分类器（</span><span class="s63">naïve Bayesian classifier</span><span style=" color: #00F;">）</span>和 其他学习算法，包括决策树和神经网络。他们发现朴素贝叶斯分类器在多数情况下与其他学 习算法性能相当，在某些情况下还优于其他算法。本章描述了朴素贝叶斯分类器，并提供了 一个详细例子：即它应用于文本文档分类的学习问题（如电子新闻分类）。对于这样的学习 任务，朴素贝叶斯分类是最有效的算法之一。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 112%;text-align: justify;">贝叶斯方法对于机器学习研究的重要性还体现在，它为理解多数学习算法提供了一种有 效的手段，而这些算法不一定直接操作概率数据。例如，本章分析了第 <span class="s6">2 </span>章的 <span class="s6">Find-S </span>和候 选消除算法，以判断在给定数据时哪一个算法将输出最有可能的假设。我们还使用贝叶斯分 析证明了神经网络学习中的一个关键性的选择：即在搜索神经网络空间时，选择使误差平方 和最小化的神经网络。我们还推导出另一种误差函数：交叉熵。它在学习预测概率目标函数 时比误差平方和更合适。本章还用贝叶斯的手段分析了决策树的归纳偏置（即优选最短的决 策树），并考查了密切相关的最小描述长度（<span class="s6">Minimum Description Length</span>）原则。对贝叶斯 方法的基本了解，对于理解和刻画机器学习中许多算法的操作很重要。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 27pt;text-indent: 0pt;text-align: left;">贝叶斯学习方法的特性包括：</p><p class="s10" style="padding-top: 6pt;padding-left: 49pt;text-indent: -21pt;text-align: justify;"> <span class="p">观察到的每个训练样例可以增量式地降低或升高某假设的估计概率。这提供了 一种比其他算法更合理的学习途径。其他算法会在某个假设与任一样例不一致 时完全去掉该假设。</span></p><p style="padding-left: 49pt;text-indent: -21pt;line-height: 94%;text-align: justify;"><span class="s10"> </span>先验知识可以与观察数据一起决定假设的最终概率。在贝叶斯学习中，先验知 识的形式可以是（<span class="s6">1</span>）每个候选假设的先验概率（<span class="s6">2</span>）每个可能假设在可观察数 据上的概率分布。</p><p style="padding-top: 1pt;padding-left: 49pt;text-indent: -21pt;line-height: 14pt;text-align: justify;"><span class="s10"> </span>贝叶斯方法可允许假设做出不确定性的预测。（比如这样的假设：这一肺炎病 人有 <span class="s6">93%</span>的机会康复）。</p><p class="s10" style="padding-left: 28pt;text-indent: 0pt;line-height: 13pt;text-align: left;"> <span class="p">新的实例分类可由多个假设一起作出预测，以它们的概率为权重。</span></p><p class="s10" style="padding-left: 49pt;text-indent: -21pt;line-height: 14pt;text-align: justify;"> <span class="p">即使在贝叶斯方法计算复杂度较高时，它们仍可做为一个最优的决策的标准衡 量其他方法。</span></p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 21pt;line-height: 113%;text-align: justify;">在实践中应用贝叶斯方法的难度之一在于，它们<span style=" color: #00F;">需要概率的初始知识</span>。当这概率预先未 知时，可以基于背景知识、预先准备好的数据以及关于基准分布的假定来估计这些概率。另 一实际困难在于，<span style=" color: #00F;">一般情况下确定贝叶斯最优假设的计算代价比较大</span>（同候选假设的数量成 线性关系）。在某些特定情形下，这种计算代价可以被大大降低。</p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 109%;text-align: justify;">本章剩余部分的组成如下。<span class="s6">6.2 </span>节介绍了贝叶斯理论，并定义了极大似然（<span class="s6">maximum likelihood</span>）假设和极大后验概率假设（<span class="s6">maximum a posteriori probability hypotheses</span>）。接下来 的四节将此概率框架应用于分析前面章节的相关问题和学习算法。例如，我们证明了在特定 前提下，几个前述的算法能输出极大似然假设。剩余的几节则介绍了几种直接操作概率的学 习算法。包括贝叶斯最优分类器、<span class="s6">Gibbs </span>算法和朴素贝叶斯分类器。最后，我们讨论了贝叶 斯置信网，它是一种基于概率推理的较新的学习方法；以及 <span class="s6">EM </span>算法，是当存在未观测到变 量时广泛使用的学习算法。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">6.2 <span class="s17">贝叶斯法则</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 109%;text-align: justify;">在机器学习中，通常我们感兴趣的是在给定训练数据 <span class="s21">D </span>时，确定假设空间 <span class="s21">H </span>中的最佳 假设。所谓最佳假设，一种办法是把它定义为在给定数据 <span class="s21">D </span>以及 <span class="s21">H </span>中不同假设的先验概率 的有关知识条件下的最可能（<span class="s6">most probable</span>）假设。贝叶斯理论提供了计算这种可能性的一 种直接的方法。更精确地讲，贝叶斯法则提供了一种计算假设概率的方法，它基于假设的先 验概率、给定假设下观察到不同数据的概率、以及观察的数据本身。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: left;"><span class="p">要精确地定义贝叶斯理论，先引入一些记号。我们用 </span>P<span class="s6">(</span>h<span class="s6">)</span><span class="p">来代表还没有训练数据前，假 设 </span>h <span class="p">拥有的初始概率。</span>P<span class="s6">(</span>h<span class="s6">)</span><span class="p">常被称为 </span>h <span class="p">的先验概率（</span><span class="s6">prior probability </span><span class="p">），它反映了我们所拥 有的关于 </span>h <span class="p">是一正确假设的机会的背景知识。如果没有这一先验知识，那么可以简单地将每 一候选假设赋予相同的先验概率。相似地，可用 </span>P<span class="s6">(</span>D<span class="s6">)</span><span class="p">代表将要观察的训练数据 </span>D <span class="p">的先验概 率（换言之，在没有确定某一假设成立时，</span>D <span class="p">的概率）。下一步，以 </span>P<span class="s6">(</span>D<span class="s6">|</span>h<span class="s6">)</span><span class="p">代表假设 </span>h <span class="p">成立 的情形下观察到数据 </span>D <span class="p">的概率。更一般地，我们使用 </span>P<span class="s6">(</span>x<span class="s6">|</span>y<span class="s6">)</span><span class="p">代表给定 </span>y <span class="p">时 </span>x <span class="p">的概率。在机器 学习中，我们感兴趣的是 </span>P<span class="s6">(</span>h<span class="s6">|</span>D<span class="s6">)</span><span class="p">，即给定训练数据 </span>D <span class="p">时 </span>h <span class="p">成立的概率。</span>P<span class="s6">(</span>h<span class="s6">|</span>D<span class="s6">)</span><span class="p">被称为 </span>h <span class="p">的后 验概率（</span><span class="s6">posterior probability</span><span class="p">），因为它反映了在看到训练数据 </span>D <span class="p">后 </span>h <span class="p">成立的置信度。应注意， 后验概率 </span>P<span class="s6">(</span>h<span class="s6">|</span>D<span class="s6">)</span><span class="p">反映了训练数据 </span>D <span class="p">的影响；相反，先验概率 </span>P<span class="s6">(</span>h<span class="s6">)</span><span class="p">是独立于 </span>D <span class="p">的。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 26pt;text-indent: 0pt;text-align: left;"><span class="p">贝叶斯法则是贝叶斯学习方法的基础，因为它提供了从先验概率 </span>P<span class="s6">(</span>h<span class="s6">)</span><span class="p">以及 </span>P<span class="s6">(</span>D<span class="s6">)</span><span class="p">和 </span>P<span class="s6">(</span>D<span class="s6">|</span>h<span class="s6">)</span></p><p class="s21" style="padding-top: 1pt;padding-left: 5pt;text-indent: 0pt;text-align: left;"><span class="p">计算后验概率 </span>P<span class="s6">(</span>h<span class="s6">|</span>D<span class="s6">)</span><span class="p">的方法。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 26pt;text-indent: 0pt;text-align: left;">贝叶斯公式</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s91" style="padding-left: 26pt;text-indent: 0pt;line-height: 19pt;text-align: left;"><span class="s204">P</span><span class="s33">(</span><span class="s30">h </span><span class="s33">| </span><span class="s30">D</span><span class="s33">) </span><span class="s38"> </span>P<span class="s92">( </span>D <span class="s92">| </span>h<span class="s92">) </span>P<span class="s92">(</span>h<span class="s92">)</span></p><p class="s30" style="text-indent: 0pt;line-height: 12pt;text-align: right;">P<span class="s33">(</span>D<span class="s33">)</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;">（<span class="s6">6.1</span>）</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;"><span class="p">直观可看出，</span>P<span class="s6">(</span>h<span class="s6">|</span>D<span class="s6">)</span><span class="p">随着 </span>P<span class="s6">(</span>h<span class="s6">)</span><span class="p">和 </span>P<span class="s6">(</span>D<span class="s6">|</span>h<span class="s6">)</span><span class="p">的增长而增长。同时也可看出 </span>P<span class="s6">(</span>h<span class="s6">|</span>D<span class="s6">)</span><span class="p">随 </span>P<span class="s6">(</span>D<span class="s6">)</span><span class="p">的增 加而减少，这是很合理的，因为如果 </span>D <span class="p">独立于 </span>h <span class="p">被观察到的可能性越大，那么 </span>D <span class="p">对 </span>h <span class="p">的支 持度越小。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">在许多学习场景中，学习器考虑候选假设集合<span class="s21">H</span>并在其中寻找给定数据<span class="s21">D</span>时可能性最大 的假设<span class="s21">h</span>∈<span class="s21">H</span>（或者存在多个这样的假设时选择其中之一）。这样的具有最大可能性的假设被 称为极大后验（<span class="s6">maximum a posteriori, MAP</span>）假设。确定<span class="s6">MAP</span>假设的方法是用贝叶斯公式计 算每个候选假设的后验概率。更精确地说当下式成立时，称<span class="s21">h</span><span class="s36">MAP</span>为—<span class="s6">MAP</span>假设：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="padding-top: 2pt;padding-left: 24pt;text-indent: 0pt;line-height: 16pt;text-align: center;">h<span class="s52">MAP </span><span class="s38"> </span><span class="s33">arg max </span>P<span class="s33">(</span>h <span class="s33">| </span>D<span class="s33">)</span></p><p class="s41" style="padding-left: 24pt;text-indent: 0pt;line-height: 8pt;text-align: center;">h<span class="s40"></span>H</p><p class="s91" style="padding-top: 2pt;padding-left: 24pt;text-indent: 0pt;line-height: 19pt;text-align: center;"><span class="s114"> </span><span class="s33">arg max </span>P<span class="s92">( </span>D <span class="s92">| </span>h<span class="s92">) </span>P<span class="s92">(</span>h<span class="s92">)</span></p><p class="s41" style="padding-top: 2pt;text-indent: 0pt;text-align: right;">h<span class="s40"></span>H</p><p class="s30" style="padding-left: 31pt;text-indent: 0pt;line-height: 12pt;text-align: left;">P<span class="s33">(</span>D<span class="s33">)</span></p><p class="s33" style="padding-top: 1pt;padding-left: 123pt;text-indent: 0pt;line-height: 15pt;text-align: left;"><span class="s38"> </span>arg max <i>P</i>(<i>D </i>| <i>h</i>)<i>P</i>(<i>h</i>)</p><p class="s41" style="padding-left: 145pt;text-indent: 0pt;text-align: left;">h<span class="s40"></span>H</p><p style="padding-top: 1pt;padding-left: 33pt;text-indent: 0pt;text-align: left;">（<span class="s6">6.2</span>）</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;"><span class="p">注意在最后一步我们去掉了 </span>P<span class="s6">(</span>D<span class="s6">)</span><span class="p">，因为它是不依赖于 </span>h <span class="p">的常量。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 5pt;text-indent: 21pt;text-align: justify;"><span class="p">在某些情况下，可假定 </span>H <span class="p">中每个假设有相同的先验概率（ 即对 </span>H <span class="p">中任意 </span>h<span class="s36">i</span><span class="s41"> </span><span class="p">和 </span>h<span class="s36">j</span><span class="s41"> </span><span class="p">， </span>P<span class="s6">(</span>h<span class="s36">i</span><span class="s6">)=</span>P<span class="s6">(</span>h<span class="s36">j</span><span class="s6">)</span><span class="p">）。这时可把等式 </span><span class="s6">6-2 </span><span class="p">进一步简化，只需考虑</span>P<span class="s6">(</span>D<span class="s6">|</span>h<span class="s6">)</span><span class="p">来寻找极大可能假设。</span>P<span class="s6">(</span>D<span class="s6">|</span>h<span class="s6">) </span><span class="p">常称为给定 </span>h <span class="p">时数据 </span>D <span class="p">的似然度（ </span><span class="s6">likelihood </span><span class="p">），而 使 </span><span class="s6">P(</span>D<span class="s6">|</span>h<span class="s6">) </span><span class="p">最大的假设被称为极大似然 </span></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">（<span class="s6">maximum likelihood</span>，<span class="s6">ML</span>）假设<span class="s21">h</span><span class="s36">ML</span>。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="padding-top: 2pt;padding-left: 152pt;text-indent: 0pt;line-height: 16pt;text-align: left;">h<span class="s52">ML</span><span class="s41"> </span><span class="s38"> </span><span class="s33">arg max </span>P<span class="s33">(</span>D <span class="s33">| </span>h<span class="s33">) </span><span class="p">（</span><span class="s6">6.3</span><span class="p">）</span></p><p class="s41" style="padding-left: 24pt;text-indent: 0pt;line-height: 8pt;text-align: center;">h<span class="s40"></span>H</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: left;">为了使上面的讨论与机器学习问题相联系，我们把数据 <span class="s21">D </span>称作某目标函数的训练样例， 而把 <span class="s21">H </span>称为候选目标函数空间。实际上，贝叶斯公式有着更为普遍的意义。它同样可以很 好地用于任意互斥命题的集合 <span class="s21">H</span>，只要这些命题的概率之和为 <span class="s6">1</span>（例如：“天空是兰色的” 和“天空不是兰色的”）。本章中有时将 <span class="s21">H </span>作为包含目标函数的假设空间，而 <span class="s21">D </span>作为训练例 集合。其他一些时候考虑将 <span class="s21">H </span>看作一些互斥命题的集合，而 <span class="s21">D </span>为某种数据。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">6.2.1 <span class="s25">示例</span></h3><p style="padding-top: 10pt;padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: left;">为说明贝叶斯规则，可考虑一医疗诊断问题，其中有两个可选的假设：（<span class="s6">1</span>）病人有某种 类型的癌症，（<span class="s6">2</span>）病人无癌症。可用的数据来自于一化验测试，它有两种可能的输出：<span class="s10"></span>（正） 和 <span class="s71">Θ</span>（负）。我们有先验知识：在所有人口中只有 <span class="s6">0.008 </span>的人患有该疾病。另外，该化验测 试只是该病的一个不完全的预计。该测试针对确实有病的患者有 <span class="s6">98%</span>的可能返回正确的<span class="s10"></span>结 果，而对无该病的患者有 <span class="s6">97%</span>的可能正确返回 <span class="s71">Θ </span>结果。除此以外，测试返回的结果是错误 的。上面的情况可由以下的概率式概括：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s108" style="padding-top: 3pt;padding-left: 96pt;text-indent: 16pt;line-height: 112%;text-align: justify;"><i>P</i>(<i>cancer</i>) <span class="s109"> </span>0.008 <span class="s6">, </span><i>P</i>(<span class="s109"> </span>| <i>cancer</i>) <span class="s109"> </span>0.98 <span class="s6">, </span><i>P</i>(<span class="s109"> </span>| <span class="s109"></span><i>cancer</i>) <span class="s109"> </span>0.03 <span class="s6">,</span></p><p class="s108" style="padding-top: 3pt;padding-left: 13pt;text-indent: -5pt;line-height: 112%;text-align: left;"><i>P</i>(<span class="s109"></span><i>cancer</i>) <span class="s109"> </span>0.992 <i>P</i>(<span class="s109"> </span>| <i>cancer</i>) <span class="s109"> </span>0.02 <i>P</i>(<span class="s109"> </span>| <span class="s109"></span><i>cancer</i>) <span class="s109"> </span>0.97</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: left;">假定现有一新病人，化验测试返回了<span class="s10"></span>结果。是否应将病人断定为有癌症呢？极大后验 假设可用式 <span class="s6">6.2 </span>来计算：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s108" style="padding-top: 3pt;padding-left: 24pt;text-indent: 0pt;text-align: center;"><i>P</i>(<span class="s109"> </span>| <i>cancer</i>)<i>P</i>(<i>cancer</i>) <span class="s109"> </span>(0.98) <span class="s109"> </span>(0.008) <span class="s109"> </span>0.0078</p><p class="s108" style="padding-top: 1pt;padding-left: 24pt;text-indent: 0pt;text-align: center;"><i>P</i>(<span class="s109"> </span>| <span class="s109"></span><i>cancer</i>)<i>P</i>(<span class="s109"></span><i>cancer</i>) <span class="s109"> </span>(0.03) <span class="s109"> </span>(0.992) <span class="s109"> </span>0.0298</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-top: 1pt;padding-left: 26pt;text-indent: 0pt;text-align: left;"><span class="p">因此，</span>h<span class="s36">MAP</span><span class="s6">=</span><span class="s10"></span>cancer<span class="p">。确切的后验概率可将上面的结果归一化以使它们的和为— （即</span></p><p class="s33" style="padding-left: 88pt;text-indent: 0pt;line-height: 10pt;text-align: left;">0.0078</p><p class="s6" style="padding-left: 6pt;text-indent: 0pt;line-height: 11pt;text-align: left;"><i>P</i>(<i>cancer</i>|<span class="s10"></span>)=</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="106" height="1" alt="image" src="机器学习/Image_219.png"/></span></p><p class="s33" style="text-indent: 0pt;text-align: left;">0.0078 <span class="s38"> </span>0.0298</p><p class="s6" style="padding-left: 5pt;text-indent: 0pt;line-height: 11pt;text-align: left;">=0.21<span class="p">）。该步骤的根据在于，贝叶斯公式说明后验概率就是</span></p><p class="s6" style="padding-left: 5pt;text-indent: 0pt;line-height: 107%;text-align: justify;"><span class="p">上面的量除以数据</span><i>P</i>(<span class="s10"></span>)<span class="p">。虽然</span><i>P</i>(<span class="s10"></span>)<span class="p">没有作为问题陈述的一部分直接给出，但因为已知 </span><i>P</i>(<i>cancer</i>|<span class="s10"></span>)<span class="p">和</span><i>P</i>(<span class="s10"></span><i>cancer</i>|<span class="s10"></span>)<span class="p">的和必为 </span>1<span class="p">（即该病人要么有癌症，要么没有），因此可以进行归 一化。注意虽然有癌症的后验概率比先验概率要大，但最可能的假设仍为此人没有癌症。</span></p><p style="padding-left: 12pt;text-indent: 21pt;line-height: 113%;text-align: justify;">如上例所示，贝叶斯推理的结果很大地依赖于先验概率，要直接应用该方法必须先获取 该值。还要注意该例中并没有完全地被接受或拒绝假设，而只是在观察到较多的数据后假设 的可能性增大或减小了。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 33pt;text-indent: 0pt;text-align: left;">计算概率的基本公式在表 <span class="s6">6-1 </span>中列举。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 2pt;text-align: left;"><span><img width="570" height="2" alt="image" src="机器学习/Image_220.png"/></span></p><p class="s56" style="padding-left: 12pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span><span class="s14">乘法公式</span><span class="s16">(Product rule)</span><span class="s14">：两事件 </span>A <span class="s14">和 </span>B <span class="s14">的交的概率 </span>P<span class="s16">(</span>A<span class="s57"></span>B<span class="s16">)</span></p><p class="s108" style="padding-top: 4pt;padding-left: 10pt;text-indent: 0pt;text-align: center;"><i>P</i>( <i>A </i><span class="s109"> </span><i>B</i>) <span class="s109"> </span>P(A | B)P(B) <span class="s109"> </span>P(B | A)P(A)</p><p class="s56" style="padding-top: 4pt;padding-left: 11pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span><span class="s14">加法公式</span><span class="s16">(Sum Rule)</span><span class="s14">：两事件 </span>A <span class="s14">和 </span>B <span class="s14">的并的概率 </span>P<span class="s16">(</span>A<span class="s57"></span>B<span class="s16">)</span></p><p class="s108" style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: center;"><i>P</i>( <i>A </i><span class="s109"> </span><i>B</i>) <span class="s109"> </span>P(A) <span class="s109"> </span>P(B) - P(A <span class="s109"> </span>B)</p><p class="s56" style="padding-top: 4pt;padding-left: 11pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span><span class="s14">贝叶斯法则</span><span class="s16">(Bayes theorem)</span><span class="s14">：给定 </span>D <span class="s14">时 </span>h <span class="s14">的后验概率 </span>P<span class="s16">(</span>h<span class="s16">|</span>D<span class="s16">)</span></p><p class="s91" style="padding-top: 4pt;padding-left: 9pt;text-indent: 0pt;line-height: 19pt;text-align: center;"><span class="s204">P</span><span class="s33">(</span><span class="s30">h </span><span class="s33">| </span><span class="s30">D</span><span class="s33">) </span><span class="s38"> </span>P<span class="s92">( </span>D <span class="s92">| </span>h<span class="s92">) </span>P<span class="s92">(</span>h<span class="s92">)</span></p><p class="s30" style="padding-left: 62pt;text-indent: 0pt;line-height: 12pt;text-align: center;">P<span class="s33">(</span>D<span class="s33">)</span></p><p class="s41" style="text-indent: 0pt;line-height: 7pt;text-align: left;">n</p><p style="text-indent: 0pt;text-align: left;"/><p class="s14" style="padding-top: 5pt;padding-left: 12pt;text-indent: 0pt;line-height: 14pt;text-align: left;"><span class="s55">n </span>全概率公式<span class="s16">(Theorem of total probability)</span>：如果事件<span class="s56">A</span><span class="s64">1</span><span class="s16">, …, </span><span class="s56">A</span><span class="s65">n</span>互斥且 <span class="s39"></span></p><p class="s33" style="padding-top: 8pt;padding-left: 5pt;text-indent: 0pt;line-height: 11pt;text-align: left;"><i>P</i>( <i>A</i><span class="s52">i</span><span class="s41"> </span>) <span class="s38"> </span>1 <span class="s14">，则：</span></p><p class="s41" style="text-indent: 0pt;line-height: 7pt;text-align: right;">i<span class="s40"></span><span class="s42">1</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s41" style="padding-left: 32pt;text-indent: 0pt;line-height: 6pt;text-align: center;">n</p><p class="s30" style="padding-left: 10pt;text-indent: 0pt;line-height: 19pt;text-align: center;">P<span class="s33">(</span>B<span class="s33">) </span><span class="s38"> </span><span class="s39"></span><span class="s121"> </span>P<span class="s33">(</span>B <span class="s33">| </span>A<span class="s52">i</span><span class="s41"> </span><span class="s33">)</span>P<span class="s33">( </span>A<span class="s52">i</span><span class="s41"> </span><span class="s33">)</span></p><p class="s41" style="padding-left: 32pt;text-indent: 0pt;line-height: 7pt;text-align: center;">i<span class="s40"></span><span class="s42">1</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 2pt;text-align: left;"><span><img width="570" height="2" alt="image" src="机器学习/Image_221.png"/></span></p><p style="padding-top: 6pt;padding-left: 31pt;text-indent: 0pt;text-align: center;">表 <span class="h4">6-1 </span>基本概率公式表</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 12pt;text-indent: 0pt;text-align: justify;">6.3 <span class="s17">贝叶斯法则和概念学习</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 12pt;text-indent: 21pt;line-height: 110%;text-align: justify;">贝叶斯法则和概念学习问题的关系是什么？因为贝叶斯法则为计算给定训练数据下任 一假设的后验概率提供了原则性方法，我们可直接将其作为一个基本的学习算法：计算每个 假设的概率，再输出其中概率最大的。本节考虑了这样一个 <span class="s6">Brute-Force </span>贝叶斯概念学习算 法，然后将其与第 <span class="s6">2 </span>章介绍的概念学习算法相比较。通过比较可以看到一个有趣的结论，即 在特定条件下，前面提到的几种算法都输出与 <span class="s6">Brute-Force </span>贝叶斯算法相同的假设，只不过 前面的算法不明确计算概率，而且在相当程度上效率更高。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 12pt;text-indent: 0pt;text-align: justify;">6.3.1 Brute-Force <span class="s25">贝叶斯概念学习</span></h3><p style="padding-top: 10pt;padding-left: 11pt;text-indent: 21pt;line-height: 107%;text-align: justify;">考虑第 <span class="s6">2 </span>章首先提到的概念学习问题。其中，我们假定学习器考虑的是定义在实例空间 <span class="s21">X</span>上的有限的假设空间<span class="s21">H</span>，任务是学习某个目标概念<span class="s21">c</span><span class="s6">:</span><span class="s21">X</span>→<span class="s6">{0,1}</span>。如通常那样，假定给予学习 器某训练样例序列〈〈<span class="s21">x</span><span class="s35">1</span>，<span class="s21">d</span><span class="s35">1</span>，〉⋯〈<span class="s21">x</span><span class="s36">m</span>，<span class="s21">d</span><span class="s36">m</span>〉，其中<span class="s21">x</span><span class="s36">i</span>为<span class="s21">X</span>中的某实例，<span class="s21">d</span><span class="s36">i</span>为<span class="s21">x</span><span class="s36">i</span>的目标函数值</p><p class="s21" style="padding-left: 12pt;text-indent: 0pt;text-align: justify;"><span class="p">（即</span>d<span class="s36">i</span><span class="s6">=</span>c<span class="s6">(</span>x<span class="s36">i</span><span class="s6">)</span><span class="p">）。为简化讨论，假定实例序列〈</span>x<span class="s35">1</span><span class="p">⋯</span>x<span class="s36">m</span><span class="p">〉是固定不变的，因此训练数据</span>D<span class="p">可被简 单地写作目标函数值序列：</span>D<span class="s6">=</span><span class="p">〈</span>d<span class="s35">1</span><span class="p">⋯</span>d<span class="s36">m</span><span class="p">〉。可以看到（见习题 </span><span class="s6">6.4</span><span class="p">），这一简化不会改变本节 的主要结论。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 33pt;text-indent: 0pt;text-align: left;">基于贝叶斯理论的直接概念学习算法定义如下：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h4 style="padding-left: 33pt;text-indent: 0pt;text-align: left;">Brute-Force MAP <span class="p">学习算法</span></h4><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 32pt;text-indent: 0pt;text-align: left;"><span class="s6">1</span>．对于 <span class="s21">H </span>中每个假设 <span class="s21">h</span>，计算后验概率：</p><p class="s91" style="padding-top: 2pt;padding-left: 24pt;text-indent: 0pt;line-height: 19pt;text-align: center;"><span class="s204">P</span><span class="s33">(</span><span class="s30">h </span><span class="s33">| </span><span class="s30">D</span><span class="s33">) </span><span class="s38"> </span>P<span class="s92">( </span>D <span class="s92">| </span>h<span class="s92">) </span>P<span class="s92">(</span>h<span class="s92">)</span></p><p class="s30" style="padding-left: 154pt;text-indent: 0pt;line-height: 12pt;text-align: center;">P<span class="s33">(</span>D<span class="s33">)</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">2<span class="p">．输出有最高后验概率的假设</span><i>h</i><span class="s36">MAP</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="padding-top: 2pt;padding-left: 24pt;text-indent: 0pt;line-height: 16pt;text-align: center;">h<span class="s52">MAP </span><span class="s38"> </span><span class="s33">arg max </span>P<span class="s33">(</span>h <span class="s33">| </span>D<span class="s33">)</span></p><p class="s41" style="padding-left: 24pt;text-indent: 0pt;line-height: 8pt;text-align: center;">h<span class="s40"></span>H</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;line-height: 110%;text-align: left;"><span class="p">此算法需要较大的计算量，因为它对 </span>H <span class="p">中每个假设都应用了贝叶斯公式以计算 </span>P<span class="s6">(</span>h<span class="s6">|</span>D<span class="s6">)</span><span class="p">。 虽然对于大的假设空间这很不切实际，但该算法仍然值得关注，因为它提供了一个标准，以 判断其他概念学习算法的性能。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;"><span class="p">下面为 </span>Brute-Force MAP <span class="p">学习算法指定一学习问题，我们必须确定 </span><i>P</i>(<i>h</i>)<span class="p">和 </span><i>P</i>(<i>D</i>|<i>h</i>)<span class="p">分别应 取何值（可以看出，</span><i>P</i>(<i>D</i>)<span class="p">的值会依这两者而定）。我们可以以任意方法选择 </span><i>P</i>(<i>h</i>)<span class="p">和 </span><i>P</i>(<i>D</i>|<i>h</i>)<span class="p">的 概率分布，以描述该学习任务的先验知识。这里令其与下面的前提一致：</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 26pt;text-indent: 0pt;text-align: left;"><span class="s6">1</span><span class="p">．训练数据</span>D<span class="p">是无噪声的（即</span>d<span class="s36">i</span><span class="s6">=</span>c<span class="s6">(</span>x<span class="s36">i</span><span class="s6">)</span><span class="p">）；</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 26pt;text-indent: 0pt;text-align: left;"><span class="s6">2</span>．目标概念 <span class="s21">c </span>包含在假设空间 <span class="s21">H </span>中；</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 26pt;text-indent: 0pt;text-align: left;">3<span class="p">．没有任何理由认为某假设比其他的假设的可能性大。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">有了这些假定，如何确定 <span class="s21">P</span><span class="s6">(</span><span class="s21">h</span><span class="s6">)</span>的值？由于任一假设不比其他假设可能性大，很显然可对 <span class="s21">H </span>中每个假设 <span class="s21">h </span>赋以相同的先验概率。进一步地，由于目标概念在 <span class="s21">H </span>中，所以可要求 <span class="s21">H </span>中 所有假设的概率和为 <span class="s6">1</span>。将这些限制合起来可得：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 24pt;text-indent: 0pt;line-height: 19pt;text-align: center;">对 <span class="s21">H </span>中任一 <span class="s21">h </span>， <span class="s30">P</span><span class="s33">(</span><span class="s30">h</span><span class="s33">) </span><span class="s38"> </span><span class="s92">1  </span></p><p class="s205" style="padding-left: 160pt;text-indent: 0pt;line-height: 13pt;text-align: center;"><span><img width="1" height="20" alt="image" src="机器学习/Image_222.png"/></span>H<span class="s30"> </span><span><img width="1" height="20" alt="image" src="机器学习/Image_223.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 6pt;text-indent: 21pt;text-align: justify;"><span class="p">如何选择</span>P<span class="s6">(</span>D<span class="s6">|</span>h<span class="s6">)</span><span class="p">的值？</span>P<span class="s6">(</span>D<span class="s6">|</span>h<span class="s6">)</span><span class="p">是已知假设</span>h<span class="p">成立的条件下（即已知</span>h<span class="p">为目标概念</span>c<span class="p">的正确描 述），观察到目标值</span>D<span class="s6">=</span><span class="p">〈</span>d<span class="s35">1</span><span class="s6">…</span>d<span class="s36">m</span><span class="p">〉的概率。由于假定训练数据无噪声，那么给定</span>h<span class="p">时，如果 </span>d<span class="s36">i</span><span class="s6">=</span>h<span class="s6">(</span>x<span class="s36">i</span><span class="s6">)</span><span class="p">则分类</span>d<span class="s36">i</span><span class="p">为 </span><span class="s6">1</span><span class="p">，如果</span>d<span class="s36">i</span><span class="p">≠</span>h<span class="s6">(</span>x<span class="s36">i</span><span class="s6">)</span><span class="p">则</span>d<span class="s36">i</span><span class="p">为 </span><span class="s6">0</span><span class="p">。因此：</span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="13" height="43" alt="image" src="机器学习/Image_224.png"/></span></p><p class="s21" style="padding-top: 7pt;padding-left: 130pt;text-indent: 0pt;line-height: 13pt;text-align: left;"><span class="s6">1 </span><span class="p">如果对 </span>D <span class="p">中所有 </span>d<span class="s36">i</span><span class="p">，</span>d<span class="s36">i</span><span class="s6">=</span>h<span class="s6">(</span>x<span class="s36">i</span><span class="s6">)</span></p><p class="s6" style="padding-left: 24pt;text-indent: 0pt;line-height: 10pt;text-align: center;"><i>P</i>(<i>D</i>|<i>h</i>)= <span class="p">（</span>6.4<span class="p">）</span></p><p class="s6" style="padding-left: 130pt;text-indent: 0pt;line-height: 13pt;text-align: left;">0 <span class="p">其他情况</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">换言之，给定假设 <span class="s21">h</span>，数据 <span class="s21">D </span>的概率在其与假设 <span class="s21">h </span>一致时值为 <span class="s6">1</span>，否则值为 <span class="s6">0</span>。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;"><span class="p">有了 </span>P<span class="s6">(</span>h<span class="s6">)</span><span class="p">和 </span>P<span class="s6">(</span>D<span class="s6">|</span>h<span class="s6">)</span><span class="p">的值，现在我们对于上面的 </span><span class="s6">Brute-Force MAP </span><span class="p">学习算法有了一个完整 定义的问题。接下来考虑该算法的第一步，使用贝叶斯公式计算每个假设 </span>h <span class="p">的后验概率 </span>P<span class="s6">(</span>h<span class="s6">|</span>D<span class="s6">)</span><span class="p">：</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s91" style="padding-top: 3pt;padding-left: 24pt;text-indent: 0pt;line-height: 19pt;text-align: center;"><span class="s204">P</span><span class="s33">(</span><span class="s30">h </span><span class="s33">| </span><span class="s30">D</span><span class="s33">) </span><span class="s38"> </span>P<span class="s92">( </span>D <span class="s92">| </span>h<span class="s92">) </span>P<span class="s92">(</span>h<span class="s92">)</span></p><p class="s30" style="padding-left: 154pt;text-indent: 0pt;line-height: 12pt;text-align: center;">P<span class="s33">(</span>D<span class="s33">)</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 6pt;text-indent: 20pt;line-height: 107%;text-align: left;">首先考虑 <span class="s21">h </span>与训练数据 <span class="s21">D </span>不一致的情形。由于式 <span class="s6">6.4 </span>定义当 <span class="s21">h </span>与 <span class="s21">D </span>不一致时 <span class="s21">P</span><span class="s6">(</span><span class="s21">D</span><span class="s6">|</span><span class="s21">h</span><span class="s6">)</span>为 <span class="s6">0</span>， 有：</p><p class="s33" style="padding-top: 1pt;padding-left: 122pt;text-indent: 0pt;line-height: 20pt;text-align: left;"><i>P</i>(<i>h </i>| <i>D</i>) <span class="s38"> </span><u>0 </u><span class="s117"> </span><u><i>P</i></u><u>(</u><u><i>h</i></u><u>) </u><span class="s38"> </span>0 <span class="p">，当 </span><span class="s21">h </span><span class="p">与 </span><span class="s21">D </span><span class="p">不一致。</span></p><p class="s30" style="padding-left: 24pt;text-indent: 0pt;line-height: 12pt;text-align: center;">P<span class="s33">(</span>D<span class="s33">)</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 26pt;text-indent: 0pt;text-align: left;">与 <span class="s21">D </span>不一致的假设 <span class="s21">h </span>的后验概率为 <span class="s6">0</span>。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 26pt;text-indent: 0pt;text-align: left;">再考虑 <span class="s21">h </span>与 <span class="s21">D </span>一致的情况。由于式 <span class="s6">6.4 </span>定义当 <span class="s21">h </span>与 <span class="s21">D </span>一致时 <span class="s21">P</span><span class="s6">(</span><span class="s21">D </span><span class="s6">|</span><span class="s21">h</span><span class="s6">)</span>为 <span class="s6">1</span>，有：</p><p style="text-indent: 0pt;text-align: left;"><span><img width="38" height="22" alt="image" src="机器学习/Image_225.png"/></span></p><p class="s115" style="padding-top: 7pt;padding-left: 113pt;text-indent: 0pt;line-height: 19pt;text-align: center;">1<span class="s38"> </span><u>1  </u></p><p class="s30" style="padding-left: 124pt;text-indent: 0pt;line-height: 8pt;text-align: center;">H</p><p class="s21" style="text-indent: 0pt;line-height: 12pt;text-align: right;">P<span class="s6">(</span>h<span class="s6">|</span>D<span class="s6">) </span><span class="s38"></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s38" style="text-indent: 0pt;text-align: right;"></p><p class="s30" style="padding-top: 7pt;padding-left: 1pt;text-indent: 0pt;text-align: center;">P<span class="s33">(</span>D<span class="s33">)</span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="47" height="69" alt="image" src="机器学习/Image_226.png"/></span></p><p class="s115" style="padding-top: 2pt;padding-left: 1pt;text-indent: 0pt;line-height: 19pt;text-align: center;">1<span class="s38"> </span><u>1  </u></p><p class="s30" style="padding-left: 3pt;text-indent: 15pt;line-height: 11pt;text-align: left;">H</p><p class="s41" style="padding-top: 4pt;padding-left: 1pt;text-indent: 0pt;text-align: center;"><span class="s49">VS</span>H <span class="s42">,</span>D</p><p class="s30" style="padding-top: 3pt;padding-left: 1pt;text-indent: 0pt;text-align: center;">H</p><p style="text-indent: 0pt;text-align: left;"><span><img width="1" height="23" alt="image" src="机器学习/Image_227.png"/></span></p><p style="padding-top: 4pt;padding-left: 208pt;text-indent: 0pt;line-height: 19pt;text-align: left;"><span class="s38"> </span><span class="s92">1 </span>当 <span class="s21">h </span>与 <span class="s21">D </span>一致</p><p class="s41" style="padding-left: 122pt;text-indent: 0pt;line-height: 15pt;text-align: center;"><span class="s49">VS</span>H <span class="s42">,</span>D <span><img width="1" height="23" alt="image" src="机器学习/Image_228.png"/></span></p><p style="padding-top: 8pt;padding-left: 26pt;text-indent: 0pt;text-align: left;">其中<span class="s21">VS</span><span class="s36">H</span><span class="s42">,</span><span class="s41">D</span>是<span class="s21">H</span>中与<span class="s21">D</span>一致的假设子集（即<span class="s21">VS</span><span class="s36">H</span><span class="s42">,</span><span class="s41">D</span>是相对于<span class="s21">D</span>的变型空间，如第 <span class="s6">2 </span>章的定义）。</p><p style="text-indent: 0pt;text-align: left;"><span><img width="46" height="47" alt="image" src="机器学习/Image_229.png"/></span></p><p class="s41" style="padding-top: 2pt;padding-left: 99pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><span class="s49">VS</span>H <span class="s42">,</span>D</p><p class="s21" style="padding-left: 6pt;text-indent: 0pt;line-height: 9pt;text-align: left;"><span class="p">很容易可验证</span>P<span class="s6">(</span>D<span class="s6">)=</span></p><p class="s30" style="text-indent: 0pt;line-height: 12pt;text-align: right;">H</p><p class="s21" style="padding-left: 6pt;text-indent: 0pt;line-height: 11pt;text-align: left;"><span class="p">，因为在所有假设上</span>P<span class="s6">(</span>h<span class="s6">|</span>D<span class="s6">)</span><span class="p">的和必为 </span><span class="s6">1</span><span class="p">，并且</span>H<span class="p">中与</span>D<span class="p">一致的假</span></p><p class="s6" style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;"><span class="p">设数量为</span>|<i>VS</i><span class="s36">H</span><span class="s42">,</span><span class="s41">D</span>|<span class="p">。另外，可从全概率公式（见表 </span>6-1<span class="p">）以及所有假设是互斥的条件（即</span></p><p class="s38" style="padding-left: 7pt;text-indent: 0pt;text-align: left;"><span class="s33">(</span><span class="s30">i </span></p><p class="s30" style="padding-left: 3pt;text-indent: 0pt;line-height: 17pt;text-align: left;">j<span class="s33">)(</span>P<span class="s33">(</span>h<span class="s52">i </span><span class="s38"> </span>h<span class="s52">j </span><span class="s33">) </span><span class="s38"> </span><span class="s33">0) </span><span class="p">），推导出</span><span class="s21">P</span><span class="s6">(</span><span class="s21">D</span><span class="s6">)</span><span class="p">的值：</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="text-indent: 0pt;text-align: right;">P<span class="s6">(</span>D<span class="s6">)</span></p><p class="s30" style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;line-height: 21pt;text-align: left;"><span class="s38"> </span><span class="s39"></span><span class="s121"> </span>P<span class="s33">(</span>D <span class="s33">| </span>h<span class="s52">i</span><span class="s41"> </span><span class="s33">)</span>P<span class="s33">(</span>h<span class="s52">i </span><span class="s33">)</span></p><p class="s41" style="padding-left: 14pt;text-indent: 0pt;line-height: 8pt;text-align: left;">h<span class="s180">i</span><span class="s44"> </span><span class="s40"></span>H</p><p class="s38" style="padding-top: 5pt;text-indent: 0pt;line-height: 21pt;text-align: right;"> <span class="s39"></span></p><p class="s41" style="text-indent: 0pt;line-height: 8pt;text-align: right;">h<span class="s180">i </span><span class="s40"></span>VS<span class="s180">H</span><span class="s44"> </span><span class="s189">,</span><span class="s44">D</span></p><p class="s38" style="padding-top: 6pt;text-indent: 0pt;line-height: 21pt;text-align: right;"> <span class="s39"></span></p><p class="s41" style="text-indent: 0pt;line-height: 8pt;text-align: right;">h<span class="s180">i </span><span class="s40"></span>VS<span class="s180">H</span><span class="s44"> </span><span class="s189">,</span><span class="s44">D</span></p><p class="s115" style="padding-top: 2pt;padding-left: 1pt;text-indent: 0pt;line-height: 19pt;text-align: center;">1<span class="s38"> </span><u>1 </u><span class="s114"></span></p><p class="s205" style="padding-left: 2pt;text-indent: 0pt;line-height: 13pt;text-align: center;"><span><img width="1" height="20" alt="image" src="机器学习/Image_230.png"/></span>H<span class="s30"> </span><span><img width="1" height="20" alt="image" src="机器学习/Image_231.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="1" height="20" alt="image" src="机器学习/Image_232.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="1" height="20" alt="image" src="机器学习/Image_233.png"/></span></p><p class="s115" style="padding-top: 3pt;text-indent: 0pt;line-height: 19pt;text-align: left;">1<span class="s38"> </span><u>1  </u></p><p class="s30" style="padding-left: 1pt;text-indent: 0pt;line-height: 11pt;text-align: center;">H</p><p class="s121" style="padding-top: 5pt;padding-left: 1pt;text-indent: 0pt;line-height: 21pt;text-align: center;"></p><p class="s41" style="text-indent: 0pt;line-height: 8pt;text-align: center;">h<span class="s180">i </span><span class="s40"></span>VS<span class="s180">H</span><span class="s44"> </span><span class="s189">,</span><span class="s44">D</span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="1" height="20" alt="image" src="机器学习/Image_234.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="1" height="20" alt="image" src="机器学习/Image_235.png"/></span></p><p class="s115" style="padding-top: 2pt;text-indent: 0pt;line-height: 19pt;text-align: left;">0 <span class="s38"> </span><u>1  </u></p><p class="s30" style="padding-left: 15pt;text-indent: 0pt;line-height: 11pt;text-align: left;">H</p><p style="text-indent: 0pt;text-align: left;"><span><img width="44" height="46" alt="image" src="机器学习/Image_236.png"/></span></p><p class="s41" style="padding-top: 5pt;padding-left: 114pt;text-indent: 0pt;line-height: 12pt;text-align: center;"><span class="s49">VS</span>H <span class="s42">, </span>D</p><p class="s38" style="padding-left: 24pt;text-indent: 0pt;line-height: 9pt;text-align: center;"></p><p class="s30" style="padding-left: 115pt;text-indent: 0pt;line-height: 12pt;text-align: center;">H</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;"><span class="p">概而言之，贝叶斯公式说明在我们的 </span>P<span class="s6">(</span>h<span class="s6">)</span><span class="p">和 </span>P<span class="s6">(</span>D<span class="s6">|</span>h<span class="s6">)</span><span class="p">的定义下，后验概率 </span>P<span class="s6">(</span>h<span class="s6">|</span>D<span class="s6">)</span><span class="p">为：</span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="17" height="68" alt="image" src="机器学习/Image_237.png"/></span></p><p class="s33" style="padding-top: 3pt;padding-left: 24pt;text-indent: 0pt;line-height: 10pt;text-align: center;">1</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 79pt;text-indent: 0pt;text-align: left;">P<span class="s6">(</span>h<span class="s6">|</span>D<span class="s6">)=</span></p><p class="s41" style="padding-top: 7pt;padding-left: 8pt;text-indent: 0pt;text-align: left;"><span class="s49">VS</span>H <span class="s42">,</span>D</p><p style="text-indent: 0pt;text-align: left;"><span><img width="45" height="25" alt="image" src="机器学习/Image_238.png"/></span></p><p style="padding-left: 15pt;text-indent: 0pt;line-height: 11pt;text-align: left;">如果 <span class="s21">h </span>与 <span class="s21">D </span>一致</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: center;">（<span class="s6">6.5</span>）</p><p class="s6" style="padding-top: 6pt;padding-left: 24pt;text-indent: 0pt;text-align: center;">0 <span class="p">其他情况</span></p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 20pt;text-align: justify;">其中<span class="s6">|</span><span class="s21">VS</span><span class="s36">H</span><span class="s42">,</span><span class="s41">D</span><span class="s6">|</span>是<span class="s21">H</span>中与<span class="s21">D</span>一致的假设数量。假设的概率演化情况如图 <span class="s6">6-1 </span>中所示。初始时（图 <span class="s6">6-1a</span>）所有假设具有相同的概率。当训练数据逐步出现后，（图 <span class="s6">6-1b</span>和 <span class="s6">6-1c</span>），不一致假设的 概率变为 <span class="s6">0</span>，而整个概率的和仍为 <span class="s6">1</span>，它们均匀地分布到剩余的一致假设中。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 27pt;text-indent: 0pt;text-align: left;"><span class="p">上面的分析说明，在我们选定的</span>P<span class="s6">(</span>h<span class="s6">)</span><span class="p">和</span>P<span class="s6">(</span>D<span class="s6">|</span>h<span class="s6">)</span><span class="p">取值下，每个一致的假设后验概率为</span></p><p class="s6" style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;"><span class="p">（</span>1/|<i>VS</i><span class="s36">H</span><span class="s42">,</span><span class="s41">D</span>|<span class="p">），每个不一致假设后验概率为 </span>0<span class="p">。因此，每个一致的假设都是</span>MAP<span class="p">假设。</span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="547" height="1" alt="image" src="机器学习/Image_239.png"/></span></p><p class="s48" style="padding-top: 5pt;padding-left: 15pt;text-indent: 0pt;text-align: left;">原书页码： <span class="s21">162</span></p><p class="s6" style="padding-top: 12pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">hypotheses: <span class="p">假设</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 14pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="531" height="1" alt="image" src="机器学习/Image_240.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 130pt;text-indent: 0pt;text-align: left;">图 <span class="h4">6-1 </span>后验概率随着训练数据增长的演化</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s16" style="padding-left: 37pt;text-indent: 21pt;line-height: 125%;text-align: left;">(a)<span class="s14">对每个假设赋予均匀的先验概率。当训练数据首先增长到 </span><i>D</i>1(b)<span class="s14">，然后增长到 </span><i>D</i>1<span class="s14">∧</span><i>D</i>2(c)<span class="s14">， 不一致假设的后验概率变成 </span>0<span class="s14">，而保留在变型空间中的假设的后验概率增加。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 6pt;text-indent: 0pt;text-align: justify;">6.3.2 MAP <span class="s25">假设和一致学习器</span></h3><p class="s21" style="padding-top: 10pt;padding-left: 5pt;text-indent: 21pt;line-height: 108%;text-align: left;"><span class="p">上面的分析说明在给定条件下，与</span>D<span class="p">一致的每个假设都是</span><span class="s6">MAP</span><span class="p">假设。根据这一结论可直 接得到一类普遍的学习器，称为一致学习器。某学习算法被称为一致学习器，说明它输出的 假设在训练例上有零错误率。由以上的分析可得，如果假定</span>H<span class="p">上有均匀的先验概率（即 </span>P<span class="s6">(</span>h<span class="s36">i</span><span class="s6">)=</span>P<span class="s6">(</span>h<span class="s36">j</span><span class="s6">)</span><span class="p">，对所有的</span>i<span class="s6">,</span>j<span class="p">），且训练数据是确定性的和无噪声的（即当</span>D<span class="p">和</span>h<span class="p">一致时，</span>P<span class="s6">(</span>D<span class="s6">|</span>h<span class="s6">)=1</span><span class="p">）， 否则为 </span><span class="s6">0</span><span class="p">）时，任意一致学习器将输出一个</span><span class="s6">MAP</span><span class="p">假设。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: left;"><span class="p">例如第 </span>2 <span class="p">章讨论的 </span>Find-S <span class="p">概念学习算法。</span>Find-S <span class="p">按照特殊到一般的顺序搜索假设空间 </span><i>H</i><span class="p">， 并输出一个极大特殊性的一致假设，可知在上面定义的 </span><i>P</i>(<i>h</i>)<span class="p">和 </span><i>P</i>(<i>D</i>|<i>h</i>)<span class="p">概率分布下，它输出 </span>MAP <span class="p">假设。当然，</span>Find-S <span class="p">并不直接操作概率，它只简单地输出变型空间的极大特殊性成员。 然而，通过决定 </span><i>P</i>(<i>h</i>)<span class="p">和 </span><i>P</i>(<i>D</i>|<i>h</i>)<span class="p">的分布，以使其输出为 </span>MAP <span class="p">假设，我们有了一种刻画 </span>Find-S <span class="p">算法的有效途径。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 5pt;text-indent: 21pt;text-align: justify;"><span class="p">是否还有其他可能的</span><i>P</i>(<i>h</i>)<span class="p">和</span><i>P</i>(<i>D</i>|<i>h</i>)<span class="p">分布，使</span>Find-S<span class="p">输出</span>MAP<span class="p">假设？回答是肯定的。因为 </span>Find-S<span class="p">从变型空间中输出极大特殊性</span>(maximally specific)<span class="p">假设，所以对于先验概率偏袒于更特 殊假设的任何概率分布，它输出的假设都将是</span>MAP<span class="p">假设。更精确地讲，假如</span><span class="s68">H</span><span class="p">是</span><i>H</i><span class="p">上任意概 率分布</span><i>P</i>(<i>h</i>)<span class="p">，它在</span><i>h</i><span class="s35">1</span><span class="p">比</span><i>h</i><span class="s35">2</span><span class="p">更特殊时赋予</span><i>P</i>(<i>h</i><span class="s35">1</span>)<span class="p">≥</span><i>P</i>(<i>h</i><span class="s35">2</span>)<span class="p">。可见，在假定有先验分布</span><span class="s68">H</span><span class="p">和与上面相 同的</span><i>P</i>(<i>D</i>|<i>h</i>)<span class="p">分布时，</span>Find-S<span class="p">输出一</span>MAP<span class="p">假设。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;"><span class="p">概括以上讨论，贝叶斯框架提出了一种刻画学习算法（如 </span>Find-S <span class="p">算法）行为的方法， 即使该学习算法不进行概率操作。通过确定算法输出最优（如 </span>MAP<span class="p">）假设时使用的概率分 布 </span><i>P</i>(<i>h</i>)<span class="p">和 </span><i>P</i>(<i>D</i>|<i>h</i>)<span class="p">，可以刻画出算法具有最优行为时的隐含假定。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 110%;text-align: justify;">使用贝叶斯的途径刻画学习算法，与揭示学习器中的归纳偏置在思想上是相类似的。注 意在第 <span class="s6">2 </span>章将学习算法的归纳偏置定义为断言集合 <span class="s21">B</span>，通过它可充分地演绎推断出学习器所 执行的归纳推理结果。例如，候选消除算法的归纳偏置为，假定目标概念 <span class="s21">c </span>包含在假定空间 <span class="s21">H </span>中。进一步地，我们还证明学习算法的输出是由其输入以及这一隐含的归纳偏置假定所演 绎得出的。上面的贝叶斯解释对于描述学习算法中的隐含假定提供了另一种方法。这里，不 是用一等效的演绎系统去对归纳推理建模，而是用基于贝叶斯理论的一个等效的概率推理</p><p class="s6" style="padding-left: 5pt;text-indent: 0pt;line-height: 107%;text-align: justify;"><span class="p">（</span>probabilistic reasoning<span class="p">）系统。这里应用于学习器的隐含假定形式为：“</span><i>H </i><span class="p">上的先验概率由 </span><i>P</i>(<i>h</i>)<span class="p">分布给出，而数据拒绝或接受假设的强度由 </span><i>P</i>(<i>D</i>|<i>h</i>)<span class="p">给出。”本书的 </span><i>P</i>(<i>h</i>)<span class="p">和 </span><i>P</i>(<i>D</i>|<i>h</i>)<span class="p">定义刻 画了候选消除和 </span>Find-S <span class="p">系统中的隐含假定。在已知这些假定的概率分布后，一个基于贝叶 斯理论的概率推理系统将产生等效于这些算法的输入</span>-<span class="p">输出行为。</span></p><p class="s6" style="padding-left: 27pt;text-indent: 0pt;text-align: left;"><span class="p">本节中的讨论是贝叶斯推理的一种特殊形式，因为我们只考虑了 </span><i>P</i>(<i>D</i>|<i>h</i>)<span class="p">取值只能为 </span>0</p><p class="s6" style="padding-top: 1pt;padding-left: 5pt;text-indent: 0pt;line-height: 107%;text-align: justify;"><span class="p">或 </span>1 <span class="p">的情况，它反映了假设预测的确定性以及无噪声数据的前提。如后一节所示，还可以通 过允许 </span><i>P</i>(<i>D</i>|<i>h</i>)<span class="p">取值为 </span>0 <span class="p">和 </span>1 <span class="p">之外的值，以及在 </span><i>P</i>(<i>D</i>|<i>h</i>)<span class="p">中包含附加的描述以表示噪声数据的分 布情况，来模拟从有噪声训练数据中学习的行为。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 6pt;text-indent: 0pt;text-align: justify;">6.4 <span class="s17">极大似然和最小误差平方假设</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 107%;text-align: justify;">如上节所示，贝叶斯分析可用来表明一个特定学习算法会输出 <span class="s6">MAP </span>假设，即使该算法 没有显式地使用贝叶斯规则，或以某种形式计算概率。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 113%;text-align: left;">本节考虑学习连续值目标函数的问题，这是在许多学习算法中都会遇到的，如神经网络 学习、线性回归、以及多项式曲线拟合。通过简单的贝叶斯分析，可以表明在特定前提下， 任一学习算法如果使输出的假设预测和训练数据之间的误差平方最小化，它将输出一极大似 然假设。这一结论的意义在于，对于许多神经网络和曲线拟合的方法，如果它们试图在训练 数据上使误差平方和最小化，此结论提供了一种贝叶斯的论证方法（在特定前提下）。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 5pt;text-indent: 21pt;line-height: 106%;text-align: justify;"><span class="p">设想问题定义如下，学习器</span>L<span class="p">工作在实例空间</span>X<span class="p">和假设空间</span>H<span class="p">上，</span>H<span class="p">中的假设为</span>X<span class="p">上定义 的某种实数值函数（即，</span>H<span class="p">中每个</span>h<span class="p">为一函数：</span>h<span class="s6">: </span>X<span class="p">→</span><span class="s72"></span><span class="p">，其中</span><span class="s72"></span><span class="p">代表实数集）。</span>L<span class="p">面临的问题 是学习一个从</span>H<span class="p">中抽取出的未知目标函数</span>f<span class="p">：</span>X<span class="p">→</span><span class="s72"></span><span class="p">。给定</span>m<span class="p">个训练样例的集合，每个样例的 目标值被某随机噪声干扰，此随机噪声服从正态分布。更精确地讲，每个训练样例是序偶〈</span>x<span class="s36">i</span><span class="s6">, </span>d<span class="s36">i</span><span class="p">〉，其中</span>d<span class="s36">i</span><span class="s6">=</span>f<span class="s6">(</span>x<span class="s36">i</span><span class="s6">)+</span>e<span class="s36">i</span><span class="p">。这里</span>f<span class="s6">(</span>x<span class="s36">i</span><span class="s6">)</span><span class="p">是目标函数的无噪声值，</span>e<span class="s36">i</span><span class="p">是一代表噪声的随机变量。假定</span>e<span class="s36">i</span><span class="p">的 值是独立抽取的，并且它们的分布服从零均值的正态分布。学习器的任务是在所有假设有相 等的先验概率前提下，输出极大可能假设（即</span><span class="s6">MAP</span><span class="p">假设），。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 108%;text-align: justify;">虽然我们的分析应用于任意实数值函数学习，然而可以用一个简单的例子来描述这一问 题，即学习线性函数。图 <span class="s6">6-2 </span>所示为一线性目标函数<span class="s21">f</span>（以实线表示），以及该目标函数的有 噪声训练样例集。虚线对应有最小平方训练误差的假设<span class="s21">h</span><span class="s36">ML</span>，也即极大似然假设。注意，其 中极大似然假设不一定等于正确假设<span class="s21">f</span>，因为它是从有限的带噪声数据中推论得出的。</p><p style="text-indent: 0pt;text-align: left;"><span><img width="547" height="1" alt="image" src="机器学习/Image_241.png"/></span></p><p class="s48" style="padding-top: 13pt;padding-left: 15pt;text-indent: 0pt;text-align: left;">原书页码： <span class="s21">164</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 14pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="531" height="1" alt="image" src="机器学习/Image_242.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 24pt;text-indent: 0pt;text-align: center;">图 <span class="h4">6-2 </span>学习一实值函数。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-left: 37pt;text-indent: 21pt;line-height: 117%;text-align: left;">目标函数<span class="s56">f</span>对应实线。假定训练样例〈<span class="s56">x</span><span class="s65">i</span><span class="s16">, </span><span class="s56">d</span><span class="s65">i</span>〉为真实目标值加上一零均值的正态分布噪声<span class="s56">e</span><span class="s65">i</span>。虚 线代表使误差平方之和最小的线性函数。因此，它就是这 <span class="s16">5 </span>个训练样例下的极大似然假设<span class="s56">h</span><span class="s65">ML</span>。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 109%;text-align: justify;">这里的误差平方和最小的假设即为极大似然假设，为说明这一点，首先快速地回顾一下 统计理论中的两个基本概念：概率密度和正态分布。首先，为讨论像<span class="s21">e</span>这样的连续变量上的 概率，我们引入概率密度（<span class="s6">probability density</span>）。简单的解释是，我们需要随机变量所有可能 值的概率和为 <span class="s6">1</span>。由于变量是连续的，因此不能为随机变量的无限种可能的值赋予一个有限 概率。这里需要用概率密度来代替，以使<span class="s21">e</span>这样的连续变量在所有值上的概率密度的积分为 <span class="s6">1</span>。一般地，用小写字母<span class="s21">p</span>来代表概率密度函数，以区分有限概率<span class="s21">P</span>（它有时又称为概率质量</p><p class="s6" style="padding-left: 6pt;text-indent: 0pt;line-height: 16pt;text-align: left;"><span class="p">（</span>probability mass<span class="p">）。概率密度</span><i>p</i>(<i>x</i><span class="s35">0</span>)<span class="p">是当</span><span class="s47">ε</span><span class="p">趋近于 </span>0 <span class="p">时，</span><i>x</i><span class="p">取值在</span>[<i>x</i><span class="s35">0</span>, <i>x</i><span class="s35">0</span>+<span class="s47">ε</span>)<span class="p">区间内的概率与</span></p><p class="s6" style="padding-left: 5pt;text-indent: 0pt;line-height: 15pt;text-align: left;">1/<span class="s47">ε</span><span class="p">乘积的极限。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">概率密度函数：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="padding-left: 27pt;text-indent: 0pt;text-align: left;">p<span class="s33">(</span>x<span class="s79">0</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s33" style="text-indent: 0pt;line-height: 18pt;text-align: left;">) <span class="s38"> </span>lim <u>1 </u><i>P</i>(<i>x</i></p><p class="s181" style="padding-left: 16pt;text-indent: 0pt;line-height: 13pt;text-align: left;"> <span class="s40"></span><span class="s42">0 </span><span class="s206"></span><span class="s119"> </span><span class="s207">0</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s38" style="padding-left: 2pt;text-indent: 0pt;text-align: left;"> <span class="s30">x </span> <span class="s30">x</span><span class="s79">0</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s38" style="padding-top: 7pt;padding-left: 1pt;text-indent: 0pt;text-align: left;"> <span class="s119"> </span><span class="s33">)</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;text-align: justify;">其次，这里断定随机噪声变量 <span class="s21">e </span>由正态分布生成。正态分布是一平滑的钟形分布，它可 由其均值<span class="s47">μ</span>和标准差<span class="s47">σ</span>完全刻画。见表 <span class="s6">5-4 </span>中的精确定义。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 110%;text-align: justify;">有了以上的两个概念，再来讨论在我们的问题里为什么最小误差平方假设实际上就是极 大似然假设。证明的过程先使用前面的式 <span class="s6">6-3 </span>的定义来推导极大可能假设，但使用小写的 <span class="s21">p </span>代表概率密度：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="padding-top: 2pt;padding-left: 169pt;text-indent: 0pt;line-height: 16pt;text-align: center;">h<span class="s52">ML</span><span class="s41"> </span><span class="s38"> </span><span class="s33">arg max </span>P<span class="s33">(</span>D <span class="s33">| </span>h<span class="s33">)</span></p><p class="s41" style="padding-left: 158pt;text-indent: 0pt;line-height: 8pt;text-align: center;">h<span class="s40"></span>H</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-top: 1pt;padding-left: 26pt;text-indent: 0pt;text-align: left;"><span class="p">如前所述，假定有一固定的训练实例集合〈</span>x<span class="s35">1</span><span class="s6">…</span>x<span class="s36">m</span><span class="p">〉，因此只考虑相应的目标值序列</span>D<span class="s6">=</span></p><p class="s21" style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><span class="p">〈</span>d<span class="s35">1</span><span class="s6">…</span>d<span class="s36">m</span><span class="p">〉。这里</span>d<span class="s36">i</span><span class="s6">=</span>f<span class="s6">(</span>x<span class="s36">i</span><span class="s6">)+</span>e<span class="s36">i</span><span class="p">。假定训练样例是相互独立的，给定</span>h<span class="p">时，可将</span>P<span class="s6">(</span>D<span class="s6">|</span>h<span class="s6">)</span><span class="p">写成各</span>p<span class="s6">(</span>d<span class="s36">i</span><span class="s6">|</span>h<span class="s6">) </span><span class="p">的积：</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s41" style="padding-top: 4pt;padding-left: 169pt;text-indent: 0pt;line-height: 6pt;text-align: center;">m</p><p class="s30" style="padding-left: 160pt;text-indent: 0pt;line-height: 17pt;text-align: left;">h<span class="s52">ML </span><span class="s38"> </span><span class="s33">arg max </span><span class="s39"> </span>p<span class="s33">(</span>d<span class="s52">i </span><span class="s33">| </span>h<span class="s33">)</span></p><p class="s41" style="text-indent: 0pt;line-height: 7pt;text-align: right;">h<span class="s40"></span>H</p><p class="s41" style="padding-left: 15pt;text-indent: 0pt;text-align: left;">i<span class="s40"></span><span class="s42">1</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 3pt;padding-left: 5pt;text-indent: 21pt;line-height: 16pt;text-align: justify;">如果误差<span class="s21">e</span><span class="s36">i</span>服从零均值和未知方差<span class="s47">σ</span><span class="s46">2</span>的正态分布，每个<span class="s21">d</span><span class="s36">i</span>也必须服从正态分布，其方差 为<span class="s47">σ</span><span class="s46">2</span>，而且以真实的目标值<span class="s21">f</span><span class="s6">(</span><span class="s21">x</span><span class="s36">i</span><span class="s6">)</span>为中心（而不是 <span class="s6">0</span>）。因此，<span class="s21">p</span><span class="s6">(</span><span class="s21">d</span><span class="s36">i</span><span class="s6">)</span>的可被写为方差<span class="s47">σ</span><span class="s46">2</span>，均值 <span class="s47">μ</span><span class="s6">=</span><span class="s21">f</span><span class="s6">(</span><span class="s21">x</span><span class="s36">i</span><span class="s6">)</span>的正态分布。现使用表 <span class="s6">5-4 </span>中的正态分布公式并将相应的<span class="s47">μ</span>和<span class="s47">σ</span><span class="s46">2</span>代入，写出描述<span class="s21">p</span><span class="s6">(</span><span class="s21">d</span><span class="s36">i</span><span class="s6">|</span><span class="s21">h</span><span class="s6">) </span>的正态分布。由于概率<span class="s21">d</span><span class="s36">i</span>的表达式是在<span class="s21">h</span>为目标函数<span class="s21">f</span>的正确描述条件下的，所以还要替换<span class="s47">μ</span></p><p class="s6" style="padding-left: 6pt;text-indent: 0pt;text-align: left;">=<i>f</i>(<i>x</i><span class="s36">i</span>)=<i>h</i>(<i>x</i><span class="s36">i</span>)<span class="p">。得到。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s41" style="padding-top: 4pt;padding-left: 212pt;text-indent: 0pt;line-height: 4pt;text-align: left;"><span class="s166">m</span> <span class="s40"> </span><u>1 </u><span class="s42">( </span>d <span class="s40"></span><span class="s181"> </span><span class="s42">)</span><span class="s209">2</span></p><p class="s49" style="padding-top: 5pt;text-indent: 0pt;line-height: 13pt;text-align: right;">h<span class="s41">ML</span></p><p class="s38" style="padding-top: 2pt;padding-left: 2pt;text-indent: 0pt;line-height: 17pt;text-align: left;"> <span class="s33">arg max</span><span class="s39"></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="51" height="22" alt="image" src="机器学习/Image_243.png"/></span></p><p class="s33" style="padding-left: 15pt;text-indent: 0pt;line-height: 19pt;text-align: left;">1 <i>e </i><span class="s79">2</span><span class="s181"> </span><span class="s189">2 </span><span class="s210">i</span></p><p class="s42" style="padding-left: 30pt;text-indent: 0pt;line-height: 0pt;text-align: left;">2</p><p class="s41" style="text-indent: 0pt;text-align: right;">h<span class="s40"></span>H</p><p class="s41" style="padding-top: 2pt;padding-left: 15pt;text-indent: 0pt;text-align: left;">i<span class="s40"></span><span class="s42">1</span></p><p class="s33" style="padding-left: 11pt;text-indent: 0pt;line-height: 13pt;text-align: left;">2<span class="s119"></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s41" style="padding-top: 4pt;padding-left: 196pt;text-indent: 0pt;line-height: 4pt;text-align: left;"><span class="s166">m </span><span class="s40"> </span><u>1 </u><span class="s42">(</span>d <span class="s40"></span>h<span class="s42">( </span>x <span class="s42">))</span><span class="s209">2</span></p><p class="s38" style="padding-top: 2pt;text-indent: 0pt;line-height: 17pt;text-align: right;"> <span class="s33">arg max </span><span class="s39"></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="51" height="22" alt="image" src="机器学习/Image_244.png"/></span></p><p class="s211" style="padding-left: 15pt;text-indent: 0pt;line-height: 19pt;text-align: left;">1 <i>e </i><span class="s178">2</span><span class="s181"> </span><span class="s197">2 </span><span class="s44">i i</span></p><p class="s42" style="padding-left: 30pt;text-indent: 0pt;line-height: 0pt;text-align: left;">2</p><p class="s41" style="text-indent: 0pt;text-align: right;">h<span class="s40"></span>H</p><p class="s41" style="padding-top: 2pt;padding-left: 15pt;text-indent: 0pt;text-align: left;">i<span class="s40"></span><span class="s42">1</span></p><p class="s33" style="padding-left: 11pt;text-indent: 0pt;line-height: 13pt;text-align: left;">2<span class="s119"></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;line-height: 110%;text-align: justify;">现在使用一个极大似然计算中常用的转换：不是用上面这个复杂的表达式取最大值，而 是使用其对数取最大，这样较容易。原因是 <span class="s6">ln</span><span class="s21">p </span>是 <span class="s21">p </span>的单调函数。因此使 <span class="s6">ln</span><span class="s21">p </span>最大也就使 <span class="s21">p </span>最大：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s41" style="padding-top: 4pt;text-indent: 0pt;line-height: 6pt;text-align: right;">m</p><p class="s33" style="padding-left: 109pt;text-indent: 0pt;line-height: 15pt;text-align: left;"><i>h</i><span class="s52">ML </span><span class="s38"> </span>arg max <span class="s39"></span>ln</p><p style="text-indent: 0pt;text-align: left;"><span><img width="51" height="22" alt="image" src="机器学习/Image_245.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="30" height="1" alt="image" src="机器学习/Image_246.png"/></span></p><p class="s33" style="padding-top: 4pt;padding-left: 15pt;text-indent: 0pt;line-height: 19pt;text-align: left;">1 <span class="s114"></span><span class="s38"> </span>1</p><p class="s213" style="padding-left: 30pt;text-indent: 0pt;line-height: 2pt;text-align: left;">2 <span class="s33">2</span><span class="s119"> </span><span class="s46">2</span></p><p class="s42" style="text-indent: 0pt;line-height: 7pt;text-align: left;">2</p><p style="text-indent: 0pt;text-align: left;"/><p class="s30" style="padding-top: 10pt;text-indent: 0pt;line-height: 14pt;text-align: left;"><span class="s33">(</span>d<span class="s52">i </span><span class="s38"> </span>h<span class="s33">(</span>x<span class="s52">i</span><span class="s41"> </span><span class="s33">))</span></p><p class="s41" style="text-indent: 0pt;text-align: right;">h<span class="s40"></span>H</p><p class="s41" style="padding-top: 2pt;padding-left: 14pt;text-indent: 0pt;text-align: left;">i<span class="s40"></span><span class="s42">1</span></p><p class="s33" style="padding-left: 21pt;text-indent: 0pt;line-height: 13pt;text-align: left;">2<span class="s119"></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 26pt;text-indent: 0pt;text-align: left;">此表达式中第一项为一独立于 <span class="s21">h </span>的常数，可被忽略，因此得到：</p><p class="s41" style="padding-top: 3pt;text-indent: 0pt;line-height: 6pt;text-align: right;">m</p><p class="s38" style="padding-left: 134pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><span class="s30">h</span><span class="s52">ML </span> <span class="s33">arg max </span><span class="s39"></span></p><p class="s33" style="padding-top: 3pt;padding-left: 14pt;text-indent: 0pt;line-height: 11pt;text-align: center;">1 <span class="s120">2</span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="30" height="1" alt="image" src="机器学习/Image_247.png"/></span></p><p class="s30" style="padding-left: 17pt;text-indent: 0pt;line-height: 7pt;text-align: center;"><span class="s178">2 </span><span class="s33">(</span>d<span class="s52">i </span><span class="s38"> </span>h<span class="s33">(</span>x<span class="s52">i</span><span class="s41"> </span><span class="s33">))</span></p><p class="s41" style="padding-top: 3pt;text-indent: 0pt;text-align: right;">h<span class="s40"></span>H</p><p class="s41" style="padding-left: 14pt;text-indent: 0pt;line-height: 14pt;text-align: left;">i<span class="s40"></span><span class="s42">1 </span><span class="s84">2</span><span class="s119"></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">使一个负的量最大等效于使相应的正的量最小：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s41" style="padding-top: 4pt;text-indent: 0pt;line-height: 6pt;text-align: right;">m</p><p class="s30" style="text-indent: 0pt;line-height: 12pt;text-align: right;">h<span class="s52">ML </span><span class="s38"> </span><span class="s33">arg min </span><span class="s39"></span></p><p class="s33" style="padding-top: 3pt;padding-left: 13pt;text-indent: 0pt;line-height: 11pt;text-align: center;">1 <span class="s120">2</span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="30" height="1" alt="image" src="机器学习/Image_248.png"/></span></p><p class="s30" style="padding-left: 17pt;text-indent: 0pt;line-height: 7pt;text-align: center;"><span class="s178">2 </span><span class="s33">(</span>d<span class="s52">i </span><span class="s38"> </span>h<span class="s33">(</span>x<span class="s52">i</span><span class="s41"> </span><span class="s33">))</span></p><p class="s41" style="padding-top: 3pt;text-indent: 0pt;text-align: right;">h<span class="s40"></span>H</p><p class="s41" style="padding-left: 13pt;text-indent: 0pt;line-height: 14pt;text-align: left;">i<span class="s40"></span><span class="s42">1 </span><span class="s84">2</span><span class="s119"></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">最后，可以再一次忽略掉与 <span class="s21">h </span>无关的常数：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s41" style="padding-top: 4pt;text-indent: 0pt;line-height: 6pt;text-align: right;">m</p><p class="s42" style="text-indent: 0pt;line-height: 7pt;text-align: left;">2</p><p style="text-indent: 0pt;text-align: left;"/><p class="s33" style="padding-left: 120pt;text-indent: 0pt;line-height: 17pt;text-align: left;"><i>h</i><span class="s52">ML</span><span class="s41">   </span><span class="s38"></span> arg min <span class="s39"></span>(<i>d</i><span class="s52">i</span><span class="s41">  </span><span class="s38"></span> <i>h</i>(<i>x</i><span class="s52">i</span><span class="s41"> </span>))</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 46pt;text-indent: 0pt;text-align: left;">(6.6)</p><p class="s41" style="text-indent: 0pt;line-height: 7pt;text-align: right;">h<span class="s40"></span>H</p><p class="s41" style="padding-left: 13pt;text-indent: 0pt;text-align: left;">i<span class="s40"></span><span class="s42">1</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;text-align: justify;"><span class="p">这样，式 </span><span class="s6">6.6 </span><span class="p">说明了极大似然假设</span>h<span class="s36">ML</span><span class="p">为，使训练值</span>d<span class="s36">i</span><span class="p">和假设预测值</span>h<span class="s6">(</span>x<span class="s36">i</span><span class="s6">)</span><span class="p">之间的误差的平 方和最小的那一个。该结论前提是观察的训练值</span>d<span class="s36">i</span><span class="p">由真实目标值加上随机噪声产生，其中随 机噪声是从一零均值的正态分布中独立抽取的。从上面的推导中可明确看出，误差平方项 </span><span class="s6">(</span>d<span class="s36">i</span><span class="s6">-</span>h<span class="s6">(</span>x<span class="s36">i</span><span class="s6">))</span><span class="s46">2</span><span class="p">是从正态分布定义中的指数项中得来。如果假定噪声分布有另外的形式，可进行类 似的推导得到不同的结果。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 6pt;text-indent: 21pt;line-height: 109%;text-align: justify;"><span class="p">注意上面的推导包含了选择假设使似然的对数值（</span>ln<i>p</i>(<i>D</i>|<i>h</i>)<span class="p">）为最大，以确定最可能的 假设。如前所述，这导致了与使 </span><i>p</i>(<i>D</i>|<i>h</i>)<span class="p">这个似然性最大化相同的结果。这一用对数似然性来 计算的方法在许多贝叶斯分析中都用到了，因为它比直接计算似然性需要的数学运算量小很 多。当然，如前所述，极大似然假设也许不是 </span>MAP <span class="p">假设，但如果所有假设有相等的先验概 率，两者相同。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 112%;text-align: justify;">为什么用正态分布来描述噪声是合理的？一个必须承认的原因是为了数学计算的简洁 性。另一原因是，这一平滑的钟形分布对许多物理系统的噪声都是良好的近似。实际上，第 <span class="s6">5 </span>章讨论的中心极限定律显示，足够多的独立同分布随机变量的和服从一正态分布，而不论 独立变量本身的分布是什么。这说明由许多独立同分布的因素的和所生成的噪声将成为正态 分布。当然，在现实中不同的分量对噪声的贡献也许不是同分布的，这样该定理将不能证明 我们的选择。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 113%;text-align: justify;">使误差平方最小化的方法经常被用于神经网络、曲线拟合及其他实函数逼近的许多算法 中。第 <span class="s6">4 </span>章讨论了梯度下降方法，它在神经网络中搜索最小误差平方的假设。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 113%;text-align: justify;">在结束这里关于极大似然假设和最小平方误差假设的关系的讨论之前，必须认识到该问 题框架中的某些限制。上面的分析只考虑了训练样例的目标值中的噪声，而没有考虑实例属 性中的噪声。例如，如果学习问题是基于某人的年龄和高度，预测他的重量，那么上面的分 析要求，重量的测量中可以有噪声，而年龄和高度的测量必须是精确的。如果将这些简化假 定去掉，分析过程将十分复杂。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">6.5 <span class="s17">用于预测概率的极大似然假设</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 113%;text-align: left;">在前一章的问题框架中，我们确定了极大似然假设是使其在训练样例上的误差平方和最 小的假设。本节将推导一个类似的准则，它针对神经网络学习这样的问题：即学习预测概率。</p><p style="padding-left: 6pt;text-indent: 20pt;line-height: 108%;text-align: justify;">考虑问题的框架为学习一个不确定性（概率的）函数 <span class="s21">f</span>：<span class="s21">X</span>→<span class="s6">{0, 1}</span>，它有两个离散的值 输出。例如，实例空间 <span class="s21">X </span>代表有某些症状的病人，目标函数 <span class="s21">f</span><span class="s6">(</span><span class="s21">x</span><span class="s6">)</span>在病人能存活下来时为 <span class="s6">1</span>， 否则为 <span class="s6">0</span>。或者说，<span class="s21">X </span>代表借货申请者，表示为其过去的信用历史，如果他能成功地归还下 一次借贷，<span class="s21">f</span><span class="s6">(</span><span class="s21">x</span><span class="s6">)</span>为 <span class="s6">1</span>，否则为 <span class="s6">0</span>。这两种情况下都要 <span class="s21">f </span>有不确定性。例如，一群有相同症状的 病人为 <span class="s6">92%</span>可以存活，<span class="s6">8%</span>不能。这种不可预测性来源于未能观察到的症状特征，或者是疾 病转化中确实存在的不确定性机制。无论问题的来源是什么，结果都是要求目标函数的输出 为输入的概率函数。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 5pt;text-indent: 21pt;line-height: 109%;text-align: justify;"><span class="p">有了这样的问题描述，我们希望学习得到的神经网络（或其他实函数逼近器）的输出是 </span><i>f</i>(<i>x</i>)=1 <span class="p">的概率。换言之，需要找到目标函数 </span><i>f´</i>=<i>X</i><span class="p">→</span>[0, 1]<span class="p">，使 </span><i>f</i>´=<i>P</i>(<i>f</i>(<i>x</i>)=1<span class="p">）。在上面的病人存 活预测的例子中，如果 </span><i>x </i><span class="p">为存活率是 </span>92%<span class="p">的病人之一，那么 </span><i>f</i>´(<i>x</i>)=0.92<span class="p">，概率函数 </span><i>f</i>(<i>x</i>)<span class="p">将有 </span>92%<span class="p">的机会等于 </span>1<span class="p">，剩余的 </span>8%<span class="p">的机会等于 </span>0<span class="p">。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">如何使用一个神经网络来学习 <span class="s21">f</span><span class="s6">´</span>？一个很明显的、蛮力的方法是首先收集对 <span class="s21">x </span>的每个可 能值观察到的 <span class="s6">1 </span>和 <span class="s6">0 </span>的频率，然后训练神经网络，对每个 <span class="s21">x </span>输出目标频率。下面将见到，我 们可以直接从 <span class="s21">f </span>的训练样例中训练神经网络，而且仍能推导出 <span class="s21">f</span><span class="s6">´</span>的极大可能性假设。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 108%;text-align: justify;">在此情况下为寻找极大似然假设，应使用怎样的优化准则？为回答该问题首先需要获得 <span class="s21">P</span><span class="s6">(</span><span class="s21">D</span><span class="s6">|</span><span class="s21">h</span><span class="s6">)</span>的表示。这里假定训练数据<span class="s21">D</span>的形式为<span class="s21">D</span><span class="s6">={</span>〈<span class="s21">x</span><span class="s35">1</span>，<span class="s21">d</span><span class="s35">1</span>〉⋯〈<span class="s21">x</span><span class="s36">m</span>，<span class="s21">d</span><span class="s36">m</span>〉<span class="s6">}</span>，其中<span class="s21">d</span><span class="s36">i</span>为观察到 的<span class="s21">f</span><span class="s6">(</span><span class="s21">x</span><span class="s36">i</span><span class="s6">)</span>的 <span class="s6">0 </span>或 <span class="s6">1 </span>值。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 5pt;text-indent: 21pt;text-align: justify;"><span class="p">回忆前一节中的极大似然及最小误差平方分析，其中简单地假定实例〈</span>x<span class="s35">1</span><span class="p">，⋯</span>x<span class="s36">m</span><span class="p">〉是固 定的。这样就可以只用目标值</span>d<span class="s36">i</span><span class="p">来刻画数据。虽然这里也可以作这样的简单假定，但我们这 里可以避免这一假定以说明这对最后的输出没有影响。将</span>x<span class="s36">i</span><span class="p">和</span>d<span class="s36">i</span><span class="p">都看作随机变量，并假定每 个训练样例都是独立抽取的，可把</span>P<span class="s6">(</span>D<span class="s6">|</span>h<span class="s6">)</span><span class="p">写作：</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s41" style="padding-top: 4pt;text-indent: 0pt;line-height: 6pt;text-align: right;">m</p><p class="s30" style="padding-left: 134pt;text-indent: 0pt;line-height: 19pt;text-align: center;">P<span class="s33">(</span>D <span class="s33">| </span>h<span class="s33">) </span><span class="s38"> </span><span class="s39"></span><span class="s121"> </span>P<span class="s33">(</span>x<span class="s52">i</span><span class="s41"> </span><span class="s33">, </span>d<span class="s52">i</span><span class="s41"> </span><span class="s33">| </span>h<span class="s33">)</span></p><p class="s41" style="text-indent: 0pt;line-height: 7pt;text-align: right;">i<span class="s40"></span><span class="s42">1</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 21pt;text-indent: 0pt;text-align: left;">（<span class="s6">6.7</span>）</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 6pt;text-indent: 21pt;text-align: left;">进一步地，可以假定遇到每一特定实例<span class="s21">x</span><span class="s36">i</span>的概率独立于假设<span class="s21">h</span>。例如，训练数据集中包 含一特定病人<span class="s21">x</span><span class="s36">i</span>的概率独立于关于存活率的假设（虽然病人的存活与否<span class="s21">d</span><span class="s36">i</span>确实强烈依赖于<span class="s21">h</span>）。 当<span class="s21">x</span>独立于<span class="s21">h</span>时，可将上式重写（应用表 <span class="s6">6-1 </span>的乘法规则）为：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s41" style="padding-top: 4pt;padding-left: 24pt;text-indent: 0pt;line-height: 7pt;text-align: center;">m m</p><p class="s30" style="padding-left: 90pt;text-indent: 0pt;line-height: 18pt;text-align: left;">P<span class="s33">(</span>D <span class="s33">| </span>h<span class="s33">) </span><span class="s38"> </span><span class="s39"></span><span class="s121"> </span>P<span class="s33">(</span>x<span class="s52">i</span><span class="s41"> </span><span class="s33">, </span>d<span class="s52">i</span><span class="s41"> </span><span class="s33">| </span>h<span class="s33">) </span><span class="s38"> </span><span class="s39"></span><span class="s121"> </span>P<span class="s33">(</span>d<span class="s52">i</span><span class="s41"> </span><span class="s33">| </span>h<span class="s33">, </span>x<span class="s52">i</span><span class="s41"> </span><span class="s33">)</span>P<span class="s33">(</span>x<span class="s52">i</span><span class="s41"> </span><span class="s33">) </span><span class="p">（</span><span class="s6">6.8</span><span class="p">）</span></p><p class="s41" style="text-indent: 0pt;line-height: 7pt;text-align: right;">i<span class="s40"></span><span class="s42">1</span></p><p class="s41" style="padding-left: 72pt;text-indent: 0pt;line-height: 7pt;text-align: left;">i<span class="s40"></span><span class="s42">1</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-top: 1pt;padding-left: 6pt;text-indent: 20pt;text-align: left;"><span class="p">现在计算在假设</span>h<span class="p">成立的条件下，对一个实例</span>x<span class="s36">i</span><span class="p">观察到</span>d<span class="s36">i</span><span class="s6">=1 </span><span class="p">的概率</span>P<span class="s6">(</span>d<span class="s36">i</span><span class="s6">|</span>h<span class="s6">, </span>x<span class="s36">i</span><span class="p">）。注意</span>h<span class="p">是对 应目标函数的假设，它正好能计算这一概率。因此，</span>P<span class="s6">(</span>d<span class="s36">i</span><span class="s6">=1|</span>h<span class="s6">, </span>x<span class="s36">i</span><span class="p">）</span><span class="s6">=</span>h<span class="s6">(</span>x<span class="s36">i</span><span class="s6">)</span><span class="p">，并且一般情况下：</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="18" height="48" alt="image" src="机器学习/Image_249.png"/></span></p><p class="s41" style="text-indent: 0pt;line-height: 7pt;text-align: left;">i                              i</p><p style="text-indent: 0pt;text-align: left;"/><p class="s6" style="padding-left: 74pt;text-indent: 0pt;text-align: left;"><i>P</i>(<i>d</i><span class="s36">i</span>|<i>h</i>, <i>x</i><span class="s36">i</span>)= <i>h</i>(<i>x </i>) <span class="p">如果 </span><i>d </i>=1 <span class="p">（</span>6.9<span class="p">）</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 26pt;text-indent: 0pt;text-align: left;">为将其代入到式 <span class="s6">6.8</span></p><p class="s6" style="padding-top: 6pt;padding-left: 20pt;text-indent: 0pt;line-height: 11pt;text-align: left;">(1-<i>h</i>(<i>x</i><span class="s36">i</span>)) <span class="p">如果 </span><i>d</i><span class="s36">i</span>=0</p><p class="s21" style="text-indent: 0pt;line-height: 10pt;text-align: left;"><span class="p">中求 </span>P<span class="s6">(</span>D<span class="s6">|</span>h<span class="s6">)</span><span class="p">，首先将其表达为一可数学操作形式。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s41" style="text-indent: 0pt;line-height: 8pt;text-align: left;">d<span class="s180">i</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s30" style="padding-top: 4pt;padding-left: 123pt;text-indent: 0pt;text-align: left;">P<span class="s33">(</span>d<span class="s52">i </span><span class="s33">| </span>h<span class="s33">, </span>x<span class="s52">i </span><span class="s33">) </span><span class="s38"> </span>h<span class="s33">(</span>x<span class="s52">i</span><span class="s41"> </span><span class="s33">)</span></p><p class="s33" style="padding-top: 4pt;text-indent: 0pt;text-align: left;">(1 <span class="s38"> </span><i>h</i>(<i>x</i><span class="s52">i</span><span class="s41"> </span>))</p><p class="s42" style="padding-top: 3pt;text-indent: 0pt;text-align: left;">1<span class="s40"></span><i>d</i><span class="s180">i</span></p><p style="padding-top: 4pt;padding-left: 1pt;text-indent: 0pt;text-align: left;">（<span class="s6">6.10</span>）</p><p style="padding-top: 2pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">容易验证，等式 <span class="s6">6.9 </span>和 <span class="s6">6.10 </span>是等价的。注意当<span class="s21">d</span><span class="s36">i</span><span class="s6">=1 </span>时，式 <span class="s6">6-10 </span>中第二项 <span class="s33">(1 </span><span class="s38"> </span><span class="s30">h</span><span class="s33">(</span><span class="s30">x</span><span class="s52">i</span><span class="s41"> </span><span class="s33">))</span></p><p class="s42" style="padding-top: 2pt;text-indent: 0pt;text-align: left;">1<span class="s40"></span><i>d</i><span class="s180">i</span></p><p class="s6" style="padding-top: 1pt;padding-left: 27pt;text-indent: -21pt;line-height: 181%;text-align: left;"><span class="p">等于</span>1<span class="p">。因此</span><i>P</i>(<i>d</i><span class="s36">i</span>=1|<i>h</i>, <i>x</i><span class="s36">i</span><span class="p">）</span>=<i>h</i>(<i>x</i><span class="s36">i</span>)<span class="p">，它与式 </span>6.9 <span class="p">等价。同样可分析</span><i>d</i><span class="s36">i</span>=0 <span class="p">时的情形。 将式 </span>6.10 <span class="p">代换式 </span>6.8 <span class="p">中的</span><i>P</i>(<i>d</i><span class="s36">i</span>|<i>h</i>, <i>x</i><span class="s36">i</span>)<span class="p">得到：</span></p><p class="s41" style="padding-top: 3pt;padding-left: 24pt;text-indent: 0pt;line-height: 6pt;text-align: center;">m</p><p class="s33" style="padding-left: 108pt;text-indent: 0pt;line-height: 10pt;text-align: left;"><i>P</i>(<i>D </i>| <i>h</i>) <span class="s38"></span> <span class="s124"></span><span class="s136"> </span><i>h</i>(<i>x </i>)<span class="s83">d</span><span class="s215">i</span><span class="s44">  </span>(1 <span class="s38"></span> <i>h</i>(<i>x </i>))<span class="s46">1</span><span class="s40"></span><span class="s41">d</span><span class="s215">i</span><span class="s44">   </span><i>P</i>(<i>x </i>) <span class="p">（</span><span class="s6">6.11</span><span class="p">）</span></p><p class="s41" style="padding-left: 193pt;text-indent: 0pt;line-height: 7pt;text-align: left;">i i i</p><p class="s41" style="padding-left: 24pt;text-indent: 0pt;line-height: 9pt;text-align: center;">i<span class="s40"></span><span class="s42">1</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 26pt;text-indent: 0pt;text-align: left;">现写出极大似然假设的表达式：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s49" style="padding-top: 11pt;text-indent: 0pt;text-align: right;">h<span class="s41">ML</span></p><p class="s38" style="padding-top: 10pt;padding-left: 13pt;text-indent: 0pt;line-height: 15pt;text-align: center;"> <span class="s33">arg max</span></p><p class="s41" style="padding-left: 13pt;text-indent: 0pt;line-height: 9pt;text-align: center;">h<span class="s40"></span>H</p><p class="s41" style="padding-top: 4pt;text-indent: 0pt;line-height: 6pt;text-align: center;">m</p><p class="s135" style="text-indent: 0pt;line-height: 18pt;text-align: center;"></p><p class="s41" style="padding-left: 2pt;text-indent: 0pt;line-height: 7pt;text-align: left;">i<span class="s40"></span><span class="s42">1</span></p><p class="s41" style="text-indent: 0pt;line-height: 8pt;text-align: left;">d<span class="s180">i</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s30" style="padding-top: 11pt;text-indent: 0pt;text-align: left;">h<span class="s33">(</span>x<span class="s52">i</span><span class="s41"> </span><span class="s33">)</span></p><p class="s33" style="padding-top: 10pt;text-indent: 0pt;text-align: left;">(1 <span class="s38"></span></p><p class="s30" style="padding-top: 11pt;text-indent: 0pt;text-align: left;">h<span class="s33">(</span>x<span class="s52">i</span><span class="s41"> </span><span class="s33">))</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s42" style="text-indent: 0pt;text-align: left;">1<span class="s40"></span><i>d</i><span class="s180">i</span></p><p class="s30" style="padding-top: 11pt;padding-left: 1pt;text-indent: 0pt;text-align: left;">P<span class="s33">(</span>x<span class="s52">i</span><span class="s41"> </span><span class="s33">)</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">最后一项为独立于 <span class="s21">h </span>的常量，可去掉：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s41" style="padding-top: 4pt;padding-left: 77pt;text-indent: 0pt;line-height: 6pt;text-align: center;">m</p><p class="s33" style="padding-left: 104pt;text-indent: 0pt;line-height: 10pt;text-align: left;"><i>h     </i><span class="s38"></span> arg max<span class="s124"></span><span class="s136"> </span><i>h</i>(<i>x </i>)<span class="s83">d</span><span class="s215">i</span><span class="s44">  </span>(1 <span class="s38"></span> <i>h</i>(<i>x </i>))<span class="s46">1</span><span class="s40"></span><span class="s41">d</span><span class="s215">i</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 34pt;text-indent: 0pt;line-height: 7pt;text-align: left;">(6.12)</p><p class="s41" style="text-indent: 0pt;line-height: 6pt;text-align: right;">ML</p><p class="s41" style="text-indent: 0pt;line-height: 8pt;text-align: right;">h<span class="s40"></span>H</p><p class="s41" style="padding-left: 45pt;text-indent: 0pt;line-height: 7pt;text-align: left;">i i</p><p class="s41" style="padding-left: 15pt;text-indent: 0pt;line-height: 9pt;text-align: left;">i<span class="s40"></span><span class="s42">1</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;text-align: justify;"><span class="p">式 </span>6.12 <span class="p">中右边的表达式可看作是表 </span>5-3 <span class="p">中二项分布（</span>Binomial distribution<span class="p">）的一般化形 式。该式描述的概率相当于投掷</span><i>m</i><span class="p">个不同硬币，输出得到〈</span><i>d</i><span class="s35">1</span>…<i>d</i><span class="s36">m</span><span class="p">〉的概率，其中假定每个 硬币</span><i>x</i><span class="s36">i</span><span class="p">产生正面的概率为</span><i>h</i>(<i>x</i><span class="s36">i</span>)<span class="p">。注意表 </span>5-3 <span class="p">描述的二项分布很简单，但它附加了一个假定， 即所有硬币掷出正面的概率是相同的（即</span><i>h</i>(<i>x</i><span class="s36">i</span>)=<i>h</i>(<i>x</i><span class="s36">j</span>), <span class="s10"></span><i>i</i>, <i>j</i><span class="p">）。两种情况下我们都假定硬币投掷 的输出是相互独立的，这一假设也适用于当前的问题。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 27pt;text-indent: 0pt;text-align: left;">与前面的情况相同，如果用似然性的对数计算会比较容易，得到：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s41" style="padding-top: 4pt;padding-left: 24pt;text-indent: 0pt;line-height: 6pt;text-align: center;">m</p><p class="s33" style="padding-left: 86pt;text-indent: 0pt;line-height: 16pt;text-align: left;"><i>h</i><span class="s52">ML</span><span class="s41"> </span><span class="s38"> </span>arg max <span class="s124"></span><span class="s135"> </span><i>d</i><span class="s52">i</span><span class="s41"> </span>ln <i>h</i>(<i>x</i><span class="s52">i</span><span class="s41"> </span>) <span class="s38"> </span>(1 <span class="s38"> </span><i>d</i><span class="s52">i</span><span class="s41"> </span>) ln(1 <span class="s38"> </span><i>h</i>(<i>x</i><span class="s52">i</span><span class="s41"> </span>)) <span class="p">（</span><span class="s6">6.13</span><span class="p">）</span></p><p class="s41" style="text-indent: 0pt;line-height: 7pt;text-align: right;">h<span class="s40"></span>H</p><p class="s41" style="padding-left: 14pt;text-indent: 0pt;text-align: left;">i<span class="s40"></span><span class="s42">1</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">式 <span class="s6">6.13 </span>描述了在我们的问题中必须被最大化的量。此结果可与前面的使误差平方最小</p><p style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">化的分析相类比。注意式 <span class="s6">6.13 </span>与熵函数的一般式<span class="s6">-</span>Σ<span class="s36">i</span><span class="s21">p</span><span class="s36">i</span><span class="s6">log</span><span class="s21">p</span><span class="s36">i</span>（在第 <span class="s6">3 </span>章讨论过）的相似性。 正因为此相似性，以上量的负值有时被称为交叉熵（<span class="s6">cross entropy</span>）。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">6.5.1 <span class="s25">在神经网络中梯度搜索以达到似然性最大化</span></h3><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-top: 1pt;padding-left: 6pt;text-indent: 21pt;line-height: 107%;text-align: left;"><span class="p">上面讨论了使式 </span>6.13 <span class="p">中的量最大化可得到极大可能假设。现用 </span><i>G</i>(<i>h</i>, <i>D</i>)<span class="p">代表该量。本节 为神经网络学习推导一个权值训练规则，它使用梯度上升以使 </span><i>G</i>(<i>h</i>, <i>D</i>)<span class="p">最大化。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-top: 1pt;padding-left: 6pt;text-indent: 20pt;line-height: 107%;text-align: left;"><span class="p">如第 </span><span class="s6">4 </span><span class="p">章中的讨论，</span>G<span class="s6">(</span>h<span class="s6">, </span>D<span class="s6">)</span><span class="p">的梯度可由</span>G<span class="s6">(</span>h<span class="s6">, </span>D<span class="s6">) </span><span class="p">关于不同的网络权值的偏导的向量给出， 它定义了由此学习到的网络表示的假设</span>h<span class="p">（见第 </span><span class="s6">4 </span><span class="p">章中梯度下降搜索的一般讨论，以及这里 所使用的术语的细节）。在此情况下，对应于权值</span>w<span class="s36">jk</span><span class="p">（从输入</span>k<span class="p">到单元</span>j<span class="p">）的</span>G<span class="s6">(</span>h<span class="s6">, </span>D<span class="s6">)</span><span class="p">的偏导为：</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s41" style="text-indent: 0pt;line-height: 7pt;text-align: left;">m</p><p style="text-indent: 0pt;text-align: left;"/><p class="s91" style="padding-left: 152pt;text-indent: 0pt;line-height: 10pt;text-align: left;"><span class="s117"></span>G<span class="s92">(</span>h<span class="s92">, </span>D<span class="s92">) </span><span class="s114"></span><span class="s38"> </span><span class="s153"></span><span class="s121"> </span><span class="s117"></span>G<span class="s92">(</span>h<span class="s92">, </span>D<span class="s92">) </span><span class="s117"></span>h<span class="s92">( </span>x <span class="s92">)</span></p><p class="s38" style="padding-top: 7pt;text-indent: 0pt;text-align: right;"><span class="s30">w</span><span class="s52">jk</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s41" style="text-indent: 0pt;text-align: right;">i<span class="s40"></span><span class="s42">1</span></p><p class="s30" style="padding-top: 7pt;padding-left: 8pt;text-indent: 0pt;text-align: left;"><span class="s38"></span>h<span class="s33">(</span>x<span class="s52">i</span><span class="s41"> </span><span class="s33">)</span></p><p class="s41" style="padding-left: 30pt;text-indent: 0pt;line-height: 7pt;text-align: left;">i</p><p class="s38" style="padding-left: 11pt;text-indent: 0pt;text-align: left;"><span class="s30">w</span><span class="s52">jk</span></p><p class="s41" style="text-indent: 0pt;line-height: 7pt;text-align: left;">m</p><p style="text-indent: 0pt;text-align: left;"/><p class="s92" style="padding-top: 2pt;padding-left: 199pt;text-indent: 0pt;line-height: 9pt;text-align: left;"><span class="s152"></span><span class="s38"> </span><span class="s153"></span><span class="s121"> </span><span class="s117"></span>(<i>d </i>ln <i>h</i>( <i>x </i>) <span class="s117"> </span>(1 <span class="s117"> </span><i>d </i>) ln(1 <span class="s117"> </span><i>h</i>( <i>x </i>))) <span class="s117"></span><i>h</i>( <i>x </i>)</p><p class="s41" style="padding-left: 211pt;text-indent: 30pt;line-height: 7pt;text-align: left;">i</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s41" style="text-indent: 0pt;text-align: right;">i<span class="s40"></span><span class="s42">1</span></p><p class="s41" style="padding-left: 29pt;text-indent: 0pt;line-height: 7pt;text-align: left;">i i</p><p class="s30" style="padding-left: 46pt;text-indent: 0pt;text-align: left;"><span class="s38"></span>h<span class="s33">(</span>x<span class="s52">i</span><span class="s41"> </span><span class="s33">)</span></p><p class="s41" style="text-indent: 0pt;line-height: 7pt;text-align: right;">i i</p><p class="s38" style="text-indent: 0pt;text-align: right;"><span class="s30">w</span><span class="s52">jk</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s41" style="text-indent: 0pt;line-height: 7pt;text-align: left;">m</p><p style="text-indent: 0pt;text-align: left;"/><p class="s30" style="padding-top: 2pt;text-indent: 0pt;line-height: 8pt;text-align: right;"><span class="s152"> </span>d<span class="s52">i </span><span class="s38"> </span>h<span class="s33">(</span>x<span class="s52">i</span><span class="s41"> </span><span class="s33">)</span></p><p class="s30" style="padding-top: 2pt;padding-left: 14pt;text-indent: 0pt;line-height: 8pt;text-align: left;"><span class="s38"></span>h<span class="s33">(</span>x<span class="s52">i</span><span class="s41"> </span><span class="s33">)</span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="145" height="1" alt="image" src="机器学习/Image_250.png"/></span></p><p class="s30" style="padding-left: 209pt;text-indent: 0pt;line-height: 18pt;text-align: left;"><span class="s216"> </span>h<span class="s33">(</span>x <span class="s33">)(1 </span><span class="s38"> </span>h<span class="s33">(</span>x <span class="s33">)) </span><span class="s38"></span>w</p><p style="padding-left: 46pt;text-indent: 0pt;line-height: 14pt;text-align: left;">（<span class="s6">6.14</span>）</p><p class="s122" style="text-indent: 0pt;line-height: 8pt;text-align: right;">i <span class="s40"></span><span class="s42">1 </span><span class="s41">i</span></p><p class="s41" style="padding-left: 40pt;text-indent: 0pt;text-align: left;">i jk</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">为使分析过程简明，假定神经网络从一个单层的 <span class="s6">sigmoid </span>单元建立。这种情况下有：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="padding-top: 2pt;text-indent: 0pt;text-align: right;"><span class="s38"></span>h<span class="s33">(</span>x<span class="s52">i</span><span class="s41"> </span><span class="s33">)</span></p><p style="padding-left: 129pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="43" height="1" alt="image" src="机器学习/Image_251.png"/></span></p><p class="s38" style="text-indent: 0pt;text-align: right;"><span class="s119"> </span><span class="s52">jk</span></p><p class="s38" style="padding-top: 10pt;padding-left: 1pt;text-indent: 0pt;text-align: left;"> <span class="s119"> </span><span class="s33">(</span><span class="s30">x</span><span class="s52">i</span><span class="s41"> </span><span class="s33">)</span><span class="s30">x</span><span class="s52">ijk</span></p><p class="s30" style="padding-top: 10pt;padding-left: 3pt;text-indent: 0pt;text-align: left;"><span class="s38"> </span>h<span class="s33">(</span>x<span class="s52">i</span><span class="s41"> </span><span class="s33">)(1 </span><span class="s38"> </span>h<span class="s33">(</span>x<span class="s52">i</span><span class="s41"> </span><span class="s33">))</span>x<span class="s52">ijk</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;text-align: justify;">其中<span class="s21">x</span><span class="s36">ijk</span>是对第<span class="s21">i</span>个样例的到单元 <span class="s21">j</span>的第<span class="s21">k</span>个输出，而<span class="s47">σ</span><span class="s6">´(</span><span class="s21">x</span><span class="s6">)</span>为<span class="s6">sigmoid </span>挤压（<span class="s6">squashing</span>）函 数的导数（见第 <span class="s6">4 </span>章）。最后，将此表达式代入到等式 <span class="s6">6.14</span>，可得到组成梯度的导数的简单 表示：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s121" style="text-indent: 0pt;line-height: 18pt;text-align: left;"></p><p style="text-indent: 0pt;text-align: left;"/><p class="s91" style="padding-top: 3pt;padding-left: 153pt;text-indent: 0pt;line-height: 11pt;text-align: left;"><span class="s117"></span>G<span class="s92">(</span>h<span class="s92">, </span>D<span class="s92">) </span><span class="s90">m</span></p><p class="s38" style="text-indent: 0pt;line-height: 8pt;text-align: right;"> <span class="s33">(</span><span class="s30">d</span><span class="s52">i</span></p><ul id="l18"><li style="padding-top: 10pt;padding-left: 11pt;text-indent: -9pt;line-height: 12pt;text-align: left;"><p class="s30" style="display: inline;">h<span class="s33">(</span>x<span class="s52">i</span><span class="s41"> </span><span class="s33">))</span>x</p></li></ul><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s41" style="text-indent: 0pt;line-height: 3pt;text-align: left;">ijk</p><p class="s38" style="text-indent: 0pt;line-height: 14pt;text-align: right;"><span class="s30">w</span><span class="s52">jk</span></p><p class="s41" style="padding-top: 4pt;padding-left: 26pt;text-indent: 0pt;text-align: left;">i<span class="s40"></span><span class="s42">1</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: left;"><span class="p">因为需要使用 </span>P<span class="s6">(</span>D<span class="s6">|</span>h<span class="s6">)</span><span class="p">最大化而不是最小化，所以我们执行梯度上升搜索而不是梯度下降 搜索。在搜索的每一次迭代中，权值向量按梯度的方向调整，使用权值更新规则：</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s49" style="padding-top: 3pt;text-indent: 0pt;text-align: right;">w<span class="s41">jk</span></p><p class="s38" style="padding-top: 2pt;padding-left: 3pt;text-indent: 0pt;text-align: left;"> <span class="s30">w</span><span class="s52">jk </span> <span class="s30">w</span><span class="s52">jk</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">其中：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s38" style="padding-top: 10pt;text-indent: 0pt;text-align: right;"><span class="s30">w</span><span class="s52">jk</span></p><p class="s41" style="padding-top: 4pt;padding-left: 23pt;text-indent: 0pt;line-height: 6pt;text-align: left;">m</p><p class="s33" style="padding-left: 3pt;text-indent: 0pt;line-height: 18pt;text-align: left;"><span class="s38"></span> <span class="s119"></span><span class="s124"></span>(<i>d</i><span class="s52">i</span><span class="s41">  </span><span class="s38"></span> <i>h</i>(<i>x</i><span class="s52">i</span><span class="s41"> </span>))<i>x</i><span class="s52">ijk</span><span class="s41">  </span><span class="p">（</span><span class="s6">6.15</span><span class="p">）</span></p><p class="s41" style="padding-left: 21pt;text-indent: 0pt;line-height: 7pt;text-align: left;">i<span class="s40"></span><span class="s42">1</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">其中<span class="s47">η</span>是一小的正常量，表示梯度上升搜索的步进大小。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 113%;text-align: justify;">将这一权值更新规则与反向传播算法（其用途是使预测和观察的网络输出的误差平方和 最小化）中用到的权值更新规则相比较，可以得到有趣的结论。用于输出单元权值的反向传 播更新规则（见第 <span class="s6">4 </span>章），使用这里的记号可重新表示为：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s49" style="padding-top: 3pt;text-indent: 0pt;text-align: right;">w<span class="s41">jk</span></p><p class="s38" style="padding-top: 2pt;padding-left: 3pt;text-indent: 0pt;text-align: left;"> <span class="s30">w</span><span class="s52">jk </span> <span class="s30">w</span><span class="s52">jk</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">其中</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s38" style="padding-top: 10pt;text-indent: 0pt;text-align: right;"><span class="s30">w</span><span class="s52">jk</span></p><p class="s41" style="padding-top: 4pt;padding-left: 23pt;text-indent: 0pt;line-height: 6pt;text-align: left;">m</p><p class="s30" style="padding-left: 3pt;text-indent: 0pt;line-height: 18pt;text-align: left;"><span class="s38"> </span><span class="s119"></span><span class="s124"></span><span class="s135"> </span>h<span class="s33">(</span>x<span class="s52">i</span><span class="s41"> </span><span class="s33">)(1 </span><span class="s38"> </span>h<span class="s33">(</span>x<span class="s52">i</span><span class="s41"> </span><span class="s33">))(</span>d<span class="s52">i</span><span class="s41"> </span><span class="s38"> </span>h<span class="s33">(</span>x<span class="s52">i</span><span class="s41"> </span><span class="s33">))</span>x<span class="s52">ijk</span></p><p class="s41" style="padding-left: 21pt;text-indent: 0pt;line-height: 7pt;text-align: left;">i<span class="s40"></span><span class="s42">1</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;"><span class="p">注意它与式 </span>6.15 <span class="p">中的规则相似，只是除了一项</span><i>h</i>(<i>x</i><span class="s36">i</span>)(1-<i>h</i>(<i>x</i><span class="s36">i</span>))<span class="p">，它是</span>sigmoid<span class="p">函数的导数。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 113%;text-align: left;">概括一下，这两个权值更新规则在两种不同的问题背景下收敛到极大似然假设。使误差 平方最小化的规则寻找到极大似然假设基于的前提是，训练数据可以由目标函数值加上正态</p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 113%;text-align: left;">分布噪声来模拟。使交叉熵最小化的规则寻找极大似然假设基于的前提是，观察到的布尔值 为输入实例的概率函数。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">6.6 <span class="s17">最小描述长度准则</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 111%;text-align: justify;">回忆一下第 <span class="s6">3 </span>章关于“奥坎坶剃刀”的讨论，这是一个很常用的归纳偏置，它可被概括 为：“为观察到的数据选择最短的解释”。本章我们要讨论在对奥坎坶剃刀的长期争论中的几 个论点。这里对此给出一个贝叶斯的分析，并讨论一紧密相关的准则，称为最小描述长度准 则（<span class="s6">Minimum Description Length, MDL</span>）。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;text-align: justify;">提出最小描述长度的目的是为了根据信息论中的基本概念来解释<span class="s21">h</span><span class="s36">MAP</span>的定义。再次考虑 已很熟悉的<span class="s21">h</span><span class="s36">MAP</span>定义：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="padding-top: 2pt;padding-left: 155pt;text-indent: 0pt;line-height: 16pt;text-align: left;">h<span class="s52">MAP</span><span class="s41"> </span><span class="s38"> </span><span class="s33">arg max </span>P<span class="s33">(</span>D <span class="s33">| </span>h<span class="s33">)</span>P<span class="s33">(</span>h<span class="s33">)</span></p><p class="s41" style="padding-left: 24pt;text-indent: 0pt;line-height: 8pt;text-align: center;">h<span class="s40"></span>H</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">可被等价地表示为使以 <span class="s6">2 </span>为底的对数最大化：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s33" style="padding-top: 2pt;padding-left: 127pt;text-indent: 0pt;line-height: 16pt;text-align: left;"><i>h</i><span class="s52">MAP </span><span class="s38"> </span>arg maxlog<span class="s79">2 </span><i>P</i>(<i>D </i>| <i>h</i>) <span class="s38"> </span>log<span class="s79">2</span><span class="s42"> </span><i>P</i>(<i>h</i>)</p><p class="s41" style="padding-left: 15pt;text-indent: 0pt;line-height: 8pt;text-align: center;">h<span class="s40"></span>H</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 26pt;text-indent: 0pt;text-align: left;">或使此最的负值最小化：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s33" style="padding-top: 2pt;padding-left: 99pt;text-indent: 0pt;line-height: 16pt;text-align: left;"><i>h</i><span class="s52">MAP </span><span class="s38"> </span>arg min<span class="s38"></span>log<span class="s79">2 </span><i>P</i>(<i>D </i>| <i>h</i>) <span class="s38"> </span>log<span class="s79">2</span><span class="s42"> </span><i>P</i>(<i>h</i>)</p><p class="s41" style="padding-left: 13pt;text-indent: 0pt;line-height: 8pt;text-align: center;">h<span class="s40"></span>H</p><p style="padding-top: 2pt;padding-left: 10pt;text-indent: 0pt;text-align: left;">（<span class="s6">6.16</span>）</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;line-height: 108%;text-align: left;">令人吃惊的是，式 <span class="s6">6.16 </span>可被解释为在特定的假设编码表示方案上“优先选择短的假设”。 为解释这一点，先引入信息论中的一个基本结论。设想要为随机传送的消息设计一个编码， 其中遇到消息<span class="s21">i</span>的概率是<span class="s21">p</span><span class="s36">i</span>。这里最感兴趣的是最简短的编码，即为了传输随机信息的编码所 能得到的最小期望传送位数。显然，为使期望的编码长度最小，必须为可能性较大的消息赋 予较短的编码。<span class="s6">Shannon &amp; Weaver</span>（<span class="s6">1949</span>）证明最优编码（使得期望消息长度最短的编码） 对消息<span class="s21">i</span>的编码长度为<span class="s6">-log</span><span class="s35">2</span><span class="s21">p</span><span class="s36">i</span>位。我们将使用代码<span class="s21">C</span>来编码消息<span class="s21">i</span>所需的位数称为消息<span class="s21">i</span>的关于<span class="s21">C </span>的描述长度（<span class="s6">description length of message i with respect to C</span>）。标记为<span class="s21">L</span><span class="s36">C</span><span class="s6">(</span><span class="s21">i</span><span class="s6">)</span>。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 26pt;text-indent: 0pt;text-align: left;">下面将使用以上编码理论的结论来解释等式 <span class="s6">6.16</span>：</p><p class="s6" style="text-indent: 0pt;line-height: 11pt;text-align: left;">(</p><p style="text-indent: 0pt;text-align: left;"/><p class="s21" style="padding-top: 6pt;padding-left: 49pt;text-indent: -21pt;line-height: 89%;text-align: left;"><span class="s10"> </span><span class="s6">-log</span><span class="s35">2</span>P<span class="s6">(</span>h<span class="s6">)</span><span class="p">是在假设空间</span>H<span class="p">的最优编码下</span>h<span class="p">的描述长度。换言之，这是假设</span>h<span class="p">使用其 最优表示时的大小。以这里的记号，</span>L<span class="s36">C</span><span class="s69">H </span>h<span class="s6">)= -log</span><span class="s35">2</span>P<span class="s6">(</span>h<span class="s6">)</span><span class="p">，其中</span>C<span class="s36">H</span><span class="p">为假设空间</span>H<span class="p">的</span></p><p style="padding-left: 49pt;text-indent: 0pt;line-height: 12pt;text-align: left;">最优编码。</p><p class="s21" style="padding-left: 28pt;text-indent: 0pt;line-height: 15pt;text-align: left;"><span class="s10"> </span><span class="s6">-log</span><span class="s35">2</span>P<span class="s6">(</span>D<span class="s6">|</span>h<span class="s6">)</span><span class="p">是在给定假设</span>h<span class="p">时训练数据</span>D<span class="p">的描述长度（在此最优编码下）。以这里</span></p><p style="padding-left: 49pt;text-indent: 0pt;line-height: 17pt;text-align: left;">的记号表示，<span class="s21">L</span><span class="s36">C</span><span class="s69">D</span><span class="s42">|</span><span class="s41">h</span></p><p class="s6" style="text-indent: 0pt;line-height: 14pt;text-align: left;">(<i>D</i>|<i>h</i>)= -log<span class="s35">2</span><i>P</i>(<i>D</i>|<i>h</i>)<span class="p">，其中</span><span class="s47">Ｃ</span><span class="s36">D</span><span class="s42">|</span><span class="s41">h</span><span class="p">是假定发送者和接送者都知道假</span></p><p style="padding-left: 49pt;text-indent: 0pt;line-height: 12pt;text-align: left;">设<span class="s21">h</span>时描述数据<span class="s21">D</span>的最优编码。</p><p style="padding-left: 49pt;text-indent: -21pt;line-height: 14pt;text-align: left;"><span class="s10"> </span>因此可把式 <span class="s6">6.16 </span>重写，以显示出<span class="s21">h</span><span class="s36">MAP</span>是使假设描述长度和给定假设下数据描述 长度之和最小化的假设<span class="s21">h</span>。</p><p class="s30" style="text-indent: 0pt;line-height: 9pt;text-align: right;">h <span class="s38"> </span><span class="s33">arg min </span>L</p><p class="s33" style="padding-left: 9pt;text-indent: 0pt;line-height: 9pt;text-align: left;">(<i>h</i>) <span class="s38"> </span><i>L</i></p><p class="s33" style="padding-top: 1pt;padding-left: 13pt;text-indent: 0pt;line-height: 9pt;text-align: left;">(<i>D </i>| <i>h</i>)</p><p class="s41" style="text-indent: 0pt;line-height: 7pt;text-align: right;">MAP</p><p class="s44" style="padding-left: 56pt;text-indent: 0pt;line-height: 7pt;text-align: left;"><span class="s166">C</span>H <span class="s166">C</span>D<span class="s189">|</span>h</p><p class="s41" style="padding-left: 28pt;text-indent: 0pt;line-height: 7pt;text-align: left;">h</p><p style="padding-left: 49pt;text-indent: 0pt;line-height: 14pt;text-align: left;">其中<span class="s21">C</span><span class="s36">H</span>和<span class="s21">C</span><span class="s36">D</span><span class="s42">|</span><span class="s41">h</span>分别为<span class="s21">H</span>的最优编码和给定<span class="s21">h</span>时<span class="s21">D</span>的最优编码，最小描述长度</p><p style="padding-left: 49pt;text-indent: 0pt;line-height: 14pt;text-align: left;">（<span class="s6">Minimum Description Length, MDL</span>）准则建议，应选择使这两个描述长度的和 最小化的假设。当然为应用此准则，在实践中必须选择适合于学习任务的特定</p><p style="padding-top: 1pt;padding-left: 49pt;text-indent: 0pt;line-height: 14pt;text-align: left;">编码或表示。假定使用代码<span class="s21">C</span><span class="s35">1</span>和<span class="s21">C</span><span class="s35">2</span>来表示假设和给定假设下的数据，可将<span class="s6">MDL </span>准则陈述为：</p><p style="padding-top: 6pt;padding-left: 26pt;text-indent: 0pt;text-align: left;">最小描述长度准则：选择<span class="s21">h</span><span class="s36">MDL</span>使</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s189" style="text-indent: 0pt;line-height: 5pt;text-align: left;">1</p><p style="text-indent: 0pt;text-align: left;"/><p class="s189" style="text-indent: 0pt;line-height: 5pt;text-align: left;">2</p><p style="text-indent: 0pt;text-align: left;"/><p class="s30" style="padding-top: 2pt;padding-left: 110pt;text-indent: 0pt;line-height: 16pt;text-align: left;">h<span class="s52">MDL </span><span class="s38"> </span><span class="s33">arg min </span>L<span class="s52">C </span><span class="s33">(</span>h<span class="s33">) </span><span class="s38"> </span>L<span class="s52">C</span></p><p class="s33" style="padding-top: 3pt;text-indent: 0pt;text-align: left;">(<i>D </i>| <i>h</i>)</p><p style="padding-top: 2pt;padding-left: 24pt;text-indent: 0pt;text-align: left;">（<span class="s6">6.17</span>）</p><p class="s41" style="padding-left: 24pt;text-indent: 0pt;line-height: 7pt;text-align: center;">h<span class="s40"></span>H</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">上面的分析显示，如果选择<span class="s21">C</span><span class="s35">1</span>为假设的最优编码<span class="s21">C</span><span class="s36">H</span>，并且选择<span class="s21">C</span><span class="s35">2</span>为最优编码<span class="s21">C</span><span class="s36">D</span><span class="s42">|</span><span class="s41">h</span>，那么</p><p class="s41" style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><span class="s217">h</span>MDL<span class="s218">=</span><span class="s21">h</span>MAP<span class="s219">。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: left;">直觉上，可将 <span class="s6">MDL </span>准则想象为选择最短的方法来重新编码训练数据，其中不仅计算假 设的大小，并且计算给定假设时编码数据的附加开销。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 5pt;text-indent: 21pt;text-align: left;"><span class="p">举例说明，假定将</span><span class="s6">MDL</span><span class="p">准则应用到决策树学习的问题当中。怎样选择假设和数据的表 示</span>C<span class="s35">1</span><span class="p">和</span>C<span class="s35">2</span><span class="p">？对于</span>C<span class="s35">1</span><span class="p">，可以很自然地选择某种明确的决策树编码方法，其中描述长度随着树中 节点和边的增长而增加。如何选择给定一决策树时假设的数据编码</span>C<span class="s35">2</span><span class="p">呢？为使讨论简单化， 假定实例序列〈</span>x<span class="s35">1</span><span class="s6">…</span>x<span class="s36">m</span><span class="p">〉是接收者和发送者都知道的，那么可以只传输分类结果〈</span>f<span class="s6">(</span>x<span class="s35">1</span><span class="s6">)…</span>f<span class="s6">(</span>x<span class="s36">m</span><span class="s6">)</span><span class="p">〉。</span></p><p class="s21" style="padding-left: 5pt;text-indent: 0pt;text-align: justify;"><span class="p">（注意传送实例的开销独立于正确的假设，因此它不会影响到</span>h<span class="s36">MDL</span><span class="p">的选择。）现在，如果训 练分类〈</span>f<span class="s6">(</span>x<span class="s35">1</span><span class="s6">)…</span>f<span class="s6">(</span>x<span class="s36">m</span><span class="s6">)</span><span class="p">〉与假设的预计相等，那么就没必要传输有关这些样例的任何信息（接 收者可在其收到假设后计算这些值）。因此在此情况下，给定假设的分类情况时的描述长度 为 </span><span class="s6">0</span><span class="p">。如果某些样例被</span>h<span class="p">误分类，那么对每一误分类需要传送一个消息以确定哪个样例被误 分类了（可用至多</span><span class="s6">log</span><span class="s35">2</span>m<span class="p">位传送），并传送其正确分类值（可用至多</span><span class="s6">log</span><span class="s35">2</span>k<span class="p">位，其中</span>k<span class="p">为可能分 类值的数目）。在编码</span>C<span class="s35">1</span><span class="p">和</span>C<span class="s35">2</span><span class="p">下</span>h<span class="s36">MDL</span><span class="p">这一假设就是使这些描述长度和最小的假设。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;line-height: 110%;text-align: left;">因此，<span class="s6">MDL </span>准则提供了一种方法以在假设的复杂性和假设产生错误的数量之间进行折 中，它有可能选择一个产生少量错误较短的假设；而不是能完美地分类训练数据的长的假设。 看到这一点，就有了一种处理数据过度拟合的方法。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">Quinlan &amp; Rivest<span class="p">（</span>1989<span class="p">）描述了应用 </span>MDL <span class="p">准则以选择决策树最佳大小的几个实验。报 告指出基于 </span>MDL <span class="p">的方法产生的决策树的精度相当于第 </span>3 <span class="p">章中讨论的标准的树修剪方法。 </span>Mehta et al.<span class="p">（</span>1995<span class="p">）描述了另一个基于 </span>MDL <span class="p">的方法进行决策树修剪，并实验证明该方法得 到的结果与标准树修剪方法相当。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: left;"><span class="p">从最小描述长度的原则的分析中可得到什么结论？是否说明所有情况下短假设都最 好？结论是否定的。已经证明的只是，当选定假设表示以使假设</span>h<span class="p">的大小为</span><span class="s6">-log</span><span class="s35">2</span>P<span class="s6">(</span>h<span class="s6">)</span><span class="p">，并且 选择例外情况的表示以使给定</span>h<span class="p">下</span>D<span class="p">的编码长度等于</span><span class="s6">-log</span><span class="s35">2</span>P<span class="s6">(</span>D<span class="s6">|</span>h<span class="s6">)</span><span class="p">时，</span><span class="s6">MDL</span><span class="p">准则产生</span><span class="s6">MAP</span><span class="p">假设。 然而为说明以上两者可以如此表示，必须知道所有的先验概率</span>P<span class="s6">(</span>h<span class="s6">)</span><span class="p">，以及</span>P<span class="s6">(</span>D<span class="s6">|</span>h<span class="s6">)</span><span class="p">。没有理由 相信</span><span class="s6">MDL</span><span class="p">假设对于任意编码</span>C<span class="s35">1</span><span class="p">和</span>C<span class="s35">2</span><span class="p">都是最好的。出于实际的考虑，更容易的办法是由设计 者指定一个表示，以捕获有关假设概率的知识，而不是完整地指定每个假设的概率。学术界 对</span><span class="s6">MDL</span><span class="p">应用到实际问题的争论，主要为选择</span>C<span class="s35">1</span><span class="p">和</span>C<span class="s35">2</span><span class="p">编码提供某种形式的论证。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">6.7 <span class="s17">贝叶斯最优分类器</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 113%;text-align: justify;">迄今我们已讨论了问题“给定训练数据，最可能的假设是什么？”实际上，该问题通常 与另一更有意义的问题紧密相关：“给定训练数据，对新实例的最可能分类是什么？”虽然 可看出第二个问题可简单地由应用 <span class="s6">MAP </span>假设到新实例来得到，实际上还可能更好的算法。</p><p style="padding-left: 5pt;text-indent: 21pt;text-align: justify;">为了更直观些，考虑一包含三个假设<span class="s21">h</span><span class="s35">1</span>，<span class="s21">h</span><span class="s35">2</span>，<span class="s21">h</span><span class="s35">3</span>的假设空间。假定已知训练数据时三个 假设的后验概率分别为 <span class="s6">0.4</span>，<span class="s6">0.3</span>，<span class="s6">0.3</span>。因此，<span class="s21">h</span><span class="s35">1</span>为<span class="s6">MAP</span>假设。若一新实例<span class="s21">x</span>被<span class="s21">h</span><span class="s35">1</span>分类为正， 但被<span class="s21">h</span><span class="s35">2</span>和<span class="s21">h</span><span class="s35">3</span>分类为反。计算所有假设，<span class="s21">x</span>为正例的概率为 <span class="s6">0.4</span>（即与<span class="s21">h</span><span class="s35">1</span>相联系的概率），而为反 例的概率是 <span class="s6">0.6</span>。这时最可能的分类（反例 ）与<span class="s6">MAP</span>假设生成的分类不同。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-top: 1pt;padding-left: 6pt;text-indent: 21pt;line-height: 108%;text-align: justify;"><span class="p">一般的说，新实例的最可能分类可通过合并所有假设的预测得到，其权重为它们的后验 概率。如果新的样例的可能的分类可取某集合</span>V<span class="p">中的任一值</span>v<span class="s36">j</span><span class="p">，那么概率</span>P<span class="s6">(</span>v<span class="s36">j</span><span class="s6">|</span>D<span class="s6">)</span><span class="p">为新实例正 确分类为</span>v<span class="s36">j</span><span class="p">的概率，其值为：</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="padding-top: 1pt;padding-left: 144pt;text-indent: 0pt;line-height: 21pt;text-align: left;">P<span class="s33">(</span>v <span class="s52">j </span><span class="s33">| </span>D<span class="s33">) </span><span class="s38"> </span><span class="s39"> </span>P<span class="s33">(</span>v <span class="s52">j </span><span class="s33">| </span>h<span class="s52">i </span><span class="s33">)</span>P<span class="s33">(</span>h<span class="s52">i </span><span class="s33">| </span>D<span class="s33">)</span></p><p class="s41" style="padding-left: 107pt;text-indent: 0pt;line-height: 8pt;text-align: center;">h<span class="s180">i</span><span class="s44"> </span><span class="s40"></span>H</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-top: 1pt;padding-left: 26pt;text-indent: 0pt;text-align: left;"><span class="p">新实例的最优分类为</span>P<span class="s6">(</span>v<span class="s36">j</span><span class="s6">|</span>D<span class="s6">)</span><span class="p">为最大时的</span>v<span class="s36">j</span><span class="p">值。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">贝叶斯最优分类器</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s33" style="padding-left: 19pt;text-indent: 0pt;line-height: 19pt;text-align: left;">arg max <span class="s39"></span><span class="s121"> </span><i>P</i>(<i>v </i><span class="s52">j</span><span class="s41"> </span>| <i>h</i><span class="s52">i</span><span class="s41"> </span>)<i>P</i>(<i>h</i><span class="s52">i</span><span class="s41"> </span>| <i>D</i>) <span class="p">（</span><span class="s6">6.18</span><span class="p">）</span></p><p class="s41" style="text-indent: 0pt;line-height: 9pt;text-align: right;">v <span class="s43">j</span><span class="s44"> </span><span class="s40"></span>V</p><p class="s41" style="padding-left: 11pt;text-indent: 0pt;text-align: left;">h<span class="s180">i</span><span class="s44"> </span><span class="s40"></span>H</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;"><span class="p">用上面的例子说明，新实例的可能分类集合为 </span><i>V</i>={<span class="s10"></span>,<span class="s71">Θ</span>}<span class="p">，而</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><table style="border-collapse:collapse;margin-left:135.789pt" cellspacing="0"><tr style="height:25pt"><td style="width:62pt"><p class="s96" style="padding-top: 3pt;padding-left: 2pt;text-indent: 0pt;text-align: left;">P<span class="s98">(</span>h<span class="s97">1</span><span class="s98">|</span>D<span class="s98">)=0.4,</span></p></td><td style="width:60pt"><p class="s98" style="padding-top: 3pt;padding-left: 5pt;text-indent: 0pt;text-align: left;"><i>P</i>(<span class="s220">Θ</span>|<i>h</i><span class="s97">1</span>)=0,</p></td><td style="width:55pt"><p class="s98" style="padding-top: 3pt;padding-left: 8pt;text-indent: 0pt;text-align: left;"><i>P</i>(<span class="s221"></span>|<i>h</i><span class="s97">1</span>)=1</p></td></tr><tr style="height:28pt"><td style="width:62pt"><p class="s96" style="padding-top: 6pt;padding-left: 2pt;text-indent: 0pt;text-align: left;">P<span class="s98">(</span>h<span class="s97">2</span><span class="s98">|</span>D<span class="s98">)=0.3,</span></p></td><td style="width:60pt"><p class="s98" style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;text-align: left;"><i>P</i>(<span class="s220">Θ</span>|<i>h</i><span class="s97">2</span>)=1,</p></td><td style="width:55pt"><p class="s98" style="padding-top: 6pt;padding-left: 8pt;text-indent: 0pt;text-align: left;"><i>P</i>(<span class="s221"></span>|<i>h</i><span class="s97">2</span>)=0</p></td></tr><tr style="height:25pt"><td style="width:62pt"><p class="s96" style="padding-top: 6pt;padding-left: 2pt;text-indent: 0pt;text-align: left;">P<span class="s98">(</span>h<span class="s97">3</span><span class="s98">|</span>D<span class="s98">)=0.3,</span></p></td><td style="width:60pt"><p class="s98" style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;text-align: left;"><i>P</i>(<span class="s220">Θ</span>|<i>h</i><span class="s97">3</span>)=1,</p></td><td style="width:55pt"><p class="s98" style="padding-top: 6pt;padding-left: 8pt;text-indent: 0pt;text-align: left;"><i>P</i>(<span class="s221"></span>|<i>h</i><span class="s97">3</span>)=0</p></td></tr></table><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">因此</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s33" style="padding-left: 161pt;text-indent: 0pt;line-height: 21pt;text-align: left;"><span class="s39"></span><span class="s121"> </span><i>P</i>(<span class="s38"> </span>| <i>h</i><span class="s52">i</span><span class="s41"> </span>)<i>P</i>(<i>h</i><span class="s52">i</span><span class="s41"> </span>| <i>D</i>) <span class="s38"> </span>0.4</p><p class="s41" style="padding-left: 24pt;text-indent: 0pt;line-height: 8pt;text-align: center;">h<span class="s180">i</span><span class="s44"> </span><span class="s40"></span>H</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s33" style="padding-left: 161pt;text-indent: 0pt;line-height: 21pt;text-align: left;"><span class="s39"></span><span class="s121"> </span><i>P</i>(<span class="s38"> </span>| <i>h</i><span class="s52">i</span><span class="s41"> </span>)<i>P</i>(<i>h</i><span class="s52">i</span><span class="s41"> </span>| <i>D</i>) <span class="s38"> </span>0.6</p><p class="s41" style="padding-left: 24pt;text-indent: 0pt;line-height: 8pt;text-align: center;">h<span class="s180">i</span><span class="s44"> </span><span class="s40"></span>H</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 5pt;padding-left: 26pt;text-indent: 0pt;text-align: left;">并且</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s33" style="padding-left: 134pt;text-indent: 0pt;line-height: 19pt;text-align: center;">arg max <span class="s39"></span><span class="s121"> </span><i>P</i>(<i>v </i><span class="s52">j</span><span class="s41"> </span>| <i>h</i><span class="s52">i</span><span class="s41"> </span>)<i>P</i>(<i>h</i><span class="s52">i</span><span class="s41"> </span>| <i>D</i>) <span class="s38"> </span><span class="s38"></span></p><p class="s40" style="text-indent: 0pt;line-height: 8pt;text-align: right;"><span class="s41">v </span><span class="s180">j</span><span class="s44"> </span><span class="s42">{</span><span class="s42">,</span><span class="s42">}</span></p><p class="s41" style="padding-left: 3pt;text-indent: 0pt;text-align: left;">h<span class="s180">i</span><span class="s44"> </span><span class="s40"></span>H</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;line-height: 111%;text-align: justify;">按照式 <span class="s6">6.18 </span>分类新实例的系统被为贝叶斯最优分类器（<span class="s6">Bayes optimal classifier</span>），或贝 叶斯最优学习器。使用相同的假设空间和相同的先验概率，没有其他方法能比其平均性能更 好。该方法在给定可用数据、假设空间及这些假设的先验概率下使新实例的正确分类的可能 性达到最大。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;line-height: 113%;text-align: justify;">例如，在布尔概念学习问题中，使用前面章节的变型空间方法，对一新实例的贝叶斯最 优分类是在变型空间的所有成员中进行加权选举获得的，每个候选假设的权重为其后验概 率。</p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">贝叶斯最优分类器的一个极有趣的属性是，它所做的分类可以对应于 <span class="s21">H </span>中不存在的假 设。设想使用式 <span class="s6">6.18 </span>来分类 <span class="s21">X </span>中每个实例。按此定义的的实例标注不必对应于 <span class="s21">H </span>中的任一 单个假设 <span class="s21">h </span>的对实例的标注。理解该命题的一种方法是将贝叶斯分类器看成是不同于假设空 间 <span class="s21">H </span>的另一空间 <span class="s21">H</span><span class="s6">´</span>，在其上应用贝叶斯公式。确切地讲，<span class="s21">H</span><span class="s6">´</span>有效地包含了一组假设，它能 在 <span class="s21">H </span>中多个假设的线性组合所作的预言中进行比较。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">6.8 Gibbs <span class="s17">算法</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;line-height: 110%;text-align: justify;">虽然贝叶斯最优分类器能从给定训练数据中获得最好的性能，应用此算法的开销可能很 大。原因在于它要计算 <span class="s21">H </span>中每个假设的后验概率，然后合并每个假设的预测，以分类新实 例。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 26pt;text-indent: 0pt;line-height: 190%;text-align: left;">一个替代的、非最优的方法是 <span class="s6">Gibbs</span>（见 <span class="s6">Opper &amp; Haussler 1991</span>），定义如下： <span class="s6">1</span>．按照 <span class="s21">H </span>上的后验概率分布，从 <span class="s21">H </span>中随机选择假设 <span class="s21">h</span>。</p><p style="padding-top: 2pt;padding-left: 26pt;text-indent: 0pt;text-align: left;"><span class="s6">2</span>．使用 <span class="s21">h </span>来预言下一实例 <span class="s21">x </span>的分类。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">当有一待分类新实例时，<span class="s6">Gibbs </span>算法简单地按照当前的后验概率分布，使用一随机抽取 的假设。令人吃惊的是，可证明在一定条件下 <span class="s6">Gibbs </span>算法的误分类率的期望值最多为贝叶斯 最优分类器的两倍（<span class="s6">Haussher et al. 1994</span>）。更精确地讲，期望值是在随机抽取的目标概念上 作出，抽取过程按照学习器假定的先验概率。在此条件下，<span class="s6">Gibbs </span>算法的错误率期望值最差 为贝叶斯分类器的两倍。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 111%;text-align: justify;">该结论对前述的概念学习问题有一有趣的启示。即如果学习器假定 <span class="s21">H </span>上有均匀的先验 概率，而且如果目标概念实际上也按该分布抽取，那么当前变型空间中随机抽取的假设对下 一实例分类的期望误差最多为贝叶斯分类器的两倍。这里又有了一个例子说明贝叶斯分析可 以对一非贝叶斯算法的性能进行评估。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">6.9 <span class="s17">朴素贝叶斯分类器</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">贝叶斯学习方法中实用性很高的一种为朴素贝叶斯学习器，常被称为朴素贝叶斯分类器</p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 0pt;line-height: 107%;text-align: left;">（<span class="s6">naive Bayes classifier</span>）。在某些领域内其性能可与神经网络和决策树学习相当。本节介绍 朴素贝叶斯分类器，下一节将其应用于实际的问题，即自然语言文本文档的分类问题。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;"><span class="p">朴素贝叶斯分类器应用的学习任务中，每个实例</span>x<span class="p">可由属性值的合取描述，而目标函数 </span>f<span class="s6">(</span>x<span class="s6">)</span><span class="p">从某有限集合</span>V<span class="p">中取值。学习器被提供一系列关于目标函数的训练样例，以及新实例（描 述为属性值的元组）</span><span class="s6">&lt;</span>a<span class="s35">1</span><span class="s6">,</span>a<span class="s35">2</span><span class="s6">…</span>a<span class="s36">n</span><span class="s6">&gt;</span><span class="p">，然后要求预测新实例的目标值（或分类）。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 5pt;text-indent: 21pt;text-align: justify;"><span class="p">贝叶斯方法的新实例分类目标是在给定描述实例的属性值</span>&lt;<i>a</i><span class="s35">1</span>,<i>a</i><span class="s35">2</span>…<i>a</i><span class="s36">n</span>&gt;<span class="p">下，得到最可能的 目标值</span><i>V</i><span class="s36">MAP</span><span class="p">。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="padding-top: 2pt;padding-left: 146pt;text-indent: 0pt;line-height: 16pt;text-align: left;">v<span class="s52">MAP</span><span class="s41"> </span><span class="s38"> </span><span class="s33">arg max </span>P<span class="s33">(</span>v <span class="s52">j</span><span class="s41"> </span><span class="s33">| </span>a<span class="s79">1</span><span class="s42"> </span><span class="s33">, </span>a<span class="s79">2</span><span class="s42"> </span><span class="s33">...</span>a<span class="s52">n</span><span class="s41"> </span><span class="s33">)</span></p><p class="s41" style="padding-left: 88pt;text-indent: 0pt;line-height: 9pt;text-align: center;">v <span class="s43">j</span><span class="s44"> </span><span class="s40"></span>V</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 26pt;text-indent: 0pt;text-align: left;">可使用贝叶斯公式将此表达式重写为</p><p class="s30" style="padding-top: 10pt;padding-left: 87pt;text-indent: 0pt;line-height: 16pt;text-align: left;">v<span class="s52">MAP </span><span class="s38"> </span><span class="s33">arg max</span></p><p class="s41" style="text-indent: 0pt;line-height: 9pt;text-align: right;">v <span class="s43">j</span><span class="s44"> </span><span class="s40"></span>V</p><p class="s30" style="padding-top: 2pt;padding-left: 1pt;text-indent: 0pt;text-align: center;">P<span class="s33">(</span>a<span class="s79">1</span><span class="s42"> </span><span class="s33">, </span>a<span class="s79">2</span><span class="s42"> </span><span class="s33">...</span>a<span class="s52">n</span><span class="s41"> </span><span class="s33">| </span>v <span class="s52">j</span><span class="s41"> </span><span class="s33">)</span>P<span class="s33">(</span>v <span class="s52">j</span><span class="s41"> </span><span class="s33">)</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="148" height="1" alt="image" src="机器学习/Image_252.png"/></span></p><p class="s30" style="padding-left: 1pt;text-indent: 0pt;text-align: center;">P<span class="s33">(</span>a<span class="s79">1</span><span class="s42"> </span><span class="s33">, </span>a<span class="s79">2</span><span class="s42"> </span><span class="s33">...</span>a<span class="s52">n</span><span class="s41"> </span><span class="s33">)</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s33" style="padding-top: 2pt;padding-left: 110pt;text-indent: 0pt;line-height: 16pt;text-align: left;"><span class="s38"> </span>arg max <i>P</i>(<i>a</i><span class="s79">1</span><span class="s42"> </span>, <i>a</i><span class="s79">2</span><span class="s42"> </span>...<i>a</i><span class="s52">n</span><span class="s41"> </span>| <i>v </i><span class="s52">j</span><span class="s41"> </span>)<i>P</i>(<i>v </i><span class="s52">j</span><span class="s41"> </span>)</p><p class="s41" style="padding-left: 8pt;text-indent: 0pt;line-height: 9pt;text-align: center;">v <span class="s43">j</span><span class="s44"> </span><span class="s40"></span>V</p><p style="padding-top: 2pt;padding-left: 29pt;text-indent: 0pt;text-align: left;">（<span class="s6">6.19</span>）</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;text-align: justify;"><span class="p">现在要做的是基于训练数据估计式 </span><span class="s6">6.19 </span><span class="p">中两个数据项的值。估计每个</span>P<span class="s6">(</span>v<span class="s36">j</span><span class="s6">)</span><span class="p">很容易，只 要计算每个目标值</span>v<span class="s36">j</span><span class="p">出现在训练数据中的频率就可以。然而，除非有一非常大的训练数据的 集合，否则用这样方法估计不同的 </span>P<span class="s6">(</span>a<span class="s35">1</span><span class="s6">,</span>a<span class="s35">2</span><span class="s6">…</span>a<span class="s36">n</span><span class="s6">|</span>v<span class="s36">j</span><span class="s6">)</span><span class="p">项不太可行。问题在于这些项的数量等于 可能实例的数量乘以可能目标值的数量。因此为获得合理的估计，实例空间中每个实例必须 出现多次。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;line-height: 108%;text-align: justify;"><span class="p">朴素贝叶斯分类器基于一个简单的假定：在给定目标值时属性值之间相互条件独立。换 言之，该假定说明给定实例的目标值情况下，观察到联合的</span>a<span class="s35">1</span><span class="s6">, </span>a<span class="s35">2</span><span class="s6">…</span>a<span class="s36">n</span><span class="p">的概率正好是对每个单 独属性的概率乘积：</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s33" style="padding-top: 2pt;padding-left: 145pt;text-indent: 0pt;text-align: left;"><i>P</i>(<i>a</i><span class="s79">1</span><span class="s42"> </span>, <i>a</i><span class="s79">2</span><span class="s42"> </span>...<i>a</i><span class="s52">n</span><span class="s41">  </span>| <i>v </i><span class="s52">j</span><span class="s41"> </span>) <span class="s38"></span> <span class="s124"></span><span class="s176">i</span><span class="s41"> </span><i>P</i>(<i>a</i><span class="s52">i</span><span class="s41">  </span>| <i>v </i><span class="s52">j</span><span class="s41"> </span>)</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 26pt;text-indent: 0pt;text-align: left;">将其代入 <span class="s6">6.19 </span>式中，可得到朴素贝叶斯分类器所使用的方法：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 26pt;text-indent: 0pt;text-align: left;">朴素贝叶斯分类器：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="padding-left: 99pt;text-indent: 0pt;line-height: 20pt;text-align: left;">v<span class="s52">NB</span><span class="s41">   </span><span class="s38"></span><span class="s33"> arg max </span>P<span class="s33">(</span>v <span class="s52">j</span><span class="s41"> </span><span class="s33">)</span><span class="s39"></span><span class="s176">i</span><span class="s41"> </span>P<span class="s33">(</span>a<span class="s52">i</span><span class="s41">  </span><span class="s33">| </span>v <span class="s52">j</span><span class="s41"> </span><span class="s33">)</span></p><p class="s41" style="padding-left: 35pt;text-indent: 0pt;line-height: 7pt;text-align: center;">v <span class="s180">j</span><span class="s44"> </span><span class="s40"></span>V</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 26pt;text-indent: 0pt;text-align: left;">（<span class="s6">6.20</span>）</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;text-align: justify;"><span class="p">其中</span>v<span class="s36">NB</span><span class="p">表示朴素贝叶斯分类器输出的目标值。注意在朴素贝叶斯分类器中，须从训练 数据中估计的不同</span>P<span class="s6">(</span>a<span class="s36">i</span><span class="s6">|</span>v<span class="s36">j</span><span class="s6">)</span><span class="p">项的数量只是不同的属性值数量乘以不同目标值数量——这比要 估计</span>P<span class="s6">(</span>a<span class="s35">1</span><span class="s6">,</span>a<span class="s35">2</span><span class="s6">…</span>a<span class="s36">n</span><span class="s6">|</span>v<span class="s36">j</span><span class="s6">)</span><span class="p">项所需的量小得多。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;text-align: left;"><span class="p">概括地讲，朴素贝叶斯学习方法需要估计不同的</span>P<span class="s6">(</span>v<span class="s36">j</span><span class="s6">)</span><span class="p">和</span>P<span class="s6">(</span>a<span class="s36">i</span><span class="s6">|</span>v<span class="s36">j</span><span class="s6">)</span><span class="p">项，基于它们在训练数据 上的频率。这些估计对应了待学习的假设。然后该假设使用式 </span><span class="s6">6.20 </span><span class="p">中的规则来分类新实例。 只要所需的条件独立性能够被满足，朴素贝叶斯分类</span>v<span class="s36">NB</span><span class="p">等于</span>MAP<span class="p">分类。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;line-height: 108%;text-align: justify;"><span class="p">朴素贝叶斯学习方法和其他已介绍的学习方法之间有一有趣的差别：没有明确的搜索假 设空间的过程（这里，可能假设的空间为可被赋予不同的</span>P<span class="s6">(</span>v<span class="s36">j</span><span class="s6">)</span><span class="p">和</span>P<span class="s6">(</span>a<span class="s36">i</span><span class="s6">|</span>v<span class="s36">j</span><span class="s6">)</span><span class="p">项的可能值。相反， 假设的形成不需要搜索，只是简单地计算训练样例中不同数据组合的出现频率）。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-top: 1pt;padding-left: 27pt;text-indent: -21pt;text-align: left;">6.9.1 <span class="s25">示例</span></h3><p style="padding-top: 10pt;padding-left: 5pt;text-indent: 21pt;line-height: 109%;text-align: justify;">现将朴素贝叶斯分类器应用到前面决策树中讨论过的概念学习问题：按照某人是否要打 网球来划分天气。第 <span class="s6">3 </span>章的表 <span class="s6">3-2 </span>提供了目标概念 <span class="s21">PlayTennis </span>的 <span class="s6">14 </span>个训练样例，其中每一 天由属性 <span class="s21">Outlook</span><span class="s6">, </span><span class="s21">Temprature</span><span class="s6">, </span><span class="s21">Humidity </span>和 <span class="s21">Wind </span>来描述。这里我们使用此表中的数据结合 朴素贝叶斯分类器来分类下面的新实例：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-top: 3pt;padding-left: 26pt;text-indent: 0pt;text-align: left;">&lt;<i>Outlook</i>=<i>sunny</i>, <i>Temperature</i>=<i>cool</i>, <i>Humidity</i>=<i>high</i>, <i>Wind</i>=<i>strong</i>&gt;</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 26pt;text-indent: 0pt;text-align: left;">我们的任务是对此新实例预测目标概念<span class="s21">PlayTennis </span>的目标值（<span class="s21">yes </span>或<span class="s21">no</span>）。将式 <span class="s6">6.20 </span>应</p><p style="padding-left: 5pt;text-indent: 0pt;text-align: center;">用到当前的任务，目标值<span class="s21">v</span><span class="s36">NB</span><span class="s41"> </span>由下式给出：</p><p class="s30" style="padding-top: 9pt;padding-left: 13pt;text-indent: 0pt;line-height: 20pt;text-align: center;">v<span class="s52">NB</span><span class="s41">   </span><span class="s38"></span><span class="s33"> arg max </span>P<span class="s33">(</span>v <span class="s52">j</span><span class="s41"> </span><span class="s33">)</span><span class="s39"></span><span class="s176">i</span><span class="s41"> </span>P<span class="s33">(</span>a<span class="s52">i</span><span class="s41">  </span><span class="s33">| </span>v <span class="s52">j</span><span class="s41"> </span><span class="s33">)</span></p><p class="s41" style="padding-left: 59pt;text-indent: 0pt;line-height: 7pt;text-align: left;">v <span class="s180">j</span><span class="s44"> </span><span class="s40"></span><span class="s42">{ </span>yes<span class="s42">,</span>no<span class="s42">}</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="padding-top: 2pt;padding-left: 36pt;text-indent: 0pt;line-height: 16pt;text-align: left;"><span class="s38"> </span><span class="s33">arg max </span>P<span class="s33">(</span>v <span class="s52">j</span><span class="s41"> </span><span class="s33">)</span>P<span class="s33">(</span>Outlook <span class="s38"> </span>sunny <span class="s33">| </span>v <span class="s52">j</span><span class="s41"> </span><span class="s33">)</span>P<span class="s33">(</span>Temperature <span class="s38"> </span>cool <span class="s33">| </span>v <span class="s52">j</span><span class="s41"> </span><span class="s33">)</span></p><p class="s41" style="padding-left: 46pt;text-indent: 0pt;line-height: 9pt;text-align: left;">v <span class="s180">j</span><span class="s44"> </span><span class="s40"></span><span class="s42">{ </span>yes<span class="s42">,</span>no<span class="s42">}</span></p><p class="s30" style="padding-top: 3pt;padding-left: 139pt;text-indent: 0pt;text-align: left;">P<span class="s33">(</span>Humidity <span class="s38"> </span>high <span class="s33">| </span>v <span class="s52">j</span><span class="s41"> </span><span class="s33">)</span>P<span class="s33">(</span>Wind <span class="s38"> </span>strong <span class="s33">| </span>v <span class="s52">j</span><span class="s41"> </span><span class="s33">)</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 14pt;text-indent: 0pt;text-align: left;">（<span class="s6">6.21</span>）</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;text-align: justify;">注意在最后一个表达式中<span class="s21">a</span><span class="s36">i</span>已经用新实例的特定属性值实例化了。为计算<span class="s21">v</span><span class="s36">NB</span>，现在需要 <span class="s6">10 </span>个概率，它们都可以训练数据中估计出。首先不同目标值的概率可以基于这 <span class="s6">14 </span>个训练样 例的频率很容易地估计出：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 160pt;text-indent: 0pt;line-height: 229%;text-align: center;">P<span class="s6">(</span>PlayTennis<span class="s6">=</span>yes<span class="s6">)=9/14=0.64 </span>P<span class="s6">(</span>PlayTennis<span class="s6">=</span>no<span class="s6">)=5/14=0.36</span></p><p class="s21" style="padding-left: 26pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><span class="p">相似地，可以估计出条件概率，例如对于 </span>Wind<span class="s6">=</span>Strong <span class="p">有：</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 24pt;text-indent: 0pt;text-align: center;">P<span class="s6">(</span>Wind<span class="s6">=</span>strong<span class="s6">|</span>PlayTennis<span class="s6">=</span>yes<span class="s6">)=3/9=0.33</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-top: 3pt;padding-left: 136pt;text-indent: 0pt;text-align: left;">P<span class="s6">(</span>Wind<span class="s6">=</span>strong<span class="s6">|</span>PlayTennis<span class="s6">=</span>no<span class="s6">)=3/5=0.60</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 20pt;text-align: left;">使用这些概率估计以及相似的对剩余属性的估计，可按照式 <span class="s6">6.21 </span>计算<span class="s21">v</span><span class="s36">NB</span>如下（为简明 起见忽略了属性名）。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-top: 3pt;padding-left: 91pt;text-indent: 0pt;text-align: left;">P<span class="s6">(</span>yes<span class="s6">)</span>P<span class="s6">(</span>sunny<span class="s6">|</span>yes<span class="s6">)</span>P<span class="s6">(</span>cool<span class="s6">|</span>yes<span class="s6">)</span>P<span class="s6">(</span>high<span class="s6">|</span>yes<span class="s6">)</span>P<span class="s6">(</span>strong<span class="s6">|</span>yes<span class="s6">)=0.0053</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-top: 3pt;padding-left: 98pt;text-indent: 0pt;text-align: left;">P<span class="s6">(</span>no<span class="s6">)</span>P<span class="s6">(</span>sunny<span class="s6">|</span>no<span class="s6">)</span>P<span class="s6">(</span>cool<span class="s6">|</span>no<span class="s6">)</span>P<span class="s6">(</span>high<span class="s6">|</span>no<span class="s6">)</span>P<span class="s6">(</span>strong<span class="s6">|</span>no<span class="s6">)=0.0206</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;line-height: 110%;text-align: justify;">这样，基于从训练数据中学习到的概率估计，朴素贝叶斯分类器将此实例赋以目标值 <span class="s21">PlayTennis</span><span class="s6">= </span><span class="s21">no </span>。更进一步，通过将上述的量归一化，可计算给定观察值下目标值为 <span class="s21">no </span>的 条件概率。对于此例，概率为 <span class="s6">0.0206/(0.0206+0.0053)=0.795</span>。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s37" style="padding-top: 1pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">6.9.1.1 <span class="s20">估计概率</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;line-height: 108%;text-align: left;"><span class="p">至此，我们通过在全部事件基础上观察某事件出现的比例来估计概率。例如，在上例中， 估计</span>P<span class="s6">(</span>Wind<span class="s6">=</span>Strong<span class="s6">|</span>PlayTennis<span class="s6">=</span>no<span class="s6">)</span><span class="p">使用的是比值</span>n<span class="s36">c</span><span class="s6">/</span>n<span class="p">，其中</span>n<span class="s6">=5</span><span class="p">，为所有</span>PlayTennis<span class="s6">= </span>no <span class="p">的训 练样例数目，而</span>n<span class="s36">c</span><span class="s6">=3 </span><span class="p">是在其中</span>Wind<span class="s6">=</span>Strong <span class="p">的数目。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 5pt;text-indent: 21pt;text-align: justify;"><span class="p">显然多数情况下，观察到的比例是对概率的一个良好估计，但当</span><i>n</i><span class="s36">c</span><span class="p">很小时估计都较差。 难度在于，设想</span><i>P</i>(<i>Wind</i>=<i>Strong</i>|<i>PlayTennis</i>= <i>no</i>)<span class="p">的值为 </span>0.08<span class="p">，而样本中只有 </span>5 <span class="p">个样例的 </span><i>PlayTennis</i>=<i>no</i><span class="p">。那么对于</span><i>n</i><span class="s36">c</span><span class="p">最可能的值只有 </span>0<span class="p">。这产生了两个难题，首先，</span><i>n</i><span class="s36">c</span>/<i>n</i><span class="p">产生了一个 有偏的过低估计（</span>underestimate<span class="p">）概率。其次，当此概率估计为 </span>0 <span class="p">时，如果将来的查询包含</span></p><p class="s6" style="padding-left: 6pt;text-indent: 0pt;line-height: 107%;text-align: left;"><i>Wind</i>=<i>Strong</i><span class="p">，此概率项会在贝叶斯分类器占有统治地位。原因在于，由式 </span>6.20 <span class="p">计算的量需 要将所有其他的概率项乘以此 </span>0 <span class="p">值。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 27pt;text-indent: 0pt;text-align: left;">为避免这些难题，这里采用一种估计概率的贝叶斯方法，使用如下定义的 <span class="s21">m</span><span class="s6">-</span>估计：</p><p style="padding-left: 27pt;text-indent: 0pt;text-align: left;">概率的 <span class="s7">m</span><span class="h4">-</span>估计</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="52" height="1" alt="image" src="机器学习/Image_253.png"/></span></p><p class="s30" style="padding-left: 33pt;text-indent: -5pt;text-align: left;">n<span class="s52">c </span><span class="s38"> </span>mp n <span class="s38"> </span>m</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 27pt;text-indent: 0pt;text-align: left;">（<span class="s6">6.22</span>）</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;text-align: justify;"><span class="p">这里，</span>n<span class="s36">c</span><span class="p">和</span>n<span class="p">如前面定义，</span>p<span class="p">是将要确定的概率的先验估计，而</span>m<span class="p">是一称为等效样本大小 的常量，它确定了对于观察到的数据如何衡量</span>p<span class="p">的作用。在缺少其他信息时选择</span>p<span class="p">的一种典型 的方法是假定均匀的先验概率，也就是，如果某属性有</span>k<span class="p">个可能值，那么设置</span>p<span class="s6">=1/</span>k<span class="p">。例如， 为估计（</span>Wind<span class="s6">=</span>Strong<span class="s6">|</span>PlayTennis<span class="s6">= </span>no<span class="p">），注意到属性</span>Wind<span class="p">有两个可能值，因此均匀的先验概 率为</span>p<span class="s6">=0.5</span><span class="p">。注意如果</span>m<span class="p">为 </span><span class="s6">0</span><span class="p">，</span>m<span class="s6">-</span><span class="p">估计等效于简单的比例</span>n<span class="s36">c</span><span class="s6">/</span>n<span class="p">。如果</span>n<span class="p">和</span>m<span class="p">都非 </span><span class="s6">0</span><span class="p">，那么观察到 的比例</span>n<span class="s36">c</span><span class="s6">/</span>n<span class="p">和先验概率</span>p<span class="p">可按照权重</span>m<span class="p">合并。</span>m<span class="p">被称为等效样本大小的原因是，式 </span><span class="s6">6.22 </span><span class="p">可被解 释为将</span>n<span class="p">个实际的观察扩大，加上</span>m<span class="p">个按</span>p<span class="p">分布的虚拟样本。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">6.10 <span class="s17">示例：学习分类文本</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 113%;text-align: justify;">为演示贝叶斯学习方法在实践上的重要性，考虑一个学习问题，其中的实例都为文本文 档。例如，要学习目标概念：“我感兴趣的电子新闻稿”或“讨论机器学习的万维网页”。在 这两种情况下，如果计算机可以精确地学习到目标概念，就可从大量在线文本文档中自动过 滤出最相关的文档显示给读者。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 6pt;text-indent: 21pt;line-height: 110%;text-align: justify;">这里描述了一个基于朴素贝叶斯分类器的文本分类的通用算法。有趣的是，这样的概率 方法是目前所知文本文档分类算法中的最有效的一类。这样的系统例子由 <span class="s6">Lewis(1991)</span>， <span class="s6">Lang(1995)</span>和 <span class="s6">Joachims(1996)</span>提出。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;line-height: 109%;text-align: justify;"><span class="p">将要展示的朴素贝叶斯算法遵循以下的问题背景。考虑实例空间 </span>X <span class="p">包含了所有的文本 文档（即任意长度的所有可能的单词和标点符号串）。给定某未知目标函数 </span>f<span class="s6">(</span>x<span class="s6">) </span><span class="p">的一组训练 样例，</span>f<span class="s6">(</span>x<span class="s6">)</span><span class="p">的取值来自于某有限集合 </span>V<span class="p">。此任务是从训练样例中学习，以预测后续文本文档 的目标值。作为示例，这里考虑的目标函数是，将文档分类为对某人是否感兴趣，使用目标 值 </span>like <span class="p">和 </span>dislike <span class="p">代表这两类。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 113%;text-align: justify;">在应用朴素贝叶斯分类器时包含的两个主要设计问题是，首先要决定怎样将任意文档表 示为属性值的形式，第二要决定如何估计朴素贝叶斯分类器所需的概率。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;line-height: 113%;text-align: left;">这里表示任意文本文档的途径出奇地简单。给定一文本文档，（这里先考虑英文文档）， 可对每个单词的位置定义一个属性，该属性的值为在此位置上找到的英文单词。该文本文档 如下例所示：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 5pt;text-indent: 21pt;line-height: 129%;text-align: left;">This is an example document for the naive Bayes classifier. This document contains only one paragraph, or two sentences.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: left;">这样，上例中的文本被表示为 <span class="s6">19 </span>个属性，对应 <span class="s6">19 </span>个单词位置。第一个属性的值为“<span class="s6">This</span>”， 第二个为“<span class="s6">is</span>”，依次类推。注意较长的文档也需要较多的属性数目。我们将看到，这不会 带来任何麻烦。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;line-height: 113%;text-align: left;">如果文本文档这样表示，现在就可以应用朴素贝叶斯分类器了。为了明确起见，假定我 们有 <span class="s6">700 </span>个训练文档，并且已由人工将其分类为 <span class="s21">dislike</span>，而另外 <span class="s6">300 </span>个文档被分类为 <span class="s21">like</span>。</p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 113%;text-align: left;">现在有了一个新文档要分类。仍为明确起见，该文档就是上面的两句英文例子。在此情况下， 可应用式 <span class="s6">6.20 </span>计算朴素贝叶斯分类器如：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="padding-top: 10pt;padding-left: 28pt;text-indent: 0pt;text-align: left;">v<span class="s52">NB</span><span class="s41"> </span><span class="s38"></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s33" style="padding-left: 5pt;text-indent: 0pt;line-height: 14pt;text-align: left;">arg max</p><p class="s41" style="padding-left: 1pt;text-indent: 0pt;line-height: 10pt;text-align: left;">v <span class="s180">j</span><span class="s44"> </span><span class="s40"></span><span class="s42">{</span>like<span class="s42">,</span>dislike<span class="s42">}</span></p><p class="s42" style="padding-top: 4pt;padding-left: 30pt;text-indent: 0pt;line-height: 6pt;text-align: left;">19</p><p class="s30" style="text-indent: 0pt;line-height: 19pt;text-align: left;">P<span class="s33">(</span>v <span class="s52">j</span><span class="s41"> </span><span class="s33">)</span><span class="s39"></span><span class="s121"> </span>P<span class="s33">(</span>a<span class="s52">i</span><span class="s41"> </span><span class="s33">| </span>v <span class="s52">j</span><span class="s41"> </span><span class="s33">)</span></p><p class="s41" style="padding-left: 29pt;text-indent: 0pt;line-height: 7pt;text-align: left;">i<span class="s40"></span><span class="s42">1</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s38" style="padding-top: 2pt;padding-left: 28pt;text-indent: 0pt;line-height: 15pt;text-align: left;"> <span class="s33">arg max</span></p><p class="s41" style="padding-left: 38pt;text-indent: 0pt;line-height: 10pt;text-align: left;">v <span class="s43">j</span><span class="s44"> </span><span class="s40"></span><span class="s42">{</span>like<span class="s42">,</span>dislike<span class="s42">}</span></p><p class="s30" style="padding-top: 2pt;text-indent: 0pt;text-align: left;">P<span class="s33">(</span>v <span class="s52">j</span><span class="s41"> </span><span class="s33">)</span>P<span class="s33">(</span>a<span class="s79">1</span><span class="s42"> </span><span class="s38"></span><span class="s33">&quot;</span>this<span class="s33">&quot;| </span>v <span class="s52">j</span><span class="s41"> </span><span class="s33">)</span>P<span class="s33">(</span>a<span class="s79">2</span><span class="s42"> </span><span class="s38"></span><span class="s33">&quot;</span>is<span class="s33">&quot;| </span>v <span class="s52">j</span><span class="s41"> </span><span class="s33">)...</span>P<span class="s33">(</span>a<span class="s79">19</span><span class="s42"> </span><span class="s38"></span><span class="s33">&quot; </span>sentence<span class="s33">&quot;| </span>v <span class="s52">j</span><span class="s41"> </span><span class="s33">)</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">概括地讲，朴素贝叶斯分类<span class="s21">v</span><span class="s36">NB</span>是使该文档中的单词在此处被观察到的概率最大的一个</p><p class="s42" style="text-indent: 0pt;line-height: 2pt;text-align: right;">19</p><p class="s33" style="padding-left: 5pt;text-indent: 0pt;line-height: 19pt;text-align: left;"><span class="p">分类，它遵循通常的朴素贝叶斯独立性假定。独立性假定 </span><i>P</i>(<i>a</i><span class="s79">1</span><span class="s42"> </span>,...<i>a</i><span class="s79">19</span><span class="s42">  </span>| <i>v </i><span class="s52">j</span><span class="s41"> </span>) <span class="s38"></span> <span class="s39"></span><span class="s222">1</span></p><p class="s30" style="padding-left: 3pt;text-indent: 0pt;text-align: left;">P<span class="s33">(</span>a<span class="s52">i</span><span class="s41"> </span><span class="s33">| </span>v <span class="s52">j</span><span class="s41"> </span><span class="s33">)</span></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: justify;">说明在此设定下在一个位置上出现某单词的概率独立于另外一个位置的单词。这一假定在有 些时候并不反映真实情况。例如，在某处观察到单词<span class="s6">learning </span>的概率会因为它前一位置单词 是<span class="s6">machine</span>而增大。虽然此独立性假定很不精确，但这里别无选择，必须作此假定——没有 这个假定，要计算的概率项将极为庞大。幸运的是，在实践中朴素贝叶斯学习器在许多文本 分类问题中性能非常好，即使此独立性假定不正确。 <span class="s6">Domingos </span>和<span class="s6">Pazzani(1996)</span>对这一幸运 的现象作了一个有趣的分析。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 5pt;text-indent: 21pt;line-height: 106%;text-align: justify;"><span class="p">为使用上式计算</span><i>v</i><span class="s36">NB</span><span class="p">，需要估计概率项</span><i>P</i>(<i>v</i><span class="s36">i</span>)<span class="p">和</span><i>P</i>(<i>a</i><span class="s36">i</span>=<i>w</i><span class="s36">k</span>|<i>v</i><span class="s36">i</span>)<span class="p">。这里引入</span><i>w</i><span class="s36">k</span><span class="p">代表英文词典中的 第</span><i>k</i><span class="p">个单词。前一项可基于每一类在训练数据中的比例很容易地得到（此例中</span><i>P</i>(<i>like</i>)=0.3 <span class="p">且 </span><i>P</i>(<i>dislike</i>)= 0.7<span class="p">）。如以往那样，估计类别的条件概率（如</span><i>P</i>(<i>a</i><span class="s35">1</span>)=“<i>This</i>”| <i>P</i>(<i>dislike</i>)<span class="p">）要困难的 多，因为必须对每个文本位置、英文单词和目标值的组合计算此概率项。非常不幸，在英文 词汇中包含约 </span>5 <span class="p">万个不同单词，然后本例中有 </span>2 <span class="p">个可能的目标值和 </span>19 <span class="p">个文本位置，所以必 须从训练数据中估计 </span>2×19×50000<span class="p">≈</span>200 <span class="p">万个这样的概率项。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 5pt;text-indent: 21pt;line-height: 106%;text-align: left;"><span class="p">幸运的是，可以再引入一合理的假定以减少需要估计的概率数量。确切地讲，可假定遇 到一特定单词</span>w<span class="s36">k</span><span class="p">的概率独立于单词所在位置。形式化的表述是，在给定目标分类的情况下， 假定各属性是独立同分布的，即对所有的</span>i<span class="s6">, </span>j<span class="s6">, </span>k<span class="s6">, </span>m<span class="p">，</span>P<span class="s6">(</span>a<span class="s36">i</span><span class="s6">=</span>w<span class="s36">k</span><span class="s6">|</span>v<span class="s36">j</span><span class="s6">)=</span>P<span class="s6">(</span>a<span class="s36">m</span><span class="s6">=</span>w<span class="s36">k</span><span class="s6">|</span>v<span class="s36">j</span><span class="s6">)</span><span class="p">。因此，为估计整 个概率集合</span>P<span class="s6">(</span>a<span class="s35">1</span><span class="s6">=</span>w<span class="s36">k</span><span class="s6">|</span>v<span class="s36">j</span><span class="s6">), </span>P<span class="s6">(</span>a<span class="s35">2</span><span class="s6">=</span>w<span class="s36">k</span><span class="s6">|</span>v<span class="s36">j</span><span class="s6">)</span><span class="p">，可通过一个位置无关的概率</span>P<span class="s6">(</span>w<span class="s36">k</span><span class="s6">|</span>v<span class="s36">j</span><span class="s6">)</span><span class="p">，而不考虑单词的位 置。其效果是，现在只需要 </span><span class="s6">2×50000 </span><span class="p">个不同的概率项</span>P<span class="s6">(</span>w<span class="s36">k</span><span class="s6">|</span>v<span class="s36">j</span><span class="s6">)</span><span class="p">。虽然这仍然是一个较大的数 值，但却是可管理的。注意到如果训练数据有限，作此假定的一个主要优点在于，它使可用 于估计每个所需概率的样例数增加了，因此增加了估计的可靠程度。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: left;"><span class="p">为完成学习算法的设计，仍需要选择一个方法估计概率项。这里采纳了等式 </span><span class="s6">6.22 </span><span class="p">中的</span>m <span class="p">估计，即有统一的先验概率并且</span>m<span class="p">等于词汇表的大小。因此，对</span>P<span class="s6">(</span>w<span class="s36">k</span><span class="s6">|</span>v<span class="s36">j</span><span class="s6">)</span><span class="p">的估计为：</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="104" height="23" alt="image" src="机器学习/Image_254.png"/></span></p><p class="s30" style="padding-top: 2pt;padding-left: 24pt;text-indent: 0pt;text-align: center;">n<span class="s52">k </span><span class="s38"> </span><span class="s33">1</span></p><p class="s30" style="padding-left: 24pt;text-indent: 0pt;text-align: center;">n <span class="s38"> </span>Vocabulary</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;text-align: justify;">其中<span class="s21">n</span>为所有目标值为<span class="s21">v</span><span class="s36">j</span>的训练样例中单词位置的总数，<span class="s21">n</span><span class="s36">k</span>是在<span class="s21">n</span>个单词位置中找到<span class="s21">w</span><span class="s36">k</span>的 次数，而<span class="s6">|</span><span class="s21">Vocabulary</span><span class="s6">|</span>为训练数据中的不同单词（以及其他记号）的总数。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 109%;text-align: justify;">概括地说，最终的算法使用的朴素贝叶斯分类器假定单词出现的概率与它在文本中的位 置无关。最终的算法显示在表 <span class="s6">6-2 </span>中。注意该算法非常简单。在学习过程中，过程 <span class="s6">Learn-naive-Bayes-text</span>分析所有训练文档，从中抽取出所有出现的单词的记号；然后在不同 目标类中计算其频率以获得必要的概率估计。以后，若给定一个待分类新实例，过程</p><p style="padding-left: 11pt;text-indent: 0pt;line-height: 108%;text-align: justify;"><span class="s6">Classify-naive-Bayes-text </span>使用此概率估计来按照式 <span class="s6">6.20 </span>计算<span class="s21">V</span><span class="s36">NB</span><a href="http://www.cs.cmu.edu/tom/book.html%E4%B8%AD%E6%89%BE%E5%88%B0" class="s223" target="_blank">。注意在新文档中出现但不 在训练集的文档中的任何单词将被简单地忽略。该算法的代码以及训练数据集，可在万维网 的</a><a href="http://www.cs.cmu.edu/tom/book.html%E4%B8%AD%E6%89%BE%E5%88%B0" class="a" target="_blank">http://www.cs.cmu.edu/tom/book.html</a>中找到。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 2pt;text-align: left;"><span><img width="570" height="2" alt="image" src="机器学习/Image_255.png"/></span></p><p class="s16" style="padding-top: 1pt;padding-left: 11pt;text-indent: 0pt;text-align: left;">Learn_naive_Bayes_text(<i>Examples</i>, <i>V</i>)</p><p class="s56" style="padding-top: 3pt;padding-left: 11pt;text-indent: 0pt;line-height: 88%;text-align: left;">Examples<span class="s14">为一组文本文档以及它们的目标值。</span>V<span class="s14">为所有可能目标值的集合。此函数作用是学习概率项</span>P<span class="s16">(</span>w<span class="s65">k</span><span class="s16">|</span>v<span class="s65">j</span><span class="s16">)</span><span class="s14">， 它描述了从类别</span>v<span class="s65">j</span><span class="s14">中的一个文档中随机抽取的一个单词为英文单词</span>w<span class="s65">k</span><span class="s14">的概率。该函数也学习类别的先验概率 </span>P<span class="s16">(</span>v<span class="s65">j</span><span class="s16">)</span><span class="s14">。</span></p><p class="s14" style="padding-top: 2pt;padding-left: 11pt;text-indent: 0pt;text-align: left;"><span class="s16">1.</span>收集 <span class="s56">Examples </span>中所有的单词、标点符号以及其他记号</p><p class="s56" style="padding-top: 3pt;padding-left: 29pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span>Vocabulary<span class="s14">←在 </span>Examples <span class="s14">中任意文本文档中出现的所有单词及记号的集合</span></p><p class="s16" style="padding-top: 3pt;padding-left: 11pt;text-indent: 0pt;text-align: left;">2.<span class="s14">计算所需要的概率项</span><i>P</i>(<i>v</i><span class="s65">j</span>)<span class="s14">和 </span><i>P</i>(<i>w</i><span class="s65">k</span>|<i>v</i><span class="s65">j</span>)</p><p class="s14" style="padding-top: 2pt;padding-left: 29pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span>对<span class="s56">V</span>中每个目标值<span class="s56">v</span><span class="s65">j</span></p><p class="s56" style="padding-top: 2pt;padding-left: 47pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span>docs<span class="s65">j</span><span class="s14">←</span>Examples<span class="s14">中目标值为</span>v<span class="s65">j</span><span class="s14">的文档子集</span></p><p class="s56" style="padding-top: 4pt;padding-left: 48pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span>P<span class="s16">(</span>v<span class="s65">j</span><span class="s16">) </span><span class="s14">←</span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="48" height="33" alt="image" src="机器学习/Image_256.png"/></span></p><p class="s224" style="padding-top: 5pt;text-indent: 0pt;text-align: center;">docs <span class="s225">j</span></p><p class="s224" style="padding-top: 2pt;text-indent: 0pt;text-align: center;">Examples</p><p class="s56" style="padding-top: 5pt;padding-left: 47pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span>Text<span class="s65">j</span><span class="s14">←将</span>docs<span class="s65">j</span><span class="s14">中所有成员连接起来建立的单个文档</span></p><p class="s56" style="padding-top: 2pt;padding-left: 47pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span>n<span class="s14">←在</span>Text<span class="s65">j</span><span class="s14">中不同单词位置的总数</span></p><p class="s14" style="padding-top: 2pt;padding-left: 47pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span>对<span class="s56">Vocabulary</span>中每个单词<span class="s56">w</span><span class="s65">k</span></p><p class="s56" style="padding-top: 2pt;padding-left: 65pt;text-indent: 0pt;text-align: left;"><span class="s55">n</span>n<span class="s65">k</span><span class="s14">←单词</span>w<span class="s65">k</span><span class="s14">出现在</span>Text<span class="s65">j</span><span class="s14">中的次数</span></p><p class="s56" style="padding-top: 2pt;padding-left: 62pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span>P<span class="s16">(</span>w<span class="s65">k</span><span class="s16">|</span>v<span class="s65">j</span><span class="s16">) </span><span class="s14">←</span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="73" height="16" alt="image" src="机器学习/Image_257.png"/></span></p><p class="s226" style="padding-top: 3pt;text-indent: 0pt;text-align: center;">n<span class="s43">k </span><span class="s227"> </span><span class="s228">1</span></p><p class="s226" style="text-indent: 0pt;text-align: center;">n <span class="s227"> </span>Vocabulary</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s16" style="padding-top: 3pt;padding-left: 11pt;text-indent: 0pt;text-align: left;">Classify_naive_Bayes_text(<i>Doc</i>)</p><p class="s14" style="padding-top: 2pt;padding-left: 11pt;text-indent: 0pt;text-align: left;">对文档<span class="s56">Doc</span>返回其估计的目标值。<span class="s56">a</span><span class="s65">i</span>代表在<span class="s56">Doc</span>中的第<span class="s56">i</span>个位置上出现的单词。</p><p class="s56" style="padding-top: 2pt;padding-left: 30pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span>positions<span class="s14">←在 </span>Doc <span class="s14">中包含的能在 </span>Vocabulary <span class="s14">中找到的记号的所有单词位置</span></p><p class="s55" style="padding-top: 3pt;padding-left: 30pt;text-indent: 0pt;line-height: 5pt;text-align: left;">n <span class="s14">返回</span></p><p class="s56" style="padding-left: 70pt;text-indent: 0pt;line-height: 12pt;text-align: center;">v<span class="s43">NB</span><span class="s44"> </span><span class="s57"> </span><span class="s16">arg max </span>P<span class="s16">(</span>v <span class="s43">j</span><span class="s44"> </span><span class="s16">)</span></p><p class="s44" style="text-indent: 0pt;line-height: 7pt;text-align: right;">v <span class="s229">j</span><span class="s230"> </span><span class="s231"></span>V</p><p class="s56" style="padding-left: 5pt;text-indent: 0pt;line-height: 14pt;text-align: left;"><span class="s232"></span><span class="s233"> </span>P<span class="s16">(</span>a<span class="s43">i</span><span class="s44"> </span><span class="s16">| </span>v <span class="s43">j</span><span class="s44"> </span><span class="s16">)</span></p><p class="s44" style="text-indent: 0pt;line-height: 6pt;text-align: left;">i<span class="s231"></span>positions</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 2pt;text-align: left;"><span><img width="570" height="2" alt="image" src="机器学习/Image_258.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 31pt;text-indent: 0pt;text-align: center;">表 <span class="h4">6-2 </span>用于学习和分类文本的朴素贝叶斯算法</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-left: 32pt;text-indent: 0pt;text-align: center;">除通常的朴素贝叶斯假定外，算法还假定单词出现的概率独立于其在文本中的位置。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 12pt;text-indent: 0pt;text-align: left;">6.10.1 <span class="s25">实验结果</span></h3><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 11pt;text-indent: 21pt;line-height: 108%;text-align: justify;">表 <span class="s6">6-2 </span>的学习算法效率如何？在 <span class="s6">Joachims</span>（<span class="s6">1996</span>）的一个实验中，此算法（有微小的变 化）被应用于分类新闻组的文章。其中每一文章的分类是该文章所属的新闻组名称。此实验 考虑了 <span class="s6">20 </span>个电子新闻组，然后从每个新闻组中搜集 <span class="s6">1000 </span>篇文章，形成一个包含 <span class="s6">2 </span>万个文档 的数据集。然后应用朴素贝叶斯算法，其中 <span class="s6">2/3 </span>作为训练样例，而性能的衡量在剩余 <span class="s6">1/3 </span>中 进行。因为有 <span class="s6">20 </span>个可能的新闻组，那么随机猜测的分类精确度为 <span class="s6">5%</span>。由程序获得的精确 度为 <span class="s6">89%</span>。此实验中使用的算法与表 <span class="s6">6-2 </span>中的算法只有一点不同：只有文档中出现单词的一 个子集被选为算法中的词汇表，确切地说，<span class="s6">100 </span>个最常见的单词被移去（如“<span class="s6">the</span>”和“<span class="s6">of</span>” 这样的单词），而且任何出现少于 <span class="s6">3 </span>次的单词也被移去。得到的词汇表包含大约 <span class="s6">38,500 </span>个单 词。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 32pt;text-indent: 0pt;text-align: left;">其他应用类似的统计学习算法进行文本分类的实验也获得了同样好的结果。例如，<span class="s6">Lang</span></p><p style="padding-top: 1pt;padding-left: 11pt;text-indent: 0pt;text-align: left;">（<span class="s6">1995</span>）描述了朴素贝叶斯算法的另一变种，把它应用到学习目标概念“我感兴趣的新闻组</p><p style="padding-left: 11pt;text-indent: 0pt;line-height: 107%;text-align: justify;">文章”。他描述了 <span class="s6">NewsWeeder </span>系统——是一个让用户阅读新闻组文章并为其评分的系统。 然后 <span class="s6">NewsWeeder </span>使用这些评分的文章作为训练样例，来预测后续的文章哪些是用户感兴趣 的，再将其送给用户阅读。<span class="s6">Lang (1995)</span>报告了他的实验，其中用 <span class="s6">NewsWeeder </span>中学到的用户 兴趣配置文件，每天向用户推荐分值最高的新闻文章。通过向用户展示前 <span class="s6">10%</span>的自动评分 文章，它建立的文章序列中用户感兴趣的比率比通常情况下高出 <span class="s6">3-4 </span>倍。例如，若一个用户 对通常的文章有 <span class="s6">16%</span>感兴趣，其对于 <span class="s6">NewsWeeder </span>推荐的文章有 <span class="s6">59%</span>感兴趣。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 32pt;text-indent: 0pt;text-align: left;">其他几种非贝叶斯的统计文本学习算法也很常见，其中许多基于信息检索领域</p><p style="padding-top: 1pt;padding-left: 11pt;text-indent: 0pt;line-height: 107%;text-align: justify;">（<span class="s6">Information Retrieval</span>）中的最先发明的相似性度量（见 <span class="s6">Rocchio 1971</span>；<span class="s6">Salton 1991</span>）。另外 的文本学习算法见 <span class="s6">Hearst &amp; Hirsh</span>（<span class="s6">1996</span>）。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 2pt;text-align: left;"><span><img width="570" height="2" alt="image" src="机器学习/Image_259.png"/></span></p><p class="s234" style="padding-top: 1pt;padding-left: 11pt;text-indent: 0pt;line-height: 146%;text-align: left;">comp.graphics comp.os.ms-windows.misc comp.sys.ibm.pc.hardware comp.sys.mac.hardware</p><p class="s234" style="padding-top: 1pt;padding-left: 11pt;text-indent: 0pt;line-height: 146%;text-align: left;">misc.forsale rec.autos rec.motocycles rec.sport.baseball</p><p class="s234" style="padding-top: 1pt;padding-left: 11pt;text-indent: 0pt;line-height: 146%;text-align: left;">soc.religion.christian talk.politics.guns talk.politics.mideast talk.politics.misc</p><p class="s234" style="padding-top: 1pt;padding-left: 11pt;text-indent: 0pt;line-height: 146%;text-align: left;">sci.space sci.crypt sci.electronics sci.med</p><p class="s234" style="padding-left: 11pt;text-indent: 0pt;text-align: left;">comp.windows.x</p><p style="text-indent: 0pt;text-align: left;"><span><img width="570" height="2" alt="image" src="机器学习/Image_260.png"/></span></p><p class="s234" style="padding-left: 118pt;text-indent: -106pt;line-height: 146%;text-align: left;">rec.sport.hockey talk.religion.misc alt.atheism</p><p style="padding-top: 6pt;padding-left: 31pt;text-indent: 0pt;text-align: center;">表 <span class="h4">6-3 </span>在文本分类实验中使用的 <span class="h4">20 </span>个新闻组</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-left: 43pt;text-indent: 21pt;line-height: 125%;text-align: left;">在对每个新闻组用 <span class="s16">667 </span>篇文章训练后，朴素贝叶斯分类器在预测后续文章属于哪一个新闻组 时获得了 <span class="s16">89%</span>的精度。随机猜测只能得到 <span class="s16">5%</span>的精确度。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 12pt;text-indent: 0pt;text-align: left;">6.11 <span class="s17">贝叶斯置信网</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 11pt;text-indent: 21pt;line-height: 108%;text-align: justify;">如前两节所讨论的，朴素贝叶斯分类器假定了属性<span class="s21">a</span><span class="s35">1</span>⋯<span class="s21">a</span><span class="s36">n</span>的值在给定目标值<span class="s21">v</span>下是条件 独立的。这一假定显著地减小了目标函数学习的计算复杂度。当此条件成立时，朴素贝叶斯 分类器可得到最优贝叶斯分类。然而在许多情形下，这一条件独立假定明显过于严格了。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 11pt;text-indent: 21pt;line-height: 112%;text-align: left;">贝叶斯置信网描述的是一组变量所遵从的概率分布，它通过一组条件概率来指定一组条 件独立性假定。朴素贝叶斯分类器假定所有变量在给定目标变量值时为条件独立的，与此不 同，贝叶斯置信网中可表述应用到变量的一个子集上的条件独立性假定。因此，贝叶斯置信 网提供了一种中间的方法，它比朴素贝叶斯分类器中条件独立性的全局假定的限制更少，又 比在所有变量中计算条件依赖更可行。贝叶斯置信网是目前研究中一个非常活跃的焦点，而 且有多种方法被提出以学习它和用它进行推理。本节介绍贝叶斯置信网的关键概念和表示。 更详细的讨论见 <span class="s6">Pearl(1988) </span>， <span class="s6">Rusell &amp; Norvig(1995) </span>， <span class="s6">Herkerman et al.</span>（ <span class="s6">1995 </span>）以及 <span class="s6">Jensen(1996)</span>。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 32pt;text-indent: 0pt;text-align: left;">一般来说，贝叶斯置信网描述了在一组变量上的概率分布。考虑一任意的随机变量集合</p><p class="s21" style="padding-top: 1pt;padding-left: 11pt;text-indent: 0pt;text-align: left;">Y<span class="s35">1</span><span class="p">⋯</span>Y<span class="s36">n</span><span class="p">，其中每个</span>Y<span class="s36">i</span><span class="p">可取的值集合为</span>V<span class="s6">(</span>Y<span class="s36">i</span><span class="s6">)</span><span class="p">。定义变量集合</span>Y<span class="p">的联合空间</span><span class="s6">(joint space)</span><span class="p">为叉乘</span>V<span class="s6">(</span>Y<span class="s35">1</span><span class="s6">)</span></p><p class="s6" style="padding-left: 11pt;text-indent: 0pt;text-align: left;"><span class="p">×</span><i>V</i>(<i>Y</i><span class="s35">2</span>)<span class="p">⋯</span><i>V</i>(<i>Y</i><span class="s36">n</span>)<span class="p">。换言之，在联合空间中的每一项对应变量元组的一个可能的赋值</span>&lt;<i>Y</i><span class="s35">1</span>…<i>Y</i><span class="s36">n</span>&gt;<span class="p">。 在此联合空间上的概率分布称为联合概率分布</span>(joint probability distribution)<span class="p">。联合概率分布指 定了元组</span>&lt;<i>Y</i><span class="s35">1</span>…<i>Y</i><span class="s36">n</span>&gt;<span class="p">的每个可能的变量约束的概率。贝叶斯置信网则对一组变量描述了联合概 率分布。</span></p><h3 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">6.11.1 <span class="s25">条件独立性</span></h3><p style="padding-top: 10pt;padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">首先，为讨论贝叶斯置信网，需要精确定义条件独立性。令 <span class="s21">X</span>，<span class="s21">Y </span>和 <span class="s21">Z </span>为 <span class="s6">3 </span>个离散值随 机变量。当 <span class="s21">X </span>服从的概率分布独立于给定 <span class="s21">Z </span>值时 <span class="s21">Y </span>的值，称 <span class="s21">X </span>在给定 <span class="s21">Z </span>时条件独立于 <span class="s21">Y</span>， 即：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s33" style="padding-top: 2pt;padding-left: 80pt;text-indent: 0pt;text-align: left;">(<span class="s38"></span><i>x</i><span class="s52">i </span>, <i>y </i><span class="s52">j</span><span class="s41"> </span>, <i>z</i><span class="s52">k</span><span class="s41"> </span>)<i>P</i>( <i>X</i></p><p class="s30" style="padding-top: 2pt;padding-left: 3pt;text-indent: 0pt;text-align: left;"><span class="s38"> </span>x<span class="s52">i </span><span class="s33">| </span>Y <span class="s38"> </span>y <span class="s52">j </span><span class="s33">, </span>Z <span class="s38"> </span>z<span class="s52">k </span><span class="s33">) </span><span class="s38"> </span>P<span class="s33">( </span>X</p><p class="s30" style="padding-top: 2pt;padding-left: 3pt;text-indent: 0pt;text-align: left;"><span class="s38"> </span>x<span class="s52">i </span><span class="s33">| </span>Z <span class="s38"> </span>z<span class="s52">k</span><span class="s41"> </span><span class="s33">)</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-top: 2pt;padding-left: 5pt;text-indent: 21pt;line-height: 110%;text-align: justify;"><span class="p">其中 </span><span class="s30">x</span><span class="s52">i</span><span class="s41"> </span><span class="s38"></span><span class="s30">V </span><span class="s33">( </span><span class="s30">X </span><span class="s33">) </span><span class="p">， </span><span class="s30">y </span><span class="s52">j</span><span class="s41"> </span><span class="s38"></span><span class="s30">V </span><span class="s33">(</span><span class="s30">Y </span><span class="s33">) </span><span class="p">， </span><span class="s30">z</span><span class="s52">k</span><span class="s41"> </span><span class="s38"></span><span class="s30">V </span><span class="s33">(</span><span class="s30">Z </span><span class="s33">) </span><span class="p">。通常将上式简写为</span>P<span class="s6">(</span>X<span class="s6">|</span>Y<span class="s6">,</span>Z<span class="s6">)=</span>P<span class="s6">(</span>X<span class="s6">|</span>Z<span class="s6">)</span><span class="p">。这一 关于条件独立性的定义可被扩展到变量集合。当下列条件成立时，称变量集合</span>X<span class="s35">1</span><span class="s6">…</span>X<span class="s36">l</span><span class="p">给定变 量集合</span>Z<span class="s35">1</span><span class="s6">…</span>Z<span class="s36">n</span><span class="p">时条件独立于变量集合</span>Y<span class="s35">1</span><span class="s6">…</span>Y<span class="s36">m</span><span class="p">：</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="padding-top: 2pt;padding-left: 107pt;text-indent: 0pt;text-align: left;">P<span class="s33">( </span>X <span class="s79">1</span><span class="s42"> </span><span class="s33">...</span>X <span class="s52">l</span><span class="s41"> </span><span class="s33">| </span>Y<span class="s79">1</span><span class="s33">...</span>Y<span class="s52">m</span><span class="s41"> </span><span class="s33">, </span>Z<span class="s79">1</span><span class="s42"> </span><span class="s33">...</span>Z <span class="s52">n</span><span class="s41"> </span><span class="s33">) </span><span class="s38"> </span>P<span class="s33">( </span>X <span class="s79">1</span><span class="s33">...</span>X <span class="s52">l</span><span class="s41"> </span><span class="s33">| </span>Z<span class="s79">1</span><span class="s42"> </span><span class="s33">...</span>Z <span class="s52">n</span><span class="s41"> </span><span class="s33">)</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;line-height: 108%;text-align: justify;"><span class="p">注意此定义与朴素贝叶斯分类器中使用的条件独立性之间的关系。朴素贝叶斯分类器假 定给定目标值</span>V<span class="p">时，实例属性</span>A<span class="s35">1</span><span class="p">条件独立于实例属性</span>A<span class="s35">2</span><span class="p">。这使得朴素贝叶斯分类器可以按照 下式计算 </span><span class="s6">6.20 </span><span class="p">式中的</span>P<span class="s6">(</span>A<span class="s35">1</span><span class="s6">,</span>A<span class="s35">2</span><span class="s6">|</span>V<span class="s6">)</span><span class="p">：</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 136pt;text-indent: 0pt;text-align: left;">P<span class="s6">(</span>A<span class="s35">1</span><span class="s6">,</span>A<span class="s35">2</span><span class="s6">|</span>V<span class="s6">)=</span>P<span class="s6">(</span>A<span class="s35">1</span><span class="s6">|</span>A<span class="s35">2</span><span class="s6">,</span>V<span class="s6">)</span>P<span class="s6">(</span>A<span class="s35">2</span><span class="s6">|</span>V<span class="s6">) (6.23)</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-top: 3pt;padding-left: 136pt;text-indent: 0pt;text-align: left;">=<i>P</i>(<i>A</i><span class="s35">1</span>|<i>V</i>)<i>P</i>(<i>A</i><span class="s35">2</span>|<i>V</i>) (6.24)</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 5pt;text-indent: 21pt;text-align: left;"><span class="p">式 </span><span class="s6">6.23 </span><span class="p">只是表 </span><span class="s6">6-1 </span><span class="p">中概率的乘法规则的一般形式。式 </span><span class="s6">6.24 </span><span class="p">成立是因为</span>A<span class="s35">1</span><span class="p">在给定</span>V<span class="p">时条件 独立于</span>A<span class="s35">2</span><span class="p">，然后由条件独立性的定义可以得到</span>P<span class="s6">(</span>A<span class="s35">1</span><span class="s6">|</span>A<span class="s35">2</span><span class="s6">,</span>V<span class="s6">)=</span>P<span class="s6">(</span>A<span class="s35">1</span><span class="s6">|</span>V<span class="s6">)</span><span class="p">。</span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="547" height="1" alt="image" src="机器学习/Image_261.png"/></span></p><p class="s48" style="padding-top: 13pt;padding-left: 15pt;text-indent: 0pt;text-align: left;">原书页码： <span class="s21">186</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 14pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="531" height="1" alt="image" src="机器学习/Image_262.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 48pt;text-indent: 0pt;text-align: center;">图 <span class="h4">6-3 </span>一个贝叶斯置信网。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s56" style="padding-left: 37pt;text-indent: 21pt;line-height: 130%;text-align: left;"><span class="s14">左边的网络表示了一组条件独立性假定。确切地说，每个节点在给定其父结点时，条件独立 于其非后代结点。每个结点关联一个条件概率表，它指定了该变量在给定其父结点时的条件分布。 右边列出了 </span>Campfire <span class="s14">结点的条件概率表，其中 </span>Campfire<span class="s16">, </span>Storm <span class="s14">和 </span>BusTourGroup <span class="s14">分别缩写为 </span>C<span class="s14">，</span>S<span class="s14">， </span>B<span class="s14">。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">6.11.2 <span class="s25">表示</span></h3><p style="padding-top: 10pt;padding-left: 5pt;text-indent: 21pt;line-height: 110%;text-align: justify;">贝叶斯置信网（简写为贝叶斯网）表示一组变量的联合概率分布。例如，图 <span class="s6">6-3 </span>中的贝 叶斯网表示了在布尔变量<span class="s21">Storm</span>，<span class="s21">Lightning</span>，<span class="s21">Thunder</span>，<span class="s21">ForestFire</span>，<span class="s21">Campfire</span>和<span class="s21">BusTourGroup </span>上的联合概率分布。一般地说，贝叶斯网表示联合概率分布的方法是指定一组条件独立性假 定（它表示为一有向无环图），以及一组局部条件概率集合。联合空间中每个变量在贝叶斯 网中表示为一结点。对每一变量需要两种类型的信息。首先，网络弧表示断言“此变量在给</p><p class="s21" style="padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;"><span class="p">定其立即前驱时条件独立于其非后继”。 当从</span>Y<span class="p">到</span>X<span class="p">存在一条有向的路径，我们称</span>X<span class="p">是</span>Y<span class="p">的后 继。第二，对每个变量有一个条件概率表，它描述了该变量在给定其立即前驱时的概率分布。 对网络变量的元组</span><span class="s6">&lt;</span>Y<span class="s35">1</span><span class="s6">…</span>Y<span class="s36">n</span><span class="s6">&gt;</span><span class="p">赋以所希望的值（</span>y<span class="s35">1</span><span class="s6">…</span>y<span class="s36">n</span><span class="p">）的联合概率可由下面的公式计算。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s41" style="padding-top: 4pt;padding-left: 24pt;text-indent: 0pt;line-height: 6pt;text-align: center;">n</p><p class="s30" style="padding-left: 139pt;text-indent: 0pt;line-height: 18pt;text-align: left;">P<span class="s33">( </span>y<span class="s79">1</span><span class="s42"> </span><span class="s33">,...</span>y<span class="s52">n</span><span class="s41"> </span><span class="s33">) </span><span class="s38"> </span><span class="s124"></span><span class="s135"> </span>P<span class="s33">( </span>y<span class="s52">i</span><span class="s41"> </span><span class="s33">| </span>Parents<span class="s33">(</span>Y<span class="s52">i</span><span class="s41"> </span><span class="s33">))</span></p><p class="s41" style="padding-left: 24pt;text-indent: 0pt;line-height: 7pt;text-align: center;">i<span class="s40"></span><span class="s42">1</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;text-align: justify;"><span class="p">其中</span>Parents<span class="s6">(</span>Y<span class="s36">i</span><span class="s6">)</span><span class="p">表示网络中</span>Y<span class="s36">i</span><span class="p">的立即前驱的集合。注意 </span>P<span class="s6">(</span>y<span class="s36">i</span><span class="s6">|</span>Parents<span class="s6">(</span>y<span class="s36">i</span><span class="s6">))</span><span class="p">的值等于与结点 </span>Y<span class="s36">i</span><span class="p">关联的条件概率表中的值。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 6pt;text-indent: 20pt;line-height: 107%;text-align: justify;"><span class="p">为说明这一点，图 </span><span class="s6">6-3 </span><span class="p">表示了在布尔变量 </span>Storm<span class="s6">, </span>Lighting<span class="s6">, </span>Thunder<span class="s6">, </span>ForestFire<span class="s6">, </span>Campfire <span class="p">以及 </span>BusTourGroup <span class="p">上的联合概率分布。考虑结点 </span>Campfire<span class="p">。网络结点和孤表示了断言： </span>Campfire <span class="p">在给定其父结点 </span>Storm <span class="p">和 </span>BusTourGroup <span class="p">时条件独立于其非后继 </span>Lighting <span class="p">和 </span>Thunder <span class="p">。这意味着一但我们知道了变量 </span>Storm <span class="p">和 </span>BusTourGroup <span class="p">的值，变量 </span>Lighting <span class="p">和 </span>Thunder <span class="p">不会提供有关 </span>Campfire <span class="p">的更多的信息。图右边显示了与变量 </span>Campfire <span class="p">联系的条件 概率表。比如表的最左上一个数据表示了以下的断言：</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-top: 3pt;padding-left: 103pt;text-indent: 0pt;text-align: left;">P<span class="s6">(</span>Campfire<span class="s6">=</span>True<span class="s6">|</span>Storm<span class="s6">=</span>True<span class="s6">, </span>BusTourGroup<span class="s6">=</span>True<span class="s6">)=0.4</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 6pt;text-indent: 21pt;line-height: 110%;text-align: justify;">注意此表只提供了给定其父变量 <span class="s21">Storm </span>和 <span class="s21">BusTourGroup </span>下 <span class="s21">Campfire </span>的条件概率。所有 变量的局部条件概率表以及由网络所描述的一组条件独立假定，描述了该网络的整个联合概 率分布。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">贝叶斯置信网的一个吸引人的特性在于，它提供了一种方便的途径以表示因果知识，比</p><p style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">如 <span class="s21">Lightin</span>（<span class="s21">g</span></p><p style="padding-top: 1pt;padding-left: 3pt;text-indent: 0pt;text-align: left;">闪电）导致 <span class="s21">Thunder</span>（打雷）。以条件独立性的术语，可将其表述为在给定 <span class="s21">Lighting</span></p><p style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;line-height: 107%;text-align: left;">的值情况下，<span class="s21">Thunder </span>条件独立于网络中其他变量。注意此条件独立性假定是由图 <span class="s6">6-3 </span>的贝 叶斯网的弧指定的。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">6.11.3 <span class="s25">推理</span></h3><p style="padding-top: 10pt;padding-left: 5pt;text-indent: 21pt;line-height: 110%;text-align: left;">可以用贝叶斯网在给定其他变量的观察值时推理出某些目标变量（如 <span class="s21">ForestFire</span>）的值。 当然，由于所处理的是随机变量，所以一般不会赋予目标变量一个确切的值。真正需要推理 的是目标变量的概率分布，它指定了在给与其他变量的观察值条件下，目标变量取每一可能 值的概率。在网络中所有其他变量都确切知道了以后，这一推理步骤是很简单的。在更通常 的情况下<span class="s6">,</span>我们希望在知道一部分变量的值（比如 <span class="s21">Thunder </span>和 <span class="s21">BusTourGroup </span>为仅有可用的观 察值）时获得某变量的概率分布（如 <span class="s21">ForestFire</span>）。一般地，贝叶斯网络可用于在知道某些变 量的值或分布时计算网络中另一部分变量的概率分布。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">一般情况下对任意贝叶斯网络的概率的确切推理已经知道是一个 <span class="s6">NP </span>难题（<span class="s6">Cooper 1990</span>）。已提出了多种方法在贝叶斯网络中进行不确定性推理，包括确切的推理以及牺牲精 度换取效率的近似推理方法。例如，<span class="s6">Monte Carlo </span>方法提供了一种近似的方法，通过对未观 察到变量进行随机采样（ <span class="s6">Pradham Dagum 1996</span>）。理论上，即使是贝叶斯网络中的近似推理 也可是 <span class="s6">NP </span>难题（<span class="s6">Dagnm </span>和 <span class="s6">Luby1993</span>）。幸运的是，实践中许多情况下近似的方法被证明</p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 113%;text-align: left;">是有效的，对于贝叶斯网络推理方法的讨论由 作出。</p><p class="s6" style="padding-left: 3pt;text-indent: 0pt;text-align: left;">Russell &amp; Norvig<span class="p">（</span>1995<span class="p">）和 </span>Jensen<span class="p">（</span>1996<span class="p">）</span></p><h3 style="padding-left: 27pt;text-indent: -21pt;text-align: left;">6.11.4 <span class="s25">学习贝叶斯置信网</span></h3><p style="padding-top: 10pt;padding-left: 6pt;text-indent: 21pt;line-height: 113%;text-align: justify;">是否可以设计出有效的算法以从训练数据中学到贝叶斯置信网？这是目前研究中的一 个焦点的问题。对于这一问题有多种可以考虑的框架。首先网络结构可以预先给出，或可由 训练数据中推得。第二，所有的网络变量可以直接从每个训练样例中观察到，或某些变量不 能观察到。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 6pt;text-indent: 21pt;line-height: 113%;text-align: justify;">在网络结构的预先已知，并且变量可以从训练样例中完全获得时，通过学习得到条件概 率表就比较简单了。只需要象在朴素贝叶斯分类器中那样估计表中的条件概率项。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 111%;text-align: justify;">若网络结构已知，但只有一部分变量值能在数据中观察到，学习问题就困难得多了。这 一问题在某种程度上类似于在人工神经网络中学习隐藏单元的权值，其中输入和输出结点值 由训练样例给出，但隐藏单元的值未指定。实际上，<span class="s6">Russtll et al.</span>（<span class="s6">1995</span>）提出了一个简单的 梯度上升过程以学习条件概率表中的项。这一梯度上升过程搜索一个假设空间，它对应于条 件概率表中所有可能的项。在梯度上升中最大化的目标函数是给定假设 <span class="s21">h </span>下观察到训练数据 <span class="s21">D </span>的概率 <span class="s21">P</span><span class="s6">(</span><span class="s21">D</span><span class="s6">|</span><span class="s21">h</span><span class="s6">)</span>。按照定义，它对应于对表项搜索极大似然假设。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">6.11.5 <span class="s25">贝叶斯网的梯度上升训练</span></h3><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;text-align: justify;"><span class="p">由</span><span class="s6">Russell et al. (1995)</span><span class="p">给出的梯度上升规则使用相应于定义条件概率表的参数的</span><span class="s6">ln</span>P<span class="s6">(</span>D<span class="s6">|</span>h<span class="s6">) </span><span class="p">的梯度来使</span>P<span class="s6">(</span>D<span class="s6">|</span>h<span class="s6">)</span><span class="p">最大化。令</span>w<span class="s36">ijk</span><span class="p">代表一个条件概率表的一个表项。确切地讲，令</span>w<span class="s36">ijk</span><span class="p">为在给 定父结点</span>U<span class="s36">i</span><span class="p">取值</span>u<span class="s36">ik</span><span class="p">时，网络变量</span>Y<span class="s36">i</span><span class="p">值为</span>y<span class="s36">ij</span><span class="p">的概率。例如，若</span>w<span class="s36">ijk</span><span class="p">为图 </span><span class="s6">6-3 </span><span class="p">中条件概率表中最右 上方的表项，那么</span>Y<span class="s36">i</span><span class="p">为变量</span>Campfire<span class="p">，</span>U<span class="s36">i</span><span class="p">是其父结点的元组</span><span class="s6">&lt;</span>Storm<span class="s6">, </span>BusTourGroup<span class="s6">&gt;</span><span class="p">，</span>y<span class="s36">ij</span><span class="s6">=</span>True<span class="p">，</span></p><p class="s33" style="padding-left: 288pt;text-indent: 0pt;line-height: 9pt;text-align: left;"><span class="s38"> </span>ln <i>P</i>(<i>D </i>| <i>h</i>)</p><p class="s21" style="padding-left: 5pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><span class="p">并且</span>u<span class="s36">ik</span><span class="s6">=&lt;</span>False<span class="s6">, </span>False<span class="s6">&gt;</span><span class="p">。对于每个</span>w<span class="s36">ijk</span><span class="s41"> </span><span class="p">，</span><span class="s6">ln</span>P<span class="s6">(</span>D<span class="s6">|</span>h<span class="s6">)</span><span class="p">的梯度由导数</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">见，每个导数可如下计算：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="80" height="1" alt="image" src="机器学习/Image_263.png"/></span></p><p class="s118" style="padding-left: 18pt;text-indent: 0pt;text-align: left;"><span class="s30">w</span><span class="s41">ijk</span></p><p style="text-indent: 0pt;line-height: 11pt;text-align: left;">给出。如下面可</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s33" style="padding-top: 4pt;padding-left: 104pt;text-indent: 0pt;text-align: center;"><span class="s38"> </span>ln <i>P</i>(<i>D </i>| <i>h</i>)</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 104pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="80" height="1" alt="image" src="机器学习/Image_264.png"/></span></p><p class="s118" style="text-indent: 0pt;text-align: right;"><span class="s30">w</span><span class="s41">ijk</span></p><p class="s38" style="padding-top: 9pt;padding-left: 1pt;text-indent: 0pt;line-height: 21pt;text-align: left;"> <span class="s39"></span></p><p class="s41" style="padding-left: 11pt;text-indent: 0pt;line-height: 7pt;text-align: left;">d<span class="s40"></span>D</p><p class="s30" style="padding-top: 2pt;padding-left: 3pt;text-indent: 0pt;text-align: center;">P<span class="s33">(</span>Y<span class="s52">i </span><span class="s38"> </span>y<span class="s52">ij </span><span class="s33">,</span>U<span class="s52">i </span><span class="s38"> </span>u<span class="s52">ik </span><span class="s33">| </span>d <span class="s33">)</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="150" height="1" alt="image" src="机器学习/Image_265.png"/></span></p><p class="s49" style="padding-left: 1pt;text-indent: 0pt;text-align: center;">w<span class="s41">ijk</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;">（<span class="s6">6.25</span>）</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;line-height: 109%;text-align: justify;"><span class="p">例如，为计算对应于图 </span><span class="s6">6-3 </span><span class="p">中表左上方的表项的 </span><span class="s6">ln</span>P<span class="s6">(</span>D<span class="s6">|</span>h<span class="s6">)</span><span class="p">的导数，需要对 </span>D <span class="p">中每个训练 样例 </span>d <span class="p">计算 </span>P<span class="s6">(</span>Campfire<span class="s6">=</span>True<span class="s6">, </span>Storm<span class="s6">=</span>False<span class="s6">, </span>BusTourGroup<span class="s6">=</span>False <span class="s6">| </span>d<span class="s6">)</span><span class="p">。当这些变量对训练样例 </span>d <span class="p">无法观察到时，这些所需的概率可以 </span>d <span class="p">中观察到的变量中用标准的贝叶斯网络推理得到。 实际上这些所需的量可在多数贝叶斯网络推理的过程中计算得到，因此无论何时贝叶斯网络 被用于推理，并且后来获得了新的证据，学习过程几乎不需要附加的花销，。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;"><span class="p">下面根据</span>Russell et al.<span class="p">（</span>1995<span class="p">）推导式 </span>6.25<span class="p">。本节的后面在第一次阅读时可以被跳过， 而不会丧失连续性，为使记号简单化，下面的推导将用</span><i>P</i><span class="s36">h</span>(<i>D</i>)<span class="p">来简写</span><i>P</i>(<i>D</i>|<i>h</i>)<span class="p">。因此，我们的问</span></p><p class="s30" style="padding-left: 92pt;text-indent: 0pt;line-height: 10pt;text-align: left;"><span class="s38"></span>P <span class="s33">(</span>D<span class="s33">)</span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="49" height="1" alt="image" src="机器学习/Image_266.png"/></span></p><p class="s21" style="padding-left: 5pt;text-indent: 0pt;line-height: 9pt;text-align: left;"><span class="p">题是获得导数集合 </span><span class="s83">h </span><span class="p">（对所有的</span>i<span class="s6">, </span>j<span class="s6">, </span>k<span class="p">）的梯度，假定在数据集</span>D<span class="p">中的各样例</span>d<span class="p">都是独</span></p><p class="s118" style="padding-left: 6pt;text-indent: 92pt;line-height: 14pt;text-align: left;"><span class="s30">w</span><span class="s41">ijk</span></p><p style="padding-top: 2pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">立抽取的。可将此导数写为</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="67" height="1" alt="image" src="机器学习/Image_267.png"/></span></p><p class="s41" style="text-indent: 0pt;line-height: 7pt;text-align: left;">h</p><p style="text-indent: 0pt;text-align: left;"/><p class="s33" style="padding-top: 2pt;padding-left: 179pt;text-indent: 0pt;line-height: 20pt;text-align: left;"><span class="s38"> </span>ln <i>P</i><span class="s192">h</span><span class="s41"> </span>(<i>D</i>) <span class="s114"></span><span class="s38"> </span><span class="s117"> </span><span class="s115">ln</span> <span class="s153"></span><span class="s121"> </span><i>P</i><i> </i>(<i>d </i>)</p><p class="s118" style="text-indent: 0pt;line-height: 14pt;text-align: right;"><span class="s30">w</span><span class="s41">ijk</span></p><p class="s118" style="padding-left: 27pt;text-indent: 0pt;line-height: 14pt;text-align: left;"><span class="s30">w</span><span class="s41">ijk</span></p><p class="s41" style="padding-top: 5pt;padding-left: 14pt;text-indent: 0pt;text-align: left;">d<span class="s40"></span>D</p><p style="text-indent: 0pt;text-align: left;"><span><img width="64" height="1" alt="image" src="机器学习/Image_268.png"/></span></p><p class="s33" style="padding-top: 2pt;padding-left: 232pt;text-indent: 0pt;line-height: 20pt;text-align: left;"><span class="s152"></span><span class="s38"> </span><span class="s153"></span><span class="s121"> </span><span class="s38"> </span>ln <i>P</i><span class="s52">h</span><span class="s41"> </span>(<i>d </i>)</p><p class="s41" style="padding-top: 4pt;text-indent: 0pt;text-align: right;">d<span class="s40"></span>D</p><p class="s118" style="padding-left: 11pt;text-indent: 0pt;line-height: 14pt;text-align: left;"><span class="s30">w</span><span class="s41">ijk</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="46" height="1" alt="image" src="机器学习/Image_269.png"/></span></p><p class="s30" style="padding-top: 2pt;padding-left: 232pt;text-indent: 0pt;line-height: 20pt;text-align: left;"><span class="s114"> </span><span class="s153"> </span><u>1 </u><span class="s38"></span>P<span class="s192">h </span><span class="s33">(</span>d <span class="s33">)</span></p><p class="s30" style="text-indent: 0pt;line-height: 14pt;text-align: right;"><span class="s192">d</span><span class="s40"></span><span class="s41">D </span>P<span class="s52">h </span><span class="s33">(</span>d <span class="s33">)</span></p><p class="s118" style="padding-left: 6pt;text-indent: 0pt;line-height: 14pt;text-align: left;"><span class="s30">w</span><span class="s41">ijk</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s236" style="padding-top: 3pt;padding-left: 27pt;text-indent: 0pt;line-height: 15pt;text-align: left;"><span class="p">最后一步使用了等式 </span><span class="s235"> </span>ln <i>f </i>( <i>x</i>) <span class="s238"></span><span class="s239"> </span>1 <span class="s235"></span><i>f </i>( <i>x</i>) <span class="p">。现在可以引入变量</span><span class="s21">Y</span><span class="s36">i</span><span class="s41"> </span><span class="p">和</span><span class="s21">U</span><span class="s36">i</span><span class="s6">=</span><span class="s21">Parents</span><span class="s6">(</span><span class="s21">Y</span><span class="s36">i</span><span class="s6">)</span><span class="p">的值，</span></p><p class="s240" style="padding-left: 135pt;text-indent: 0pt;line-height: 10pt;text-align: left;"><span class="s239"></span>x f <span class="s241">(</span>x<span class="s241">) </span><span class="s239"></span>x</p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">方法是通过在其可能的值<span class="s21">y</span><span class="s36">ij</span><span class="s42">´</span>和<span class="s21">u</span><span class="s36">ik</span><span class="s42">´</span>上计算加和。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="67" height="1" alt="image" src="机器学习/Image_270.png"/></span></p><p class="s41" style="text-indent: 0pt;line-height: 7pt;text-align: left;">h</p><p style="text-indent: 0pt;text-align: left;"/><p class="s33" style="padding-left: 98pt;text-indent: 0pt;line-height: 20pt;text-align: left;"><span class="s38"> </span>ln <i>P</i><span class="s192">h </span>(<i>D</i>) <span class="s114"> </span><span class="s153"> </span><u>1 </u><span class="s117"> </span><span class="s153"> </span><i>P </i>(<i>d </i>|</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s49" style="padding-left: 1pt;text-indent: 0pt;line-height: 11pt;text-align: left;">y<span class="s41">ij </span><span class="s42">&#39; </span><span class="s31">,</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s49" style="text-indent: 0pt;line-height: 11pt;text-align: left;">u<span class="s41">ik </span><span class="s42">&#39; </span><span class="s31">)</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="text-indent: 0pt;line-height: 11pt;text-align: left;">P<span class="s52">h</span><span class="s41"> </span><span class="s33">(</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s49" style="text-indent: 0pt;line-height: 11pt;text-align: left;">y<span class="s41">ij </span><span class="s42">&#39; </span><span class="s31">,</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s49" style="text-indent: 0pt;line-height: 11pt;text-align: left;">u<span class="s41">ik </span><span class="s42">&#39; </span><span class="s31">)</span></p><p class="s118" style="text-indent: 0pt;line-height: 14pt;text-align: right;"><span class="s30">w</span><span class="s41">ijk</span></p><p class="s41" style="padding-left: 26pt;text-indent: 0pt;line-height: 14pt;text-align: left;"><span class="s122">d</span><span class="s40"></span>D <span class="s49">P</span>h <span class="s31">(</span><span class="s30">d </span><span class="s33">) </span><span class="s38"></span><span class="s30">w</span>ijk</p><p class="s41" style="padding-top: 5pt;padding-left: 3pt;text-indent: 0pt;text-align: left;">j <span class="s42">&#39;,</span>k <span class="s42">&#39;</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s41" style="text-indent: 0pt;line-height: 7pt;text-align: left;">h</p><p style="text-indent: 0pt;text-align: left;"/><p class="s153" style="padding-top: 2pt;padding-left: 151pt;text-indent: 0pt;line-height: 19pt;text-align: left;"><span class="s114"> </span> <span class="s92">1 </span><span class="s117"> </span> <span class="s204">P </span><span class="s33">(</span><span class="s30">d </span><span class="s33">| </span><span class="s30">y</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s41" style="text-indent: 0pt;line-height: 3pt;text-align: left;">ij <span class="s42">&#39;</span></p><p class="s31" style="padding-top: 11pt;text-indent: 0pt;line-height: 11pt;text-align: left;">,<span class="s33"> </span><i>u</i><span class="s41">ik </span><span class="s42">&#39;</span></p><p class="s33" style="padding-top: 11pt;text-indent: 0pt;line-height: 11pt;text-align: left;">)<i>P</i><span class="s52">h </span>( <i>y</i></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s41" style="text-indent: 0pt;line-height: 3pt;text-align: left;">ij <span class="s42">&#39;</span></p><p class="s31" style="padding-top: 11pt;padding-left: 1pt;text-indent: 0pt;line-height: 11pt;text-align: left;">|<span class="s33"> </span><i>u</i><span class="s41">ik </span><span class="s42">&#39;</span></p><p class="s33" style="padding-top: 11pt;text-indent: 0pt;line-height: 11pt;text-align: left;">)<i>P</i><span class="s52">h</span><span class="s41"> </span>(<i>u</i></p><p class="s41" style="padding-top: 11pt;text-indent: 0pt;line-height: 11pt;text-align: left;">ik <span class="s42">&#39; </span><span class="s31">)</span></p><p class="s41" style="text-indent: 0pt;line-height: 14pt;text-align: right;"><span class="s122">d</span><span class="s40"></span>D <span class="s49">P</span>h <span class="s31">(</span><span class="s30">d </span><span class="s33">) </span><span class="s38"></span><span class="s30">w</span>ijk</p><p class="s41" style="padding-top: 5pt;padding-left: 3pt;text-indent: 0pt;text-align: left;">j <span class="s42">&#39;,</span>k <span class="s42">&#39;</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-top: 3pt;padding-left: 5pt;text-indent: 21pt;line-height: 14pt;text-align: left;"><span class="p">最后一步来自于概率的乘法公式，见表 </span><span class="s6">6-1</span><span class="p">。现在考虑上面最后一式最右边的加和项。 给定了</span>w<span class="s36">ijk </span><span class="p">≡</span>P<span class="s36">h</span><span class="s6">(</span>y<span class="s36">ij</span><span class="s6">|</span>u<span class="s36">ik</span><span class="s6">)</span><span class="p">，在此加和中惟一 </span><span class="s242"> </span><span class="p">不等于 </span><span class="s6">0 </span><span class="p">的项是其中</span>j<span class="s6">´=</span>j<span class="p">和</span>i<span class="s6">´=</span>i<span class="p">的项，因此：</span></p><p class="s243" style="padding-left: 24pt;text-indent: 0pt;line-height: 12pt;text-align: center;"><span class="s56">w</span><span class="s44">ijk</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s33" style="padding-top: 2pt;padding-left: 98pt;text-indent: 0pt;line-height: 8pt;text-align: left;"><span class="s38"> </span>ln <i>P</i><span class="s52">h </span>(<i>D</i>) <span class="s114"></span></p><p class="s30" style="padding-top: 2pt;padding-left: 16pt;text-indent: 0pt;line-height: 8pt;text-align: left;"><u>    1 </u><span class="s117"> </span>P <span class="s33">(</span>d <span class="s33">| </span>y <span class="s33">,</span>u</p><p class="s33" style="padding-top: 10pt;padding-left: 4pt;text-indent: 0pt;line-height: 1pt;text-align: left;">)<i>P </i>( <i>y</i></p><p class="s33" style="padding-top: 10pt;padding-left: 5pt;text-indent: 0pt;line-height: 1pt;text-align: left;">| <i>u </i>)<i>P </i>(<i>u </i>)</p><p style="text-indent: 0pt;text-align: left;"><span><img width="65" height="1" alt="image" src="机器学习/Image_271.png"/></span></p><p class="s30" style="padding-left: 116pt;text-indent: 0pt;line-height: 11pt;text-align: left;">w <span class="s216"> </span>P <span class="s33">(</span>d <span class="s33">) </span>w <span class="s244">h</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s41" style="padding-left: 24pt;text-indent: 0pt;line-height: 3pt;text-align: left;">ij ik</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s41" style="padding-left: 10pt;text-indent: 0pt;line-height: 3pt;text-align: left;">h ij</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s41" style="padding-left: 12pt;text-indent: 0pt;line-height: 3pt;text-align: left;">ik h ik</p><p class="s118" style="text-indent: 0pt;line-height: 14pt;text-align: right;"><span class="s38"> </span><span class="s41">ijk</span></p><p class="s122" style="padding-top: 4pt;padding-left: 25pt;text-indent: 0pt;text-align: left;">d<span class="s40"></span><span class="s41">D h</span></p><p class="s118" style="padding-left: 18pt;text-indent: 0pt;line-height: 14pt;text-align: left;"><span class="s38"> </span><span class="s41">ijk</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="padding-top: 2pt;padding-left: 151pt;text-indent: 0pt;line-height: 8pt;text-align: left;"><span class="s38"> </span><u>1 </u><span class="s117"> </span>P <span class="s33">(</span>d <span class="s33">| </span>y <span class="s33">,</span>u <span class="s33">)</span>w</p><p class="s30" style="padding-top: 10pt;padding-left: 5pt;text-indent: 0pt;line-height: 1pt;text-align: left;">P <span class="s33">(</span>u <span class="s33">)</span></p><p class="s30" style="text-indent: 0pt;line-height: 11pt;text-align: right;"><span class="s216"> </span>P <span class="s33">(</span>d <span class="s33">) </span>w <span class="s244">h</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s41" style="padding-left: 24pt;text-indent: 0pt;line-height: 3pt;text-align: left;">ij ik</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s41" style="padding-left: 11pt;text-indent: 0pt;line-height: 3pt;text-align: left;">ijk h ik</p><p class="s122" style="padding-top: 4pt;text-indent: 0pt;text-align: right;">d<span class="s40"></span><span class="s41">D h</span></p><p class="s118" style="padding-left: 18pt;text-indent: 0pt;line-height: 14pt;text-align: left;"><span class="s38"> </span><span class="s41">ijk</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s41" style="text-indent: 0pt;line-height: 7pt;text-align: left;">h</p><p style="text-indent: 0pt;text-align: left;"/><p class="s30" style="padding-top: 3pt;padding-left: 151pt;text-indent: 0pt;line-height: 16pt;text-align: left;"><span class="s38"> </span><span class="s124"> </span><u>1 </u>P <span class="s33">(</span>d <span class="s33">| </span>y <span class="s33">,</span>u</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s33" style="padding-left: 4pt;text-indent: 0pt;line-height: 9pt;text-align: left;">)<i>P </i>(<i>u </i>)</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s41" style="text-indent: 0pt;text-align: right;">d<span class="s40"></span>D</p><p class="s30" style="text-indent: 0pt;text-align: left;">P<span class="s52">h </span><span class="s33">(</span>d <span class="s33">)</span></p><p class="s41" style="padding-left: 24pt;text-indent: 0pt;line-height: 7pt;text-align: left;">ij ik</p><p class="s41" style="padding-left: 9pt;text-indent: 0pt;line-height: 7pt;text-align: left;">h ik</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-top: 1pt;padding-left: 26pt;text-indent: 0pt;text-align: left;"><span class="p">应用贝叶斯公式来重写</span>P<span class="s36">h</span><span class="s6">(</span>d<span class="s6">|</span>y<span class="s36">ij</span><span class="s6">,</span>u<span class="s36">ik</span><span class="s6">)</span><span class="p">可得</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s33" style="padding-top: 4pt;text-indent: 0pt;line-height: 8pt;text-align: right;"><span class="s38"> </span>ln <i>P</i><span class="s52">h</span><span class="s41"> </span>(<i>D</i>)</p><p class="s30" style="padding-top: 3pt;padding-left: 25pt;text-indent: 0pt;line-height: 8pt;text-align: left;"><u>    1 </u>P<span class="s52">h</span><span class="s41"> </span><span class="s33">( </span>y<span class="s52">ij</span><span class="s41"> </span><span class="s33">,</span>u<span class="s52">ik</span><span class="s41"> </span><span class="s33">| </span>d <span class="s33">)</span>P<span class="s52">h </span><span class="s33">(</span>d <span class="s33">)</span>P<span class="s52">h</span><span class="s41"> </span><span class="s33">(</span>u<span class="s52">ik</span><span class="s41"> </span><span class="s33">)</span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="65" height="1" alt="image" src="机器学习/Image_272.png"/></span></p><p class="s30" style="padding-left: 129pt;text-indent: 0pt;line-height: 18pt;text-align: left;"><span class="s38"></span>w <span class="s245"> </span><span class="s216"> </span>P <span class="s33">(</span>d <span class="s33">)</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="163" height="1" alt="image" src="机器学习/Image_273.png"/></span></p><p class="s30" style="padding-left: 38pt;text-indent: 0pt;line-height: 8pt;text-align: left;">P <span class="s33">( </span>y <span class="s33">,</span>u <span class="s33">)</span></p><p class="s41" style="text-indent: 0pt;text-align: right;">ijk</p><p class="s122" style="padding-left: 26pt;text-indent: 0pt;line-height: 8pt;text-align: left;">d<span class="s40"></span><span class="s41">D h</span></p><p class="s41" style="padding-left: 61pt;text-indent: 0pt;text-align: left;">h ij ik</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="padding-top: 3pt;text-indent: 0pt;line-height: 8pt;text-align: right;">P <span class="s33">( </span>y <span class="s33">,</span>u</p><p class="s33" style="padding-top: 3pt;padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">| <i>d </i>)<i>P </i>(<i>u </i>)</p><p class="s191" style="padding-left: 169pt;text-indent: 0pt;line-height: 12pt;text-align: left;"> <span class="s246"> </span><span class="s143">h ij ik h ik    </span></p><p class="s41" style="padding-top: 4pt;text-indent: 0pt;text-align: right;">d<span class="s40"></span>D</p><p class="s30" style="padding-left: 23pt;text-indent: 0pt;line-height: 14pt;text-align: left;">P<span class="s52">h</span><span class="s41"> </span><span class="s33">( </span>y<span class="s52">ij</span><span class="s41"> </span><span class="s33">,</span>u<span class="s52">ik</span><span class="s41"> </span><span class="s33">)</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="padding-top: 3pt;text-indent: 0pt;line-height: 8pt;text-align: right;">P <span class="s33">( </span>y <span class="s33">,</span>u</p><p class="s33" style="padding-top: 3pt;padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">| <i>d </i>)</p><p class="s191" style="padding-left: 24pt;text-indent: 0pt;line-height: 12pt;text-align: center;"> <span class="s246"> </span><span class="s143">h ij ik            </span></p><p class="s41" style="padding-top: 4pt;text-indent: 0pt;text-align: right;">d<span class="s40"></span>D</p><p class="s30" style="padding-left: 6pt;text-indent: 0pt;line-height: 14pt;text-align: left;">P<span class="s52">h</span><span class="s41"> </span><span class="s33">( </span>y<span class="s52">ij</span><span class="s41"> </span><span class="s33">| </span>u<span class="s52">ik</span><span class="s41"> </span><span class="s33">)</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="padding-top: 3pt;text-indent: 0pt;line-height: 8pt;text-align: right;">P <span class="s33">( </span>y <span class="s33">,</span>u</p><p class="s33" style="padding-top: 3pt;padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">| <i>d </i>)</p><p class="s191" style="padding-left: 169pt;text-indent: 0pt;line-height: 12pt;text-align: left;"> <span class="s246"> </span><span class="s143">h ij ik            </span></p><p style="padding-left: 22pt;text-indent: 0pt;line-height: 12pt;text-align: left;">（<span class="s6">6.26</span>）</p><p class="s41" style="padding-top: 4pt;text-indent: 0pt;text-align: right;">d<span class="s40"></span>D</p><p class="s49" style="padding-left: 22pt;text-indent: 0pt;line-height: 14pt;text-align: left;">w<span class="s41">ijk</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 6pt;text-indent: 21pt;line-height: 107%;text-align: left;">这样我们已导出了式 <span class="s6">6.25 </span>中的梯度。在描述梯度上升训练前还要考虑一个问题。确切 地说，我们要求当权值<span class="s21">w</span><span class="s36">ijk</span>更新时，它们必须保持在区间<span class="s6">[0</span>，<span class="s6">1]</span>之间，这样才是有效的概率。</p><p style="padding-left: 6pt;text-indent: 0pt;text-align: left;">我们还要求Σ<span class="s36">j</span><span class="s21">w</span><span class="s36">ijk</span>对所有的<span class="s21">i</span><span class="s6">,</span><span class="s21">k</span>保持为 <span class="s6">1</span>。这些限制可由一个两步骤的权值更新来满足。首先 用梯度上升来更新每个<span class="s21">w</span><span class="s36">ijk</span>：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="padding-top: 3pt;text-indent: 0pt;line-height: 9pt;text-align: right;">P <span class="s33">( </span>y <span class="s33">, </span>u</p><p class="s33" style="padding-top: 3pt;padding-left: 8pt;text-indent: 0pt;line-height: 9pt;text-align: left;">| <i>d </i>)</p><p class="s49" style="text-indent: 0pt;text-align: right;">w<span class="s41">ijk</span></p><p class="s121" style="text-indent: 0pt;line-height: 18pt;text-align: left;"></p><p style="text-indent: 0pt;text-align: left;"/><p class="s118" style="padding-left: 3pt;text-indent: 0pt;text-align: left;"><span class="s38"> </span><span class="s30">w</span><span class="s41">ijk</span></p><p class="s191" style="padding-left: 2pt;text-indent: 0pt;line-height: 13pt;text-align: left;"> <span class="s119"> </span><span class="s143">h ij ik            </span></p><p class="s30" style="padding-left: 58pt;text-indent: 0pt;line-height: 5pt;text-align: left;">w</p><p class="s41" style="text-indent: 0pt;line-height: 7pt;text-align: right;">d<span class="s40"></span>D</p><p class="s41" style="padding-left: 32pt;text-indent: 0pt;text-align: left;">ijk</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;text-align: justify;">其中<span class="s47">η</span>是一小的常量，称为学习率。其次，再将权值<span class="s21">w</span><span class="s36">ijk</span>归一化，以保证上面的限制得 到满足。如<span class="s6">Russell</span>所描述的那样，这一过程将收敛到贝叶斯网络中的条件概率的一个局部的 极大似然假设。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 113%;text-align: justify;">如在其他基于梯度的方法中那样，该算法只保证寻找到局部最优解。替代梯度上升的一 个算法是 <span class="s6">EM </span>算法，它在 <span class="s6">6.12 </span>节中讨论，它也只找局部极大可能性的解。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: justify;">6.11.6 <span class="s25">学习贝叶斯网的结构</span></h3><p style="padding-top: 10pt;padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">当网络结构预先未知时，学习贝叶斯网络也很困难。 <span class="s6">Cooper &amp; Herskovits</span>（<span class="s6">1992</span>） 提 出了一个贝叶斯评分度量（<span class="s6">Bayesian scoring metric</span>）以从不同网络中进行选择。他们还提出 一个称为 <span class="s21">K</span><span class="s6">2 </span>的启发式搜索算法用于在数据完全可观察到时学习网络结构。如多数学习网络 结构的算法，<span class="s21">K</span><span class="s6">2 </span>执行的是一个贪婪搜索，以在网络的复杂性和它在训练数据上的精度之间 作出折中。在一个实验中，<span class="s21">K</span><span class="s6">2 </span>被给与 <span class="s6">3000 </span>个训练样例，这些样例是从包含了 <span class="s6">37 </span>个节点和</p><p class="s6" style="padding-left: 5pt;text-indent: 0pt;text-align: justify;">46 <span class="p">条弧的手工创建的贝叶斯网络中随机抽取的。这一网络描述了在一医院的手术室中潜在</span></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: justify;">的细菌问题。除了数据以外，程序还被给与 <span class="s6">37 </span>个变量的初始排序，它与实际网络中变量之 间的偏序关系一致。该程序成功地创建出了与正确网络结构几乎一样的贝叶斯网，除了一个 不正确地被删除的和一不正确地被加入的弧。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;line-height: 110%;text-align: justify;">基于约束的学习贝叶斯网络结构的途径也已被开发出来（例如，<span class="s6">Spirtes et al. 1993</span>）。这 些途径从数据中推论出不相关和相关的关系，然后用这些关系来构造贝叶斯网。关于当前学 习贝叶斯网的途径的调研由 <span class="s6">Heckerman</span>（<span class="s6">1995</span>）和 <span class="s6">Buntine</span>（<span class="s6">1994</span>）给出。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">6.12 EM <span class="s17">算法</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 6pt;text-indent: 21pt;line-height: 108%;text-align: justify;"><span class="p">在许多实际的学习问题框架中，相关实例特征中只有一部分可观察到。例如，在训练或 使用图 </span>6-3 <span class="p">中的贝叶斯置信网时，可能网络变量 </span><i>Storm</i>, <i>Lighting</i>, <i>Thunder</i>, <i>ForestFire</i>, <i>Campfire </i><span class="p">和 </span><i>BusTourGroup </i><span class="p">中只有其一个子集能在数据中观察到。已有许多方法被提出用来处理存在 未观察到变量时的问题。如在第 </span>3 <span class="p">章看到的，若某些变量有时能观察到，有时不能，那么可 以用观察到的实例去预测未观察到的。在本节中描述 </span>EM <span class="p">算法（ </span>Dempster et al. 1977<span class="p">），这 是存在隐含变量时广泛使用的一种学习方法。</span>EM <span class="p">算法可用于变量的值从来没有被直接观察 到的情形，只要这些变量所遵循的概率分布的一般形式已知。</span>EM <span class="p">算法已被用于训练贝叶斯 置信网（见 </span>Heckerman 1995<span class="p">）以及 </span>8.4 <span class="p">节讨论的径向基函数（</span>radial basis function<span class="p">）网络。 </span>EM <span class="p">算法还是许多非监督聚类算法的基础（如 </span>Cheeseman et al. 1988<span class="p">），而且它是用于学习部 分可观察马尔可夫模型（</span>Partially Observable Markov Model<span class="p">）的广泛使用的 </span>Baum-Welch <span class="p">前 向后向算法的基础（</span>Rabiner 1989<span class="p">）。</span></p><p class="s25" style="padding-left: 27pt;text-indent: -21pt;text-align: left;"><span class="h3">6.12.1 </span>估计 <span class="s203">k </span>个 高斯分布的均值</p><p style="padding-top: 10pt;padding-left: 5pt;text-indent: 21pt;line-height: 106%;text-align: justify;">介绍<span class="s6">EM</span>算法最方便的方法是通过一个例子。考虑数据<span class="s21">D</span>是一实例集合，它由<span class="s21">k</span>个不同正 态分布的混合所得分布所生成。该问题框架在图 <span class="s6">6-4 </span>中示出，其中<span class="s21">k</span><span class="s6">=2 </span>而且实例为沿着<span class="s21">x</span>轴显 示的点。每个实例使用一个两步骤过程形成。首先了随机选择<span class="s21">k</span>个正态分布其中之一。其次 随机变量<span class="s21">x</span><span class="s36">i</span>按照此选择的分布生成。这一过程不断重复，生成一组数据点如图所示。为使讨 论简单化，我们考虑一个简单情形，即单个正态分布的选择基于统一的概率进行选择，并且 <span class="s21">k</span>个正态分布有相同的方差<span class="s47">σ</span><span class="s46">2</span>，且<span class="s47">σ</span><span class="s46">2</span>已知。学习任务是输出一个假设<span class="s21">h</span><span class="s6">=&lt;</span><span class="s47">μ</span><span class="s35">1</span><span class="s6">…</span><span class="s47">μ</span><span class="s36">k</span><span class="s6">&gt;</span>，它描述 了<span class="s21">k</span>个分布中每一个分布的均值。我们希望对这些均值找到一个极大似然假设，即一个使 <span class="s21">P</span><span class="s6">(</span><span class="s21">D</span><span class="s6">|</span><span class="s21">h</span><span class="s6">)</span>最大化的假设<span class="s21">h</span>。</p><p style="text-indent: 0pt;text-align: left;"><span><img width="547" height="1" alt="image" src="机器学习/Image_274.png"/></span></p><p class="s48" style="padding-top: 14pt;padding-left: 15pt;text-indent: 0pt;text-align: left;">原书页码： <span class="s21">192</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 14pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="531" height="1" alt="image" src="机器学习/Image_275.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 76pt;text-indent: 0pt;text-align: left;">图 <span class="h4">6-4 </span>由两个具有相等方差<span class="s47">σ</span><span class="s247">2</span>的正态分布的混合生成的实例集。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-left: 58pt;text-indent: 0pt;text-align: left;">实例为沿着 <span class="s56">x </span>轴显示的点集。如果正态分布的均值未知，<span class="s16">EM </span>算法可用于搜索其极大似然估计。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 106%;text-align: justify;">注意到，当给定从一个正态分布中抽取的数据实例<span class="s21">x</span><span class="s35">1</span><span class="s6">, </span><span class="s21">x</span><span class="s35">2</span><span class="s6">, …, </span><span class="s21">x</span><span class="s36">m</span>时，很容易计算该分布的 均值的极大似然假设。这一寻找单个分布均值的问题只是在 <span class="s6">6.4 </span>节的式 <span class="s6">6.6 </span>中讨论的问题的 一个特例，在其中我们证明了极大似然假设是使<span class="s21">m</span>个训练实例上的误差平方和最小化的假 设。使用当前的记号重新表述一下式 <span class="s6">6.6</span>，可以得到：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s41" style="padding-top: 4pt;text-indent: 0pt;line-height: 6pt;text-align: right;">m</p><p class="s42" style="text-indent: 0pt;line-height: 7pt;text-align: left;">2</p><p style="text-indent: 0pt;text-align: left;"/><p class="s33" style="padding-left: 110pt;text-indent: 0pt;line-height: 16pt;text-align: left;"><span class="s119"></span><span class="s125"> </span><span class="s52">ML</span><span class="s41">   </span><span class="s38"></span> arg min <span class="s124"></span>(<i>x</i><span class="s52">i</span><span class="s41">  </span><span class="s38"></span> <span class="s119"></span>)</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 61pt;text-indent: 0pt;text-align: left;">（<span class="s6">6.27</span>）</p><p class="s248" style="padding-left: 22pt;text-indent: 0pt;line-height: 9pt;text-align: center;"><span class="s181"> </span><span class="s41">i</span><span class="s40"></span><span class="s42">1</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">在此情况下，误差平方和是由样本均值最小化的：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s195" style="padding-top: 3pt;padding-left: 166pt;text-indent: 0pt;line-height: 7pt;text-align: left;">1<span class="s33"> </span><span class="s41">m</span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="14" height="1" alt="image" src="机器学习/Image_276.png"/></span></p><p class="s41" style="padding-top: 4pt;padding-left: 165pt;text-indent: -33pt;line-height: 60%;text-align: left;"><span class="s154"> </span>ML <span class="s118"> </span><span class="s135"> </span><span class="s49">x</span>i <span class="s196">m</span><span class="s30"> </span>i<span class="s40"></span><span class="s42">1</span></p><p style="text-indent: 0pt;line-height: 14pt;text-align: center;">（<span class="s6">6.28</span>）</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;text-align: justify;">然而，在这里我们的问题涉及到<span class="s21">k</span>个不同正态分布的混合，而且我们不能知道哪个实例 是哪个分布产生的。因此这是一个涉及隐藏变量的典型例子。在图 <span class="s6">6-4 </span>的例子中，可把每个 实例的完整描述看作是三元组<span class="s6">&lt;</span><span class="s21">x</span><span class="s36">i</span><span class="s6">, </span><span class="s21">z</span><span class="s36">i</span><span class="s42">1</span><span class="s6">, </span><span class="s21">z</span><span class="s36">i</span><span class="s42">2</span><span class="s6">&gt;</span>，其中<span class="s21">x</span><span class="s36">i</span>是第<span class="s21">i</span>个实例的观测值，<span class="s21">z</span><span class="s36">i</span><span class="s42">1</span>和<span class="s21">z</span><span class="s36">i</span><span class="s42">2</span>表示两个正 态分布中哪个被用于产生值<span class="s21">x</span><span class="s36">i</span>。确切地讲，<span class="s21">z</span><span class="s36">ij</span>在<span class="s21">x</span><span class="s36">i</span>由第<span class="s21">j</span>个正态分布产生时值为 <span class="s6">1</span>，否则为 <span class="s6">0</span>。 这里<span class="s21">x</span><span class="s36">i</span>是实例的描述中已观察到的变量，<span class="s21">z</span><span class="s36">i</span><span class="s42">1</span>和<span class="s21">z</span><span class="s36">i</span><span class="s42">2</span>是隐藏变量。如果<span class="s21">z</span><span class="s36">i</span><span class="s42">1</span>和<span class="s21">z</span><span class="s36">i</span><span class="s42">2</span>的值可知，就可以 用式 <span class="s6">6.27 </span>来解决均值<span class="s47">μ</span><span class="s35">1</span>和<span class="s47">μ</span><span class="s35">2</span>。因为它们未知，因此我们只能用<span class="s6">EM</span>算法。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;"><span class="s6">EM</span>算法应用于我们的<span class="s21">k</span>均值问题，目的是搜索一个极大似然假设，方法是根据当前假设</p><p class="s6" style="padding-left: 6pt;text-indent: 0pt;text-align: left;">&lt;<span class="s47">μ</span><span class="s35">1</span>…<span class="s47">μ</span><span class="s36">k</span>&gt;<span class="p">不断地再估计隐藏变量</span><i>z</i><span class="s36">ij</span><span class="p">的期望值。然后用这些隐藏变量的期望值重新计算极大 似然假设。这里首先描述这一实例化的</span>EM<span class="p">算法，以后将给出</span>EM<span class="p">算法的一般形式。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 16pt;text-align: left;">为了估计图 <span class="s6">6-4 </span>中的两个均值，<span class="s6">EM</span>算法首先将假设初始化为<span class="s21">h</span><span class="s6">=&lt;</span><span class="s47">μ</span><span class="s35">1</span><span class="s6">, </span><span class="s47">μ</span><span class="s35">2</span><span class="s6">&gt;</span>，其中<span class="s47">μ</span><span class="s35">1</span>和 <span class="s47">μ</span><span class="s35">2</span>为任意的初始值。然后重复以下的两个步骤以重估计<span class="s21">h</span>，直到该过程收敛到一个稳定的<span class="s21">h</span></p><p style="padding-left: 6pt;text-indent: 0pt;text-align: left;">值。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 27pt;text-indent: 0pt;text-align: left;"><span class="p">步骤 </span>1<span class="p">：计算每个隐藏变量</span><i>z</i><span class="s36">ij</span><span class="p">的期望值</span><i>E</i>[<i>z</i><span class="s36">ij</span>]<span class="p">，假定当前假设</span><i>h</i>=&lt;<span class="s47">μ</span><span class="s35">1</span>, <span class="s47">μ</span><span class="s35">2</span>&gt;<span class="p">成立。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;text-align: justify;"><span class="p">步骤 </span>2<span class="p">：计算一个新的极大似然假设</span><i>h</i>´=&lt;<span class="s47">μ</span><span class="s35">1</span>´, <span class="s47">μ</span><span class="s35">2</span>´&gt;<span class="p">，假定由每个隐藏变量</span><i>z</i><span class="s36">ij</span><span class="p">所取的值 为第 </span>1 <span class="p">步中得到的期望值</span><i>E</i>[<i>z</i><span class="s36">ij</span>]<span class="p">，然后将假设</span><i>h</i>=&lt;<span class="s47">μ</span><span class="s35">1</span>, <span class="s47">μ</span><span class="s35">2</span>&gt;<span class="p">替换为新的假设</span><i>h</i>´=&lt;<span class="s47">μ</span><span class="s35">1</span>´, <span class="s47">μ</span><span class="s35">2</span>´&gt;<span class="p">， 然后循环。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 26pt;text-indent: 0pt;text-align: left;">现在考察第一步是如何实现的。步骤 <span class="s6">1 </span>要计算每个<span class="s21">z</span><span class="s36">ij</span><span class="s41"> </span>的期望值。此<span class="s21">E</span><span class="s6">[</span><span class="s21">z</span><span class="s36">ij</span><span class="s6">]</span>正是实例<span class="s21">x</span><span class="s36">i</span>由第</p><p class="s21" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">j<span class="p">个正态分布生成的概率：</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="148" height="1" alt="image" src="机器学习/Image_277.png"/></span></p><p class="s41" style="text-indent: 0pt;line-height: 8pt;text-align: left;">ij                  <span class="s42">2</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s33" style="padding-top: 2pt;padding-left: 170pt;text-indent: 0pt;line-height: 21pt;text-align: left;"><i>E</i>[<i>z </i>] <span class="s38"> </span><i>p</i>(<i>x </i><span class="s38"> </span><i>x</i><span class="s52">i </span>| <span class="s119"> </span><span class="s38"> </span><span class="s119"> </span><span class="s52">j</span><span class="s41"> </span>)</p><p class="s33" style="padding-left: 209pt;text-indent: 0pt;line-height: 19pt;text-align: left;"><span class="s39"></span><span class="s176">n</span><span class="s41"> </span><span class="s40"></span><span class="s42">1 </span><i>p</i>(<i>x </i><span class="s38"></span> <i>x</i><span class="s52">i</span><span class="s41">  </span>| <span class="s119"></span><span class="s125"> </span><span class="s38"></span> <span class="s119"></span><span class="s52">n</span><span class="s41"> </span>)</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s40" style="padding-top: 4pt;padding-left: 134pt;text-indent: 0pt;line-height: 9pt;text-align: center;"> <span class="s208">1 </span><span class="s42">( </span><span class="s41">x </span> <span class="s200"> </span><span class="s42">) </span><span class="s209">2</span></p><p class="s249" style="padding-top: 1pt;text-indent: 0pt;line-height: 11pt;text-align: right;">e <span class="s42">2</span><span class="s200"> </span><span class="s209">2</span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="110" height="1" alt="image" src="机器学习/Image_278.png"/></span></p><p class="s38" style="text-indent: 0pt;line-height: 10pt;text-align: right;"></p><p class="s79" style="text-indent: 0pt;line-height: 5pt;text-align: right;">2<span class="s42"> </span><span class="s40"></span></p><p class="s44" style="padding-left: 2pt;text-indent: 0pt;line-height: 5pt;text-align: center;">i</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s208" style="text-indent: 0pt;text-align: center;">   1   </p><p class="s44" style="padding-left: 6pt;text-indent: 0pt;line-height: 5pt;text-align: left;">j</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s180" style="padding-top: 3pt;text-indent: 0pt;line-height: 6pt;text-align: left;"><span class="s42">( </span><span class="s41">x</span>i<span class="s44"> </span><span class="s40"> </span><span class="s200"> </span>n<span class="s44"> </span><span class="s42">) </span><span class="s209">2</span></p><p class="s106" style="text-indent: 0pt;line-height: 19pt;text-align: right;"><span class="s41">n </span><span class="s40"></span><span class="s42">1 </span><span class="s250">e</span></p><p class="s42" style="padding-left: 3pt;text-indent: 0pt;text-align: left;">2<span class="s200"> </span><span class="s209">2</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;"><span class="p">因此第一步可由将当前值</span>&lt;<span class="s47">μ</span><span class="s35">1</span>, <span class="s47">μ</span><span class="s35">2</span>&gt;<span class="p">和已知的</span><i>x</i><span class="s36">i</span><span class="p">代入到上式中实现。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 5pt;text-indent: 21pt;text-align: left;"><span class="p">在第二步，使用第 </span>1 <span class="p">步中得到的</span><i>E</i>[<i>z</i><span class="s36">ij</span>] <span class="p">来导出一新的极大似然假设</span><i>h</i>´=&lt;<span class="s47">μ</span><span class="s35">1</span>´, <span class="s47">μ</span><span class="s35">2</span>´&gt;<span class="p">。如 后面将讨论到的，这时的极大似然假设为：</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="82" height="1" alt="image" src="机器学习/Image_279.png"/></span></p><p class="s41" style="text-indent: 0pt;line-height: 7pt;text-align: left;">m</p><p style="text-indent: 0pt;text-align: left;"/><p class="s41" style="text-indent: 0pt;line-height: 7pt;text-align: left;">m</p><p style="text-indent: 0pt;text-align: left;"/><p class="s41" style="text-indent: 0pt;line-height: 7pt;text-align: left;">j</p><p style="text-indent: 0pt;text-align: left;"/><p class="s33" style="padding-top: 3pt;padding-left: 134pt;text-indent: 0pt;line-height: 24pt;text-align: center;"><span class="s251"></span><span class="s125">   </span><span class="s38"></span> <span class="s39"></span><span class="s176">i</span><span class="s41"> </span><span class="s40"></span><span class="s42">1 </span><i>E</i>[<i>z</i><span class="s52">ij</span><span class="s41"> </span>]<i>x</i><span class="s52">i</span></p><p class="s30" style="padding-left: 134pt;text-indent: 0pt;line-height: 19pt;text-align: center;"><span class="s39"></span><span class="s176">i</span><span class="s41"> </span><span class="s40"></span><span class="s42">1 </span>E<span class="s33">[</span>z<span class="s52">ij</span><span class="s41"> </span><span class="s33">]</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;text-align: left;">注意此表达式类似于式 <span class="s6">6.28 </span>中的样本均值，它用于从单个正态分布中估计<span class="s47">μ</span>。新的表 达式只是对<span class="s47">μ</span><span class="s36">j</span>的加权样本均值，每个实例的权重为其由第<span class="s21">j</span>个正态分布产生的期望值。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;text-align: justify;"><span class="p">上面估计</span><i>k</i><span class="p">个正态分布均值的算法描述了</span>EM<span class="p">方法的要点：即当前的假设用于估计未知变 量，而这些变量的期望值再被用于改进假设。可以证明，在此算法第一次循环中，</span>EM<span class="p">算法 能使似然性</span><i>P</i>(<i>D</i>|<i>h</i>)<span class="p">增加，除非它已达到局部的最大。因此该算法收敛到对于</span>&lt;<span class="s47">μ</span><span class="s35">1</span>, <span class="s47">μ</span><span class="s35">2</span>&gt;<span class="p">的一 个局部极大可能性假设。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">6.12.2 EM <span class="s25">算法的一般表述</span></h3><p style="padding-top: 10pt;padding-left: 5pt;text-indent: 21pt;text-align: justify;">上面的<span class="s6">EM</span>算法针对的是估计混合正态分布均值的问题。更一般地，<span class="s6">EM</span>算法可用于许多 问题框架，其中需要估计一组描述基准概率分布的参数<span class="s47">θ</span>，只给定了由此分布产生的全部数 据中能观察到的一部分。在上面的二均值问题中，感兴趣的参数为<span class="s47">θ</span><span class="s6">=&lt;</span><span class="s47">μ</span><span class="s35">1</span><span class="s6">, </span><span class="s47">μ</span><span class="s35">2</span><span class="s6">&gt;</span>，而全部 数据为三元组<span class="s6">&lt;</span><span class="s21">x</span><span class="s36">i</span><span class="s6">, </span><span class="s21">z</span><span class="s36">i</span><span class="s42">1</span><span class="s6">, </span><span class="s21">z</span><span class="s36">i</span><span class="s42">2</span><span class="s6">&gt;</span>，而只有<span class="s21">x</span><span class="s36">i</span>可观察到，一般地令<span class="s21">X</span><span class="s6">=&lt;</span><span class="s21">x</span><span class="s35">1</span><span class="s6">, …, </span><span class="s21">x</span><span class="s36">m</span><span class="s6">&gt;</span>代表在同样的实例中 未观察到的数据，并令<span class="s21">Y</span><span class="s6">=</span><span class="s21">X</span>∪<span class="s21">Z</span>代表全体数据。注意到未观察到的<span class="s21">Z</span>可被看作一随机变量，它 的概率分布依赖于未知参数<span class="s47">θ</span>和已知数据<span class="s21">X</span>。类似地，<span class="s21">Y</span>是一随机变量，因为它是由随机变 量<span class="s21">Z</span>来定义的。在本节的后续部分，将描述<span class="s6">EM</span>算法的一般形式。使用<span class="s21">h</span>来代表参数<span class="s47">θ</span>的假设 值，而<span class="s21">h</span><span class="s6">´</span>代表在<span class="s6">EM</span>算法的每次迭代中修改的假设。</p><p class="s21" style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: left;"><span class="s6">EM </span><span class="p">算法通过搜寻使 </span>E<span class="s6">[ln</span>P<span class="s6">(</span>Y<span class="s6">|</span>h<span class="s6">´)]</span><span class="p">最大的 </span>h<span class="s6">´</span><span class="p">来寻找极大似然假设 </span>h<span class="s6">´</span><span class="p">。此期望值是在 </span>Y <span class="p">所 遵循的概率分布上计算，此分布由未知参数</span><span class="s47">θ</span><span class="p">确定。考虑此表达式究竟意味了什么。首先 </span>P<span class="s6">(</span>Y<span class="s6">|</span>h<span class="s6">´)</span><span class="p">是给定假设 </span>h<span class="s6">´</span><span class="p">下全部数据 </span>Y <span class="p">的似然性。其合理性在于我们要寻找一个 </span>h<span class="s6">´</span><span class="p">使该量的某 函数值最大化。其次使该量的对数 </span><span class="s6">ln</span>P<span class="s6">(</span>Y<span class="s6">|</span>h<span class="s6">´)</span><span class="p">最大化也使 </span>P<span class="s6">(</span>Y<span class="s6">|</span>h<span class="s6">´)</span><span class="p">最大化，如已经介绍过的那样。 第三，引入期望值 </span>E<span class="s6">[ln</span>P<span class="s6">(</span>Y<span class="s6">|</span>h<span class="s6">´)]</span><span class="p">是因为全部数据 </span>Y <span class="p">本身也是一随机变量。已知全部数据 </span>Y <span class="p">是 观察到的 </span>X <span class="p">和未观察到的 </span>Z <span class="p">的合并，我们必须在未观察到的 </span>Z <span class="p">的可能值上取平均，并以相 应的概率为权值。换言之，要在随机变量 </span>Y <span class="p">遵循的概率分布上取期望值 </span>E<span class="s6">[ln</span>P<span class="s6">(</span>Y<span class="s6">|</span>h<span class="s6">´)]</span><span class="p">。该分 布由完全已知的 </span>X <span class="p">值加上 </span>Z <span class="p">服从的分布来确定。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 5pt;text-indent: 21pt;text-align: justify;">Y <span class="p">遵从的概率分布是什么？一般来说不能知道此分布，因为它是由待估计的</span><span class="s47">θ</span><span class="p">参数确定 的。然而，</span><span class="s6">EM </span><span class="p">算法使用其当前的假设 </span>h <span class="p">代替实际参数</span><span class="s47">θ</span><span class="p">，以估计 </span>Y <span class="p">的分布。现定义一函数 </span>Q<span class="s6">(</span>h<span class="s6">´|</span>h<span class="s6">)</span><span class="p">，它将 </span>E<span class="s6">[ln</span>P<span class="s6">(</span>Y<span class="s6">|</span>h<span class="s6">´)]</span><span class="p">作为 </span>h<span class="s6">´</span><span class="p">的一个函数给出，在</span><span class="s47">θ</span><span class="s6">=</span>h <span class="p">和全部数据 </span>Y <span class="p">的观察到的部分 </span>X <span class="p">的假定之下。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="padding-top: 2pt;padding-left: 152pt;text-indent: 0pt;text-align: left;">Q<span class="s33">(</span>h<span class="s33">&#39;| </span>h<span class="s33">) </span><span class="s38"> </span>E<span class="s33">[ln </span>p<span class="s33">(</span>Y <span class="s33">| </span>h<span class="s33">&#39;) | </span>h<span class="s33">, </span>X <span class="s33">]</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: left;">将 <span class="s21">Q </span>函数写成 <span class="s21">Q</span><span class="s6">(</span><span class="s21">h</span><span class="s6">´|</span><span class="s21">h</span><span class="s6">)</span>是为了表示其定义是在当前假设 <span class="s21">h </span>等于<span class="s47">θ</span>的假定下。在 <span class="s6">EM </span>算法 的一般形式里，它重复以下两个步骤直至收敛。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: left;">步骤 <span class="s6">1</span>：估计（<span class="s6">E</span>）步骤：使用当前假设 <span class="s21">h </span>和观察到的数据 <span class="s21">X </span>来估计 <span class="s21">Y </span>上的概率分布以 计算 <span class="s21">Q</span><span class="s6">(</span><span class="s21">h</span><span class="s6">´|</span><span class="s21">h</span><span class="s6">)</span>。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="padding-top: 2pt;padding-left: 148pt;text-indent: 0pt;text-align: left;">Q<span class="s33">(</span>h<span class="s33">&#39;| </span>h<span class="s33">) </span><span class="s38"> </span>E<span class="s33">[ln </span>P<span class="s33">(</span>Y <span class="s33">| </span>h<span class="s33">&#39;) | </span>h<span class="s33">, </span>X <span class="s33">]</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 26pt;text-indent: 0pt;text-align: left;">步骤 <span class="s6">2</span>：最大化（<span class="s6">M</span>）步骤：将假设 <span class="s21">h </span>替换为使 <span class="s21">Q </span>函数最大化的假设 <span class="s21">h</span><span class="s6">´</span>：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="padding-top: 2pt;padding-left: 24pt;text-indent: 0pt;text-align: center;">h <span class="s38"> </span><span class="s33">argmax </span>Q<span class="s33">(</span>h<span class="s33">&#39;| </span>h<span class="s33">)</span></p><p class="s41" style="padding-left: 24pt;text-indent: 0pt;text-align: center;">h<span class="s42">&#39;</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;"><span class="p">当函数 </span><i>Q </i><span class="p">连续时，</span>EM <span class="p">算法收敛到似然函数 </span><i>P</i>(<i>Y</i>|<i>h</i>´)<span class="p">的一个不动点。若此似然函数有单 个的最大值时，</span>EM <span class="p">算法可以收敛到这个对 </span><i>h</i>´<span class="p">的全局的极大似然估计。否则，它只保证收敛 到一个局部最大值。因此，</span>EM <span class="p">与其他最优化方法有同样的局限性，如第 </span>4 <span class="p">章讨论的梯度下 降，线性搜索和变形梯度等。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">6.12.3 <i>k</i>-<span class="s25">均值算法的推导</span></h3><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;text-align: left;"><span class="p">为说明一般的</span>EM<span class="p">算法，我们用它来推导 </span>6.12.1 <span class="p">节中估计</span><i>k</i><span class="p">个正态分布混合均值的算法。 如上所讨论，</span><i>k</i>-<span class="p">均值算法是为了估计</span><i>k</i><span class="p">个正态分布的均值</span><span class="s47">θ</span>=&lt;<span class="s47">μ</span><span class="s35">1</span>, …, <span class="s47">μ</span><span class="s36">k</span>&gt;<span class="p">。已有的数据为观 察到的</span><i>X</i>={&lt;<i>x</i><span class="s36">i</span>&gt;}<span class="p">，这里的隐藏变量</span><i>Z</i>={&lt;<i>z</i><span class="s36">i</span><span class="s42">1</span>, …, <i>z</i><span class="s36">ik</span>&gt;}<span class="p">表示</span><i>k</i><span class="p">个正态分布中哪一个用于生成</span><i>x</i><span class="s36">i</span><span class="p">。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: left;"><span class="p">要应用</span>EM<span class="p">算法，必须推导出可用于</span><i>k</i>-<span class="p">均值问题的表达式</span><i>Q</i>(<i>h</i>´|<i>h</i>)<span class="p">。首先推导出</span>ln<i>p</i>(<i>Y</i>|<i>h</i>´) <span class="p">的表达式。注意对每个实例</span><i>y</i><span class="s36">i</span>=&lt;<i>x</i><span class="s36">i</span>, <i>z</i><span class="s36">i</span><span class="s42">1</span>, …, <i>z</i><span class="s36">ik</span>&gt;<span class="p">的概率</span><i>p</i>(<i>y</i><span class="s36">i</span>|<i>h</i>´)<span class="p">可被写作：</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="text-indent: 0pt;text-align: right;">p<span class="s33">( </span>y<span class="s52">i</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s33" style="padding-left: 1pt;text-indent: 0pt;text-align: left;">| <i>h</i>&#39;) <span class="s38"> </span><i>p</i>(<i>x</i><span class="s52">i </span>, <i>z</i><span class="s52">i</span><span class="s42">1</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s33" style="text-indent: 0pt;text-align: left;">,..., <i>z</i><span class="s52">ik</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s33" style="padding-left: 1pt;text-indent: 0pt;text-align: left;">| <i>h</i>&#39;) <span class="s38"></span></p><p class="s33" style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;text-align: center;">1</p><p class="s33" style="padding-top: 3pt;padding-left: 11pt;text-indent: 0pt;text-align: center;">2<span class="s119"> </span><span class="s46">2</span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="19" height="0" alt="image" src="机器学习/Image_280.png"/></span></p><p class="s252" style="padding-top: 4pt;padding-left: 4pt;text-indent: 0pt;line-height: 11pt;text-align: center;"><span class="s40"> </span><span class="s42">1</span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="49" height="21" alt="image" src="机器学习/Image_281.png"/></span></p><p class="s249" style="padding-left: 2pt;text-indent: 0pt;line-height: 13pt;text-align: center;">e <span class="s42">2</span><span class="s200"> </span><span class="s209">2</span></p><p class="s44" style="text-indent: 0pt;line-height: 5pt;text-align: left;">k</p><p style="text-indent: 0pt;text-align: left;"/><p class="s116" style="padding-top: 5pt;text-indent: 0pt;text-align: left;"><span class="s44">j </span><span class="s231"></span><span class="s189">1</span></p><p class="s180" style="padding-top: 7pt;text-indent: 0pt;text-align: left;"><span class="s41">z</span>ij<span class="s44"> </span><span class="s42">( </span><span class="s41">x</span>i<span class="s44"> </span><span class="s40"> </span><span class="s200"> </span><span class="s42">&#39; </span>j<span class="s44"> </span><span class="s42">) </span><span class="s209">2</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 26pt;text-indent: 0pt;text-align: left;">要验证此式，必须注意只有一个<span class="s21">z</span><span class="s36">ij</span>值为 <span class="s6">1</span>，其他的为 <span class="s6">0</span>。因此，该式给出了由所选的正</p><p class="s21" style="padding-left: 6pt;text-indent: 0pt;text-align: left;"><span class="p">态分布生成的</span>x<span class="s36">i</span><span class="p">的概率分布。已知了单个实例的分布</span>p<span class="s6">(</span>y<span class="s36">i</span><span class="s6">|</span>h<span class="s6">´)</span><span class="p">，对所有</span>m<span class="p">个实例的概率的对数</span></p><p class="s6" style="padding-left: 6pt;text-indent: 0pt;text-align: left;">ln<i>P</i>(<i>Y</i>|<i>h</i>´)<span class="p">为：</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s41" style="padding-top: 4pt;padding-left: 134pt;text-indent: 0pt;line-height: 6pt;text-align: center;">m</p><p class="s33" style="padding-left: 107pt;text-indent: 0pt;line-height: 18pt;text-align: center;">ln <i>P</i>(<i>Y </i>| <i>h</i>&#39;) <span class="s38"> </span>ln<span class="s124"></span><span class="s135"> </span><i>p</i>( <i>y</i><span class="s52">i</span><span class="s41"> </span>| <i>h</i>&#39;)</p><p class="s41" style="padding-left: 134pt;text-indent: 0pt;line-height: 7pt;text-align: center;">i <span class="s40"></span><span class="s42">1</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s41" style="padding-top: 4pt;padding-left: 115pt;text-indent: 0pt;line-height: 6pt;text-align: center;">m</p><p class="s33" style="padding-left: 134pt;text-indent: 0pt;line-height: 18pt;text-align: center;"><span class="s38"> </span><span class="s124"></span>ln <i>p</i>( <i>y</i><span class="s52">i </span>| <i>h</i>&#39;)</p><p class="s41" style="padding-left: 115pt;text-indent: 0pt;line-height: 7pt;text-align: center;">i <span class="s40"></span><span class="s42">1</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s41" style="padding-top: 3pt;padding-left: 210pt;text-indent: 0pt;line-height: 9pt;text-align: left;">m <span class="s103">⎛ </span><span class="s93">1 1 </span>k <span class="s103">⎞</span></p><p class="s38" style="text-indent: 0pt;line-height: 12pt;text-align: left;">⎜</p><p style="text-indent: 0pt;text-align: left;"/><p class="s42" style="text-indent: 0pt;line-height: 7pt;text-align: left;">2</p><p style="text-indent: 0pt;text-align: left;"/><p class="s33" style="text-indent: 0pt;line-height: 17pt;text-align: right;"><span class="s38"></span> <span class="s39"></span><span class="s94">⎜</span>ln</p><p class="s41" style="text-indent: 0pt;line-height: 11pt;text-align: right;">i <span class="s40"></span><span class="s42">1 </span><span class="s134">⎝</span></p><p class="s33" style="padding-top: 10pt;padding-left: 8pt;text-indent: 0pt;text-align: left;">2<span class="s119"> </span><span class="s46">2</span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="49" height="21" alt="image" src="机器学习/Image_282.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="28" height="1" alt="image" src="机器学习/Image_283.png"/></span></p><p class="s33" style="text-indent: 0pt;line-height: 13pt;text-align: left;">2<span class="s119"></span><span class="s125"> </span><span class="s46">2</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s38" style="text-indent: 0pt;line-height: 12pt;text-align: left;">⎟</p><p style="text-indent: 0pt;text-align: left;"/><p class="s52" style="padding-left: 3pt;text-indent: 0pt;line-height: 16pt;text-align: left;"><span class="s38"> </span><span class="s39"> </span><span class="s30">z</span>ij <span class="s33">(</span><span class="s30">x</span>i <span class="s38"> </span><span class="s119"></span><span class="s33">&#39; </span>j <span class="s33">) </span><span class="s116">⎟</span></p><p class="s41" style="padding-left: 37pt;text-indent: 0pt;line-height: 12pt;text-align: left;">j <span class="s40"></span><span class="s42">1 </span><span class="s134">⎠</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;text-align: justify;"><span class="p">最后，必须在</span>Y<span class="p">所遵从的概率分布，也就是</span>Y<span class="p">的未观察到部分</span>z<span class="s36">ij</span><span class="p">遵从的概率分布上，计算 此</span><span class="s6">ln</span>P<span class="s6">(</span>Y<span class="s6">|</span>h<span class="s6">´)</span><span class="p">的均值。注意上面</span><span class="s6">ln</span>P<span class="s6">(</span>Y<span class="s6">|</span>h<span class="s6">´)</span><span class="p">的表达式为这些</span>z<span class="s36">ij</span><span class="p">的线性函数。一般的，对</span>Z<span class="p">的任意线 性函数</span>f<span class="s6">(</span>z<span class="s6">)</span><span class="p">来说，下面的等式成立：</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 134pt;text-indent: 0pt;text-align: center;">E<span class="s6">[</span>f<span class="s6">(</span>z<span class="s6">)]=</span>f<span class="s6">(</span>E<span class="s6">[</span>z<span class="s6">])</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 26pt;text-indent: 0pt;text-align: left;">根据此等式，可得：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s164" style="padding-top: 2pt;padding-left: 185pt;text-indent: 0pt;line-height: 10pt;text-align: left;"><span class="s116">⎡ </span>m <span class="s38">⎛ </span><span class="s211">1 1 </span>k<span class="s41"> </span><span class="s38">⎞</span><span class="s116">⎤</span></p><p class="s38" style="text-indent: 0pt;line-height: 12pt;text-align: left;">⎜</p><p style="text-indent: 0pt;text-align: left;"/><p class="s42" style="text-indent: 0pt;line-height: 12pt;text-align: left;">2 <span class="s161">⎟</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s30" style="padding-left: 98pt;text-indent: 0pt;line-height: 15pt;text-align: left;">E<span class="s33">[ln </span>P<span class="s33">(</span>Y <span class="s33">| </span>h<span class="s33">&#39;)] </span><span class="s38"> </span>E</p><p class="s134" style="text-indent: 0pt;line-height: 16pt;text-align: left;">⎢<span class="s39"></span><span class="s94">⎜</span><span class="s33">ln</span></p><p class="s38" style="text-indent: 0pt;line-height: 13pt;text-align: left;">⎢<span class="s102">⎣</span> <span class="s41">i</span><span class="s40"></span><span class="s42">1 </span><span class="s134">⎝</span></p><p class="s33" style="padding-top: 10pt;padding-left: 8pt;text-indent: 0pt;text-align: left;">2<span class="s119"> </span><span class="s46">2</span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="49" height="21" alt="image" src="机器学习/Image_284.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="28" height="1" alt="image" src="机器学习/Image_285.png"/></span></p><p class="s33" style="text-indent: 0pt;line-height: 13pt;text-align: left;">2<span class="s119"></span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s38" style="text-indent: 0pt;line-height: 18pt;text-align: right;"> <span class="s178">2</span><span class="s42"> </span><span class="s39"></span></p><p class="s41" style="text-indent: 0pt;line-height: 7pt;text-align: right;">j<span class="s40"></span><span class="s42">1</span></p><p class="s49" style="text-indent: 0pt;text-align: left;">z<span class="s41">ij</span></p><p class="s33" style="text-indent: 0pt;text-align: left;">(<i>x</i><span class="s52">i</span></p><p class="s38" style="padding-left: 1pt;text-indent: 0pt;line-height: 17pt;text-align: left;"> <span class="s119"></span><span class="s33">&#39; </span><span class="s52">j</span></p><p class="s33" style="text-indent: 0pt;line-height: 15pt;text-align: left;">) <span class="s94">⎟</span><span class="s134">⎥</span></p><p class="s134" style="padding-left: 11pt;text-indent: 0pt;line-height: 13pt;text-align: left;">⎠<span class="s38">⎥</span><span class="s102">⎦</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s41" style="padding-top: 3pt;padding-left: 183pt;text-indent: 0pt;line-height: 9pt;text-align: left;">m <span class="s103">⎛ </span><span class="s93">1 1 </span>k <span class="s103">⎞</span></p><p class="s38" style="text-indent: 0pt;line-height: 12pt;text-align: left;">⎜</p><p style="text-indent: 0pt;text-align: left;"/><p class="s42" style="text-indent: 0pt;line-height: 7pt;text-align: left;">2</p><p style="text-indent: 0pt;text-align: left;"/><p class="s33" style="text-indent: 0pt;line-height: 17pt;text-align: right;"><span class="s38"></span> <span class="s39"></span><span class="s94">⎜</span>ln</p><p class="s41" style="text-indent: 0pt;line-height: 11pt;text-align: right;">i <span class="s40"></span><span class="s42">1 </span><span class="s134">⎝</span></p><p class="s33" style="padding-top: 10pt;padding-left: 8pt;text-indent: 0pt;text-align: left;">2<span class="s119"> </span><span class="s46">2</span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="49" height="21" alt="image" src="机器学习/Image_286.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="28" height="1" alt="image" src="机器学习/Image_287.png"/></span></p><p class="s33" style="text-indent: 0pt;line-height: 13pt;text-align: left;">2<span class="s119"></span><span class="s125"> </span><span class="s46">2</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s38" style="text-indent: 0pt;line-height: 12pt;text-align: left;">⎟</p><p style="text-indent: 0pt;text-align: left;"/><p class="s33" style="padding-left: 3pt;text-indent: 0pt;line-height: 16pt;text-align: left;"><span class="s38"> </span><span class="s39"> </span><i>E</i>[<i>z</i><span class="s52">ij </span>](<i>x</i><span class="s52">i </span><span class="s38"> </span><span class="s119"></span>&#39; <span class="s52">j </span>) <span class="s116">⎟</span></p><p class="s41" style="padding-left: 37pt;text-indent: 0pt;line-height: 12pt;text-align: left;">j <span class="s40"></span><span class="s42">1 </span><span class="s134">⎠</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;"><span class="p">概括地说，</span>k<span class="s6">-</span><span class="p">均值问题中函数 </span>Q<span class="s6">(</span>h<span class="s6">´|</span>h<span class="s6">)</span><span class="p">为</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s41" style="padding-top: 3pt;padding-left: 153pt;text-indent: 0pt;line-height: 9pt;text-align: left;">m <span class="s103">⎛ </span><span class="s93">1 1 </span>k <span class="s103">⎞</span></p><p class="s38" style="text-indent: 0pt;line-height: 12pt;text-align: left;">⎜</p><p style="text-indent: 0pt;text-align: left;"/><p class="s42" style="text-indent: 0pt;line-height: 7pt;text-align: left;">2</p><p style="text-indent: 0pt;text-align: left;"/><p class="s33" style="padding-left: 100pt;text-indent: 0pt;line-height: 17pt;text-align: left;"><i>Q</i>(<i>h</i>&#39;| <i>h</i>) <span class="s38"></span> <span class="s39"></span><span class="s94">⎜</span>ln</p><p class="s41" style="text-indent: 0pt;line-height: 11pt;text-align: right;">i <span class="s40"></span><span class="s42">1 </span><span class="s134">⎝</span></p><p class="s33" style="padding-top: 10pt;padding-left: 8pt;text-indent: 0pt;text-align: left;">2<span class="s119"> </span><span class="s46">2</span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="49" height="21" alt="image" src="机器学习/Image_288.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="28" height="1" alt="image" src="机器学习/Image_289.png"/></span></p><p class="s33" style="text-indent: 0pt;line-height: 13pt;text-align: left;">2<span class="s119"></span><span class="s125"> </span><span class="s46">2</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s38" style="text-indent: 0pt;line-height: 12pt;text-align: left;">⎟</p><p style="text-indent: 0pt;text-align: left;"/><p class="s33" style="padding-left: 3pt;text-indent: 0pt;line-height: 16pt;text-align: left;"><span class="s38"> </span><span class="s39"> </span><i>E</i>[<i>z</i><span class="s52">ij </span>](<i>x</i><span class="s52">i </span><span class="s38"> </span><span class="s119"></span>&#39; <span class="s52">j </span>) <span class="s116">⎟</span></p><p class="s41" style="padding-left: 37pt;text-indent: 0pt;line-height: 12pt;text-align: left;">j <span class="s40"></span><span class="s42">1 </span><span class="s134">⎠</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;"><span class="p">其中</span><i>h</i>´=&lt;<span class="s47">μ</span><span class="s35">1</span>´, …, <span class="s47">μ</span><span class="s36">k</span>´&gt;<span class="p">，而</span><i>E</i>[<i>z</i><span class="s36">ij</span>]<span class="p">基于当前假设</span><i>h</i><span class="p">和观察到的数据</span><i>X</i><span class="p">计算得出。如前所讨</span></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">论：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s40" style="padding-top: 4pt;padding-left: 104pt;text-indent: 0pt;line-height: 9pt;text-align: center;"> <span class="s208">1 </span><span class="s42">( </span><span class="s41">x </span> <span class="s200"> </span><span class="s42">) </span><span class="s209">2</span></p><p class="s178" style="padding-left: 102pt;text-indent: 0pt;line-height: 3pt;text-align: center;">2<span class="s200"> </span><span class="s197">2 </span><span class="s44">i j</span></p><p class="s30" style="padding-top: 5pt;text-indent: 0pt;line-height: 13pt;text-align: right;">E<span class="s33">[</span>z<span class="s52">ij </span><span class="s33">] </span><span class="s38"></span></p><p class="s91" style="padding-left: 1pt;text-indent: 0pt;line-height: 12pt;text-align: center;">    e                     </p><p class="s208" style="padding-top: 1pt;padding-left: 5pt;text-indent: 0pt;line-height: 4pt;text-align: center;">   1   </p><p class="s6" style="padding-top: 7pt;padding-left: 50pt;text-indent: 0pt;line-height: 11pt;text-align: left;">(6.29)</p><p class="s41" style="text-indent: 0pt;line-height: 7pt;text-align: left;">k</p><p style="text-indent: 0pt;text-align: left;"/><p class="s106" style="padding-top: 1pt;text-indent: 0pt;text-align: right;"><span class="s41">n </span><span class="s40"></span><span class="s42">1 </span><span class="s250">e</span></p><p class="s40" style="text-indent: 0pt;line-height: 8pt;text-align: left;"> <span class="s42">( </span><span class="s41">x</span><span class="s43">i </span> <span class="s200"></span><span class="s43">n </span><span class="s42">) </span><span class="s209">2</span></p><p class="s42" style="padding-left: 3pt;text-indent: 0pt;line-height: 7pt;text-align: left;">2<span class="s200"> </span><span class="s209">2</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;line-height: 16pt;text-align: left;">因此，<span class="s6">EM</span>算法的第 <span class="s6">1 </span>步（估计步）基于估计的<span class="s21">E</span><span class="s6">[</span><span class="s21">z</span><span class="s36">ij</span><span class="s6">]</span>项定义了<span class="s21">Q</span>函数。第 <span class="s6">2 </span>步（最大化 步）接着寻找使此<span class="s21">Q</span>函数最大的值<span class="s47">μ</span><span class="s35">1</span><span class="s6">´, …, </span><span class="s47">μ</span><span class="s36">k</span><span class="s6">´</span>。在当前例子中：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s38" style="text-indent: 0pt;line-height: 12pt;text-align: left;">⎜</p><p style="text-indent: 0pt;text-align: left;"/><p class="s41" style="padding-top: 3pt;text-indent: 0pt;line-height: 10pt;text-align: right;">m <span class="s103">⎛</span></p><p class="s33" style="padding-left: 70pt;text-indent: 0pt;line-height: 9pt;text-align: left;">argmax <i>Q</i>(<i>h</i>&#39;| <i>h</i>) <span class="s38"></span> argmax<span class="s39"></span><span class="s94">⎜</span>ln</p><p style="text-indent: 0pt;text-align: left;"><span><img width="49" height="21" alt="image" src="机器学习/Image_290.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="28" height="1" alt="image" src="机器学习/Image_291.png"/></span></p><p class="s33" style="padding-top: 5pt;padding-left: 15pt;text-indent: 0pt;line-height: 20pt;text-align: left;">1 <span class="s114"></span><span class="s38"> </span>1</p><p class="s42" style="padding-left: 2pt;text-indent: 0pt;line-height: 2pt;text-align: center;">2</p><p class="s42" style="text-indent: 0pt;line-height: 7pt;text-align: left;">2</p><p style="text-indent: 0pt;text-align: left;"/><p class="s41" style="padding-top: 3pt;padding-left: 11pt;text-indent: 0pt;line-height: 10pt;text-align: left;">k <span class="s103">⎞</span></p><p class="s38" style="text-indent: 0pt;line-height: 12pt;text-align: left;">⎟</p><p style="text-indent: 0pt;text-align: left;"/><p class="s33" style="text-indent: 0pt;line-height: 9pt;text-align: left;"><span class="s178">2 </span><span class="s39"> </span><i>E</i>[<i>z</i><span class="s52">ij </span>](<i>x</i><span class="s52">i </span><span class="s38"> </span><span class="s119"></span>&#39; <span class="s52">j </span>) <span class="s116">⎟</span></p><p class="s41" style="padding-top: 1pt;padding-left: 87pt;text-indent: 0pt;text-align: left;">h<span class="s42">&#39; </span>h<span class="s42">&#39;</span></p><p class="s41" style="padding-left: 16pt;text-indent: 0pt;line-height: 15pt;text-align: left;">i <span class="s40"></span><span class="s42">1 </span><span class="s134">⎝</span></p><p class="s33" style="padding-left: 19pt;text-indent: 0pt;line-height: 13pt;text-align: left;">2<span class="s119"></span></p><p class="s84" style="padding-left: 19pt;text-indent: 0pt;line-height: 15pt;text-align: left;">2<span class="s119"> </span><span class="s41">j </span><span class="s40"></span><span class="s42">1 </span><span class="s134">⎠</span></p><p class="s41" style="padding-top: 3pt;padding-left: 24pt;text-indent: 0pt;line-height: 7pt;text-align: center;">m k</p><p class="s42" style="text-indent: 0pt;line-height: 7pt;text-align: left;">2</p><p style="text-indent: 0pt;text-align: left;"/><p class="s33" style="padding-left: 151pt;text-indent: 0pt;line-height: 16pt;text-align: left;"><span class="s38"> </span>arg min <span class="s39"></span><span class="s121"> </span><i>E</i>[<i>z</i><span class="s52">ij</span><span class="s41"> </span>](<i>x</i><span class="s52">i</span><span class="s41"> </span><span class="s38"> </span><span class="s119"></span>&#39; <span class="s52">j</span><span class="s41"> </span>)</p><p style="padding-left: 41pt;text-indent: 0pt;line-height: 14pt;text-align: left;">（<span class="s6">6.30</span>）</p><p class="s42" style="text-indent: 0pt;line-height: 9pt;text-align: right;"><i>h</i>&#39; <i>i</i><span class="s40"></span>1</p><p class="s41" style="padding-left: 3pt;text-indent: 0pt;text-align: left;">j<span class="s40"></span><span class="s42">1</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;line-height: 16pt;text-align: left;">因此，这里的极大似然假设使平方误差的加权和最小化了，其中每个实例<span class="s21">x</span><span class="s36">i</span>对误差的贡 献<span class="s47">μ</span><span class="s36">j</span><span class="s6">´</span>权重为<span class="s21">E</span><span class="s6">[</span><span class="s21">z</span><span class="s36">ij</span><span class="s6">]</span>。由等式 <span class="s6">6.30 </span>给出的量是通过将每个<span class="s47">μ</span><span class="s36">j</span><span class="s6">´</span>设为加权样本均值来最小化。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="82" height="1" alt="image" src="机器学习/Image_292.png"/></span></p><p class="s41" style="text-indent: 0pt;line-height: 7pt;text-align: left;">m</p><p style="text-indent: 0pt;text-align: left;"/><p class="s41" style="text-indent: 0pt;line-height: 7pt;text-align: left;">m</p><p style="text-indent: 0pt;text-align: left;"/><p class="s41" style="text-indent: 0pt;line-height: 7pt;text-align: left;">j</p><p style="text-indent: 0pt;text-align: left;"/><p class="s33" style="padding-top: 3pt;text-indent: 0pt;line-height: 24pt;text-align: right;"><span class="s251"></span><span class="s125">   </span><span class="s38"></span> <span class="s39"></span><span class="s176">i</span><span class="s41"> </span><span class="s40"></span><span class="s42">1 </span><i>E</i>[<i>z</i><span class="s52">ij</span><span class="s41"> </span>]<i>x</i><span class="s52">i</span></p><p class="s30" style="text-indent: 0pt;line-height: 19pt;text-align: right;"><span class="s39"></span><span class="s176">i</span><span class="s41"> </span><span class="s40"></span><span class="s42">1 </span>E<span class="s33">[</span>z<span class="s52">ij</span><span class="s41"> </span><span class="s33">]</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 54pt;text-indent: 0pt;text-align: left;">（<span class="s6">6.31</span>）</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 26pt;text-indent: 0pt;text-align: left;">式 <span class="s6">6.29 </span>和式 <span class="s6">6.31 </span>定义了 <span class="s6">6.12.1 </span>节中定义的 <span class="s21">k</span><span class="s6">-</span>均值算法中的两个步骤。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">6.13 <span class="s17">小结和补充读物</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">本章的要点包括：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s71" style="padding-top: 3pt;padding-left: 48pt;text-indent: -21pt;line-height: 111%;text-align: justify;">n <span class="p">概率学习方法利用（并且要求）关于不同假设的先验概率以及在给定假设时观察到 不同数据的概率的知识。贝叶斯方法则提供了概率学习方法的基础。贝叶斯方法还 可基于这些先验和数据观察假定，赋予每个候选假设一个后验概率。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 3pt;padding-left: 48pt;text-indent: -21pt;line-height: 107%;text-align: left;"><span class="s71">n </span>贝叶斯方法可用于确定在给定数据时最可能的假设——极大后验概率（<span class="s6">MAP</span>）假 设。它比其他的假设更可能成为最优假设。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s71" style="padding-top: 3pt;padding-left: 48pt;text-indent: -21pt;line-height: 108%;text-align: left;">n <span class="p">贝叶斯最优分类器将所有假设的预测结合起来，并以其后验概率为权重，以计算对 新实例的最可能分类。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 3pt;padding-left: 48pt;text-indent: -21pt;line-height: 109%;text-align: left;"><span class="s71">n </span>朴素贝叶斯分类器是在许多实际应用问题中很有用的一种贝叶斯学习方法。它被称 为朴素的（<span class="s6">naive</span>）是因为其作的简化假定：属性值在给定实例的分类时条件独立。 当该假定成立时，朴素贝叶斯分类器可输出 <span class="s6">MAP </span>分类。即使此假定不成立，在学 习分类文本的情况下，朴素贝叶斯分类通常也是很有效的。贝叶斯置信网对于属性 的子集上的一组条件独立性假定提供了更强的表达能力。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s71" style="padding-top: 3pt;padding-left: 48pt;text-indent: -21pt;line-height: 111%;text-align: left;">n <span class="p">贝叶斯推理框架可对其他不直接应用贝叶斯公式的学习方法的分析提供理论基础。 例如，在特定条件下学习一个对应于极大似然假设的实值目标函数时，它可使误差 平方最小化。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s71" style="padding-top: 3pt;padding-left: 48pt;text-indent: -21pt;line-height: 108%;text-align: left;">n <span class="p">最小描述长度准则建议选取这样的假设，它使假设的描述长度和给定假设下数据的 描述长度的和最小化。贝叶斯公式和信息论中的基本结论可提供此准则的根据。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 3pt;padding-left: 48pt;text-indent: -21pt;line-height: 110%;text-align: justify;"><span class="s71">n </span>在许多实际的学习问题中，某些相关的实例变量是不可观察到的。<span class="s6">EM </span>算法提供了 一个很通用的方法，当存在隐藏变量时进行学习。该算法开始于一个任意的初始假 设。然后迭代地计算隐藏变量的期望值（假定当前假设是正确的），再重新计算极 大似然假设（假定隐藏变量等于第 <span class="s6">1 </span>步中得到的期望值）。这一过程收敛到一个局 部的极大似然假设，以及隐藏变量的估计值。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 27pt;text-indent: 0pt;text-align: left;">在概率和统计方面有许多很好的介绍性文章，如 <span class="s6">Casella &amp; Berger(1990)</span>。几本快速参考</p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 107%;text-align: justify;">类书籍（如 <span class="s6">Maisel 1971; Speigel 1991)</span>也对机器学习相关的概率和统计理论提供了优秀的阐 述。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 27pt;text-indent: 0pt;text-align: left;">对贝叶斯分类器和最小平方误差分类器的基本介绍由 <span class="s6">Duda &amp; Hart(1973)</span>给出，<span class="s6">Domigos</span></p><p class="s6" style="padding-top: 1pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: justify;">&amp; Pazzani<span class="p">（</span>1996<span class="p">）分析了在怎样的条件下朴素贝叶斯方法可输出最优的分类，即使其独立 性假定不成立时（关键在于在怎样的条件下即使相关联的后验概率估计不正确也可输出最优 分类）。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-top: 1pt;padding-left: 26pt;text-indent: 0pt;text-align: left;">Cestnik(1990)<span class="p">讨论了使用 </span><i>m</i>-<span class="p">估计来估计概率。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: left;">将不同贝叶斯方法与决策树等其他算法进行比较的实验结果可在 <span class="s6">Michie et al.</span>（<span class="s6">1994</span>） 中找到。<span class="s6">Chauvin &amp; Rumelhart(1995)</span>提供了基于反向传播算法的神经网络的贝叶斯分析。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: left;">对最小描述长度准则的讨论可参考 <span class="s6">Rissanen(1983, 1989)</span>。<span class="s6">Quinlan &amp; Rivest</span>（<span class="s6">1989</span>）描 述了其使用以避免决策树的过度拟合。</p><p style="padding-left: 27pt;text-indent: 0pt;text-align: left;">习题</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;"><span class="h4">6.1 </span>再次考虑 <span class="s6">6.2.1 </span>节中应用贝叶斯规则的例子。假定医生决定对该病人做第二次化验测 试，而且化验结果也为正。根据这两次测试，<span class="s21">cancer </span>和<span class="s10"></span><span class="s21">cancer </span>的后验概率是多少？假定两 个测试是相互独立的。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: left;"><b>6.2 </b><span class="p">在 </span>6.2.1 <span class="p">节的例子中，为计算癌症的后验概率，通过将 </span><i>P</i>(+|<i>cancer</i>)<span class="p">·</span><i>P</i>(<i>cancer</i>)<span class="p">和 </span><i>P</i>(+|<span class="s10"></span><i>cancer</i>)<span class="p">·</span><i>P</i>(<span class="s10"></span><i>cancer</i>)<span class="p">归一化使它们的和为 </span>1<span class="p">。使用贝叶斯公式和全概率公式（见表 </span>6-1<span class="p">） 证明该方法是正确的（即这样的归一化可以得到 </span><i>P</i>(<i>cancer</i>|+)<span class="p">的正确值）。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: left;"><span class="h4">6.3 </span>考虑下面的概率学习算法 <span class="s21">FindG</span>，它输出一个极大一般化的一致假设（例如，变型 空间的某个极大一般成员）。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 26pt;text-indent: 0pt;line-height: 190%;text-align: left;">(a)<span class="p">给出 </span><i>P</i>(<i>h</i>)<span class="p">和 </span><i>P</i>(<i>D</i>|<i>h</i>)<span class="p">的分布，以使 </span><i>FindG </i><span class="p">保证输出 </span>MAP <span class="p">假设。 </span>(b)<span class="p">给出 </span><i>P</i>(<i>h</i>)<span class="p">和 </span><i>P</i>(<i>D</i>|<i>h</i>)<span class="p">的分布，以使 </span><i>FindG </i><span class="p">不能保证输出 </span>MAP <span class="p">假设。</span></p><p class="s6" style="padding-top: 2pt;padding-left: 26pt;text-indent: 0pt;text-align: left;">(c)<span class="p">给出 </span><i>P</i>(<i>h</i>)<span class="p">和 </span><i>P</i>(<i>D</i>|<i>h</i>)<span class="p">的分布，以使 </span><i>FindG </i><span class="p">保证输出 </span>ML <span class="p">假设但不是 </span>MAP <span class="p">假设。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 5pt;text-indent: 20pt;text-align: left;"><b>6.4 </b><span class="p">在 </span>6.3 <span class="p">节中的概念学习分析中，假定了实例序列</span>&lt;<i>x</i><span class="s35">1</span>…<i>x</i><span class="s36">m</span>&gt;<span class="p">是固定的。因此，在推导 </span><i>P</i>(<i>D</i>|<i>h</i>)<span class="p">表达式时只需考虑考察到目标值序列</span>&lt;<i>d</i><span class="s35">1</span>…<i>d</i><span class="s36">m</span>&gt;<span class="p">的概率。考虑更一般的情况，即实例顺 序不固定，但是它们是从实例空间</span><i>X</i><span class="p">上定义的某概率分布上独立抽取的。数据</span><i>D</i><span class="p">现在必须被 描述为一组序偶</span>{&lt;<i>x</i><span class="s36">i</span>, <i>d</i><span class="s36">i</span>&gt;}<span class="p">，而</span><i>P</i>(<i>D</i>|<i>h</i>)<span class="p">必须能反映遇到特定实例</span><i>x</i><span class="s36">i</span><span class="p">的概率，以及目标值</span><i>d</i><span class="s36">i</span><span class="p">的概率。 证明在此一般框架中式 </span>6.5 <span class="p">仍然成立。提示：参考 </span>6.5 <span class="p">节中的分析。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 27pt;text-indent: 0pt;text-align: left;"><span class="h4">6.5 </span>考虑将最小描述长度准则应用到一个假设空间<span class="s21">H</span>，它包含至多<span class="s21">n</span>个布尔属性的合取</p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 0pt;text-align: justify;">（如：<span class="s21">Sunny</span>∧<span class="s21">Warm</span>）。假定每个假设的编码为简单地将假设中出现的属性列举出来，其中 为了编码任意一个<span class="s21">n</span>布尔属性所需位数为<span class="s6">log</span><span class="s35">2</span><span class="s21">n</span>。设想给定假设下样例编码方式为：若样例与 假设一致编码需 <span class="s6">0 </span>位，否则用<span class="s6">log</span><span class="s35">2</span><span class="s21">m</span>位（表示<span class="s21">m</span>个样例中哪些被误分类了——正确的分类可 由该假设预测的值的否定得到）。</p><p class="s6" style="padding-left: 26pt;text-indent: 0pt;line-height: 28pt;text-align: left;">(a)<span class="p">写出要被最小化的量的表达式，按照最小描述长度准则。 </span>(b)<span class="p">是否可能建立一组训练数据，使存在一个一致假设，但 </span>MDL <span class="p">选择了一个较不一致的</span></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 0pt;text-align: justify;">假设。如果是这样，给出这样的训练集；否则解释为什么。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 26pt;text-indent: 0pt;text-align: left;">(c)<span class="p">给出 </span><i>P</i>(<i>h</i>)<span class="p">和 </span><i>P</i>(<i>D</i>|<i>h</i>)<span class="p">的概率分布以使上面的 </span>MDL <span class="p">算法输出 </span>MAP <span class="p">假设。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: left;"><span class="h4">6.6 </span>考虑节 <span class="s6">6.9.1 </span>中 <span class="s21">PlayTennis </span>问题的朴素贝叶斯分类器，用贝叶斯置信网画出其中使用 的条件独立性假定。给出与结点 <span class="s21">Wind </span>相关联的条件概率表。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s8" style="padding-left: 127pt;text-indent: 0pt;line-height: 24pt;text-align: left;">第<span class="h1">7</span>章 计算学习理论</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 111%;text-align: left;">本章理论地刻画了若干类型的机器学习问题中的困难，和若干类型的机器学习算法的能 力。该理论致力于回答如下的问题：“在什么样的条件下成功的学习是可能的？”以及“在 什么条件下一特定的学习算法可保证成功运行？”为了分析学习算法，这里考虑了两种框架。 在可能近似正确（<span class="s6">PAC</span>）框架下，我们确定了若干假设类别，判断它们能否从多项式数量的 训练样例中学习得到；我们还定义了一个对假设空间的自然度量，由它可以界定归纳学习所 需的训练样例数目。在出错界限（<span class="s6">Mistake bound</span>）框架下，我们考查了一个学习器在确定正 确假设前可能产生的训练错误数量。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">7.1 <span class="s17">介绍</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 113%;text-align: justify;">在研究机器学习过程中，很自然地想知道学习器（机器的或非机器的）应遵循什么样的 规则。是否可能独立于学习算法确定学习问题中固有的难度？能否知道为保证成功的学习有 多少训练是必要的或充足的？如果学习器被允许向施教者提出查询，而不是观察训练集的随 机样本，会对所需样例数目有怎样的影响？能否刻画出学习器在学到目标函数前会有多少次 出错？能否刻画出一类学习问题中固有的计算复杂度？</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 113%;text-align: justify;">虽然对所有这些问题的一般回答还未知，但是不完整的学习计算理论已经开始出现。本 章阐述了该理论中的一些关键结论，并提供了在特定问题下一些问题的答案。这里我们着重 讨论只给定目标函数的训练样例和候选假设空间的条件下，对该未知的目标函数的归纳学习 问题。在这样的框架下，主要要解决的问题如：需要多少训练样例才足以成功地学习到目标 函数，以及学习器在达到目标前会有多少次出错。如后面将看到，有可能对这些问题提出定 量的上下界，这基于学习问题的如下属性。</p><p class="s10" style="padding-top: 5pt;padding-left: 28pt;text-indent: 0pt;text-align: left;"> <span class="p">学习器所考虑的假设空间的大小和复杂度</span></p><p class="s10" style="padding-top: 1pt;padding-left: 28pt;text-indent: 0pt;text-align: left;"> <span class="p">目标概念须近似到怎样的精度</span></p><p class="s10" style="padding-top: 1pt;padding-left: 28pt;text-indent: 0pt;text-align: left;"> <span class="p">学习器输出成功的假设的可能性</span></p><p class="s10" style="padding-top: 1pt;padding-left: 27pt;text-indent: 1pt;text-align: left;"> <span class="p">训练样例提供给学习器的方式</span></p><p style="padding-top: 8pt;padding-left: 6pt;text-indent: 21pt;line-height: 113%;text-align: justify;">本章的大部分将不会着重于单独的学习算法，而是在较宽广的学习算法类别中刻画所考 虑的假设空间，以及训练样例的提供方式等。我们的目标是为了回答以下的问题：</p><p style="padding-top: 5pt;padding-left: 49pt;text-indent: -21pt;line-height: 107%;text-align: left;"><span class="s10"> </span>样本复杂度（<span class="s6">Sample complexity</span>）。学习器要收敛到成功假设（以较高的概率）， 需要多少训练样例？</p><p style="padding-top: 1pt;padding-left: 49pt;text-indent: -21pt;line-height: 107%;text-align: left;"><span class="s10"> </span>计算复杂度<span class="s6">(Computational complexity)</span>。学习器要收敛到成功假设（以较高的概 率）需要多大的计算量？</p><p style="padding-top: 1pt;padding-left: 49pt;text-indent: -21pt;line-height: 107%;text-align: left;"><span class="s10"> </span>出错界限（<span class="s6">Mistake bound</span>）。在成功收敛到一个假设前，学习器对训练样例的 误分类有多少次？</p><p style="padding-top: 8pt;padding-left: 6pt;text-indent: 21pt;line-height: 113%;text-align: justify;">注意为了解决这些问题需要许多特殊的条件设定。例如，有许多方法来指定对于学习器 什么是“成功的”。一种可能的判断方法是：学习器是否输出等于目标概念的假设。另一种 方法是只要求输出的假设与目标概念在多数时间内意见一致，或是学习器通常会输出这样的</p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 113%;text-align: justify;">假设。相似地，还必须指定学习器是如何获得训练样例的。可以指定训练样例由一个施教者 给出，或由学习器自己实验来获得，或按照某过程随机地生成而不受学习器的控制。可以预 料，对上述问题的回答依赖于我们所考虑的特定框架或学习模型。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 110%;text-align: justify;">本章的后续如下安排。<span class="s6">7.2 </span>节介绍可能近似正确（<span class="s6">PAC</span>）学习框架。<span class="s6">7.3 </span>节在此 <span class="s6">PAC </span>框 架下分析了几种学习算法的样本复杂度和计算复杂度。<span class="s6">7.4 </span>节介绍了假设空间复杂度的一个 重要度量标准，称为 <span class="s6">VC-</span>维，并且将 <span class="s6">PAC </span>分析扩展到假设空间无限的情况。<span class="s6">7.5 </span>节介绍了出 错界限模型，并提供了前面章节中几个学习算法出错数量的界限。最后，介绍了加权多数算 法，它是一个结合多个学习算法来产生合并的预测的实用算法，还介绍了该算法的理论出错 界限。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 6pt;text-indent: 0pt;text-align: justify;">7.2 <span class="s17">可能学习近似正确假设</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 110%;text-align: left;">本节我们考虑学习问题的一种特殊框架，称为可能近似正确 <span class="s6">(probably approximately correct, PAC)</span>学习模型。首先我们指定 <span class="s6">PAC </span>学习模型适用的问题，然后分析在此 <span class="s6">PAC </span>模型 下学习不同类别的目标函数需要多少训练样例和多大的计算量。为简明起见，这里的讨论将 限制在学习布尔值概念，且训练数据是无噪声的。然而，许多结论可扩展到更一般的情形， 如学习实值目标函数（比如 <span class="s6">Natarajan 1991 </span>），或从某种类型的有噪声数据中进行学习（例 如，见 <span class="s6">Laird 1988; Kearns &amp; Vazirani 1994</span>）。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 6pt;text-indent: 0pt;text-align: justify;">7.2.1 <span class="s25">问题框架</span></h3><p class="s21" style="padding-top: 10pt;padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;"><span class="p">如前面的章节，令 </span>X <span class="p">代表所有实例的集合，目标函数在其上定义。例如，</span>X <span class="p">可表示所有 人的集合，每个人描述为属性 </span>age<span class="p">（</span>young <span class="p">或 </span>old<span class="p">）和 </span>height <span class="s6">(</span>short <span class="p">或 </span>long<span class="s6">)</span><span class="p">。令 </span>C <span class="p">代表学习 器要学习的目标概念集合。</span>C <span class="p">中每个目标概念 </span>c <span class="p">对应于 </span>X <span class="p">的某个子集，或一个等效的布尔函 数 </span>c<span class="p">：</span>X<span class="p">→</span><span class="s6">{0,1}</span><span class="p">。例如，</span>C <span class="p">中一个目标函数 </span>c <span class="p">为概念：“是滑雪者的人”。若 </span>x <span class="p">是 </span>c <span class="p">的正例， 则 </span>c<span class="s6">(</span>x<span class="s6">)=1</span><span class="p">；若 </span>x <span class="p">为反例，则 </span>c<span class="s6">(</span>x<span class="s6">)=0</span><span class="p">。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;text-align: justify;">假定实例按照某概率分布 <span class="s68">D </span>从 <span class="s21">X </span>中随机产生。例如 <span class="s68">D </span>可为从某体育用品商店走出来的 人这样一个实例分布。一般地，<span class="s68">D </span>可为任何分布，而且它对学习器是未知的。对于 <span class="s68">D </span>所要求 的是它的稳定性，即该分布不会随时间变化。训练样例的生成按照 <span class="s68">D </span>分布随机抽取实例 <span class="s21">x</span>， 然后 <span class="s21">x </span>及其目标值 <span class="s21">c</span><span class="s6">(</span><span class="s21">x</span><span class="s6">)</span>被提供给学习器。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">学习器 <span class="s21">L </span>在学习目标概念时考虑可能假设的集合 <span class="s21">H</span>。例如，<span class="s21">H </span>可为所有能由属性 <span class="s21">age </span>和 <span class="s21">height </span>的合取表示的假设集合。在观察到了一系列关于目标概念 <span class="s21">c </span>的的训练样例后，<span class="s21">L </span>必须 从 <span class="s21">H </span>中输出某假设 <span class="s21">h</span>，它是对 <span class="s21">c </span>的估计。为公平起见，我们通过 <span class="s21">h </span>在从 <span class="s21">X </span>中抽取的新实例上 的性能来评估 <span class="s21">L </span>是否成功。抽取过程按照分布 <span class="s68">D</span>，即与产生训练数据相同的概率分布。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">在此框架下，我们感兴趣的是刻画不同学习器 <span class="s21">L </span>的性能，这些学习器使用不同假设空 间 <span class="s21">H</span>，并学习不同类别的 <span class="s21">C </span>中的目标概念。由于我们要求 <span class="s21">L </span>足够一般，以从 <span class="s21">C </span>中学到任何 目标概念，所以不论训练样例的分布如何，我们经常会对 <span class="s21">C </span>中所有可能的目标概念和所有 可能的实例分布 <span class="s68">D </span>进行最差情况的分析。</p><h3 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">7.2.2 <span class="s25">假设的错误率</span></h3><p style="padding-top: 10pt;padding-left: 6pt;text-indent: 21pt;line-height: 107%;text-align: left;">为了描述学习器输出的假设 <span class="s21">h </span>对真实目标概念的逼近程度，首先要定义假设 <span class="s21">h </span>对应于目 标概念 <span class="s21">c </span>和实例分布 <span class="s68">D </span>的真实错误率（<span class="s6">true error</span>）。非形式的描述是：<span class="s21">h </span>的真实错误率为应用</p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 15pt;text-align: left;"><span class="s21">h </span>到将来按分布 <span class="s68">D </span>抽取的实例时的期望的错误率。实际上第 <span class="s6">5 </span>章已经定义了 <span class="s21">h </span>的真实错误率。</p><p style="padding-left: 6pt;text-indent: 0pt;text-align: left;">为方便起见，这里重述一下该定义，使用 <span class="s21">c </span>表示布尔目标函数。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 48pt;text-indent: -21pt;text-align: left;">定义： 假设 <span class="s21">h </span>关于目标概念 <span class="s21">c </span>和分布 <span class="s68">D </span>的真实错误率<span class="s6">(true error)</span>为 <span class="s21">h </span>误分类按照 <span class="s68">D </span>随 机抽取的实例的概率。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="padding-top: 3pt;text-indent: 0pt;text-align: right;">error<span class="s171">D</span></p><p class="s33" style="padding-top: 2pt;text-indent: 0pt;line-height: 13pt;text-align: left;">(<i>h</i>) <span class="s38"> </span>Pr[<i>c</i>(<i>x</i>) <span class="s38"> </span><i>h</i>(<i>x</i>)]</p><p class="s41" style="padding-left: 26pt;text-indent: 0pt;line-height: 7pt;text-align: left;">x<span class="s40"></span><span class="s172">D</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 27pt;text-indent: 0pt;line-height: 14pt;text-align: left;">这里符号 <span class="s33">Pr </span>代表在实例分布 <span class="s68">D </span>上计算概率。</p><p class="s41" style="padding-left: 71pt;text-indent: 0pt;line-height: 7pt;text-align: left;">x<span class="s40"></span><span class="s172">D</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: left;">图 <span class="s6">7-1 </span>图示了该错误率的定义。概念 <span class="s21">c </span>和 <span class="s21">h </span>被表示为 <span class="s21">X </span>中标为正例的实例集合。<span class="s21">h </span>对应 于 <span class="s21">c </span>的错误率为，随机选取的实例落入 <span class="s21">h </span>和 <span class="s21">c </span>不一致区间（即它们的集合差）的概率。注意， 错误率定义在整个实例分布之上，而不只是训练样例之上，因为它是在实际应用此假设 <span class="s21">h </span>到后续实例上时会遇到的真实错误率。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 13pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="547" height="1" alt="image" src="机器学习/Image_293.png"/></span></p><p class="s48" style="padding-left: 15pt;text-indent: 0pt;text-align: left;">插图——原书页码： <span class="s21">205</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">Instance space: <span class="p">实例空间</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 27pt;text-indent: 0pt;text-align: left;">Where c and h disagree: c <span class="p">和 </span>h <span class="p">不一致的区间</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 14pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="531" height="1" alt="image" src="机器学习/Image_294.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 134pt;text-indent: 0pt;text-align: left;">图 <span class="h4">7-1 </span>关于目标概念 <span class="s7">c </span>假设 <span class="s7">h </span>的错误率</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-left: 58pt;text-indent: 0pt;text-align: left;">关于 <span class="s56">c </span>的 <span class="s56">h </span>的错误率为一个随机抽取的实例落入 <span class="s56">h </span>和 <span class="s56">c </span>对它的分类不一致的区间的概率。<span class="s16">+</span>和</p><p class="s14" style="padding-top: 3pt;padding-left: 37pt;text-indent: 0pt;line-height: 125%;text-align: left;"><span class="s16">-</span>点表示正反训练例。注意 <span class="s56">h </span>关于 <span class="s56">c </span>有一个非零的错误率，尽管迄今为止 <span class="s56">h </span>和 <span class="s56">c </span>在所有 <span class="s16">5 </span>个训练样 例上都一致。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;text-align: left;">注意，此错误率强烈地依赖于未知的概率分布 <span class="s68">D</span>。例如，如果 <span class="s68">D </span>是一个均匀的概率分布， 它对 <span class="s21">X </span>中每个实例都赋予相同的概率，那么图 <span class="s6">7-1 </span>中假设的错误率将为 <span class="s21">h </span>和 <span class="s21">c </span>不一致的空间 在全部实例空间中的比例。然而，如果 <span class="s68">D </span>恰好把 <span class="s21">h </span>和 <span class="s21">c </span>不一致区间中的实例赋予了很高的概 率，相同的 <span class="s21">h </span>和 <span class="s21">c </span>将造成更高的错误率。极端情况下若 <span class="s68">D </span>对满足 <span class="s21">h</span><span class="s6">(</span><span class="s21">x</span><span class="s6">)=</span><span class="s21">c</span><span class="s6">(</span><span class="s21">x</span><span class="s6">)</span>的所有实例赋予零 概率，图 <span class="s6">7-1 </span>中 <span class="s21">h </span>的错误率将为 <span class="s6">1</span>，而不论 <span class="s21">h </span>和 <span class="s21">c </span>在多少实例上分类一致。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;text-align: justify;">最后，注意<span class="s21">h</span>对应于<span class="s21">c</span>的错误率不能直接由学习器观察到。<span class="s21">L</span>只能观察到在训练样例上<span class="s21">h </span>的性能，它也只能在此基础上选择其假设输出。我们将使用术语训练错误率<span class="s6">(training error) </span>来指代训练样例中被<span class="s21">h</span>误分类的样例所占比例，以区分上面定义的真实错误率。这里关于学 习复杂度的分析多数围绕着这样的问题：“ <span class="s21">h</span>的观察到的训练错误率对真实错误率<span class="s21">error</span><span class="s170">D</span><span class="s6">(</span><span class="s21">h</span><span class="s6">) </span>产生不正确估计的可能性有多大？”</p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">注意此问题与第 <span class="s6">5 </span>章考虑的问题之间的密切联系。回忆在第 <span class="s6">5 </span>章中定义了 <span class="s21">h </span>关于样例集 合 <span class="s21">S </span>的样本错误率 <span class="s6">(sample error)</span>，为样例集合 <span class="s21">S </span>中被 <span class="s21">h </span>误分类的样例所占比例。上面定义 的训练错误率就是当 <span class="s21">S </span>为训练样例集合时的样本错误率。在第 <span class="s6">5 </span>章中，我们在数据样本 <span class="s21">S </span>独立于 <span class="s21">h </span>抽取的前提下，确定样本错误率对估计真实错误率产生误导的概率。然而当 <span class="s21">S </span>是训 练数据集合时，学到的假设非常依赖于 <span class="s21">S</span>。因此，本章将给出这一重要的特殊情形下的分析。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">7.2.3 PAC <span class="s25">可学习性</span></h3><p style="padding-top: 10pt;padding-left: 6pt;text-indent: 21pt;line-height: 113%;text-align: justify;">我们的目标是刻画出这样的目标概念，它们能够从合理数量的随机抽取训练样例中通过 合理的计算量可靠地学习到。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 16pt;text-align: justify;">对于可学习性怎样进行表述？一种可能的选择是描述为了学习到一个使<span class="s21">error</span><span class="s170">D</span><span class="s6">(</span><span class="s21">h</span><span class="s6">)=0 </span>的 假设<span class="s21">h</span>，所需的训练样例数。不幸的是，这样的选择是不可行的，原因有两个：首先，除非 对<span class="s21">X</span>中每个可能的实例都提供训练样例（一个不实际的假定），否则会有多个假设与训练样 例一致，而且学习器无法保证选择到目标概念。其次，由于训练样例是随机抽取的，总有一 个非 <span class="s6">0 </span>的概率使得学习器面临的训练样例有误导性。（例如，虽然我们经常可见到不同身高</p><p style="padding-left: 27pt;text-indent: -21pt;text-align: left;">的滑雪者，但在某一天中总存在这样的机会，所有训练样例都刚好是 <span class="s6">2 </span>米高。）</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 111%;text-align: left;">为解决这两个困难，我们用两种方法弱化了对学习器的要求。首先，我们不要求学习器 输出零错误率假设，而只要求其错误率被限定在某常数<span class="s47">ε</span>的范围内，<span class="s47">ε</span>可为任意小。第二， 不再要求学习器对所有的随机抽取样例序列都能成功，只要求其失败的概率被限定在某个常 数<span class="s47">δ</span>的范围内，<span class="s47">δ</span>也可取任意小。简而言之，我们只要求学习器可能学习到一个近似正确的 假设，因此得到了该术语“可能近似正确学习”，或 <span class="s6">PAC </span>学习。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;text-align: right;">考虑某一目标概念类别<span class="s21">C</span>和使用假设空间<span class="s21">H</span>的学习器<span class="s21">L</span>。非形式地，对<span class="s21">C</span>中任意目标概念 <span class="s21">c</span>，若在观察到合理数目的训练样例并执行了合理的计算量后，<span class="s21">L</span>以概率<span class="s6">(1-</span><span class="s47">δ</span><span class="s6">)</span>输出一个 <span class="s21">error</span><span class="s170">D</span><span class="s6">(</span><span class="s21">h</span><span class="s6">)&lt;</span><span class="s47">ε</span>的假设<span class="s21">h</span>，则我们称概念类别<span class="s21">C</span>是使用<span class="s21">H</span>的<span class="s21">L</span>可<span class="s6">PAC</span>学习的。更精确的定义如下：</p><p class="s185" style="text-indent: 0pt;line-height: 6pt;text-align: left;">D</p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-top: 10pt;padding-left: 47pt;text-indent: -21pt;text-align: justify;">定义： 考虑一概念类别<span class="s21">C</span>定义在长度为<span class="s21">n</span>的实例集合<span class="s21">X</span>上，学习器<span class="s21">L</span>使用假设空间<span class="s21">H</span>。 当对所有<span class="s21">c</span>∈<span class="s21">C</span>，<span class="s21">X</span>上的分布<span class="s68">D</span>，<span class="s47">ε</span>满足 <span class="s6">0&lt;</span><span class="s47">ε</span><span class="s6">&lt;1/2</span>，以及<span class="s47">δ</span>满足 <span class="s6">0&lt;</span><span class="s47">δ</span><span class="s6">&lt;1/2</span>，学习器<span class="s21">L </span>将以至少 <span class="s6">1-</span><span class="s47">δ</span>的概率输出一假设<span class="s21">h</span>∈<span class="s21">H</span>，使<span class="s21">error </span><span class="s6">(</span><span class="s21">h</span><span class="s6">)</span>≤<span class="s47">ε</span>，这时称<span class="s21">C</span>是使用<span class="s21">H</span>的<span class="s21">L</span>可<span class="s6">PAC </span>学习的。所使用的时间为 <span class="s6">1/</span><span class="s47">ε</span>，<span class="s6">1/</span><span class="s47">δ</span>，<span class="s21">n</span>以及<span class="s21">size</span><span class="s6">(</span><span class="s21">c</span><span class="s6">)</span>的多项式函数。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">这里的定义要求 <span class="s21">L </span>满足两个条件。首先，<span class="s21">L </span>必须以任意高概率<span class="s6">(1-</span><span class="s47">δ</span><span class="s6">)</span>输出一个错误率任 意低（<span class="s47">ε</span>）的假设。第二，学习过程必须是高效的，其时间最多以多项式方式增长，多项式 中 <span class="s6">1/</span><span class="s47">ε</span>和 <span class="s6">1/</span><span class="s47">δ</span>定义了对输出假设要求的强度，<span class="s21">n </span>和 <span class="s21">size</span><span class="s6">(</span><span class="s21">c</span><span class="s6">)</span>则定义了实例空间 <span class="s21">X </span>和概念类 <span class="s21">C </span>中 固有的复杂度。这里，<span class="s21">n </span>为 <span class="s21">X </span>中实例的长度。例如，如果实例为 <span class="s21">k </span>个布尔值的合取，那么 <span class="s21">n</span><span class="s6">=</span><span class="s21">k</span>。<span class="s21">size</span><span class="s6">(</span><span class="s21">c</span><span class="s6">)</span>为假定对 <span class="s21">C </span>采用某种表示方法时，其中的概念 <span class="s21">c </span>的编码长度。例如，若 <span class="s21">C </span>中的 概念为至多 <span class="s21">k </span>个布尔特征的合取，每个概念通过列出合取式中的特征的索引来描述，那么 <span class="s21">size</span><span class="s6">(</span><span class="s21">c</span><span class="s6">)</span>为实际用来描述 <span class="s21">c </span>的布尔特征数量。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">这里对 <span class="s6">PAC </span>学习的定义开始看来只关心学习所需的计算资源，而在实践中，通常更关 心所需的训练样例数。然而这两者是紧密相关的：如果 <span class="s21">L </span>对每个训练样例需要某最小处理 时间，那么为了使 <span class="s21">c </span>是 <span class="s21">L </span>可 <span class="s6">PAC </span>学习的，<span class="s21">L </span>必须从多项式数量的训练样例中进行学习。实 际上，为显示某目标概念类别 <span class="s21">C </span>是可 <span class="s6">PAC </span>学习的，一个典型的途径是证明 <span class="s21">C </span>中每个目标概 念可以从多项式数量的训练样例中学习到，而后证明每样例处理时间也限于多项式级。</p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: left;">在继续讨论以前，必须指出隐含在 <span class="s6">PAC </span>可学习性定义中的一个严格的限制。该定义隐 含假定了学习器的假设空间 <span class="s21">H </span>包含一个假设，它与 <span class="s21">C </span>中每个目标概念可有任意小的误差。 这一点来源于上面定义中要求学习器误差界限<span class="s47">ε</span>任意接近于 <span class="s6">0 </span>时也能成功运行。当然，如果 预先不知道 <span class="s21">C </span>将很难保证这一点（对于一个从图像中识别出人脸的程序来说，<span class="s21">C </span>是什么？）， 除非 <span class="s21">H </span>取为 <span class="s21">X </span>的幂集。如第 <span class="s6">2 </span>章指出的，这样一个无偏的 <span class="s21">H </span>将不会从合理数量的训练样例 中泛化。不过，基于 <span class="s6">PAC </span>学习模型的结论，对于领会不同学习问题的相对复杂度以及泛化 精度随着训练样例而提高的比率十分有益。更进一步，<span class="s6">7.3.1 </span>节中将解除这一严格假定，以 考虑学习器不预先假定目标概念形式的情况。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">7.3 <span class="s17">有限假设空间的样本复杂度</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 109%;text-align: justify;">如上所述，<span class="s6">PAC </span>可学习性很大程度上由所需的训练样例数确定。随着问题规模的增长 所带来的所需训练样例的增长称为该学习问题的样本复杂度<span class="s6">(sample complexity)</span>，它是通常 最感兴趣的特性。原因在于，在多数实际问题中，最限制学习器成功的因素是有限的可用训 练数据。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 109%;text-align: justify;">这里将样本复杂度的讨论限定于一类非常广泛的学习器，称为一致学习器<span class="s6">(consistent learner)</span>。一个学习器是一致的<span class="s6">(consistent)</span>，当它只要在可能时都输出能完美拟合训练数据的 假设。由于我们通常都更喜欢能与训练数据拟合程度更高的假设，因此要求学习算法的一致 性是合理的。注意前在章节讨论的很多学习器，包括第 <span class="s6">2 </span>章中的所有学习算法，都是一致学 习器。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 108%;text-align: justify;">是否能独立于一特定的算法，推导出任意一致学习器所需训练样例数的界限？回答是肯 定的。为进行该推导，需要回顾一下第 <span class="s6">2 </span>章定义的变型空间。在那里变型空间<span class="s21">VS</span><span class="s36">H</span><span class="s42">, </span><span class="s41">D</span>被定义 为能正确分类训练样例<span class="s21">D</span>的所有假设<span class="s21">h</span>∈<span class="s21">H</span>的集合：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="padding-top: 2pt;padding-left: 111pt;text-indent: 0pt;text-align: left;">VS<span class="s52">H</span><span class="s41"> </span><span class="s42">,</span><span class="s41">D </span><span class="s38"> </span><span class="s33">{</span>h <span class="s38"> </span>H <span class="s33">| (</span><span class="s38"></span>x<span class="s33">, </span>c<span class="s33">(</span>x<span class="s33">)</span><span class="s38"> </span><span class="s38"> </span>D<span class="s33">)(</span>h<span class="s33">(</span>x<span class="s33">) </span><span class="s38"> </span>c<span class="s33">(</span>x<span class="s33">)}</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 9pt;padding-left: 5pt;text-indent: 21pt;line-height: 109%;text-align: justify;">变型空间的重要意义在于，每个一致学习器都输出一属于变型空间的假设，而不论有怎 样的实例空间<span class="s21">X</span>、假设空间<span class="s21">H</span>或训练数据<span class="s21">D</span>。原因很简单，由变型空间的定义，<span class="s21">VS</span><span class="s36">H</span><span class="s42">, </span><span class="s41">D</span>包含<span class="s21">H </span>中所有的一致假设。因此，为界定任意一致学习器所需的样例数量，只需要界定为保证变型 空间中没有不可接受假设所需的样例数量。下面的定义精确地描述了这一条件（见<span class="s6">Haussler 1988</span>）：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 26pt;text-indent: 0pt;line-height: 15pt;text-align: left;">定义： 考虑一假设空间<span class="s21">H</span>，目标概念<span class="s21">c</span>，实例分布<span class="s68">D</span>以及<span class="s21">c</span>的一组训练样例<span class="s21">D</span>。当<span class="s21">VS</span><span class="s36">H</span><span class="s253">，</span></p><p style="padding-left: 48pt;text-indent: 0pt;line-height: 16pt;text-align: left;"><span class="s36">D</span>中每个假设<span class="s21">h</span>关于<span class="s21">c</span>和<span class="s68">D</span>错误率小于<span class="s47">ε</span>时，变型空间被称为关于<span class="s21">c</span>和<span class="s68">D</span>是<span class="s47">ε</span><span class="s6">-</span>详尽的（<span class="s47">ε</span></p><p class="s6" style="padding-left: 48pt;text-indent: 0pt;text-align: left;">-exhausted<span class="p">）。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 26pt;text-indent: 0pt;text-align: left;">该定义在图 <span class="s6">7-2 </span>中示出。<span class="s47">ε</span><span class="s6">-</span>详尽的变型空间表示与训练样例一致的所有假设（即那些</p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 107%;text-align: justify;">有 <span class="s6">0 </span>训练错误率的假设）的真实错误率恰好都小于<span class="s47">ε</span>。当然，从学习器的角度看，所能知道 的只是这些假设能同等地拟合训练数据，它们都有零训练错误率。只有知道确切的目标概念 的观察者才能确定变型空间是否为<span class="s47">ε</span><span class="s6">-</span>详尽的。令人惊讶的是，即使不知道确切的目标概念 或训练样例抽取的分布，一种概率方法可在给定数目的训练样例之后界定变型空间为<span class="s47">ε</span>详尽</p><p style="padding-left: 6pt;text-indent: 0pt;text-align: left;">的概率。<span class="s6">Haussler(1988)</span>以下面的定理形式提供了这样的界定方法。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 13pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="547" height="1" alt="image" src="机器学习/Image_295.png"/></span></p><p class="s48" style="padding-left: 15pt;text-indent: 0pt;text-align: left;">插图——原书页码： <span class="s21">208</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">Hypothesis space: <span class="p">假设空间</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 14pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="531" height="1" alt="image" src="机器学习/Image_296.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 58pt;text-indent: 108pt;text-align: left;">图 <span class="h4">7-2 </span>使变型空间详尽化</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s254" style="text-indent: 0pt;line-height: 5pt;text-align: left;">D</p><p style="text-indent: 0pt;text-align: left;"/><p class="s254" style="text-indent: 0pt;line-height: 5pt;text-align: left;">D</p><p style="text-indent: 0pt;text-align: left;"/><p class="s14" style="padding-left: 37pt;text-indent: 21pt;line-height: 119%;text-align: justify;">变型空间<span class="s56">VS</span><span class="s65">H</span><span class="s155">，</span><span class="s65">D</span>为假设<span class="s56">h</span>∈<span class="s56">H</span>的子集，其中的假设都有零训练错误率（在图中表示为<span class="s56">r</span><span class="s16">=0</span>）。当 然真实错误率<span class="s56">error </span><span class="s16">(</span><span class="s56">h</span><span class="s16">)</span>（图中表示为<span class="s56">error</span>）可能非 <span class="s16">0</span>，即使该假设在所有训练数据中错误为 <span class="s16">0</span>。当 变型空间中所有假设<span class="s56">h</span>都满足<span class="s56">error </span><span class="s16">(</span><span class="s56">h</span><span class="s16">)&lt;</span><span class="s177">ε</span>时，变型空间才是<span class="s177">ε</span><span class="s16">-</span>详尽的。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-left: 27pt;text-indent: 20pt;line-height: 119%;text-align: left;">定理 <span class="s187">7.1 </span>变型空间的<span class="s177">ε</span><span class="s187">-</span>详尽化 <span class="s187">(</span><span class="s177">ε</span><span class="s187">-exhausting the version space)</span>。若假设空间<span class="s56">H</span>有限，且<span class="s56">D</span>为目 标概念<span class="s56">c</span>的一系列<span class="s56">m</span>≥<span class="s16">1 </span>个独立随机抽取的样例，那么对于任意 <span class="s16">0</span>≤<span class="s177">ε</span>≤<span class="s16">1</span>，变型空间<span class="s56">VS</span><span class="s65">H</span><span class="s155">，</span><span class="s65">D</span>不是<span class="s177">ε</span><span class="s16">-</span>详尽</p><p class="s14" style="padding-left: 26pt;text-indent: 0pt;text-align: left;">（关于<span class="s56">c</span>）的概率小于或等于：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="1" height="20" alt="image" src="机器学习/Image_297.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="1" height="20" alt="image" src="机器学习/Image_298.png"/></span></p><p class="s255" style="padding-top: 4pt;padding-left: 124pt;text-indent: 0pt;text-align: center;">H<span class="s30"> e</span><span class="s40"></span><span class="s181"></span><span class="s41">m</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-top: 2pt;padding-left: 26pt;text-indent: 21pt;line-height: 119%;text-align: justify;">证明：令<span class="s56">h</span><span class="s64">1</span>，<span class="s56">h</span><span class="s64">2 </span><span class="s56">h</span><span class="s65">k</span>为<span class="s56">H</span>中关于<span class="s56">c</span>的真实错误率大于<span class="s177">ε</span>的所有假设。当且仅当<span class="s56">k</span>个假设中至少有 一个恰好与所有<span class="s56">m</span>个独立随机抽取样例一致时，不能使变型空间<span class="s177">ε</span><span class="s56">-</span>详尽化。任一假设真实错误率大于 <span class="s177">ε</span>，且与一个随机抽取样例一致的可能性最多为<span class="s16">(1-</span><span class="s177">ε</span><span class="s16">)</span>。因此，该假设与<span class="s56">m</span>个独立抽取样例一致的概率 最多为<span class="s16">(1-</span><span class="s177">ε</span><span class="s16">)</span><span class="s256">m</span>。由于已知有<span class="s56">k</span>个假设错误率大于<span class="s177">ε</span>，那么至少有一个与所有<span class="s56">m</span>个训练样例都不一致的概 率最多为</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s33" style="padding-top: 3pt;padding-left: 122pt;text-indent: 0pt;text-align: center;"><i>k </i>(1 <span class="s38"> </span><span class="s119"> </span>)<span class="s83">m</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s16" style="padding-left: 26pt;text-indent: 21pt;line-height: 124%;text-align: left;"><span class="s14">并且因为</span><i>k</i><span class="s14">≤</span>|<i>H</i>|<span class="s14">，上式最多为</span>|<i>H</i>|(1-<span class="s177">ε</span>)<span class="s256">m</span><span class="s14">。最后，使用一通用不等式，当 </span>0<span class="s14">≤</span><span class="s177">ε</span><span class="s14">≤</span>1 <span class="s14">则</span>(1-<span class="s177">ε</span>)<span class="s14">≤</span><i>e</i><span class="s70">-</span><span class="s257">ε</span><span class="s14">。 因此：</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-left: 47pt;text-indent: 0pt;text-align: left;">定理得证。</p><p class="s33" style="padding-top: 5pt;padding-left: 47pt;text-indent: 0pt;text-align: left;"><i>k</i>(1 <span class="s38"> </span><span class="s119"> </span>)<span class="s83">m</span><span class="s41"> </span><span class="s38"></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="1" height="20" alt="image" src="机器学习/Image_299.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="1" height="20" alt="image" src="机器学习/Image_300.png"/></span></p><p class="s33" style="padding-top: 2pt;padding-left: 3pt;text-indent: 0pt;text-align: left;"><i>H </i><span class="s258"></span>1 <span class="s38"></span> <span class="s119"></span><span class="s125"> </span><span class="s258"></span><span class="s244">m  </span><span class="s41"> </span><span class="s38"></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="1" height="20" alt="image" src="机器学习/Image_301.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="1" height="20" alt="image" src="机器学习/Image_302.png"/></span></p><p class="s255" style="padding-top: 5pt;padding-left: 3pt;text-indent: 0pt;text-align: left;">H<span class="s30"> e</span><span class="s40"></span><span class="s181"></span><span class="s41">m</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;text-align: justify;">刚才基于训练样例的数目 <span class="s21">m</span>、允许的错误率<span class="s47">ε</span>和 <span class="s21">H </span>的大小，得到了变型空间不是<span class="s47">ε</span><span class="s6">-</span>详 尽的概率的上界。换言之，它对于任意使用假设空间 <span class="s21">H </span>的学习器界定了 <span class="s21">m </span>个训练样例未能 将所有“坏”的假设（即错误率大于<span class="s47">ε</span>的假设）剔除出去的概率。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 112%;text-align: left;">可以用这一结论来确定为了减少此“未剔除”概率到一希望的程度<span class="s47">δ</span>所需的训练样例数。 由：</p><p style="text-indent: 0pt;text-align: left;"><span><img width="1" height="20" alt="image" src="机器学习/Image_303.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="1" height="20" alt="image" src="机器学习/Image_304.png"/></span></p><p class="s30" style="padding-top: 3pt;text-indent: 0pt;text-align: right;">H e<span class="s133"></span><span class="s181"></span><span class="s41">m </span><span class="s38"> </span><span class="s119"></span></p><p style="padding-top: 3pt;padding-left: 8pt;text-indent: 0pt;text-align: left;">（<span class="s6">7.1</span>）</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 9pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">从中解出 <span class="s21">m </span>可得：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="1" height="20" alt="image" src="机器学习/Image_305.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="1" height="20" alt="image" src="机器学习/Image_306.png"/></span></p><p class="s30" style="padding-left: 26pt;text-indent: 0pt;line-height: 18pt;text-align: center;">m <span class="s38"> </span><u>1 </u><span class="s33">(ln </span>H</p><p class="s119" style="padding-left: 19pt;text-indent: 0pt;line-height: 12pt;text-align: center;"></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s33" style="padding-top: 11pt;padding-left: 1pt;text-indent: 0pt;text-align: left;"><span class="s38"> </span>ln(1/ <span class="s119"> </span>)) <span class="p">（</span><span class="s6">7.2</span><span class="p">）</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;text-align: justify;">概括地说，式 <span class="s6">7.2 </span>中的不等式提供了训练样例数目的一般边界，该数目的样例足以在所 期望的值<span class="s47">δ</span>和<span class="s47">ε</span>程度下，使任何一致学习器成功地学习到 <span class="s21">H </span>中的任意目标概念。训练样例 的数目 <span class="s21">m </span>足以保证任意一致假设是可能（可能性为 <span class="s6">1-</span><span class="s47">δ</span>）近似（错误率为<span class="s47">ε</span>）正确的。注 意 <span class="s21">m </span>随着 <span class="s6">1/</span><span class="s47">ε</span>线性增长，并随 <span class="s6">1/</span><span class="s47">δ</span>对数增长。它还随着假设空间 <span class="s21">H </span>的规模对数增长。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 5pt;text-indent: 21pt;line-height: 110%;text-align: justify;"><span class="p">注意上面的界限有可能是过高的估计。例如，虽然未能详尽化变型空间的概率必须在区 间</span>[0, 1]<span class="p">内，然而此定理给出的边界随着</span>|<i>H</i>|<span class="p">对数增长。对于足够大的假设空间，该边界很容 易超过 </span>1<span class="p">。因此，式 </span>7.2 <span class="p">中的不等式给出的边界可能过高估计了所需训练样例的数量。此边 界的脆弱性主要来源于</span>|<i>H</i>|<span class="p">项，它产生于证明过程中在所有可能假设上计算那些不可接受的 假设的概率和。实际上，在许多情况下可以有一更紧凑的边界，以及能够覆盖大的假设空间 的边界。这是第 </span>7.4 <span class="p">节的主题。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">7.3.1 <span class="s25">不可知学习和不一致假设</span></h3><p style="padding-top: 9pt;padding-left: 5pt;text-indent: 21pt;line-height: 108%;text-align: justify;">式 <span class="s6">7.2 </span>的重要性在于，它告诉我们有多少训练样例才足以保证（以概率 <span class="s6">1-</span><span class="s47">δ</span>）<span class="s21">H </span>中每个 有零训练错误率的假设，其真实错误率最多为<span class="s47">ε</span>。不幸的是，如果 <span class="s21">H </span>不包含目标概念 <span class="s21">c</span>，那 么并不总能找到一个零错误率假设。这时，最多能要求学习器输出的假设在训练样例上有最 小的错误率。如果学习器不假定目标概念可在 <span class="s21">H </span>中表示，而只简单地寻找具有最小训错误 率的假设，这样的学习器称为不可知学习器，因为它不预先认定 <span class="s21">C</span><span class="s10"></span><span class="s21">H</span>。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 5pt;text-indent: 21pt;text-align: justify;"><span class="p">虽然式 </span><span class="s6">7.2 </span><span class="p">基于的假定是学习器输出一零错误率假设，对于更一段的情形下学习器考虑 到了有非零训练错误率的假设时，仍能找到一个简单的边界。精确地表述如下。令</span>D<span class="p">代表学 习器可观察到的特定训练样例集合，而与此不同的</span><span class="s68">D</span><span class="p">代表在整个实例集合上的概率分布。令 </span>error<span class="s36">D</span><span class="s6">(</span>h<span class="s6">)</span><span class="p">代表假设</span>h<span class="p">的训练错误率。确切地说，</span>error<span class="s36">D</span><span class="s6">(</span>h<span class="s6">)</span><span class="p">定义为</span>D<span class="p">中被</span>h<span class="p">误分类的训练样例所 占比例，注意</span>error<span class="s36">D</span><span class="p">（</span>h<span class="p">）是在特定训练数据样本</span>D<span class="p">上的，它与真实错误率</span>error<span class="s170">D</span><span class="s6">(</span>h<span class="s6">)</span><span class="p">不同，后 者是定义在整个概率分布</span><span class="s68">D</span><span class="p">上的。现在令</span>h<span class="s36">best </span><span class="p">代表</span>H<span class="p">中有最小训练错误率的假设。多少训练 样例才足以（以较高的概率）保证其真实错误率</span>error<span class="s170">D</span><span class="s6">(</span>h<span class="s36">best</span><span class="s6">)</span><span class="p">不会多于</span><span class="s47">ε</span><span class="s6">+</span>error<span class="s36">D</span><span class="s6">(</span>h<span class="s36">best</span><span class="s6">)</span><span class="p">？注意前 一节讨论的问题只是现在这种情况的特例，其中</span>error<span class="s36">D</span><span class="s6">(</span>h<span class="s36">best</span><span class="s6">)</span><span class="p">恰好为 </span><span class="s6">0</span><span class="p">。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">该问题的回答（见练习 <span class="s6">7.3</span>）使用类似于定理 <span class="s6">7.1 </span>的证明方法。这里有必要引入一般的 <span class="s6">Hoeffding </span>边界（有时又称为附加 <span class="s6">Chernoff </span>边界）。<span class="s6">Hoeffding </span>边界刻画的是某事件的真实概 率及其 <span class="s21">m </span>个独立试验中观察到的频率之间的差异。更精确地讲，这些边界应用于 <span class="s21">m </span>个不同 的 <span class="s6">Bernoulli </span>试验（例如，<span class="s21">m </span>次抛掷一硬币，该硬币以某概率显示为正面）。这种情况非常类 似于第 <span class="s6">5 </span>章考虑的假设错误率估计问题：即硬币显示为正面的概率对应到一随机抽取实例被 假设误分类的概率。<span class="s21">m </span>次独立的硬币抛掷对应 <span class="s21">m </span>个独立抽取的实例。<span class="s21">m </span>次实验出现正面的 频率对应于 <span class="s21">m </span>个实例中误分类的频率。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 26pt;text-indent: 0pt;text-align: left;"><span class="s6">Hoeffding</span><span class="p">边界表明，当训练错误率</span>error<span class="s36">D</span><span class="s6">(</span>H<span class="s6">)</span><span class="p">在包含</span>m<span class="p">个随机抽取样例的集合</span>D<span class="p">上测量时，</span></p><p style="padding-left: 6pt;text-indent: 0pt;text-align: left;">那么：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s33" style="padding-top: 6pt;text-indent: 0pt;text-align: right;">Pr[<i>error</i><span class="s171">D</span></p><p class="s33" style="padding-top: 5pt;text-indent: 0pt;text-align: left;">(<i>h</i>) <span class="s38"> </span><i>error</i><span class="s52">D</span></p><p class="s189" style="text-indent: 0pt;line-height: 5pt;text-align: left;">2</p><p style="text-indent: 0pt;text-align: left;"/><p class="s33" style="padding-top: 4pt;text-indent: 0pt;text-align: left;">(<i>h</i>) <span class="s38"> </span><span class="s119"> </span>] <span class="s38"> </span><i>e</i><span class="s133"></span><span class="s42">2</span><span class="s41">m</span><span class="s181"></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">它给出了一个概率边界，说明任意选择的假设训练错误率不能代表真实情况。为保证 <span class="s21">L </span>寻找到的最佳的假设的错误率有以上的边界，我们必须考虑这<span class="s6">|</span><span class="s21">H</span><span class="s6">|</span>个假设中任一个有较大错 误率的概率：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="padding-top: 5pt;padding-left: 106pt;text-indent: 0pt;text-align: left;"><span class="s33">Pr[(</span><span class="s38"></span>h <span class="s38"> </span>H <span class="s33">)</span>error<span class="s171">D</span></p><ol id="l19"><li style="padding-top: 5pt;padding-left: 16pt;text-indent: -17pt;text-align: left;"><p class="s38" style="display: inline;"> <span class="s30">error</span><span class="s52">D</span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="1" height="20" alt="image" src="机器学习/Image_307.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="1" height="20" alt="image" src="机器学习/Image_308.png"/></span></p><p class="s189" style="text-indent: 0pt;line-height: 5pt;text-align: left;">2</p><p style="text-indent: 0pt;text-align: left;"/><p class="s33" style="padding-top: 4pt;text-indent: 0pt;text-align: left;">(<i>h</i>) <span class="s38"> </span><span class="s119"> </span>] <span class="s38"> </span><i>H e</i><span class="s133"></span><span class="s42">2</span><span class="s41">m</span><span class="s200"></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: left;">如果将此概率称为<span class="s47">δ</span>，并且问：多少个训练样例 <span class="s21">m </span>才足以使<span class="s47">δ</span>维持在一指定的值内？ 可得下式：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="1" height="20" alt="image" src="机器学习/Image_309.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="1" height="20" alt="image" src="机器学习/Image_310.png"/></span></p><p class="s30" style="padding-top: 3pt;padding-left: 131pt;text-indent: 0pt;line-height: 19pt;text-align: center;">m <span class="s38"> </span><u>1 </u><span class="s33">(ln </span>H</p><p class="s33" style="text-indent: 0pt;line-height: 13pt;text-align: right;">2<span class="s119"> </span><span class="s46">2</span></p><p class="s33" style="padding-top: 9pt;padding-left: 1pt;text-indent: 0pt;text-align: left;"><span class="s38"> </span>ln(1/ <span class="s119"> </span>))</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 23pt;text-indent: 0pt;text-align: left;">（<span class="s6">7.3</span>）</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 6pt;text-indent: 21pt;text-align: justify;">这是式 <span class="s6">7.2 </span>的一般化情形，适用于当最佳假设可能有非零训练错误率时，学习器仍能选 择到最佳假设 <span class="s21">h</span>∈<span class="s21">H </span>的情形。注意 <span class="s21">m </span>依赖于 <span class="s21">H </span>和 <span class="s6">1/</span><span class="s47">δ</span>的对数，如在式 <span class="s6">7.2 </span>中一样。然而在这 个受限较少的情形下，<span class="s21">m </span>随 <span class="s6">1/</span><span class="s47">ε</span>的平方增长，而不是 <span class="s6">1/</span><span class="s47">ε</span>的线性增长。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">7.3.2 <span class="s25">布尔文字的合取是 </span>PAC <span class="s25">可学习的</span></h3><p style="padding-top: 10pt;padding-left: 6pt;text-indent: 21pt;line-height: 113%;text-align: left;">现在我们有了一个训练样例数目的边界，以表示该数目为多少时才足以可能近似学习到 目标概念。然后就可用它来确定某些特定概念类的样本复杂度和 <span class="s6">PAC </span>可学习性。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 107%;text-align: justify;">考虑目标概念类 <span class="s21">C</span>，它由布尔文字的合取表示。布尔文字（<span class="s6">literal</span>）是任意的布尔变量<span class="s6">(</span>如 <span class="s21">Old</span><span class="s6">)</span>，或它的否定<span class="s6">(</span>如<span class="s10"></span><span class="s21">Old</span><span class="s6">)</span>。因此，布尔文字的合取形式可能为“<span class="s21">Old</span>∧<span class="s10"></span><span class="s21">Tall</span>”。<span class="s21">C </span>是否为可 <span class="s6">PAC </span>学习的？可以证明，回答是肯定的。证明过程首先显示任意一致学习器只需要多项式 数目的训练样例以学习到 <span class="s21">C </span>中任意 <span class="s21">c</span>，然后得到一特定算法能对每训练样例使用多项式时间。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;text-align: left;">考虑任意学习器 <span class="s21">L</span>，它使用的假设空间 <span class="s21">H </span>等于 <span class="s21">C</span>。我们可以用式 <span class="s6">7.2 </span>计算出足以保证（以 概率 <span class="s6">1-</span><span class="s47">δ</span>）输出一最大错误率为<span class="s47">ε</span>的假设，所需的随机训练样例数目是 <span class="s21">m</span>。为达到此目标， 只需要确定假设空间的规模<span class="s6">|</span><span class="s21">H</span><span class="s6">|</span>。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 110%;text-align: left;">若假设空间<span class="s21">H</span>定义为<span class="s21">n</span>个布尔文字的合取，则假设空间<span class="s6">|</span><span class="s21">H</span><span class="s6">|</span>的大小为 <span class="s6">3</span><span class="s83">n</span>。原因在于，任一 给定的假设中每个变量可有三种可能：包含该变量作为文字；包含该变量的否定作为文字； 或不包含该变量。由于有<span class="s21">n</span>个这样的变量，所以共有 <span class="s6">3</span><span class="s83">n</span>个不同的假设。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 26pt;text-indent: 0pt;text-align: left;">将<span class="s6">|</span><span class="s21">H</span><span class="s6">|=3</span><span class="s83">n</span>代入到式 <span class="s6">7.2 </span>中，得到以下关于<span class="s21">n</span>布尔文字合取学习问题的样本复杂度：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s33" style="padding-top: 3pt;padding-left: 144pt;text-indent: 0pt;line-height: 19pt;text-align: left;"><i>m </i><span class="s38"> </span><u>1 </u>(<i>n </i>ln 3 <span class="s38"> </span>ln(1/ <span class="s119"> </span>))</p><p class="s119" style="padding-left: 166pt;text-indent: 0pt;line-height: 12pt;text-align: left;"></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 13pt;text-indent: 0pt;text-align: left;">（<span class="s6">7.4</span>）</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: left;">若一个一致学习器要学习的目标概念可由至多 <span class="s6">10 </span>个布尔文字来描述，那么可有 <span class="s6">95%</span>的 概率它将学习到一个错误率小于 <span class="s6">0.1 </span>的假设，而且所需的训练样例 数 量</p><p class="s33" style="padding-top: 2pt;text-indent: 0pt;line-height: 11pt;text-align: right;">1</p><p style="text-indent: 0pt;text-align: left;"><span><img width="21" height="1" alt="image" src="机器学习/Image_311.png"/></span></p><p class="s21" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">m<span class="s6">=</span></p><p class="s33" style="padding-left: 22pt;text-indent: 0pt;line-height: 12pt;text-align: left;">0.1</p><p class="s6" style="padding-top: 8pt;text-indent: 0pt;text-align: left;">(10ln3+ln(1/0.05))=140<span class="p">。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;line-height: 110%;text-align: justify;">注意 <span class="s21">m </span>按文字数量 <span class="s21">n </span>和 <span class="s6">1/</span><span class="s47">ε</span>线性增长，并按 <span class="s6">1/</span><span class="s47">δ</span>对数增长。总的运算量是多少？这当 然依赖于特定的学习算法。然而，只要学习算法的每训练样例计算量不超过多项式级，并且 不超过训练样例数目的多项式级，那么整体的运算也为多项式级。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 109%;text-align: justify;">在布尔文字的学习中，一个能够符合该要求的算法已经在第 <span class="s6">2 </span>章介绍了。这就是 <span class="s6">Find-S </span>算法，它增量地计算与训练样例一致的最特殊假设。对每个新的正例，该算法计算了当前假 设和新样例间共享的文字的交集，使用的时间也按 <span class="s21">n </span>线性增长。因此，<span class="s6">Find-S </span>算法可能近似 正确（<span class="s6">PAC</span>）学习一类带否定的 <span class="s21">n </span>个布尔文字合取的概念。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-left: 48pt;text-indent: 0pt;text-align: left;">定理 <span class="s16">7.2</span>：布尔合取式的 <span class="s16">PAC </span>可学习性。布尔文字合取的类 <span class="s56">C </span>是用 <span class="s16">Find-S </span>算法（使用 <span class="s56">H</span><span class="s16">=</span><span class="s56">C</span>）<span class="s16">PAC-</span></p><p class="s14" style="padding-top: 3pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">可学习的。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-left: 26pt;text-indent: 21pt;line-height: 122%;text-align: justify;">证明：式 <span class="s16">7.4 </span>显示了该概念类的样本复杂度是 <span class="s56">n</span>、<span class="s16">1/</span><span class="s177">δ</span>和 <span class="s16">1/</span><span class="s177">ε</span>的多项式级，而且独立于 <span class="s56">size</span><span class="s16">(</span><span class="s56">c</span><span class="s16">)</span>。 为增量式地处理每个训练样例，<span class="s16">Find-S </span>算法要求的运算量根据 <span class="s56">n </span>线性增长，并独立于 <span class="s16">1/</span><span class="s177">δ</span>，<span class="s16">1/</span><span class="s177">ε</span>和 <span class="s56">size</span><span class="s16">(</span><span class="s56">c</span><span class="s16">)</span>。因此，这一概念类是 <span class="s16">Find-S </span>算法 <span class="s16">PAC </span>可学习的。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 6pt;text-indent: 0pt;text-align: justify;">7.3.3 <span class="s25">其他概念类的 </span>PAC-<span class="s25">可学习性</span></h3><p style="padding-top: 10pt;padding-left: 6pt;text-indent: 21pt;line-height: 110%;text-align: justify;">如前所示，在学习给定类 <span class="s21">C </span>中的目标概念时，式 <span class="s6">7.2 </span>为界定其样本复杂度提供了一般的 基础。上例将其应用到布尔文字的合取这样的类别中。它还可用于证明许多其他概念共有多 项式级的样本复杂度（例如，见习题 <span class="s6">7.2</span>）。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s37" style="padding-left: 6pt;text-indent: 0pt;text-align: justify;">7.3.3.1 <span class="s20">无偏学习器</span></p><p style="padding-top: 8pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">并非所有概念类都有如式 <span class="s6">7.2 </span>那样的多项式级样本复杂度边界。例如，考虑一无偏</p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 0pt;text-align: justify;">（<span class="s6">unbiased</span>）概念类<span class="s21">C</span>，它包含与<span class="s21">X</span>相关的所有可教授概念。该集合<span class="s21">C</span>对应于<span class="s21">X</span>的幂集，即<span class="s21">X</span>的 有子集的集合，共包含<span class="s6">|</span><span class="s21">C</span><span class="s6">|=2</span><span class="s46">|</span><span class="s41">X</span><span class="s42">|</span>个概念。若<span class="s47">X</span>中的实例定义为<span class="s47">n</span>个布尔值特征，将有|<span class="s47">X</span>|=2<span class="s259">n</span>个不 同概念。当然为学习这样的无偏概念类，学习器本身也必须使用一无偏的假设空间<span class="s47">H</span>=<span class="s47">C</span>。将</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s260" style="padding-left: 34pt;text-indent: 0pt;line-height: 5pt;text-align: left;">n</p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 12pt;text-align: left;">|<span class="s47">H</span>|=2<span class="s9">2 </span>代入到式 7.2 中，得到为学习对应于<span class="s47">X</span>的无偏概念类的样本复杂度。 </p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s33" style="padding-top: 3pt;padding-left: 147pt;text-indent: 0pt;line-height: 18pt;text-align: left;"><i>m </i><span class="s38"> </span><u>1 </u>(2<span class="s83">n</span><span class="s41"> </span>ln 2 <span class="s38"> </span>ln(1/ <span class="s119"> </span>)) <span class="p">（7.5） </span></p><p class="s119" style="padding-left: 33pt;text-indent: 0pt;line-height: 12pt;text-align: center;"></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;line-height: 109%;text-align: justify;">这样，该无偏的目标概念类在 PAC 模型下有指数级的样本复杂度。虽然式 7.2 和 7.5 中并非紧凑的上界，实际上可证明该无偏概念类的样本复杂度确为 <span class="s47">n </span>的指数级。 </p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s37" style="padding-left: 6pt;text-indent: 0pt;text-align: left;">7.3.3.2 <i>K </i><span class="s20">项 </span>DNF <span class="s20">和 </span><i>K</i>-CNF <span class="s20">概念</span></p><p style="padding-top: 8pt;padding-left: 5pt;text-indent: 21pt;line-height: 109%;text-align: justify;">存在这种可能，即某概念类有多项式级的样本复杂度，但不能够在多项式时间内被学习 到。一个有趣的例子是概念类<span class="s47">C</span>为<span class="s47">k</span>项析取范式（<span class="s47">k</span>项DNF）的形式。<span class="s47">k</span>项DNF表达式形式为<span class="s47">T</span><span class="s253">1</span>∨ <span class="s47">T</span><span class="s253">2</span>∨ ∨<span class="s47">T</span><span class="s260">k</span>，其中每一<span class="s47">T</span><span class="s260">i</span>项为<span class="s47">n</span>个布尔属性和它们的否定的合取。假定<span class="s47">H</span>=<span class="s47">C</span>，很容易证明|<span class="s47">H</span>| 最多为 3<span class="s259">nk</span>（因为有<span class="s47">k</span>个项，每项可有 3<span class="s259">n</span>个可能值）。注意 3<span class="s259">nk</span>过高估计了|<span class="s47">H</span>|，因为它重复计 算了<span class="s47">T</span><span class="s260">i</span>=<span class="s47">T</span><span class="s260">j</span>以及<span class="s47">T</span><span class="s260">i</span>比<span class="s47">T</span><span class="s260">j</span>更一般的情形。此上界仍然可用于获得样本复杂度的上界，将其代入到</p><p style="padding-left: 6pt;text-indent: 0pt;text-align: left;">式 7.2 中： </p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s33" style="padding-left: 6pt;text-indent: 0pt;line-height: 18pt;text-align: left;"><i>m </i><span class="s38"> </span><u>1 </u>(<i>nk </i>ln 3 <span class="s38"> </span>ln(1/ <span class="s119"> </span>)) <span class="p">（7.6） </span></p><p class="s119" style="padding-left: 27pt;text-indent: 0pt;line-height: 12pt;text-align: left;"></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 6pt;text-indent: 21pt;line-height: 108%;text-align: justify;">它表示 <span class="s47">k</span>-项 DNF 的样本复杂度为 <span class="s6">1/</span><span class="s47">δ</span>、<span class="s6">1/</span><span class="s47">ε</span>、<span class="s47">n </span>和 <span class="s47">k </span>的多项式级。虽然样本复杂度是多 项式级的，计算复杂度却不是多项式级的，因为该算法等效于其他已知的不能在多项式时间 内解决的问题（除非 <span class="s47">RP</span>=<span class="s47">NP</span>）。因此，虽然 <span class="s47">k </span>项 DNF 有多项式级的样本复杂度，它对于使用 <span class="s47">H</span>=<span class="s47">C </span>的学习器没有多项式级的计算复杂度。 </p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 110%;text-align: justify;">关于<span class="s47">k</span>项DNF的令人吃惊的事实在于，虽然它不是PAC可学习的，却存在一个更大的概念 类是PAC可学习的。这个更大的概念类有每样例的多项式级时间复杂度，同时有多项式级的 样本复杂度。这一更大的类为<span class="s47">k</span>-CNF表达式：任意长度的合取式<span class="s47">T</span><span class="s253">1</span>∧<span class="s47">T</span><span class="s253">2</span>∧ ∧<span class="s47">T</span><span class="s260">j</span>，其中每个 <span class="s47">T</span><span class="s260">i</span>为最多<span class="s47">k</span>个布尔变量的析取。很容易证明<span class="s47">k</span>-CNF包含了<span class="s47">k</span>-DNF，因为任意<span class="s47">k</span>项DNF可以很容易 地重写为<span class="s47">k</span>-CNF表达式（反之却不然）。虽然<span class="s47">k</span>-CNF比<span class="s47">k</span>项DNF表达力更强，但它有多项式级样 本复杂度和多项式级时间复杂度。因此，概念类<span class="s47">k</span>-项DNF是使用<span class="s47">H</span>=<span class="s47">k</span>-CNF的一个有效算法可PAC 学习的。见Kearns &amp; Vazirani(1994)中更详细的讨论。 </p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">7.4 <span class="s17">无限假设空间的样本复杂度</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 109%;text-align: justify;">在上一节中我们证明了 PAC 学习的样本复杂度随假设空间的对数增长。虽然式 7.2 是一 很有用的不等式，但以|<span class="s47">H</span>|项来刻画样本复杂度有两个缺点。首先，它可能导致非常弱的边 界（回忆一下对于大的|<span class="s47">H</span>|在<span class="s47">δ</span>上的边界可能超出 1 很多）。其次，对于无限假设空间的情形，</p><p style="padding-left: 6pt;text-indent: 0pt;text-align: left;">式 7.2 根本无法应用。 </p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 110%;text-align: justify;">这里我们考虑 <span class="s47">H </span>的复杂度的另一种度量，称为 <span class="s47">H </span>的 Vapnik-Chervonenkis 维度（简称 VC 维或 <span class="s47">VC</span>(<span class="s47">H</span>)）。可以看到，使用 <span class="s47">VC</span>(<span class="s47">H</span>)代替|<span class="s47">H</span>|也可以得到样本复杂度的边界。在许多情形 下，基于 <span class="s47">VC</span>(<span class="s47">H</span>)的样本复杂度会比 7.2 式得到的更紧凑。另外，这些边界可以刻画许多无限 假设空间的样本复杂度，而且可证明相当紧凑。 </p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">7.4.1 <span class="s25">拆散一个实例集合</span></h3><p style="padding-top: 9pt;padding-left: 5pt;text-indent: 21pt;line-height: 112%;text-align: justify;">VC 维衡量假设空间复杂度的方法不是用不同假设的数量|<span class="s47">H</span>|，而是用 <span class="s47">X </span>中能被 <span class="s47">H </span>彻底区 分的不同实例的数量。 </p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">为精确地描述这一点，首先定义对一实例集合的拆散(Shattering)操作。考虑实例的某 子集<span class="s47">S</span><span class="s10"></span><span class="s47">X</span>。例如，图 7-3 显示了<span class="s47">X</span>中一个包含 3 个实例的子集。<span class="s47">H</span>中的每个<span class="s47">h</span>导致<span class="s47">S</span>中的某个划 分(dichotomy)，即<span class="s47">h</span>将<span class="s47">S</span>分割为两个子集{<span class="s47">x</span>∈<span class="s47">S</span>|<span class="s47">h</span>(<span class="s47">x</span>)=1}以及{<span class="s47">x</span>∈<span class="s47">S</span>|<span class="s47">h</span>(<span class="s47">x</span>)=0}。给定某实例集 合<span class="s47">S</span>，有 2<span class="s9">|</span><span class="s260">S</span><span class="s253">|</span>种可能的划分，虽然其中的一些不能由<span class="s47">H</span>来表达。当<span class="s47">S</span>的每个可能的划分可由<span class="s47">H</span>中 的某假设来表达时，我们称<span class="s47">H</span>拆散<span class="s47">S</span>。 </p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 27pt;text-indent: 0pt;text-align: left;">定义： 一实例集 <span class="s21">S </span>被假设空间 <span class="s21">H </span>拆散<span class="s6">(shatter) </span>，当且仅当对 <span class="s21">S </span>的每个划分，存在 <span class="s21">H</span></p><p style="padding-top: 1pt;padding-left: 47pt;text-indent: 0pt;text-align: left;">中的某假设与此划分一致。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 26pt;text-indent: 0pt;text-align: left;">图 7-3 显示了一包含 3 个实例的集合<span class="s47">S</span>被假设空间划分的结果。注意这 3 个实例的 2<span class="s9">3</span>种</p><p style="padding-left: 27pt;text-indent: -21pt;text-align: left;">划分中每一个都可由某假设覆盖。 </p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 111%;text-align: justify;">注意，如果一实例集合没有被假设空间拆散，那么必然存在某概念（划分），它定义在 实例集之上，但不能由假设空间表示。因此，<span class="s47">H </span>的这种拆散实例集合的能力是其表示这些实 例上定义的目标概念的能力的度量。 </p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 13pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="547" height="1" alt="image" src="机器学习/Image_312.png"/></span></p><p class="s48" style="padding-left: 15pt;text-indent: 0pt;text-align: left;">插图——原书页码： <span class="s21">215</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">Instance space X<span class="p">：实例空间 </span>X</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 14pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="531" height="1" alt="image" src="机器学习/Image_313.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 125pt;text-indent: 0pt;text-align: left;">图 <span class="h4">7-3 </span>被 <span class="h4">8 </span>个假设拆散的包含 <span class="h4">3 </span>实例的集合</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-left: 58pt;text-indent: 0pt;text-align: left;">对每种可能的实例划分，存在一个对应的假设。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">7.4.2 Vapnik-Chervonenkis <span class="s25">维度</span></h3><p style="padding-top: 10pt;padding-left: 6pt;text-indent: 21pt;line-height: 110%;text-align: justify;">拆散一实例集合的能力与假设空间的归纳偏置紧密相关。回忆第 2 章中，一个无偏的假 设空间是能够表示定义在实例空间 <span class="s47">X </span>上每个可能概念（划分）的假设空间。简短地讲，一个 无偏假设空间能够拆散实例空间。那么如果 <span class="s47">H </span>不能拆散 <span class="s47">X</span>，但它可拆散 <span class="s47">X </span>的某个大的子集 <span class="s47">S </span>会怎样？直觉上可以说被拆散的 <span class="s47">X </span>的子集越大，<span class="s47">H </span>的表示能力越强。<span class="s47">H </span>的 VC 维正是这样一种 度量标准。 </p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 47pt;text-indent: -21pt;line-height: 107%;text-align: left;"><span class="p">定义： 定义在实例空间 </span>X <span class="p">上的假设空间 </span>H <span class="p">的 </span><span class="s6">Vapnik-Chervonenkis </span><span class="p">维，或 </span>VC<span class="s6">(</span>H<span class="s6">)</span><span class="p">，是 可被 </span>H <span class="p">拆散的 </span>X <span class="p">的最大有限子集的大小。如果 </span>X <span class="p">的任意有限大的子集可被 </span>H <span class="p">拆散， 那么 </span>VC<span class="s6">(</span>H<span class="s6">)</span><span class="p">≡∞。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s253" style="text-indent: 0pt;line-height: 6pt;text-align: left;">2</p><p style="text-indent: 0pt;text-align: left;"/><p class="s253" style="text-indent: 0pt;line-height: 6pt;text-align: left;">2</p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-left: 5pt;text-indent: 20pt;line-height: 108%;text-align: justify;">注意对于任意有限的<span class="s47">H</span>，<span class="s47">VC</span>(<span class="s47">H</span>)≤log |<span class="s47">H</span>|。为证明这一点，假定<span class="s47">VC</span>(<span class="s47">H</span>)=<span class="s47">d</span>。那么<span class="s47">H</span>需要 2<span class="s259">d</span>个 不同假设来拆散<span class="s47">d</span>个实例。因此 2<span class="s259">d</span>≤|<span class="s47">H</span>|，所以<span class="s47">d</span>=<span class="s47">VC</span>(<span class="s47">H</span>) ≤log |<span class="s47">H</span>|。 </p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s37" style="padding-left: 6pt;text-indent: 0pt;text-align: left;">7.4.2.1 <span class="s20">示例</span></p><p class="s21" style="padding-top: 8pt;padding-left: 6pt;text-indent: 21pt;line-height: 107%;text-align: justify;"><span class="p">为了获得</span>VC<span class="s6">(</span>H<span class="s6">)</span><span class="p">的直觉的意义，考虑下面一些假设空间的例子。首先，假定实例空间</span>X <span class="p">为实数集合</span>X<span class="s6">=</span><span class="s10"></span><span class="p">（例如，描述人的身高</span>height<span class="p">），而且</span>H<span class="p">为实数轴上的区间的集合。换言之， </span>H<span class="p">中的假设形式为</span>a<span class="s6">&lt;</span>x<span class="s6">&lt;</span>b<span class="p">，其中</span>a<span class="p">、</span>b<span class="p">为任意实数。它的</span>VC<span class="s6">(</span>H<span class="s6">)</span><span class="p">是多少？为回答这一问题，必须 找到能被</span>H<span class="p">拆散的</span>X<span class="p">的最大子集。考虑一特定的子集，包含两个不同实例，如</span>S<span class="s6">={3.1, 5.7}</span><span class="p">。 这个</span>S<span class="p">能被</span>H<span class="p">拆散吗？回答是肯定的。例如，以下四个假设（</span><span class="s6">1&lt;</span>x<span class="s6">&lt;2</span><span class="p">），（</span><span class="s6">1&lt;</span>x<span class="s6">&lt;4</span><span class="p">），（</span><span class="s6">4&lt;</span>x<span class="s6">&lt;7</span><span class="p">）和</span></p><p class="s21" style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><span class="p">（</span><span class="s6">1&lt;</span>x<span class="s6">&lt;7</span><span class="p">），可做到这一点。它们表示了</span>S<span class="p">上的四种划分，即不包含任何实例、只包含实例中 的一个、以及包含两个实例。因为我们找到了一个大小为 </span><span class="s6">2 </span><span class="p">的集合，它可被</span>H<span class="p">拆散，所以</span>H <span class="p">的</span>VC<span class="p">维至少为 </span><span class="s6">2</span><span class="p">。大小为 </span><span class="s6">3 </span><span class="p">的集合是否可被拆散？考虑一集合</span>S<span class="s6">={</span>x<span class="s35">0</span><span class="s6">, </span>x<span class="s35">1</span><span class="s6">, </span>x<span class="s35">2</span><span class="s6">}</span><span class="p">包含 </span><span class="s6">3 </span><span class="p">个任意实 例。不失一般性，可假定</span>x<span class="s35">0</span><span class="s6">&lt;</span>x<span class="s35">1</span><span class="s6">&lt;</span>x<span class="s35">2</span><span class="p">。显然，此集合不能被拆散，因为包含</span>x<span class="s35">0</span><span class="p">和</span>x<span class="s35">2</span><span class="p">但不包含</span>x<span class="s35">1</span><span class="p">的 划分将不能由单个的闭区间来表示。因此，</span>S<span class="p">中没有大小为 </span><span class="s6">3 </span><span class="p">的子集可被拆散，因此</span>VC<span class="s6">(</span>H<span class="s6">)=2</span><span class="p">。 注意这里</span>H<span class="p">是无限的，但</span>VC<span class="s6">(</span>H<span class="s6">)</span><span class="p">有限。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">下面考虑的实例集合<span class="s21">S</span>对应<span class="s21">x</span>、<span class="s21">y</span>平面上的点（见图 <span class="s6">7-4</span>）。令<span class="s21">H</span>为此平面内所有线性决策 面的集合。换言之，<span class="s21">H</span>对应有双输入的单个感知器单元的假设空间（见第 <span class="s6">4 </span>章中对感知器的</p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 107%;text-align: left;">讨论）。<span class="s21">H</span>的<span class="s6">VC</span>维是多少？很容易可看出该平面内任意两个不同点可被<span class="s21">H</span>拆散，这是因为我 们可以找到 <span class="s6">4 </span>个线性表面，它们包含没有点、其中一点或两点。<span class="s6">3 </span>个点的集合会怎么样？只 要 <span class="s6">3 </span>个点不共线，就可以找到 <span class="s6">2</span><span class="s46">3</span>个线性表面来拆散它们。当然 <span class="s6">3 </span>个共线的点无法被拆散（与 前例中实轴上 <span class="s6">3 </span>个点无法被拆散同样的理由）。在此<span class="s6">VC</span>维是多少？<span class="s6">2 </span>还是 <span class="s6">3</span>？至少应该是 <span class="s6">3</span>。 为证明<span class="s21">VC</span><span class="s6">(</span><span class="s21">H</span><span class="s6">)&lt;</span><span class="s21">d</span>，必须证明大小为<span class="s21">d</span>的集合都不能被拆散。在此例中，大小为 <span class="s6">4 </span>的集合都不 能被拆散，因此<span class="s21">VC</span><span class="s6">(</span><span class="s21">H</span><span class="s6">)=3</span>。<span class="s6">VC</span>维的定义表示，如果能找到任意一个大小为<span class="s21">d</span>的实例集合，它 可被拆散，那么<span class="s21">VC</span><span class="s6">(</span><span class="s21">H</span><span class="s6">)</span>≥<span class="s21">d</span>。更一般地，可证明，在<span class="s21">r</span>维空间中（如有<span class="s21">r</span>个输入的感知器），线 性决策面的<span class="s6">VC</span>维为<span class="s21">r</span><span class="s6">+1</span>。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 13pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="547" height="1" alt="image" src="机器学习/Image_314.png"/></span></p><p class="s48" style="padding-left: 15pt;text-indent: 0pt;text-align: left;">插图——原书页码： <span class="s21">216</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 14pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="531" height="1" alt="image" src="机器学习/Image_315.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 117pt;text-indent: 0pt;text-align: left;">图 <span class="h4">7-4 </span>在 <span class="s7">x</span>，<span class="s7">y </span>平面中线性决策面的 <span class="h4">VC </span>维为 <span class="h4">3</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s16" style="padding-left: 58pt;text-indent: 0pt;text-align: left;">a<span class="s14">）一个 </span>3 <span class="s14">点集合可被线性决策面拆散。</span>b<span class="s14">）一 </span>3 <span class="s14">点集合不能被拆散。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">最后一个例子，假定<span class="s21">X</span>上每个实例由恰好 <span class="s6">3 </span>个布尔文字的合取表示，而且假定<span class="s21">H</span>中每个 假设由至多 <span class="s6">3 </span>个布尔文字描述。<span class="s21">VC</span><span class="s6">(</span><span class="s21">H</span><span class="s6">)</span>是多少？可证明这个值至少为 <span class="s6">3</span>。将每个实例表示为 一 <span class="s6">3 </span>位字串，对应每个实例的三个文字<span class="s21">l</span><span class="s35">1</span>，<span class="s21">l</span><span class="s35">2</span>和<span class="s21">l</span><span class="s35">3</span>。考虑下面 <span class="s6">3 </span>个实例集合：</p><p class="s21" style="padding-top: 6pt;padding-left: 26pt;text-indent: 0pt;line-height: 144%;text-align: justify;">instance<span class="s35">1</span><span class="p">：</span><span class="s6">100 </span>instance<span class="s35">2</span><span class="p">：</span><span class="s6">010 </span>instance<span class="s35">3</span><span class="p">：</span><span class="s6">001</span></p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 21pt;text-align: left;">这三个实例的集合可被<span class="s21">H</span>拆散，是因为可对任意所希望的划分建立一假设，方法如下： 如果该划分要排除<span class="s21">instance</span><span class="s36">i</span>，就将文字<span class="s10"></span><span class="s21">l</span><span class="s36">i</span>加入到假设中。例如，要包含<span class="s21">instance</span><span class="s35">2</span>，且排除 <span class="s21">instance</span><span class="s35">1</span>和<span class="s21">instance</span><span class="s35">3</span>。那么可使用假设<span class="s10"></span><span class="s21">l</span><span class="s35">1</span>∧<span class="s10"></span><span class="s21">l</span><span class="s35">3</span>。此讨论可很容易地扩展到特征数为<span class="s21">n</span>的情况。 这样，<span class="s21">n</span>个布尔文字合取的<span class="s6">VC</span>维至少为<span class="s21">n</span>。实际上也确实为<span class="s21">n</span>，实际的证明比较困难，因为它 需要说明<span class="s21">n</span><span class="s6">+1 </span>个实例的集合不可能被拆散。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">7.4.3 <span class="s25">样本复杂度和 </span>VC <span class="s25">维</span></h3><p style="padding-top: 10pt;padding-left: 5pt;text-indent: 21pt;line-height: 106%;text-align: left;">前面考虑了“有多少随机抽取训练样例才足以可能近似正确（<span class="s6">PAC</span>）地学习到 <span class="s21">C </span>中任意 目标概念”这个问题（即有多少样例足以以 <span class="s6">1-</span><span class="s47">δ</span>的概率<span class="s47">ε</span><span class="s6">-</span>详尽变型空间？）。使用 <span class="s21">VC</span><span class="s6">(</span><span class="s21">H</span><span class="s6">) </span>作为 <span class="s21">H </span>复杂度的度量，就有可能推导出该问题的另一种解答，类似于前面式 <span class="s6">7.2 </span>中的边界。 新导出的边界（见 <span class="s6">Blumer et al. 1989</span>）为：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="padding-top: 3pt;text-indent: 0pt;line-height: 18pt;text-align: right;">m <span class="s38"> </span><u>1 </u><span class="s33">(4 log</span></p><p class="s190" style="text-indent: 0pt;line-height: 13pt;text-align: right;"><span class="s119"> </span><span class="s42">2</span></p><p class="s33" style="padding-top: 9pt;text-indent: 0pt;text-align: left;">(2 / <span class="s119"> </span>) <span class="s38"> </span>8<i>VC</i>(<i>H </i>) log<span class="s79">2</span></p><p class="s33" style="padding-top: 9pt;text-indent: 0pt;text-align: left;">(13 / <span class="s119"> </span>))</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 27pt;text-indent: 0pt;text-align: left;">（<span class="s6">7.7</span>）</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;text-align: justify;"><span class="p">正如式 </span>7.2 <span class="p">中的边界一样，所需训练样例的数目</span><i>m</i><span class="p">以 </span>1/<span class="s47">δ</span><span class="p">的对数增长。但该边界现在随 着 </span>1/<span class="s47">ε</span><span class="p">的对数乘以线性增长，而不只是线性。特别要指出，前面边界中的</span>ln|<i>H</i>|<span class="p">项被替换为另 一种假设空间复杂度的度量，即</span><i>VC</i>(<i>H</i>)<span class="p">（而</span><i>VC</i>(<i>H</i>)<span class="p">≤</span>log<span class="s35">2</span>|<i>H</i>|<span class="p">）。</span></p><p style="padding-left: 6pt;text-indent: 21pt;text-align: justify;">式 <span class="s6">7.7 </span>对于足以可能近似学习到 <span class="s21">C </span>中任意目标概念所需的训练样例给出了一个上界，对 应于任意希望的<span class="s47">ε</span>和<span class="s47">δ</span>。还可能得到一个下界，如下面定理所概括的（见 <span class="s6">Ehrenfeucht et al. 1989</span>）。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-left: 27pt;text-indent: 21pt;line-height: 120%;text-align: left;">定理 <span class="s187">7.3 </span>样本复杂度下界。考虑任意概念类 <span class="s56">C</span>，且 <span class="s56">VC</span><span class="s16">(</span><span class="s56">C</span><span class="s16">)</span>≥<span class="s16">2</span>，任意学习器 <span class="s56">L</span>，以及任意 <span class="s16">0&lt;</span><span class="s177">ε</span><span class="s16">&lt;1/8</span>， <span class="s16">0&lt;</span><span class="s177">δ</span><span class="s16">&lt;1/100</span>。存在一个分布 <span class="s262">D </span>以及 <span class="s56">C </span>中一个目标概念，当 <span class="s56">L </span>观察到的样例数目小于下式时：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="11" height="1" alt="image" src="机器学习/Image_316.png"/></span></p><p class="s38" style="text-indent: 0pt;line-height: 12pt;text-align: left;">⎢</p><p style="text-indent: 0pt;text-align: left;"/><p class="s33" style="padding-top: 3pt;text-indent: 0pt;line-height: 18pt;text-align: right;">max<span class="s263">⎡</span> <span class="s169">1</span></p><p class="s33" style="padding-top: 9pt;text-indent: 0pt;line-height: 12pt;text-align: left;">log(1/ <span class="s119"> </span>),</p><p class="s33" style="padding-top: 2pt;text-indent: 0pt;line-height: 14pt;text-align: left;"><i>V</i><i>C</i>(<i>C</i>) <span class="s38"></span> 1<span class="s38">⎤</span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="65" height="1" alt="image" src="机器学习/Image_317.png"/></span></p><p class="s38" style="padding-left: 48pt;text-indent: 0pt;line-height: 5pt;text-align: left;">⎥</p><p class="s119" style="padding-left: 187pt;text-indent: 0pt;line-height: 15pt;text-align: left;"><span class="s134">⎣</span><span class="s125">                     </span><span class="s33">32</span><span class="s125">     </span><span class="s134">⎦</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s254" style="text-indent: 0pt;line-height: 5pt;text-align: left;">D</p><p style="text-indent: 0pt;text-align: left;"/><p class="s56" style="padding-top: 8pt;padding-left: 27pt;text-indent: 21pt;text-align: left;">L<span class="s14">将以至少</span><span class="s177">δ</span><span class="s14">的概率输出一假设</span>h<span class="s14">，使</span>error <span class="s16">(</span>h<span class="s16">)&gt;</span><span class="s177">ε</span><span class="s14">。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">该定理说明，若训练样例的数目太少，那么不存在学习器能够<span class="s6">PAC</span>学习到任意非平凡的 <span class="s21">C</span>中每个目标概念。因此，该定理提供了成功的学习所必要的训练样例的数目的下界，它对 于前面上界给出的保证充足的数量的上界是一补充。注意该下界是由概念类<span class="s21">C</span>的复杂度确定 的，而前面的上界由<span class="s21">H</span>确定。为什么？<span class="s46">1</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 5pt;text-indent: 21pt;text-align: justify;"><span class="p">该下界说明式 </span>7.7 <span class="p">给出的上界相当紧凑。因为两个边界都是 </span>1/<span class="s47">δ</span><span class="p">的对数和 </span><i>VC</i>(<i>H</i>)<span class="p">的线性 数量级。在这两个边界中惟一的区别是上界中多出的 </span>log(1/<span class="s47">ε</span>)<span class="p">依赖性。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">7.4.4 <span class="s25">神经网络的 </span>VC <span class="s25">维</span></h3><p style="padding-top: 10pt;padding-left: 6pt;text-indent: 21pt;line-height: 107%;text-align: justify;">对于第 <span class="s6">4 </span>章讨论的人工神经网络，我们有兴趣考虑怎样计算一个互联单元的网络的 <span class="s6">VC </span>维，如由反向传播过程训练的前馈网络。本节给出了一般性的结论，以计算分层无环网络的 <span class="s6">VC </span>维。这一 <span class="s6">VC </span>维可被用于界定训练样例的数量，该数达到多大的才足以按照希望的<span class="s47">ε</span>和 <span class="s47">δ</span>值近似可能正确地学习到一个前馈网络。本节在第一次阅读时可忽略掉，而不失连续性。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">考虑一个由单元组成的网络 <span class="s21">G</span>，它形成一个分层有向无环图。有向无环<span class="s6">(directed acyclic) </span>图是弧带有方向（如单元有输入和输出），但不存在有向环的图。分层（<span class="s6">layered</span>）图中节点 可被划分为层，这样所有第 <span class="s21">l </span>层出来的有向边进入到第 <span class="s21">l</span><span class="s6">+1 </span>层节点。第 <span class="s6">4 </span>章介绍的分层前馈 网络就是这样的分层有向无环图的例子。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;text-align: justify;">可以看出，这样的网络的<span class="s6">VC</span>维的界定可以基于其图的结构和构造该图的基本单元的<span class="s6">VC </span>维。为形式化地描述，首先定义一些术语。令<span class="s21">n</span>为网络<span class="s21">G</span>的输入数目，并且假定只有 <span class="s6">1 </span>个输 出结点。令<span class="s21">G</span>的每个内部单元<span class="s21">N</span><span class="s36">i</span>（即每个非输入节点）有最多<span class="s21">r </span>个输入，并实现一布尔函数 <span class="s21">c</span><span class="s36">i</span>：<span class="s10"></span><span class="s83">r</span>→<span class="s6">{0,1}</span>形成一函数类<span class="s21">C</span>。例如，若内部节点为感知器，那么<span class="s21">C</span>为定义在<span class="s10"></span><span class="s83">r</span>上的线性阈 值函数类。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">现在可定义 <span class="s21">C </span>的 <span class="s21">G</span><span class="s6">-</span>合成（<span class="s21">G</span><span class="s6">-composition</span>）为，在 <span class="s21">G </span>中独立单元都取类 <span class="s21">C </span>中的函数时， 由网络 <span class="s21">G </span>能实现所有函数的类。简单地说，<span class="s21">C </span>的 <span class="s21">G</span><span class="s6">-</span>合成是可由网络 <span class="s21">G </span>表示的假设空间。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 26pt;text-indent: 0pt;text-align: left;">下面的定理界定了 <span class="s21">C </span>的 <span class="s21">G </span>合成的 <span class="s6">VC </span>维，基于 <span class="s21">C </span>的 <span class="s6">VC </span>维和 <span class="s21">G </span>的结构。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 26pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="193" height="1" alt="image" src="机器学习/Image_318.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s16" style="padding-top: 3pt;padding-left: 27pt;text-indent: 0pt;text-align: left;"><span class="s70">1</span><span class="s66"> </span><span class="s14">提示：如果我们在下界中用</span>H<span class="s14">代替</span>C<span class="s14">，当</span>H<span class="s57"></span>C<span class="s14">时会得到</span>m<span class="s14">的一个更紧凑的界限</span></p><p class="s14" style="padding-top: 1pt;padding-left: 26pt;text-indent: 21pt;line-height: 122%;text-align: justify;">定理 <span class="s187">7.4 </span>分层有向无环网络的<span class="s187">VC</span>维。（见<span class="s16">Kearns &amp; Vazirani 1994</span>）令<span class="s56">G</span>为一分层有向无环图，有 <span class="s56">n</span>个输入节点和<span class="s56">s</span>≥<span class="s16">2 </span>个内部节点，每个可有至少<span class="s56">r</span>个输入。令<span class="s56">C</span>为<span class="s16">VC</span>维为<span class="s56">d</span>的<span class="s57"></span><span class="s256">r</span>上的概念类，对应于可 由每个内部节点描述的函数集合。令<span class="s56">C</span><span class="s65">G</span>为<span class="s56">C</span>的<span class="s56">G</span>合成，对应于可由<span class="s56">G</span>表示的函数集合。那么<span class="s56">VC</span><span class="s16">(</span><span class="s56">C</span><span class="s65">G</span><span class="s16">)</span>≤ 2<span class="s56">ds</span><span class="s16">log(</span><span class="s56">es</span><span class="s16">)</span>，其中<span class="s56">e</span>为自然对数底。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: left;">注意这一网络 <span class="s21">G </span>的 <span class="s6">VC </span>维边界随单个单元的 <span class="s6">VC </span>维 <span class="s21">d </span>线性增长，并随 <span class="s21">s</span>（即网络中阈值 单元的数目）的对数乘线性增长。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 26pt;text-indent: 0pt;text-align: left;">假定要考虑的分层有向无环网络中单个节点都是感知器。回忆第 <span class="s6">4 </span>章中提到的，<span class="s21">r</span>输入</p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 0pt;line-height: 107%;text-align: justify;">感知器使用线性决策面来表示<span class="s10"></span><span class="s83">r</span>上的布尔函数。如 <span class="s6">7.4.2.1 </span>节指出的那样，在<span class="s10"></span><span class="s83">r</span>上的线性决 策面的<span class="s6">VC</span>维为<span class="s21">r</span><span class="s6">+1</span>。因此，单独的<span class="s21">r</span>输入感知器<span class="s6">VC</span>维为<span class="s21">r</span><span class="s6">+1</span>。可使用这一结果及上面的定理 来计算包含<span class="s21">s</span>个<span class="s21">r </span>输入感知器的分层无环网络的<span class="s6">VC</span>维边界，如下：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s41" style="text-indent: 0pt;line-height: 7pt;text-align: left;">G</p><p style="text-indent: 0pt;text-align: left;"/><p class="s33" style="padding-top: 4pt;padding-left: 144pt;text-indent: 0pt;text-align: left;">VC(<i>C </i><span class="s83">perceptrons</span><span class="s41"> </span>) <span class="s38"> </span>2(<i>r </i><span class="s38"> </span>1)<i>s </i>log(<i>es</i>)</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s41" style="text-indent: 0pt;line-height: 2pt;text-align: right;">perceptrons</p><p style="padding-left: 27pt;text-indent: 0pt;line-height: 13pt;text-align: left;">现在可以计算，为了在误差<span class="s47">ε</span>范围内以至少 <span class="s6">1-</span><span class="s47">δ</span>的概率学习到来自<span class="s21">C</span><span class="s36">G</span></p><p style="padding-left: 27pt;text-indent: 0pt;line-height: 11pt;text-align: left;">的目标概</p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">念，足够的训练样例数目<span class="s21">m</span>的边界。将上面网络<span class="s6">VC</span>维的表达式代入到式 <span class="s6">7.7</span>，可有：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s33" style="padding-left: 24pt;text-indent: 0pt;line-height: 19pt;text-align: center;"><i>m </i><span class="s38"> </span><u>1 </u>(4 log(2 / <span class="s119"> </span>) <span class="s38"> </span>8<i>VC</i>(<i>H </i>) log(13 / <span class="s119"> </span>))</p><p class="s119" style="padding-left: 24pt;text-indent: 0pt;line-height: 12pt;text-align: center;"></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s33" style="padding-left: 24pt;text-indent: 0pt;line-height: 18pt;text-align: center;"><span class="s38"> </span><u>1 </u>(4 log(2 / <span class="s119"> </span>) <span class="s38"> </span>16(<i>r </i><span class="s38"> </span>1)<i>s </i>log(<i>es</i>) log(13 / <span class="s119"> </span>)) <span class="p">（</span><span class="s6">7.8</span><span class="p">）</span></p><p class="s119" style="padding-left: 107pt;text-indent: 0pt;line-height: 12pt;text-align: left;"></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;line-height: 109%;text-align: left;">如此感知器网络例子所示，上面的定理的作用在于，它提供了一个一般性方法，基于网 络结构和单个单元的 <span class="s6">VC </span>维界定分层无环单元网络的 <span class="s6">VC </span>维。不过，上面的结果不能直接应 用于后向传播的网络，原因有两个。首先，此结果应用于感知器网络，而不是 <span class="s6">sigmoid </span>单元 网络，后者是后向传播算法应用的范围。然而，注意到 <span class="s6">sigmoid </span>单元的 <span class="s6">VC </span>维至少会与感知 器单元的 <span class="s6">VC </span>维一样大。因为通过使用足够的权值，<span class="s6">sigmoid </span>单元可以任意精度逼近感知器。 因此，上面的 <span class="s21">m </span>边界至少会与 <span class="s6">sigmoid </span>单元组成的分层无环网络中的一样大。上述结论的第 二个不足在于，它不能处理后向传播中的训练过程，即开始以约等于 <span class="s6">0 </span>的权值，然后反复地 更新该权值，直到找到一可接受的假设。因此，后向传播带有交叉验证终止标准，它产生一 个更偏好小权值网络的归纳偏置。这一归纳偏置，降低了有效的 <span class="s6">VC </span>维，是上面的分析所不 能涵盖的。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">7.5 <span class="s17">学习的出错界限模型</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 110%;text-align: left;">除了 <span class="s6">PAC </span>学习模型以外，计算学习理论还考虑了多种不同的问题框架。已经研究的学 习问题框架中不同之处在于训练样例的生成方式（被动观察学习样例还是主动提出查询）， 数据中的噪声（有噪声数据还是无差错数据），成功学习的定义（必须学到正确的目标概念， 还是有一定的可能性和近似性），学习器所做的假定（实例的分布情况以及是否 <span class="s21">C</span><span class="s10"></span><span class="s21">H</span>），和 评估学习器的度量标准（训练样例数量、出错数量、计算时间）。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 27pt;text-indent: 0pt;text-align: left;">本节将考虑机器学习的出错界限（<span class="s6">mistake bound</span>）模型，其中学习器评估标准是它在收</p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 111%;text-align: left;">敛到正确假设前总的出错数。如在 <span class="s6">PAC </span>问题框架中一样，这里假定学习器接收到一系列的 训练样例。然而，这里我们希望每接受到一个样例 <span class="s21">x</span>，学习器必须先预测目标值 <span class="s21">c</span><span class="s6">(</span><span class="s21">x</span><span class="s6">)</span>，之后 再由施教者给出正确的目标值。这里考虑的问题是：“在学习器学习到目标概念前，它的预 测会有多少次出错”。这一问题在实际环境下十分重要，其中学习过程与系统运行同时进行， 而不是经过一段离线的训练过程。例如，如果系统要学着预测哪些信用卡购物可被允许，哪 些有欺诈行为，必须基于在使用中搜集的数据，然后我们就要在其收敛到正确目标函数前使 其出错的数目最小化。这里出错的总数可能比训练样例的总数更重要。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 5pt;text-indent: 21pt;line-height: 110%;text-align: justify;"><span class="p">这种出错界限学习问题可以在许多特殊的背景中进行研究。例如，我们可以计算学习器 在 </span>PAC <span class="p">学习到目标概念前出错的次数。在下面的例子中，我们只考虑在学习器确切学到目 标概念前出错的次数。其中确切学到目标概念意味着</span>(<span class="s10"></span><i>x</i>)<i>h</i>(<i>x</i>)=<i>c</i>(<i>x</i>)<span class="p">。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">7.5.1 Find-S <span class="s25">算法的出错界限</span></h3><p style="padding-top: 10pt;padding-left: 5pt;text-indent: 21pt;text-align: left;">再次考虑假设空间<span class="s21">H</span>包含至多<span class="s21">n</span>个布尔文字（<span class="s21">l</span><span class="s35">1 </span><span class="s21">l</span><span class="s36">n</span>或它们的否定）的合取的情况（例如： <span class="s21">Rich</span>∧<span class="s10"></span><span class="s21">Handsome</span>）。回忆第 <span class="s6">2 </span>章中的<span class="s6">Find-S</span>算法，它增量式地计算与训练样例一致的极大特 殊假设。对假设空间<span class="s21">H</span>的<span class="s6">Find-S</span>算法的一个简洁实现如下：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h4 style="padding-left: 27pt;text-indent: 0pt;text-align: left;">Find-S<span class="p">：</span></h4><p class="s21" style="padding-top: 6pt;padding-left: 28pt;text-indent: 0pt;text-align: left;"><span class="s10"> </span><span class="p">将</span>h<span class="p">被始化为最特殊假设</span>l<span class="s35">1</span><span class="p">∧</span><span class="s10"></span>l<span class="s35">1</span><span class="p">∧</span>l<span class="s35">2</span><span class="p">∧</span><span class="s10"></span>l<span class="s35">2</span><span class="s6">…</span>l<span class="s36">n</span><span class="p">∧</span><span class="s10"></span>l<span class="s36">n</span></p><p class="s10" style="padding-left: 28pt;text-indent: 0pt;text-align: left;"> <span class="p">对每个正例 </span><span class="s21">x</span></p><p style="padding-top: 1pt;padding-left: 50pt;text-indent: 0pt;text-align: left;"><span class="s10"> </span>从 <span class="s21">h </span>中移去任何不满足 <span class="s21">x </span>的文字</p><p class="s10" style="padding-top: 1pt;padding-left: 28pt;text-indent: 0pt;text-align: left;"> <span class="p">输出假设 </span><span class="s21">h</span></p><p style="padding-top: 8pt;padding-left: 5pt;text-indent: 21pt;line-height: 110%;text-align: left;">如果 <span class="s21">C</span><span class="s10"></span><span class="s21">H </span>且训练数据无噪声，<span class="s6">Find-S </span>极限时收敛到一个无差错的假设。<span class="s6">Find-S </span>开始于 最特殊的假设（它将每个实例分为反例），然后增量式地泛化该假设，以覆盖观察到的正例。 对于这里使用的假设表示，泛化过程由删除不满足的文字操作构成。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 20pt;line-height: 108%;text-align: left;">是否可以计算出一个边界，以描述 <span class="s6">Find-S </span>在确切学到目标概念 <span class="s21">c </span>前全部的出错次数？ 回答是肯定的。为证明之，首先注意如果 <span class="s21">c</span><span class="s72"></span><span class="s21">H</span>，那么 <span class="s6">Find-S </span>永远不会将一反例错误地划分 为正例。原因为当前假设 <span class="s21">h </span>总比目标概念 <span class="s21">c </span>更特殊。我们只需要计算将正例划分为反例的出 错次数。在 <span class="s6">Find-S </span>确切得到 <span class="s21">c </span>前，这样的出错有多少次？考虑 <span class="s6">Find-S </span>算法遇到的第一个正 例。学习器当然会在分类比例时出错，因为它的初始假设将全部实例都分为反例。然而，结 果将是初始假设中 <span class="s6">2</span><span class="s21">n </span>个项中半数将被删去，只留下 <span class="s21">n </span>个项。对每个后续的正例，若它被当 前假设误分类，剩余 <span class="s21">n </span>个项中至少有一项必须从假设中删去。因此，出错的总数至多为 <span class="s21">n</span><span class="s6">+1</span>。 该出错次数是最坏情况下所需的次数，对应于学习最一般的目标概念：（<span class="s10"></span><span class="s21">x</span>）<span class="s21">c</span><span class="s6">(</span><span class="s21">x</span><span class="s6">)=1</span>，并且 实例序列也是最坏情况下的每次出错只能移去一个文字。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><ol id="l20"><ol id="l21"><ol id="l22"><li style="padding-left: 48pt;text-indent: -42pt;text-align: left;"><h3 style="display: inline;">Halving <span class="s25">算法的出错界限</span></h3><p style="padding-top: 10pt;padding-left: 5pt;text-indent: 21pt;line-height: 109%;text-align: justify;">第二个例子，考虑一个算法，它的执行过程是维护一个变型空间，并在遇到新样例时精 化该变型空间。第 <span class="s6">2 </span>章的候选消除算法和列表后消除算法都是这样的算法。本节我们推导这 样的学习器针对任意有限假设空间 <span class="s21">H </span>最坏情况下出错数量的边界，并再次假定目标概念能 被确切学习到。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 26pt;text-indent: 0pt;text-align: left;">为分析学习过程中出错的数量，必须首先精确指定学习器对每个新实例会作出怎样的预</p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 113%;text-align: justify;">测。假定该预测是在当前变型空间的所有假设中作多数投票得来。如果变型空间中多数假设 将新实例划分为正例，那么该预测由学习器输出。否则输出反例的预测。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 111%;text-align: justify;">这种将变型空间学习和用多数投票来进行后续预测两者结合起来的算法通常被称为 <span class="s6">Halving </span>算法。对任意有限 <span class="s21">H</span>，<span class="s6">Halving </span>算法在确切学习到目标概念前出错的最大次数是多少？ 注意“确切”地学习到目标概念等于说到达一个状态，变型空间中只包含一个假设（如往常 那样假定目标概念 <span class="s21">c </span>在 <span class="s21">H </span>中）。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 5pt;text-indent: 21pt;line-height: 108%;text-align: left;"><span class="p">为推导该出错界限，注意</span>Halving<span class="p">算法只在当前变型空间的多数假设不能正确分类新样 例时出错。在这种情况下，一但正确分类结果提供给学习器后，变型空间可减小到它的最多 一半大小（即只有投少数票的假设被保留）。由于每次出错将变型空间至少减小一半，而且 初始变型空间包含</span>|<i>H</i>|<span class="p">个成员，所以变型空间到只包含一个成员前出错次数最大为</span>log<span class="s35">2</span>|<i>H</i>|<span class="p">。实 际上可证明该边界为</span><span class="s10">⎣</span>log<span class="s35">2</span>|<i>H</i>|<span class="s10">⎦</span><span class="p">。例如，考虑</span>|<i>H</i>|=7 <span class="p">的情况。第一个出错可将</span>|<i>H</i>|<span class="p">减小到最多为 </span>3<span class="p">， 第二次出错就可将其减小到 </span>1<span class="p">。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 6pt;text-indent: 21pt;line-height: 108%;text-align: justify;"><span class="p">注意</span><span class="s10">⎣</span>log<span class="s35">2</span>|<i>h</i>|<span class="s10">⎦</span><span class="p">为最坏情况下的边界，并且有可能</span>Halving<span class="p">算法不出任何差错就确切学习到 目标概念。因为即使多数票结果是正确的，算法仍将移去那些不正确的、少数票假设。若此 情况在整个训练过程中发生，那么变型空间可在不出差错的情况下减小到单个成员。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 111%;text-align: justify;">对 <span class="s6">Halving </span>算法的一个有趣的扩展是允许假设以不同的权值进行投票。第 <span class="s6">6 </span>章描述了贝 叶斯最优分类器，它就在假设中进行加权投票。在贝叶斯最优分类器中，为每个假设赋予的 权值为其描述目标概念的估计后验概率（给定训练数据下）。本节的后面将描述另一基于加 权投票的算法，称为加权多数算法。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 6pt;text-indent: 0pt;text-align: justify;">7.5.3 <span class="s25">最优出错界限</span></h3><p class="s21" style="padding-top: 10pt;padding-left: 5pt;text-indent: 21pt;line-height: 109%;text-align: justify;"><span class="p">上面的分析给出了两个特定算法：</span><span class="s6">Find-S</span><span class="p">和候选消除算法在最坏情况下的出错界限。一 个很有趣的问题是，对于任意概念类</span>C<span class="p">，假定</span>H<span class="s6">=</span>C<span class="p">，最优的出错边界是什么？最优出错边界 是指在所有可能的学习算法中，最坏情况下出错边界中最小的那一个。更精确地说，对任意 学习算法</span>A<span class="p">和任意目标概念</span>c<span class="p">，令</span>M<span class="s36">A</span><span class="s6">(</span>c<span class="s6">)</span><span class="p">代表</span>A<span class="p">为了确切学到</span>c<span class="p">，在所有可能训练样例序列中出</span></p><p class="s33" style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 184%;text-align: justify;"><span class="p">错的最大值。现在对于任意非空概念类</span><span class="s21">C</span><span class="p">，令</span><span class="s21">M</span><span class="s36">A</span><span class="s6">(</span><span class="s21">C</span><span class="s6">)</span><span class="p">≡ </span>max<span class="s52">c</span><span class="s40"></span><span class="s41">C </span><i>M </i><span class="s52">A</span><span class="s41"> </span>(<i>c</i>) <span class="p">。注意上面我们证明 了当</span><span class="s21">C</span><span class="p">是至多</span><span class="s21">n</span><span class="p">个布尔文字描述的概念类时， </span><i>M </i><span class="s52">Find</span><span class="s41"> </span><span class="s40"></span><span class="s41">S </span>(<i>C</i>) <span class="s38"> </span><i>n </i><span class="s38"> </span>1<span class="p">。同时，对任意概念类</span><span class="s21">C</span><span class="p">， 我们有 </span><i>M </i><span class="s52">Halving</span><span class="s41"> </span>(<i>C</i>) <span class="s38"> </span>log<span class="s79">2</span><span class="s42"> </span>(| <i>C </i>|) <span class="p">。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">下面定义概念类 <span class="s21">C </span>的最优出错边界。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 27pt;text-indent: 0pt;text-align: left;">定义： 令<span class="s21">C</span>为任意非空概念类。<span class="s21">C</span>的最优出错界限（<span class="s6">optimal mistake bound</span>）定义为</p><p class="s21" style="padding-top: 1pt;padding-left: 47pt;text-indent: 0pt;text-align: left;">Opt<span class="s6">(</span>C<span class="s6">)</span><span class="p">，是所有可能学习算法</span>A<span class="p">中</span>M<span class="s36">A</span><span class="s6">(</span>C<span class="s6">)</span><span class="p">的最小值。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="padding-top: 2pt;text-indent: 0pt;text-align: right;">Opt<span class="s33">(</span>C<span class="s33">) </span><span class="s38"></span></p><p class="s33" style="padding-top: 3pt;padding-left: 1pt;text-indent: 0pt;line-height: 13pt;text-align: center;">min</p><p class="s41" style="padding-left: 1pt;text-indent: 0pt;line-height: 7pt;text-align: center;">A<span class="s40"></span>learning <span class="s42">_</span>a <span class="s42">lg </span>orithms</p><p class="s30" style="padding-top: 3pt;text-indent: 0pt;text-align: left;">M <span class="s52">A</span><span class="s41"> </span><span class="s33">(</span>C<span class="s33">)</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-top: 1pt;padding-left: 26pt;text-indent: 0pt;text-align: left;"><span class="p">用非形式的语言来讲，该定义表明 </span>Opt<span class="s6">(</span>C<span class="s6">)</span><span class="p">是 </span>C <span class="p">中最困难的那个目标概念使用最不利的</span></p><p style="padding-left: 12pt;text-indent: 0pt;text-align: left;">训练样例序列，用最好的算法的出错次数。<span class="s6">Littlestone</span>（<span class="s6">1987</span>）证明对任意概念类 <span class="s21">C</span>，在 <span class="s21">C</span></p><p style="padding-top: 1pt;padding-left: 12pt;text-indent: 0pt;text-align: left;">的最优出错边界，<span class="s6">Halving </span>算法边界和 <span class="s21">C </span>的 <span class="s6">VC </span>维之间存在一有趣的联系，如下：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s33" style="padding-top: 2pt;padding-left: 125pt;text-indent: 0pt;text-align: left;"><i>VC</i>(<i>C</i>) <span class="s38"> </span><i>Opt</i>(<i>C</i>) <span class="s38"> </span><i>M </i><span class="s52">Halving</span><span class="s41"> </span>(<i>C</i>) <span class="s38"> </span>log<span class="s79">2</span><span class="s42"> </span>(| <i>C </i>|)</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 9pt;padding-left: 33pt;text-indent: 0pt;text-align: left;">更进一步，存在这样的概念类使上面的 <span class="s6">4 </span>个量恰好相等。这样的概念类其中之一是任意</p><p class="s6" style="padding-top: 1pt;padding-left: 12pt;text-indent: 0pt;text-align: left;"><span class="p">有限集合的幂集</span><i>C</i><span class="s36">P</span><span class="p">。在此情况下，</span><i>VC</i>(<i>C</i><span class="s36">P</span>)=|<i>X</i>|=log<span class="s35">2</span>(|<i>C</i><span class="s36">P</span>|)<span class="p">，因此所有这 </span>4 <span class="p">个量相等。</span>Littlestone</p><p class="s6" style="padding-left: 12pt;text-indent: 0pt;text-align: left;"><span class="p">（</span>1987<span class="p">）提供了其他概念类的例子，其中</span><i>VC</i>(<i>C</i>)<span class="p">严格小于</span><i>Opt</i>(<i>C</i>)<span class="p">，</span><i>Opt</i>(<i>C</i>)<span class="p">严格小于</span><i>M</i><span class="s36">Halving</span>(<i>C</i>)<span class="p">。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 12pt;text-indent: 0pt;text-align: left;">7.5.4 <span class="s25">加权多数算法</span></h3><p style="padding-top: 10pt;padding-left: 11pt;text-indent: 21pt;line-height: 111%;text-align: justify;">本节讨论 <span class="s6">Halving </span>算法的更一般的形式，称为加权多数算法。加权多数算法通过在一预 测算法池中进行加权投票来作出预测，并通过改变每个预测算法的权重来学习。这些预测算 法可被看作是 <span class="s21">H </span>中的不同假设，或被看作本身随时间变化的不同学习算法。对于这些预测 算法，所需要的只是在给定一实例时预测目标概念的值。加权多数算法的一个有趣属性是它 可以处理不一致的训练数据。这是因为它不会消除掉与样例不一致的假设，而只是降低其权 重。它的第二个有趣属性是，要计算此算法的出错数量边界，可以用预测算法池中最好的那 个算法的出错数量来计算。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 11pt;text-indent: 21pt;line-height: 107%;text-align: justify;">加权多数算法一开始将每个预测算法赋以权重 <span class="s6">1</span>，然后考虑训练样例。无论何时一预测 算法误分类一新训练样例时，它的权重被乘以某个系数<span class="s47">β</span>，<span class="s6">0</span>≤<span class="s47">β</span>&lt;1。加权多数算法的确切 定义见表 7-1。注意如果<span class="s47">β</span>=0，那么加权多数算法等于 <span class="s6">Halving </span>算法。另一方面，如果为<span class="s47">β </span>选择其他的值，没有一个预测算法会被完全去除。如果一算法误分类一个样例，它在将来会 占较少的票数比例。 </p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 31pt;text-indent: 0pt;text-align: center;">表 <span class="h4">7-1 </span>加权多数算法</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 2pt;text-align: left;"><span><img width="570" height="2" alt="image" src="机器学习/Image_319.png"/></span></p><p class="s56" style="padding-left: 12pt;text-indent: 0pt;text-align: left;">a<span class="s65">i</span><span class="s14">代表算法池</span>A<span class="s14">中第</span>i<span class="s14">个预测算法。</span>w<span class="s65">i</span><span class="s14">代表与</span>a<span class="s65">i</span><span class="s14">相关联的权值。</span></p><p class="s14" style="padding-top: 2pt;padding-left: 12pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span>对所有<span class="s56">i</span>，初始化<span class="s56">w</span><span class="s65">i</span>为 <span class="s16">1</span></p><p class="s56" style="padding-top: 2pt;padding-left: 39pt;text-indent: -27pt;line-height: 122%;text-align: left;"><span class="s55">n </span><span class="s14">对每个训练样例</span><span class="s16">&lt;</span>x<span class="s16">, </span>c<span class="s16">(</span>x<span class="s16">)&gt; </span><span class="s55">n </span><span class="s14">初始化</span>q<span class="s64">0</span><span class="s14">和</span>q<span class="s64">1</span><span class="s14">为 </span><span class="s16">0 </span><span class="s55">n </span><span class="s14">对每个预测算法</span>a<span class="s65">i</span></p><p class="s56" style="padding-left: 75pt;text-indent: -12pt;line-height: 118%;text-align: left;"><span class="s55">n </span><span class="s14">如果</span>a<span class="s65">i</span><span class="s16">(</span>x<span class="s16">)=0</span><span class="s14">，那么</span>q<span class="s64">0</span><span class="s57"></span>q<span class="s64">0</span><span class="s16">+</span>w<span class="s65">i</span><span class="s67"> </span><span class="s14">如果</span>a<span class="s65">i</span><span class="s16">(</span>x<span class="s16">)=1</span><span class="s14">，那么</span>q<span class="s64">1</span><span class="s57"></span>q<span class="s64">1</span><span class="s16">+</span>w<span class="s65">i</span></p><p class="s56" style="padding-left: 57pt;text-indent: -18pt;line-height: 118%;text-align: left;"><span class="s55">n </span><span class="s14">如果</span>q<span class="s64">1</span><span class="s16">&gt;</span>q<span class="s64">0</span><span class="s14">，那么预测</span>c<span class="s16">(</span>x<span class="s16">)=1 </span><span class="s14">如果</span>q<span class="s64">0</span><span class="s16">&gt;</span>q<span class="s64">1</span><span class="s14">，那么预测</span>c<span class="s16">(</span>x<span class="s16">)=0 </span><span class="s14">如果</span>q<span class="s64">1</span><span class="s16">=</span>q<span class="s64">0</span><span class="s14">，那么对</span>c<span class="s16">(</span>x<span class="s16">)</span><span class="s14">随机预测 </span><span class="s16">0 </span><span class="s14">或 </span><span class="s16">1</span></p><p class="s56" style="padding-left: 56pt;text-indent: -18pt;line-height: 118%;text-align: left;"><span class="s55">n </span><span class="s14">对</span>A<span class="s14">中每个预测算法</span>a<span class="s65">i</span><span class="s14">，做： 如果</span>a<span class="s65">i</span><span class="s16">(</span>x<span class="s16">) </span><span class="s57"></span>c<span class="s16">(</span>x<span class="s16">)</span><span class="s14">，那么</span>w<span class="s65">i</span><span class="s57"></span>w<span class="s65">i</span></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 2pt;text-align: left;"><span><img width="570" height="2" alt="image" src="机器学习/Image_320.png"/></span></p><p style="padding-top: 6pt;padding-left: 12pt;text-indent: 21pt;line-height: 113%;text-align: justify;">现在证明，加权多数算法的出错数量边界可以由投票池中最佳预测算法的出错数来表 示。 </p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-left: 32pt;text-indent: 21pt;line-height: 122%;text-align: justify;">定理 <span class="s187">7.5 </span>加权多数算法的相对误差界限。令 <span class="s56">D </span>为任意的训练样例序列，令 <span class="s56">A </span>为任意 <span class="s56">n </span>个预测算 法的集合，令 <span class="s56">k </span>为 <span class="s56">A </span>中任意算法对样例序列 <span class="s56">D </span>的出错次数的最小值。那么使用<span class="s177">β</span><span class="s16">=1/2 </span>的加权多数算 法在 <span class="s56">D </span>上出错次数最多为：</p><p class="s16" style="padding-top: 3pt;padding-left: 48pt;text-indent: 163pt;text-align: left;">2.4(<i>k</i>+log<span class="s64">2</span><i>n</i>)</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s41" style="text-indent: 0pt;line-height: 7pt;text-align: left;">n</p><p style="text-indent: 0pt;text-align: left;"/><p class="s14" style="padding-left: 26pt;text-indent: 21pt;line-height: 126%;text-align: justify;">证明：对定理的证明可通过比较最佳预测算法的最终权重和所有算法的权重之和。令<span class="s56">a</span><span class="s65">j</span>代表<span class="s56">A</span>中 一算法，并且它出错的次数为最优的<span class="s56">k</span>次。与<span class="s56">a</span><span class="s65">j</span>相联系的权重<span class="s56">w</span><span class="s65">j</span>将为<span class="s16">(1/2)</span><span class="s256">k</span>，因为它的初始权重为 <span class="s16">1</span>，并 在每次出错时乘以 <span class="s16">1/2</span>。现在考虑<span class="s56">A</span>中所有<span class="s56">n</span>个算法的权重和<span class="s56">W</span><span class="s16">= </span><span class="s39"></span><span class="s176">i</span><span class="s40"></span><span class="s42">1 </span><span class="s30">w</span><span class="s52">i</span><span class="s41">  </span>。<span class="s56">W</span>初始为<span class="s56">n</span>。对加权多数算 法的每次出错，<span class="s56">W</span>被减小为最多 <span class="s16">3/4 </span><span class="s56">W</span>。其原因是加权投票占有多数的算法最少拥有整个权重<span class="s56">W</span>的一半 值，而这一部分将被乘以因子 <span class="s16">1/2</span>。令<span class="s56">M</span>代表加权多数算法对训练序列<span class="s56">D</span>的总出错次数，哪么最终的总</p><p class="s41" style="text-indent: 0pt;line-height: 7pt;text-align: left;">M</p><p style="text-indent: 0pt;text-align: left;"/><p class="s38" style="padding-top: 7pt;padding-left: 87pt;text-indent: 0pt;line-height: 9pt;text-align: left;">⎛ <span class="s100">3</span><span class="s33"> </span>⎞</p><p style="text-indent: 0pt;text-align: left;"><span><img width="10" height="1" alt="image" src="机器学习/Image_321.png"/></span></p><p class="s38" style="padding-left: 26pt;text-indent: 0pt;line-height: 9pt;text-align: left;"><span class="s265">权重</span><span class="s56">W</span><span class="s14">最多为 </span><span class="s30">n</span>⎜<span class="s33">   </span>⎟</p><p class="s14" style="padding-left: 7pt;text-indent: 0pt;line-height: 9pt;text-align: left;">。因为最终的权重<span class="s56">w</span><span class="s65">j</span>不会比最终总权重大，因此有：</p><p class="s38" style="padding-left: 87pt;text-indent: 0pt;line-height: 14pt;text-align: left;">⎝ <span class="s100">4</span><span class="s33"> </span>⎠</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s41" style="text-indent: 0pt;line-height: 7pt;text-align: left;">k</p><p style="text-indent: 0pt;text-align: left;"/><p class="s38" style="text-indent: 0pt;line-height: 9pt;text-align: right;">⎛ <span class="s100">1</span><span class="s33"> </span>⎞</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s41" style="text-indent: 0pt;line-height: 7pt;text-align: left;">M</p><p style="text-indent: 0pt;text-align: left;"/><p class="s38" style="padding-left: 18pt;text-indent: 0pt;line-height: 9pt;text-align: left;">⎛ <span class="s100">3</span><span class="s33"> </span>⎞</p><p style="text-indent: 0pt;text-align: left;"><span><img width="10" height="1" alt="image" src="机器学习/Image_322.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="10" height="1" alt="image" src="机器学习/Image_323.png"/></span></p><p class="s33" style="padding-left: 134pt;text-indent: 0pt;line-height: 10pt;text-align: center;"><span class="s38">⎜</span>   <span class="s38">⎟</span>   <span class="s116"></span> <i>n</i><span class="s38">⎜</span>   <span class="s38">⎟</span></p><p class="s38" style="text-indent: 0pt;line-height: 14pt;text-align: right;">⎝ <span class="s100">2</span><span class="s33"> </span>⎠</p><p class="s38" style="padding-left: 23pt;text-indent: 0pt;line-height: 14pt;text-align: left;">⎝ <span class="s100">4</span><span class="s33"> </span>⎠</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-top: 2pt;padding-left: 47pt;text-indent: 0pt;text-align: left;">重新安排各项得到：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="76" height="1" alt="image" src="机器学习/Image_324.png"/></span></p><p class="s33" style="padding-top: 2pt;padding-left: 152pt;text-indent: 0pt;line-height: 17pt;text-align: left;"><i>M </i><span class="s38"> </span><span class="s82">(</span><i>k </i><span class="s38"> </span>log<span class="s46">2 </span><i>n</i>) <span class="s38"> </span>2.4(<i>k </i><span class="s38"> </span>log <i>n</i>)</p><p class="s38" style="padding-left: 210pt;text-indent: 0pt;line-height: 2pt;text-align: left;">⎛ ⎞ <span class="s267">2</span></p><ul id="l23"><li style="padding-top: 5pt;padding-left: 189pt;text-indent: -8pt;text-align: right;"><p class="s33" style="display: inline;">log</p></li></ul></li></ol></ol></ol><p class="s92" style="text-indent: 0pt;line-height: 9pt;text-align: center;">3</p><p class="s38" style="text-indent: 0pt;line-height: 9pt;text-align: center;"><span class="s120">2 </span>⎜ ⎟</p><p class="s38" style="text-indent: 0pt;line-height: 12pt;text-align: center;">⎝ <span class="s100">4</span><span class="s33"> </span>⎠</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-left: 27pt;text-indent: 21pt;text-align: left;">定理得证。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 113%;text-align: left;">概括地说，上面的定理说明加权多数算法的出错数量不会大于算法池中最佳算法出错数 量，加上一随着算法池大小对数增长的项，再乘以一常数因子。 </p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: left;">该定理由 <span class="s6">Littlestone </span>&amp; <span class="s6">Warmuth</span>（1991）进一步一般化，证明了对任意 0≤<span class="s47">β</span>&lt;1，上述 边界为： </p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="text-indent: 0pt;text-align: right;">k <span class="s33">log</span></p><p class="s92" style="padding-top: 3pt;padding-left: 6pt;text-indent: 0pt;line-height: 18pt;text-align: left;"> 1 <span class="s38"> </span><span class="s33">log </span><i>n</i></p><p style="text-indent: 0pt;text-align: left;"><span><img width="112" height="1" alt="image" src="机器学习/Image_325.png"/></span></p><p class="s42" style="text-indent: 0pt;line-height: 13pt;text-align: left;">2 <span class="s190"></span><span class="s119"> </span>2</p><p class="s33" style="padding-top: 9pt;text-indent: 0pt;text-align: right;">log</p><p class="s92" style="padding-top: 1pt;text-indent: 0pt;text-align: center;">   2   </p><p class="s268" style="padding-top: 1pt;padding-left: 3pt;text-indent: 0pt;text-align: center;">2 <span class="s33">1 </span><span class="s38"> </span><span class="s119"></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">7.6 <span class="s17">小结和补充读物</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 27pt;text-indent: 0pt;text-align: left;">本章的要点包括： </p><p style="padding-top: 6pt;padding-left: 49pt;text-indent: -21pt;line-height: 107%;text-align: justify;"><span class="s10"> </span>可能近似正确模型（<span class="s6">PAC</span>）针对的算法从某概念类 <span class="s21">C </span>中学习目标概念，使用按 一未知但固定的概念分布中随机抽取的训练样例。它要求学习器可能（以至少 <span class="s6">1-</span><span class="s47">δ</span>的概率）学习到一近似正确（错误率小于<span class="s47">ε</span>）的假设，而计算量和训练样例 数都只随着 <span class="s6">1/</span><span class="s47">δ</span>，<span class="s6">1/</span><span class="s47">ε</span>，实例长度和目标概念长度的多项式级线性增长。</p><p style="padding-top: 1pt;padding-left: 49pt;text-indent: -21pt;text-align: justify;"><span class="s10"> </span>在 <span class="s6">PAC </span>学习模型的框架下，任何使用一有限假设空间 <span class="s21">H</span>（其中 <span class="s21">C</span><span class="s10"></span><span class="s21">H</span>）的一致学 习器，将以概率 <span class="s6">1-</span><span class="s47">δ</span>输出一个目标概念中误差在<span class="s47">ε</span>范围内的假设，所需随机抽 取训练样例数目为 <span class="s21">m</span>，且 <span class="s21">m </span>满足</p><p style="text-indent: 0pt;text-align: left;"><span><img width="1" height="20" alt="image" src="机器学习/Image_326.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="1" height="20" alt="image" src="机器学习/Image_327.png"/></span></p><p class="s33" style="padding-top: 1pt;padding-left: 24pt;text-indent: 0pt;line-height: 19pt;text-align: center;"><i>m </i><span class="s38"> </span><u>1 </u>(ln(1/ <span class="s119"> </span>) <span class="s38"> </span>ln <i>H </i>)</p><p class="s119" style="padding-left: 9pt;text-indent: 0pt;line-height: 12pt;text-align: center;"></p><p style="padding-left: 51pt;text-indent: 0pt;line-height: 14pt;text-align: left;">该式给出了 <span class="s6">PAC </span>模型下成功的学习所需的足够的训练样例数目的边界。</p><p style="padding-top: 1pt;padding-left: 49pt;text-indent: -21pt;line-height: 106%;text-align: justify;"><span class="s10"> </span><span class="s6">PAC </span>学习模型的一个有约束的假定是，学习器预先知道某受限的概念类 <span class="s21">C</span>，它 包含要学习的目标概念。相反，不可知学习（<span class="s6">agnostic learning</span>）考虑更一般的问 题框架，其中学习器不假定目标概念所在的类别。学习器只从训练数据中输出 <span class="s21">H </span>中有最小误差率（可能非 <span class="s6">0</span>）的假设。在这个受限较少的不可知学习模型中，学 习器保证以概率 <span class="s6">1-</span><span class="s47">δ</span>从 <span class="s21">H </span>中最可能有假设中输出错误率小于<span class="s47">ε</span>的假设，要观察 的随机抽取训练样例数目 <span class="s21">m </span>满足：</p><p style="text-indent: 0pt;text-align: left;"><span><img width="1" height="20" alt="image" src="机器学习/Image_328.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="1" height="20" alt="image" src="机器学习/Image_329.png"/></span></p><p class="s33" style="padding-top: 6pt;padding-left: 169pt;text-indent: -22pt;line-height: 74%;text-align: left;"><i>m </i><span class="s38"> </span><u>1 </u>(ln(1/ <span class="s119"> </span>) <span class="s38"> </span>ln <i>H </i>) 2<span class="s119"> </span><span class="s46">2</span></p><p class="s21" style="padding-left: 49pt;text-indent: -21pt;line-height: 107%;text-align: left;"><span class="s10"> </span><span class="p">成功的学习所需的训练例数目很强烈地受到学习器所考虑的假设空间复杂度的 影响。对于假设空间 </span>H <span class="p">复杂度的一个有用的度量是 </span><span class="s6">VC </span><span class="p">维，</span>VC<span class="s6">(</span>H<span class="s6">)</span><span class="p">。</span>VC<span class="s6">(</span>H<span class="s6">)</span><span class="p">是可 被 </span>H <span class="p">拆散（以所有可能方式分割）最大实例子集的大小。</span></p><p class="s6" style="padding-left: 28pt;text-indent: 0pt;text-align: left;"><span class="s10"> </span><span class="p">在 </span>PAC <span class="p">模型下以 </span><i>VC</i>(<i>H</i>)<span class="p">表示的足以导致成功学习的训练样例数目的上界为</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 51pt;text-indent: 0pt;text-align: left;">下界为</p><p class="s30" style="padding-top: 2pt;padding-left: 22pt;text-indent: 0pt;line-height: 18pt;text-align: left;">m <span class="s38"> </span><u>1 </u><span class="s33">(4 log</span></p><p class="s190" style="padding-left: 44pt;text-indent: 0pt;line-height: 13pt;text-align: left;"><span class="s119"> </span><span class="s42">2</span></p><p class="s33" style="padding-top: 8pt;text-indent: 0pt;text-align: left;">(2 / <span class="s119"> </span>) <span class="s38"> </span>8<i>VC</i>(<i>H </i>) log <span class="s79">2</span></p><p class="s33" style="padding-top: 8pt;text-indent: 0pt;text-align: left;">(13 / <span class="s119"> </span>))</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s38" style="text-indent: 0pt;line-height: 12pt;text-align: left;">⎢</p><p style="text-indent: 0pt;text-align: left;"/><p class="s33" style="padding-top: 2pt;padding-left: 129pt;text-indent: 0pt;line-height: 15pt;text-align: left;"><i>m </i><span class="s38"></span> max<span class="s263">⎡</span> <u>1</u> log(1/ <span class="s119"></span><span class="s125"> </span>), <u><i>VC </i></u><u>(</u><u><i>C </i></u><u>) </u><span class="s117"></span> <u>1</u><span class="s263">⎤</span></p><p class="s38" style="text-indent: 0pt;line-height: 12pt;text-align: left;">⎦</p><p style="text-indent: 0pt;text-align: left;"/><p class="s119" style="padding-left: 112pt;text-indent: 0pt;line-height: 19pt;text-align: center;"><span class="s134">⎣</span><span class="s125">                     </span><span class="s33">32</span><span class="s125">     </span><span class="s159">⎥</span></p><p class="s6" style="padding-top: 6pt;padding-left: 49pt;text-indent: -21pt;text-align: left;"><span class="s10"></span>      <span class="p">另一种学习模式称为出错界限模式，它用于分析一个学习器在确切学习到目标 概念之前会产生的误分类次数。例如，</span>Halving<span class="p">算法在学习到</span><i>H</i><span class="p">中的任意目标概 念前会有至多</span><span class="s10">⎣</span>log<span class="s35">2</span>|<i>H</i>|<span class="s10">⎦</span><span class="p">次出错。对任意概念类</span><i>C</i><span class="p">，最坏情况下最佳算法将有</span><i>Opt</i>(<i>C</i>) <span class="p">次出错，其中：</span></p><p class="s6" style="padding-top: 1pt;padding-left: 24pt;text-indent: 0pt;text-align: center;"><i>VC</i>(<i>C</i>)<span class="p">≤</span><i>Opt</i>(<i>C</i>)<span class="p">≤ </span>log<span class="s35">2</span>(|<i>C</i>|)</p><p class="s10" style="padding-left: 49pt;text-indent: -21pt;line-height: 110%;text-align: justify;"> <span class="p">加权多数算法结合了多个预测算法的加权投票来分类新的实例。它基于这些预 测算法在样例序列中的出错来学习每个算法的权值。有趣的是，加权多数算法 产生的错误界限可用算法池中最佳预测算法的出错数来计算。</span></p><p class="s6" style="padding-top: 7pt;padding-left: 5pt;text-indent: 21pt;line-height: 108%;text-align: left;"><span class="p">计算学习理论中许多早期的工作针对的问题是，在给定一个不定长的训练样例序例时， 学习器是否能在极限时确定目标概念。在极限模型下的确定方法由 </span>Gold<span class="p">(1967)给出。关于 此领域的一个好的综述见(</span>Angluin <span class="p">1992)。</span>Vapnik<span class="p">(1982)详细考查了一致收敛（</span>uniform convergence<span class="p">）的问题，而密切相关的 </span>PAC <span class="p">学习模型由 </span>Valiant<span class="p">(1984)提出。本章中</span><span class="s47">ε</span><span class="p">-详尽变 型空间的讨论基于 </span>Haussler<span class="p">(1988)的阐述。在 </span>PAC <span class="p">模型下的一组有用的结论可在 </span>Bluer et al<span class="p">. </span></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 107%;text-align: left;">（1989）中找到。<span class="s6">Kearns </span>&amp; <span class="s6">Vazirani</span>(1994)提供了计算学习理论中许多结论的一个优秀的阐 述。此领域一些早期的文章包括 <span class="s6">Anthsny </span>&amp; <span class="s6">Biggs</span>(1992)和 <span class="s6">Natarajan</span>(1991)。 </p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 110%;text-align: justify;">目前计算学习理论的研究覆盖了许许多多的学习模型和学习算法。许多这方面的研究可 以在计算学习理论（<span class="s6">COLT</span>）的年度会议的论文集中找到。期刊《机器学习》(<span class="s21">Machine </span><span class="s21">Learning</span>) 中一些特殊的栏目也涉及这一主题。 </p><p style="padding-left: 27pt;text-indent: 0pt;text-align: left;">习题</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 27pt;text-indent: 0pt;text-align: left;">7.1 考虑训练一个两输入感知器。给出训练样例数目的上界，以保证学习到的感知器有</p><p style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">90%的置信度，其真实错误率不超过 5%。这一边界是否实际？ </p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 20pt;line-height: 107%;text-align: left;">7.2 考虑概念类 <span class="s21">C </span>的形式为（<span class="s21">a</span>≤<span class="s21">x</span>≤<span class="s21">b</span>）∧（<span class="s21">c</span>≤<span class="s21">y</span>≤<span class="s21">d</span>）其中 <span class="s21">a</span>,<span class="s21">b</span>,<span class="s21">c</span>,<span class="s21">d </span>为区间（0, 99） 间的整数。注意该类中的每个概念对应一个矩形，它的边界是 <span class="s21">x</span>,<span class="s21">y </span>平面的一部分上的整数值。 提示：给定一个该平面上的区间，其边界为点(0, 0)和(<span class="s21">n</span>-1, <span class="s21">n</span>-1)。在此区间内不同的实边</p><p class="s42" style="text-indent: 0pt;line-height: 7pt;text-align: left;">2</p><p style="text-indent: 0pt;text-align: left;"/><p class="s38" style="padding-top: 8pt;padding-left: 80pt;text-indent: 0pt;line-height: 11pt;text-align: left;">⎛ <span class="s264">n</span><span class="s33">(</span><span class="s30">n </span> <span class="s33">1) </span>⎞</p><p style="text-indent: 0pt;text-align: left;"><span><img width="51" height="1" alt="image" src="机器学习/Image_330.png"/></span></p><p class="s38" style="padding-left: 6pt;text-indent: 0pt;line-height: 10pt;text-align: left;"><span class="s219">界矩形的数量为 </span>⎜ ⎟ <span class="s219">。 </span></p><p class="s38" style="padding-left: 80pt;text-indent: 0pt;line-height: 13pt;text-align: left;">⎝ <span class="s100">2</span><span class="s33"> </span>⎠</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">(<span class="s6">a</span>) 给出随机抽取训练样例的数量的上界，使足以保证对 <span class="s21">C </span>中任意目标概念 <span class="s21">c</span>，任一使 用 <span class="s21">H</span>=<span class="s21">C </span>的学习器将以 95%的概率输出一个错误率最多为 0.15 的假设。 </p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 26pt;text-indent: 0pt;text-align: left;">(<span class="s6">b</span>)现假定矩形边界 <span class="s21">a</span>,<span class="s21">b</span>,<span class="s21">c</span>,<span class="s21">d </span>取实数值。重新回答第一个问题。 </p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">7.3 在本章中我们推导了训练样例数量的表达式，使足以保证每个假设的真实错误率不 会差于其观察到的训练错误率<span class="s21">error</span><span class="s36">D</span>(<span class="s21">h</span>)加上<span class="s47">ε</span>。特别地，我们使用了<span class="s6">Hoeffding</span>界限来推导 式 7.3。试推导训练样例数目的另一表达式，使足以保证每个假设的真实错误率不会差于(1+ <span class="s47">γ</span>)<span class="s21">error</span><span class="s36">D</span>(<span class="s21">h</span>)。推导的过程可使用下面的通用的<span class="s6">Chernoff</span>界限。 </p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;text-align: justify;"><span class="s6">Chernoff</span>界限：假定<span class="s21">x</span><span class="s253">1</span>, , <span class="s21">x</span><span class="s36">m</span>，为<span class="s21">m</span>个独立硬币投掷（<span class="s6">Bernonlli</span>实验）的输出，其中每 次实验正面的概率为<span class="s21">Pr</span>[<span class="s21">X</span><span class="s36">i</span>=1]=<span class="s21">p</span>，而反面概率<span class="s21">Pr</span>[<span class="s21">X</span><span class="s36">i</span>=0]=1-<span class="s21">p</span>。定义<span class="s21">S</span>=<span class="s21">X</span><span class="s253">1</span>+<span class="s21">X</span><span class="s253">2</span>+ +<span class="s21">X</span><span class="s36">m</span>为这<span class="s21">m</span>次实 验输出的和。<span class="s21">S</span>/<span class="s21">m</span>的期望值为<span class="s21">E</span>[<span class="s21">S</span>/<span class="s21">m</span>]=<span class="s21">p</span>。<span class="s6">Chernoff</span>界限描述了<span class="s21">S</span>/<span class="s21">m</span>以某因子 0≤<span class="s47">γ</span>≤1 不同于 <span class="s21">p</span>的概率： </p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s189" style="text-indent: 0pt;line-height: 5pt;text-align: left;">2</p><p style="text-indent: 0pt;text-align: left;"/><p class="s33" style="padding-top: 4pt;padding-left: 153pt;text-indent: 0pt;text-align: left;">Pr[<i>S </i>/ <i>m </i><span class="s38"> </span>(1 <span class="s38"> </span><span class="s119"> </span>) <i>p</i>] <span class="s38"> </span><i>e</i><span class="s133"></span><span class="s40"> </span><span class="s41">mp</span><span class="s181"> </span><span class="s42">/ 3 </span><span class="p"> </span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s189" style="text-indent: 0pt;line-height: 5pt;text-align: left;">2</p><p style="text-indent: 0pt;text-align: left;"/><p class="s33" style="padding-top: 4pt;padding-left: 24pt;text-indent: 0pt;text-align: center;">Pr[<i>S </i>/ <i>m </i><span class="s38"> </span>(1<span class="s38"> </span><span class="s119"> </span>) <i>p</i>] <span class="s38"> </span><i>e</i><span class="s133"></span><span class="s40"> </span><span class="s41">mp</span><span class="s181"> </span><span class="s42">/ 2 </span><span class="p"> </span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 106%;text-align: justify;">7.4 考虑一学习问题，其中 <span class="s21">X</span>=<span class="s10"></span>为实数集合，并且 <span class="s21">C</span>=<span class="s21">H </span>为实数上的区间集合， <span class="s21">H</span>={(<span class="s21">a</span>&lt;<span class="s21">x</span>&lt;<span class="s21">b</span>)| <span class="s21">a</span>,<span class="s21">b</span>∈<span class="s10"></span>}。若一假设与此目标概念的 <span class="s21">m </span>个样例一致，那么它错误率至少为<span class="s47">ε </span>的概率是多少？使用 <span class="s6">VC </span>维解决此问题。是否能找到另一种方法基于最基本的原理并且不用 <span class="s6">VC </span>维来解决此问题？ </p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 26pt;text-indent: 0pt;text-align: left;">7.5 考虑对应 <span class="s21">x</span>,<span class="s21">y </span>平面上所有点的实例空间 <span class="s21">X</span>，给出下列假设空间的 <span class="s6">VC </span>维： </p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="padding-left: 26pt;text-indent: 0pt;text-align: left;"><span class="p"> (</span><span class="s6">a</span><span class="p">)</span><span class="s21">H</span><span class="s36">r</span><span class="p">=</span><span class="s21">x</span><span class="p">,</span><span class="s21">y</span><span class="p">平面上所有矩形的集合。即</span><span class="s21">H</span><span class="p">=</span><span class="s33">{((</span>a <span class="s38"> </span>x <span class="s38"> </span>b<span class="s33">) </span><span class="s38"> </span><span class="s33">(</span>c <span class="s38"> </span>y <span class="s38"> </span>d <span class="s33">)) | </span>a<span class="s33">, </span>b<span class="s33">, </span>c<span class="s33">, </span>d <span class="s38"> </span><span class="s38"></span><span class="s33">}</span><span class="p"> </span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 26pt;text-indent: 0pt;text-align: left;"> (<span class="s6">b</span>)<span class="s21">H</span><span class="s36">c</span>=<span class="s21">x</span>,<span class="s21">y</span>平面的圆。在圆内的点被分类为正例。 </p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 27pt;text-indent: 0pt;text-align: left;"> (<span class="s6">c</span>)<span class="s21">H</span><span class="s36">t</span>=<span class="s21">x</span>,<span class="s21">y</span>平面内的三角形。在三角形内的点被分类为正例。 </p><p style="padding-left: 6pt;text-indent: 21pt;text-align: justify;">7.6 写出习题 7.5 中对<span class="s21">H</span><span class="s36">r</span>的一个一致学习器。随机生成一组不同的目标概念，对应平面 上不同的矩形。为每一个目标概念随机生成样例，其中的实例分布为矩形&lt;0, 0&gt;到&lt;100, 100&gt; 内的均匀分布。在图上画出对应训练样例数目的<span class="s21">m</span>的泛化错误率。在同一图上，画出<span class="s47">δ</span>=0.95 时<span class="s47">ε</span>和<span class="s21">m</span>之间理论上的关系曲线。该理论是否与实验相符合？ </p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 108%;text-align: justify;">7.7 考虑假设类<span class="s21">H</span><span class="s36">rd</span><span class="s253">2</span>为<span class="s21">n</span>个布尔变量上的“规则的，深度 2 的决策树”。这样的决策树是 指深度为 2（即有四个叶结点，与根的矩离都为 2），且根的左子结点和右子结点要求包含同 样的变量。例如，下面的树为<span class="s21">H</span><span class="s36">rd</span><span class="s253">2</span>中的一个实例。 </p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 13pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="547" height="1" alt="image" src="机器学习/Image_331.png"/></span></p><p class="s48" style="padding-left: 15pt;text-indent: 0pt;text-align: left;">插图——原书页码： <span class="s21">228</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 14pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="531" height="1" alt="image" src="机器学习/Image_332.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">(<span class="s6">a</span>)以<span class="s21">n</span>的函数形式表示出<span class="s21">H</span><span class="s36">rd</span><span class="s42">2</span>中有多少语法不同的树。 </p><p style="padding-left: 27pt;text-indent: 0pt;line-height: 28pt;text-align: left;"><span class="s6">(b)</span>给出<span class="s6">PAC</span>模型下所需的样例数目上界，使学习到<span class="s21">H</span><span class="s36">rd</span><span class="s42">2</span>错误率为<span class="s47">ε</span>，置信度为<span class="s47">δ</span>。 <span class="s6">(c)</span>考虑下面的对<span class="s21">H</span><span class="s36">rd</span><span class="s42">2</span>类的加权多数算法。开始，<span class="s21">H</span><span class="s36">rd</span><span class="s42">2</span>中所有假设初始权值都为 1。每次</p><p style="padding-left: 5pt;text-indent: 0pt;text-align: justify;">遇到新样例，要基于<span class="s21">H</span><span class="s36">rd</span><span class="s42">2</span>中所有假设的加权投票进行预测。然后，不是消除掉不一致的树， 而是将它们的权值以因子 2 进行削减。此过程最多会有多少次出错？以<span class="s21">H</span><span class="s36">rd</span><span class="s42">2</span>中最佳树的出错 数和<span class="s21">n</span>来表示。 </p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="8" height="1" alt="image" src="机器学习/Image_333.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="8" height="1" alt="image" src="机器学习/Image_334.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="8" height="1" alt="image" src="机器学习/Image_335.png"/></span></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 146%;text-align: justify;"><span class="s6">7.8 </span>本问题主要考虑要本章中的 <span class="s6">PAC </span>分析和第 <span class="s6">5 </span>章讨论的假设评估之间的联系。考虑一 学习任务，其中实例都由 <span class="s21">n </span>个布尔变量描述（如： <span class="s30">x</span><span class="s79">1</span><span class="s42"> </span><span class="s38"> </span><span class="s30">x</span><span class="s79">2</span><span class="s42"> </span><span class="s38"> </span><span class="s30">x</span><span class="s79">3</span><span class="s42"> </span><span class="s33">... </span><span class="s38"> </span><span class="s30">x</span><span class="s52">n</span><span class="s41"> </span>），并且其抽取按照 某固定但未知的概率分布 <span class="s68">D</span>。目标概念已知可由布尔属性或它们的否定的合取来表示（如 <span class="s30">x</span><span class="s79">2</span><span class="s42"> </span><span class="s38"> </span><span class="s30">x</span><span class="s79">5</span><span class="s42"> </span>），并且学习算法使用该概念类作为它的假设空间 <span class="s21">H</span>。一个一致学习器被给予 <span class="s6">100</span></p><p style="padding-left: 6pt;text-indent: 0pt;text-align: justify;">个按 <span class="s68">D </span>抽取的训练样例。它从 <span class="s21">H </span>中输出一个假设 <span class="s21">h</span>，是与所有 <span class="s6">100 </span>个样例一致的（即在这 些训练样例上 <span class="s21">h </span>的错误率为 <span class="s6">0</span>。）</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;text-align: left;"><span class="s6">(a)</span>我们感兴趣的是 <span class="s21">h </span>的真实错误率，即将来按 <span class="s68">D </span>抽取的实例被误分类的概率是多少。 基于上面的信息，能否给出一个区间，使真实错误率落入其中的概率至少为 <span class="s6">95%</span>？如果能， 请描述该区间并简述理由。否则，解释困难所在。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;text-align: right;"><span class="s6">(b)</span>现在抽取 <span class="s6">100 </span>个新的实例，抽取按照分布 <span class="s68">D </span>并相互独立。结果发现 <span class="s21">h </span>将 <span class="s6">100 </span>个新样 例中的 <span class="s6">30 </span>个误分类了。能否给出一个区间使真实错误率落入其中概率约为 <span class="s6">95%</span>？（在这里 忽略以前对训练数据的性能。）如果能够，请描述该区间并简述理由。否则解释困难所在。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 107%;text-align: left;"><span class="s6">(c)</span>即使 <span class="s21">h </span>能够完善地分类训练样例，它仍然把新样例 <span class="s6">30%</span>误分类了。判断这种情况是 对较大的 <span class="s21">n </span>还是较小的 <span class="s21">n </span>更有可能出现。用一句话说明你的回答的理由。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s8" style="padding-left: 118pt;text-indent: 0pt;line-height: 24pt;text-align: left;">第<span class="h1">8</span>章 基于实例的学习</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 47pt;text-indent: 21pt;line-height: 111%;text-align: left;">已知一系列的训练样例，很多学习方法为目标函数建立起明确的一般化描述； 但与此不同，基于实例的学习方法只是简单地把训练样例存储起来。从这些实例中 泛化的工作被推迟到必须分类新的实例时。每当学习器遇到一个新的查询实例，它 分析这个新实例与以前存储的实例的关系，并据此把一个目标函数值赋给新实例。 基于实例的学习方法包括最近邻（<span class="s71">nearest neighbor</span>）法和局部加权回归（<span class="s71">locally weighted regression</span>）法，它们都假定实例可以被表示为欧氏空间中的点。基于实 例的学习方法还包括基于案例的推理（<span class="s71">case-based reasoning</span>），它对实例采用更 复杂的符号表示。基于实例的学习方法有时被称为消极（<span class="s71">lazy</span>）学习法，因为它们 把处理工作延迟到必须分类新的实例时。这种延迟的或消极的学习方法有一个关键 的优点，即它们不是在整个实例空间上一次性地估计目标函数，而是针对每个待分 类新实例作出局部的和相异的估计。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">8.1 <span class="s17">简介</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 113%;text-align: left;">基于实例的学习方法中，最近邻法和局部加权回归法用于逼近实值或离散目标函数，它 们在概念上都很简明。对于这些算法，学习过程只是简单地存储已知的训练数据。当遇到新 的查询实例时，一系列相似的实例被从存储器中取出，并用来分类新的查询实例。这些方法 与其他章讨论的方法相比，一个关键差异是：<span style=" color: #00F;">基于实例的方法可以为不同的待分类查询实例 建立不同的目标函数逼近</span>。事实上，很多技术只建立目标函数的局部逼近，将其应用于与新 查询实例邻近的实例，而从不建立在整个实例空间上都表现良好的逼近。当目标函数很复杂， 但它可用不太复杂的局部逼近描述时，这样做有显著的优势。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 113%;text-align: justify;">基于实例的方法也可以使用更复杂的符号表示法来描述实例。在基于案例的学习中，实 例即以这种方式表示，而且也按照这种方式来确定邻近实例。基于案例的推理已经被应用到 很多任务中，比如，在咨询台上存储和复用过去的经验；根据以前的法律案件进行推理；通 过复用以前求解的问题的相关部分来解决复杂的调度问题。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 113%;text-align: justify;">基于实例方法的一个不足是，分类新实例的开销可能很大。这是因为几乎所有的计算都 发生在分类时，而不是在第一次遇到训练样例时。所以，如何有效地索引训练样例，以减少 查询时所需计算是一个重要的实践问题。此类方法的第二个不足是（尤其对于最近邻法）， 当从存储器中检索相似的训练样例时，它们一般考虑实例的所有属性。如果目标概念仅依赖 于很多属性中的几个时，那么真正最“相似”的实例之间很可能相距甚远。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 110%;text-align: left;">在下一节我们将介绍 <span class="s21">k</span><span class="s6">-</span>近邻（<span class="s21">k</span><span class="s6">-Nearest Neighbor</span>）法，以及这个广泛应用的方法的几个 变体。在此之后我们将讨论局部加权回归法，一种建立目标函数的局部逼近的学习方法，这 种方法可以被看作 <span class="s21">k</span><span class="s6">-</span>近邻法的一般形式。然后我们描述径向基函数（<span class="s6">radial basis function</span>） 网络，这种网络为基于实例的学习算法和神经网络学习算法提供了一个有趣的桥梁。再下一 节讨论基于案例的推理，一种使用符号表示和基于知识的推理（<span class="s6">knowledge-based inference</span>） 的方法。这一节包括了一个基于案例的推理应用实例，用于解决工程设计问题。最后，我们</p><p style="padding-left: 8pt;text-indent: 0pt;text-align: left;">讨论了本章讲述的消极学习方法和本书其他各章的积极（<span class="s6">eager</span>）学习方法间的差异。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-top: 8pt;padding-left: 8pt;text-indent: 0pt;text-align: left;">8.2 k-<span class="s17">近邻法</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 8pt;text-indent: 21pt;line-height: 107%;text-align: justify;">基于实例的学习方法中最基本的是<span class="s21">k</span><span class="s6">-</span>近邻算法。这个算法假定所有的实例对应于<span class="s21">n</span>维欧 氏空间<span class="s10"></span><span class="s83">n</span>中的点。一个实例的最近邻是根据标准欧氏距离定义的。更精确地讲，把任意的 实例<span class="s21">x</span>表示为下面的特征向量：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 20pt;text-indent: 0pt;text-align: center;">&lt;<i>a</i><span class="s35">1</span>(<i>x</i>)<span class="p">，</span><i>a</i><span class="s35">2</span>(<i>x</i>)<span class="p">，</span><span class="s10"></span><i>a</i><span class="s36">n</span>(<i>x</i>)&gt;</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 27pt;text-indent: 0pt;text-align: center;"><span class="p">其中</span>a<span class="s36">r</span><span class="s6">(</span>x<span class="s6">)</span><span class="p">表示实例</span>x<span class="p">的第</span>r<span class="p">个属性值。那么两个实例</span>x<span class="s36">i</span><span class="p">和</span>x<span class="s36">j</span><span class="p">间的距离定义为</span>d<span class="s6">(</span>x<span class="s36">i</span><span class="s6">, </span>x<span class="s36">j</span><span class="s6">)</span><span class="p">，其中：</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="147" height="44" alt="image" src="机器学习/Image_336.png"/></span></p><p class="s41" style="padding-top: 4pt;padding-left: 27pt;text-indent: 0pt;line-height: 6pt;text-align: center;">n</p><p class="s42" style="text-indent: 0pt;line-height: 7pt;text-align: left;">2</p><p style="text-indent: 0pt;text-align: left;"/><p class="s33" style="padding-left: 148pt;text-indent: 0pt;line-height: 19pt;text-align: left;"><span class="s269">d</span><span class="s6">(</span><span class="s21">x</span><span class="s192">i</span><span class="s270">, </span><span class="s21">x</span><span class="s192">j</span><span class="s270">)</span><span class="s10"></span><span class="s6">    </span><span class="s39"></span>(<i>a</i><span class="s52">r</span><span class="s41"> </span>(<i>x</i><span class="s52">i</span><span class="s41"> </span>) <span class="s38"></span> <i>a</i><span class="s52">r</span><span class="s41"> </span>(<i>x </i><span class="s52">j</span><span class="s41"> </span>))</p><p class="s41" style="padding-left: 27pt;text-indent: 0pt;line-height: 7pt;text-align: center;">r <span class="s40"></span><span class="s42">1</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 7pt;text-indent: 21pt;line-height: 113%;text-align: left;">在最近邻学习中，目标函数值可以为离散值也可以为实值。我们先考虑学习以下形式的 离散<span style=" color: #F00;">目标函数</span><span class="s22">f </span><span class="s6">: </span><span class="s10"></span><span class="s83">n</span><span class="s10"></span><span class="s21">V</span>。其中<span class="s21">V</span>是有限集合<span class="s6">{</span><span class="s21">v</span><span class="s35">1</span><span class="s6">, </span><span class="s10"></span><span class="s21">v</span><span class="s36">s</span><span class="s6">}</span>。表 <span class="s6">8-1 </span>给出了<span style=" color: #F00;">逼近离散目标函数</span>的<span class="s21">k-</span></p><p class="s6" style="padding-top: 3pt;padding-left: 7pt;text-indent: 0pt;text-align: left;"><span class="p">近邻算法。正如表中所指出的，这个算法的返回值 </span><span class="s30">f</span><span class="s31">ˆ</span><span class="s33"> </span>(<i>x</i><span class="s36">q</span>)<span class="p">为对</span><i>f</i>(<i>x</i><span class="s36">q</span>)<span class="p">的估计，它就是距离</span><i>x</i><span class="s36">q</span><span class="p">最</span></p><p style="padding-top: 13pt;padding-left: 7pt;text-indent: 0pt;text-align: left;">近的<span class="s21">k</span>个训练样例中最普遍的<span class="s21">f</span>值。如果我们选择<span class="s21">k</span><span class="s6">=1</span>，那么“<span class="s6">1-</span>近邻算法”就把<span class="s21">f</span><span class="s6">(</span><span class="s21">x</span><span class="s36">i</span><span class="s6">)</span>赋给 <span class="s30">f</span><span class="s31">ˆ</span><span class="s33"> </span><span class="s6">(</span><span class="s21">x</span><span class="s36">q</span><span class="s6">)</span>，</p><p style="padding-top: 8pt;padding-left: 7pt;text-indent: 0pt;text-align: left;">其中<span class="s21">x</span><span class="s36">i</span>是最靠近<span class="s21">x</span><span class="s36">q</span>的训练实例。对于较大的<span class="s21">k</span>值，这个算法返回前<span class="s21">k</span>个最靠近的训练实例中最 普遍的<span class="s21">f</span>值。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 121pt;text-indent: 0pt;text-align: left;">表 <span class="h4">8-1 </span>逼近离散值函数<span class="s7">f </span><span class="h4">: </span><span class="s10"></span><span class="s271">n</span><span class="s10"></span><span class="s7">V</span>的<span class="s7">k</span><span class="h4">-</span>近邻算法</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 2pt;text-align: left;"><span><img width="556" height="2" alt="image" src="机器学习/Image_337.png"/></span></p><p class="s14" style="padding-top: 1pt;padding-left: 7pt;text-indent: 18pt;line-height: 14pt;text-align: left;">训练算法：<span class="s272">K-NN(k nearest neighbor learning)</span><span class="s24">确实是分类算法，是按照与数据点最接近 的点的投票来决定该点属于哪个类。</span></p><p class="s16" style="padding-top: 2pt;padding-left: 47pt;text-indent: 0pt;text-align: left;"><span class="s273">·</span><span class="s14">对于每个训练样例</span>&lt;<i>x</i>, <i>f</i>(<i>x</i>)&gt;<span class="s14">，把这个样例加入列表 </span><i>training</i>_<i>examples</i></p><p class="s14" style="padding-top: 3pt;padding-left: 26pt;text-indent: 0pt;text-align: left;">分类算法：</p><p class="s273" style="padding-top: 3pt;padding-left: 47pt;text-indent: 0pt;text-align: left;">·<span class="s14">给定一个要分类的查询实例</span><span class="s56">x</span><span class="s65">q</span></p><p class="s56" style="padding-top: 2pt;padding-left: 68pt;text-indent: 0pt;text-align: left;"><span class="s273">·</span><span class="s14">在</span>training<span class="s16">_</span>examples<span class="s14">中选出最靠近</span>x<span class="s65">q</span><span class="s14">的</span>k<span class="s14">个实例，并用</span>x<span class="s64">1</span><span class="s57"></span>x<span class="s65">k</span><span class="s14">表示</span></p><p class="s273" style="padding-top: 2pt;padding-left: 68pt;text-indent: 0pt;text-align: left;">·<span class="s14">返回</span></p><p class="s41" style="padding-top: 6pt;padding-left: 45pt;text-indent: 0pt;line-height: 6pt;text-align: center;">k</p><p class="s41" style="text-indent: 0pt;line-height: 18pt;text-align: left;">q                                    <span class="s121"></span><span class="s89">         </span>i</p><p style="text-indent: 0pt;text-align: left;"/><p class="s33" style="padding-left: 147pt;text-indent: 0pt;line-height: 15pt;text-align: left;"><i>f</i><span class="s31">ˆ </span>(<i>x </i>) <span class="s38"> </span>arg max <span class="s119"> </span>(<i>v</i>, <i>f </i>(<i>x </i>))</p><p class="s41" style="text-indent: 0pt;line-height: 8pt;text-align: right;">v<span class="s40"></span>V</p><p class="s16" style="padding-top: 5pt;padding-left: 47pt;text-indent: 0pt;text-align: left;"><span class="s14">其中如果 </span><i>a</i>=<i>b </i><span class="s14">那么</span><span class="s127"></span>(<i>a</i>, <i>b</i>)=1<span class="s14">，否则</span><span class="s127"></span>(<i>a</i>, <i>b</i>)=0<span class="s14">。</span></p><p class="s41" style="padding-top: 1pt;padding-left: 7pt;text-indent: 0pt;text-align: left;">i<span class="s40"></span><span class="s42">1</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 2pt;text-align: left;"><span><img width="557" height="2" alt="image" src="机器学习/Image_338.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 7pt;text-indent: 21pt;text-align: justify;">图 <span class="s6">8-1 </span>图解了一种简单情况下的<span class="s21">k</span><span class="s6">-</span>近邻算法，在这里实例是二维空间中的点，目标函数 具有布尔值。正反训练样例用“<span class="s6">+</span>”和“<span class="s6">-</span>”分别表示。图中也画出了一个查询点<span class="s21">x</span><span class="s36">q</span>。注意在 这幅图中，<span class="s6">1-</span>近邻算法把<span class="s21">x</span><span class="s36">q</span>分类为正例，然而 <span class="s6">5-</span>近邻算法把<span class="s21">x</span><span class="s36">q</span>分类为反例。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 15pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="547" height="1" alt="image" src="机器学习/Image_339.png"/></span></p><p class="s48" style="padding-left: 17pt;text-indent: 0pt;text-align: left;">插图——原书页码： <span class="s21">233</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 16pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="531" height="1" alt="image" src="机器学习/Image_340.png"/></span></p><h4 style="padding-left: 37pt;text-indent: 146pt;text-align: left;"><span class="p">图 </span>8-1 <i>k</i>-<span class="p">近邻算法</span></h4><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-left: 37pt;text-indent: 0pt;line-height: 120%;text-align: justify;">左图画出了一系列的正反训练样例和一个要分类的查询实例<span class="s56">x</span><span class="s65">q</span>。<span class="s16">1-</span>近邻算法把<span class="s56">x</span><span class="s65">q</span>分类为正例，然而 <span class="s16">5-</span>近邻算法把<span class="s56">x</span><span class="s65">q</span>分类为反例。右图是对于一个典型的训练样例集合 <span class="s16">1-</span>近邻算法导致的决策面。围绕 每个训练样例的凸多边形表示最靠近这个点的实例空间（即这个空间中的实例会被 <span class="s16">1-</span>近邻算法赋予 该训练样例所属的分类）。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 143%;text-align: justify;"><span class="s21">k</span><span class="s6">-</span>近邻法隐含考虑的假设空间<span class="s21">H</span>的特性是什么呢？注意<span class="s22">k</span><span class="s19">-</span><span style=" color: #F00;">近邻算法从来不形成关于目标 函数</span><span class="s22">f</span><span style=" color: #F00;">的明确的一般假设 </span><span class="s30">f</span><span class="s31">ˆ</span><span class="s33"> </span>。它仅在需要时计算每个新查询实例的分类。然而，我们依然可</p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: justify;">以问：隐含的一般函数是什么？或者说，如果保持训练样例不变，并用<span class="s21">X</span>中的每个可能实例 查询算法，会得到什么样的分类？图 <span class="s6">8-1 </span>中的右图画出了 <span class="s6">1-</span>近邻算法在整个实例空间上导致 的决策面形状。决策面是围绕每个训练样例的凸多边形的合并。对于每个训练样例，多边形 指出了一个查询点集合，它的分类完全由相应训练样例决定。在这个多边形外的查询点更接 近其他的训练样例。这种类型的图经常被称为这个训练样例集合的<span class="s6">Voronoi</span>图 <span class="s9">①</span><span class="s253"> </span><span class="s6">(Voronoi diagram)</span>。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">对前面的<span class="s21">k</span><span class="s6">-</span>近邻算法作简单的修改后，它就可被用于逼近连续值的目标函数。为了实现 这一点，我们让算法计算<span class="s21">k</span>个最接近样例的平均值，而不是计算其中的最普遍的值。更精确 地讲，为了逼近一个实值目标函数<span class="s21">f</span><span class="s6">:</span><span class="s10"></span><span class="s46">n</span><span class="s10"></span>，我们只要把算法中的公式替换为：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="padding-top: 13pt;text-indent: 0pt;line-height: 7pt;text-align: right;">f<span class="s31">ˆ</span><span class="s33"> (</span>x</p><p class="s106" style="text-indent: 0pt;line-height: 18pt;text-align: left;"><span class="s41">i</span><span class="s40"></span><span class="s42">1</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s41" style="text-indent: 0pt;line-height: 7pt;text-align: left;">k</p><p style="text-indent: 0pt;text-align: left;"/><p class="s30" style="padding-top: 6pt;padding-left: 52pt;text-indent: 0pt;line-height: 13pt;text-align: left;">f <span class="s33">(</span>x<span class="s52">i</span><span class="s41"> </span><span class="s33">)</span></p><p class="s100" style="padding-left: 3pt;text-indent: 0pt;line-height: 1pt;text-align: left;">) <span class="s38"> </span><span class="p">（ ）</span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="69" height="1" alt="image" src="机器学习/Image_341.png"/></span></p><p class="s192" style="padding-left: 191pt;text-indent: 0pt;line-height: 20pt;text-align: left;">q <span class="s212">k</span><span class="s30"> </span><span class="s6">8.1</span></p><h3 style="padding-top: 20pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">8.2.1 <span class="s25">距离加权最近邻算法</span></h3><p style="padding-top: 10pt;padding-left: 5pt;text-indent: 21pt;text-align: justify;">对<span class="s21">k</span><span class="s6">-</span>近邻算法的一个显而易见的改进是对<span class="s21">k</span>个近邻的贡献加权，根据它们相对查询点<span class="s21">x</span><span class="s36">q</span>的 距离，将较大的权值赋给较近的近邻。例如，在表 <span class="s6">8-1 </span>逼近离散目标函数的算法中，我们可 以根据每个近邻与<span class="s21">x</span><span class="s36">q</span>的距离平方的倒数加权这个近邻的“选举权”。方法是通过用下式取代 表 <span class="s6">8-1 </span>算法中的公式来实现：</p><p class="s41" style="padding-top: 20pt;text-indent: 0pt;line-height: 6pt;text-align: right;">k</p><p class="s41" style="text-indent: 0pt;line-height: 18pt;text-align: left;">q                                    <span class="s135"></span><span class="s136">  </span>i                        i</p><p style="text-indent: 0pt;text-align: left;"/><p class="s33" style="padding-left: 142pt;text-indent: 0pt;line-height: 15pt;text-align: left;"><i>f</i><span class="s31">ˆ </span>(<i>x </i>) <span class="s38"> </span>arg max <i>w </i><span class="s119"> </span>(<i>v</i>, <i>f </i>(<i>x </i>))</p><p style="padding-top: 27pt;padding-left: 80pt;text-indent: 0pt;text-align: left;">（<span class="s6">8.2</span>）</p><p class="s41" style="text-indent: 0pt;line-height: 8pt;text-align: right;">v<span class="s40"></span>V</p><p class="s41" style="padding-top: 1pt;padding-left: 15pt;text-indent: 0pt;text-align: left;">i<span class="s40"></span><span class="s42">1</span></p><p style="padding-top: 32pt;padding-left: 26pt;text-indent: 0pt;text-align: left;">其中： <span class="s30">w</span><span class="s52">i</span><span class="s41"> </span><span class="s38"></span></p><p class="s33" style="padding-top: 25pt;padding-left: 1pt;text-indent: 0pt;text-align: center;">1</p><p style="text-indent: 0pt;text-align: left;"><span><img width="63" height="1" alt="image" src="机器学习/Image_342.png"/></span></p><p class="s30" style="padding-top: 2pt;padding-left: 1pt;text-indent: 0pt;line-height: 9pt;text-align: center;">d <span class="s33">(</span>x <span class="s33">, </span>x <span class="s33">)</span><span class="s46">2</span></p><p class="s41" style="padding-left: 101pt;text-indent: 0pt;line-height: 7pt;text-align: left;">q i</p><p style="padding-top: 20pt;text-indent: 0pt;text-align: right;">（<span class="s6">8.3</span>）</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 26pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="193" height="1" alt="image" src="机器学习/Image_343.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-top: 6pt;padding-left: 5pt;text-indent: 1pt;line-height: 125%;text-align: left;"><span class="s13">①</span>译注：又称梯森多边形（<span class="s16">Thiessen Polygons</span>），可以理解为对空间的一种分割方式，一个梯森多边形内的 任一点到本梯森多变形中心点的距离都小于到其他梯森多边形中心点的距离。</p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 136%;text-align: left;">为了处理查询点<span class="s21">x</span><span class="s36">q</span>恰好匹配某个训练样例<span class="s21">x</span><span class="s36">i</span>，从而导致分母为 <span class="s6">0 </span>的情况，我们令这种情 况下的 <span class="s30">f</span><span class="s31">ˆ</span><span class="s33"> </span><span class="s6">(</span><span class="s21">x</span><span class="s36">q</span><span class="s6">)</span>等于<span class="s21">f</span><span class="s6">(</span><span class="s21">x</span><span class="s36">i</span><span class="s6">)</span>。如果有多个这样的训练样例，我们使用它们中占多数的分类。</p><p style="padding-top: 14pt;padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: left;">我们也可以用类似的方式对实值目标函数进行距离加权，只要用下式替换表 <span class="s6">8-1 </span>中的公 式：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s41" style="text-indent: 0pt;line-height: 7pt;text-align: left;">q</p><p style="text-indent: 0pt;text-align: left;"/><p class="s30" style="padding-top: 13pt;text-indent: 0pt;text-align: right;">f<span class="s31">ˆ</span><span class="s33"> (</span>x</p><p class="s30" style="text-indent: 0pt;line-height: 18pt;text-align: left;"><span class="s39"></span><span class="s176">i</span><span class="s40"></span><span class="s42">1 </span>w<span class="s52">i</span><span class="s41">  </span>f <span class="s33">(</span>x<span class="s52">i</span><span class="s41"> </span><span class="s33">)</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s41" style="padding-top: 4pt;text-indent: 0pt;text-align: center;">k</p><p style="text-indent: 0pt;text-align: left;"><span><img width="84" height="1" alt="image" src="机器学习/Image_344.png"/></span></p><p class="s41" style="text-indent: 0pt;line-height: 7pt;text-align: left;">k</p><p style="text-indent: 0pt;text-align: left;"/><p class="s33" style="padding-top: 3pt;text-indent: 0pt;line-height: 11pt;text-align: left;">) <span class="s38"></span></p><p class="s106" style="padding-left: 35pt;text-indent: 0pt;line-height: 19pt;text-align: left;"><span class="s41">i</span><span class="s40"></span><span class="s42">1 </span><span class="s250">w</span><span class="s166">i</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: right;">（<span class="s6">8.4</span>）</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;line-height: 136%;text-align: justify;"><span class="p">其中</span>w<span class="s36">i</span><span class="p">的定义与公式（</span><span class="s6">8.3</span><span class="p">）中相同。注意公式（</span><span class="s6">8.4</span><span class="p">）中的分母是一个常量，它将不同 权值的贡献归一化（例如，它保证如果对所有的训练样例</span>x<span class="s36">i</span><span class="p">，</span>f<span class="s6">(</span>x<span class="s36">i</span><span class="s6">)=</span>c<span class="p">，那么 </span><span class="s30">f</span><span class="s31">ˆ </span><span class="s6">(</span>x<span class="s36">q</span><span class="s6">)</span><span class="s10"></span>c<span class="p">）。</span></p><p style="padding-top: 14pt;padding-left: 5pt;text-indent: 21pt;line-height: 143%;text-align: left;">注意以上<span class="s6">k-</span>近邻算法的所有变体都只考虑<span class="s6">k</span>个近邻以分类查询点。如果使用按距离加权， 那么允许所有的训练样例影响<span class="s21">x</span><span class="s36">q</span>的分类事实上没有坏处，因为非常远的实例对 <span class="s30">f</span><span class="s31">ˆ</span><span class="s33"> </span><span class="s6">(</span><span class="s21">x</span><span class="s36">q</span><span class="s6">)</span>的影响</p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: justify;">很小。考虑所有样例的惟一不足是会使分类运行得更慢。如果分类一个新的查询实例时考虑 所有的训练样例，我们称此为全局（<span class="s6">global</span>）法。如果仅考虑最靠近的训练样例，我们称此 为局部（<span class="s6">local</span>）法。当公式（<span class="s6">8.4</span>）的法则被应用为全局法时，它被称为<span class="s6">Shepard</span>法（<span class="s6">Shepard 1968</span>）。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 6pt;text-indent: 0pt;text-align: justify;">8.2.2 <span class="s25">对 </span><i>k</i>-<span class="s25">近邻算法的说明</span></h3><p class="s18" style="padding-top: 10pt;padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">按距离加权的 <span class="s22">k</span><span class="s19">-</span>近邻算法是一种非常有效的归纳推理方法。它对训练数据中的噪声有很 好的鲁棒性，而且当给定足够大的训练集合时它也非常有效<span style=" color: #000;">。注意通过取 </span><span class="s21">k </span><span style=" color: #000;">个近邻的加权平 均，可以消除孤立的噪声样例的影响。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 5pt;text-indent: 21pt;text-align: justify;"><i>k</i>-<span class="p">近邻算法的归纳偏置</span>(inductive bias)<span class="p">是什么呢？通过分析图 </span>8-1 <span class="p">中的示例，可以很容易 地理解这种算法分类新查询实例的根据。它的归纳偏置对应于假定：</span><span class="s18">一个实例的分类</span><span class="s22">x</span><span class="s130">q</span><span class="s18">最相 似于在欧氏空间中它附近的实例的分类。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 109%;text-align: justify;">应用 <span class="s21">k</span><span class="s6">-</span>近邻算法的一个实践问题是，实例间的距离是根据实例的所有属性（也就是包含 实例的欧氏空间的所有坐标轴）计算的。这与那些只选择全部实例属性的一个子集的方法不 同，例如决策树学习系统。为了理解这种策略的影响，考虑把 <span class="s21">k</span><span class="s6">-</span>近邻算法应用到这样一个问 题：每个实例由 <span class="s6">20 </span>个属性描述，但在这些属性中仅有 <span class="s6">2 </span>个与它的分类是有关。在这种情况</p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 107%;text-align: justify;">下，这两个相关属性的值一致的实例可能在这个 <span class="s6">20 </span>维的实例空间中相距很远。结果，依赖 这 <span class="s6">20 </span>个属性的相似性度量会误导 <span class="s21">k</span><span class="s6">-</span>近邻算法的分类。近邻间的距离会被大量的不相关属性 所支配。这种由于存在很多不相关属性所导致的难题，有时被称为<span style=" color: #00F;">维度灾难（</span><span class="s63">curse of dimensionality</span><span style=" color: #00F;">）。最近邻方法对这个问题特别敏感。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 111%;text-align: justify;">解决该问题的一个有趣的方法是，<span style=" color: #00F;">（</span><span class="s63">1</span><span style=" color: #00F;">）当计算两个实例间的距离时对每个属性加权。这 相当于按比例缩放欧氏空间中的坐标轴，缩短对应于不太相关属性的坐标轴，拉长对应于更 相关的属性的坐标轴。</span>每个坐标轴应伸展的数量可以通过交叉验证的方法自动决定。具体做 法如下，首先假定使用因子<span class="s21">z</span><span class="s36">j</span>伸展（乘）第<span class="s21">j</span>根坐标轴，选择<span class="s21">z</span><span class="s36">j</span>的各个值<span class="s21">z</span><span class="s35">1</span><span class="s10"></span><span class="s21">z</span><span class="s36">n</span>以使学习算法的</p><p class="s21" style="padding-left: 6pt;text-indent: 0pt;line-height: 110%;text-align: justify;"><span class="p">真实分类错误率最小化。其次，这个真实错误率可以使用交叉验证来估计。所以，一种算法 是随机选取现有数据的一个子集作为训练样例，然后决定</span>z<span class="s35">1</span><span class="s10"></span>z<span class="s36">n</span><span class="p">的值使剩余样例的分类错误 率最小化。通过多次重复这个处理过程，可以使加权因子的估计更加准确。这种伸展坐标轴 以优化</span>k<span class="s6">-</span><span class="p">近邻算法的过程，提供了一种抑制无关属性影响的机制。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 108%;text-align: justify;"><span style=" color: #00F;">（</span><span class="s63">2</span><span style=" color: #00F;">）另外一种更强有力的方法是从实例空间中完全消除最不相关的属性</span>。这等效于设 置某个缩放因子<span class="s21">z</span><span class="s36">j</span>为 <span class="s6">0</span>。<span class="s6">Moore &amp; Lee</span>（<span class="s6">1994</span>）讨论了有效的交叉验证方法，为<span class="s21">k</span><span class="s6">-</span>近邻算法选 择相关的属性子集。确切地讲，他们探索了基于“<span style=" color: #00F;">留一法”（</span><span class="s63">leave-one-out</span><span style=" color: #00F;">）</span>的交叉验证，在 这种方法中，<span class="s21">m</span>个训练实例的集合以各种可能方式被分成<span class="s21">m</span><span class="s6">-1 </span>个实例的训练集合和 <span class="s6">1 </span>个实例 的测试集合。这种方法在<span class="s21">k</span><span class="s6">-</span>近邻算法中是容易实现的，因为每一次重新定义训练集时不需要 额外的训练工作。注意上面的两种方法都可以被看作以某个常量因子伸展坐标轴。另外一种 可选的做法是使用一个在实例空间上变化的值伸展坐标轴。这样增加了算法重新定义距离度 量的自由度，然而它也增加了过度拟合的风险。所以，局部伸展坐标轴的方法是不太常见的。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 109%;text-align: justify;"><span style=" color: #00F;">应用</span><span class="s58">k</span><span class="s63">-</span><span style=" color: #00F;">近邻算法的另外一个实践问题是如何建立高效的索引。</span>因为这个算法推迟所有的 处理，直到接收到一个新的查询，所以处理每个新查询可能需要大量的计算。目前已经开发 了很多方法用来对存储的训练样例进行索引，以便在增加一定存储开销情况下更高效地确定 最近邻。一<span style=" color: #00F;">种索引方法是</span><span class="s58">kd</span><span class="s63">-tree</span>（<span class="s6">Bentley 1975</span>；<span class="s6">Friedman et al. 1977</span>），它把实例存储在树的 叶结点内，邻近的实例存储在同一个或附近的结点内。通过测试新查询<span class="s21">x</span><span class="s36">q</span>的选定属性，树的 内部结点把查询<span class="s21">x</span><span class="s36">q</span>排列到相关的叶结点。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 6pt;text-indent: 0pt;text-align: justify;">8.2.3 <span class="s25">术语注解</span></h3><p style="padding-top: 10pt;padding-left: 6pt;text-indent: 21pt;line-height: 113%;text-align: justify;">在关于最近邻法和局部加权回归法的很多文献中，使用了一些来自统计模式识别领域的 术语。在阅读这些文献时，知道下列术语是有帮助的：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 69pt;text-indent: 0pt;text-align: left;"><span class="s128">· </span>回归（<span class="s6">Regression</span>）的含义是逼近一个实值目标函数。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 69pt;text-indent: 0pt;text-align: left;"><span class="s128">· </span><span class="p">残差（</span>Residual<span class="p">）是逼近目标函数时的误差 </span><span class="s30">f</span><span class="s31">ˆ </span>(<i>x</i>)- <i>f</i>(<i>x</i>)<span class="p">。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s19" style="padding-top: 1pt;padding-left: 48pt;text-indent: 21pt;line-height: 107%;text-align: left;"><span class="s274">· </span><span class="s18">核函数（</span>Kernel function<span class="s18">）是一个距离函数，它用来决定每个训练样例的 权值。换句话说，核函数就是使</span><i>w</i><span class="s130">i</span>=<i>K</i>(<i>d</i>(<i>x</i><span class="s130">i</span>, <i>x</i><span class="s130">q</span>))<span class="s18">的函数</span><i>K</i><span class="s18">。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">8.3 <span class="s17">局部加权回归</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: left;"><span class="p">前一节描述的最近邻方法可以被看作在单一的查询点</span>x<span class="s6">=</span>x<span class="s36">q</span><span class="p">上逼近目标函数</span>f<span class="s6">(</span>x<span class="s6">)</span><span class="p">。局部加 权回归是这种方法的推广。它在环绕</span>x<span class="s36">q</span><span class="p">的局部区域内为目标函数</span>f<span class="p">建立明确的逼近。局部加 权回归使用附近的或距离加权的训练样例来形成这种对</span>f<span class="p">的局部逼近。例如，我们可以使用 线性函数、二次函数、多层神经网络或者其他函数形式在环绕</span>x<span class="s36">q</span><span class="p">的邻域内逼近目标函数。“局 部加权回归”名称中，之所以叫“局部”是因为目标函数的逼近仅仅根据查询点附近的数据， 之所以叫“加权”是因为每一个训练样例的贡献是由它与查询点间的距离加权的，之所以叫 “回归”是因为统计学习界广泛使用这个术语来表示逼近实数值函数的问题。</span></p><p style="padding-top: 2pt;padding-left: 5pt;text-indent: 21pt;line-height: 176%;text-align: justify;">给定一个新的查询实例<span class="s21">x</span><span class="s36">q</span>，局部加权回归的一般方法是建立一个逼近 <span class="s30">f</span><span class="s31">ˆ </span>，使 <span class="s30">f</span><span class="s31">ˆ </span>拟合环绕 <span class="s21">x</span><span class="s36">q</span>的邻域内的训练样例。然后用这个逼近来计算 <span class="s30">f</span><span class="s31">ˆ </span><span class="s6">(</span><span class="s21">x</span><span class="s36">q</span><span class="s6">)</span>的值，也就是为查询实例估计的目标 值输出。然后 <span class="s30">f</span><span class="s31">ˆ</span><span class="s33"> </span>的描述被删除，因为对于每一个独立的查询实例都会计算不同的局部逼近。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">8.3.1 <span class="s25">局部加权线性回归</span></h3><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;text-align: justify;">下面，我们先考虑局部加权回归的一种情况，即使用如下形式的线性函数来逼近<span class="s21">x</span><span class="s36">q</span>邻域 的目标函数<span class="s21">f</span>：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 24pt;text-indent: 0pt;text-align: center;"><span class="s30">f</span><span class="s31">ˆ</span><span class="s33"> </span><span class="s6">(</span>x<span class="s6">)=</span>w<span class="s35">0</span><span class="s6">+</span>w<span class="s35">1</span>a<span class="s35">1</span><span class="s6">(</span>x<span class="s6">)+</span><span class="s10"></span><span class="s6">+</span>w<span class="s36">n</span>a<span class="s36">n</span><span class="s6">(</span>x<span class="s6">)</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 26pt;text-indent: 0pt;text-align: left;"><span class="p">和前面一样，</span>a<span class="s36">i</span><span class="s6">(</span>x<span class="s6">)</span><span class="p">表示实例</span>x<span class="p">的第</span>i<span class="p">个属性值。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;text-align: justify;">回忆第 <span class="s6">4 </span>章中我们讨论的梯度下降方法，在拟合以上形式的线性函数到给定的训练集合 时，它被用来找到使误差最小化的系数<span class="s21">w</span><span class="s35">0</span><span class="s10"></span><span class="s21">w</span><span class="s36">n</span>。在那一章中我们感兴趣的是目标函数的全局 逼近。所以当时我们推导出的权值选择方法是使训练集合<span class="s21">D</span>上的误差平方和最小化，即：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="padding-top: 3pt;padding-left: 163pt;text-indent: 0pt;line-height: 21pt;text-align: left;">E <span class="s38"> </span><u>1 </u><span class="s39"></span><span class="s33">( </span>f <span class="s33">(</span>x<span class="s33">) </span><span class="s38"> </span>f<span class="s31">ˆ</span><span class="s33"> (</span>x<span class="s33">))</span><span class="s46">2</span></p><p class="s41" style="padding-left: 185pt;text-indent: 0pt;line-height: 10pt;text-align: left;"><span class="s84">2</span><span class="s33"> </span>x<span class="s40"></span>D</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: right;">（<span class="s6">8.5</span>）</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 26pt;text-indent: 0pt;text-align: left;">根据这个误差定义，我们得出了以下梯度下降训练法则：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s10" style="padding-top: 2pt;text-indent: 0pt;line-height: 21pt;text-align: right;"><span class="s21">w</span><span class="s36">j</span><span class="s6">=</span><span class="s72"> </span><span class="s275"></span></p><p class="s41" style="text-indent: 0pt;line-height: 7pt;text-align: right;">x<span class="s40"></span>D</p><p class="s6" style="padding-top: 3pt;padding-left: 7pt;text-indent: 0pt;text-align: left;">(<i>f</i>(<i>x</i>)- <span class="s30">f</span><span class="s31">ˆ </span>(<i>x</i>))<i>a</i><span class="s36">j</span>(<i>x</i>) <span class="p">（</span>8.6<span class="p">）</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-top: 1pt;padding-left: 6pt;text-indent: 20pt;line-height: 142%;text-align: left;"><span class="p">其中</span><span class="s72"></span><span class="p">是一个常数，称为学习速率。而且这个法则已经被重新表示，修改了其中第 </span><span class="s6">4 </span><span class="p">章 中的记号以匹配当前的记号（也就是，</span>t<span class="s10"> </span>f<span class="s6">(</span>x<span class="s6">)</span><span class="p">，</span>o<span class="s10"> </span><span class="s30">f</span><span class="s31">ˆ </span><span class="s6">(</span>x<span class="s6">)</span><span class="p">，</span>x<span class="s36">j</span><span class="s10"> </span>a<span class="s36">j</span><span class="s6">(</span>x<span class="s6">)</span><span class="p">）。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;text-align: left;"><span class="p">我们应该如何修改这个过程来推导出局部逼近呢？简单的方法是重新定义误差准则</span>E <span class="p">以着重于拟合局部训练样例。下面给出了三种可能的误差准则。注意我们把误差写为</span>E<span class="s6">(</span>x<span class="s36">q</span><span class="s6">)</span><span class="p">， 目的是为了强调目前的误差被定义为查询点</span>x<span class="s36">q</span><span class="p">的函数。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 69pt;text-indent: 0pt;text-align: left;"><span class="s6">1. </span>只在 <span class="s21">k </span>个近邻上的误差平方和最小化：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="padding-top: 10pt;text-indent: 0pt;text-align: right;">E<span class="s79">1 </span><span class="s33">(</span>x<span class="s52">q </span><span class="s33">) </span><span class="s38"></span></p><p class="s33" style="padding-top: 3pt;padding-left: 1pt;text-indent: 0pt;line-height: 21pt;text-align: left;"><u>1 </u><span class="s39"></span>( <i>f </i>(<i>x</i>) <span class="s38"> </span><i>f</i><span class="s31">ˆ</span> (<i>x</i>))<span class="s46">2</span></p><p class="s41" style="padding-left: 1pt;text-indent: 0pt;line-height: 11pt;text-align: left;"><span class="s84">2</span><span class="s33"> </span>x<span class="s40"></span>x<span class="s180">q</span><span class="s45">的</span>k<span class="s45">个近邻</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 48pt;text-indent: 21pt;line-height: 107%;text-align: left;"><span class="s6">2. </span>使整个训练样例集合<span class="s21">D</span>上的误差平方和最小化，但对每个训练样例加权， 权值为关于相距<span class="s21">x</span><span class="s36">q</span>距离的某个递减函数<span class="s21">K</span>：</p><p class="s30" style="padding-top: 8pt;text-indent: 0pt;line-height: 12pt;text-align: right;">E<span class="s79">2 </span><span class="s33">(</span>x<span class="s52">q </span><span class="s33">) </span><span class="s38"></span></p><p class="s33" style="padding-top: 2pt;padding-left: 1pt;text-indent: 0pt;line-height: 18pt;text-align: left;"><u>1 </u><span class="s39"></span>( <i>f </i>(<i>x</i>) <span class="s38"> </span><i>f</i><span class="s31">ˆ</span> (<i>x</i>))<span class="s46">2</span></p><p class="s30" style="padding-top: 9pt;text-indent: 0pt;line-height: 11pt;text-align: left;">K <span class="s33">(</span>d <span class="s33">(</span>x<span class="s52">q</span><span class="s41"> </span><span class="s33">, </span>x<span class="s33">))</span></p><p class="s41" style="padding-left: 15pt;text-indent: 0pt;line-height: 13pt;text-align: center;"><span class="s84">2</span><span class="s33"> </span>x<span class="s40"></span>D</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-top: 8pt;padding-left: 69pt;text-indent: 0pt;text-align: left;">3. <span class="p">综合 </span>1 <span class="p">和 </span>2<span class="p">：</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s92" style="padding-top: 3pt;text-indent: 0pt;line-height: 10pt;text-align: right;">1</p><p class="s30" style="text-indent: 0pt;line-height: 8pt;text-align: right;">E<span class="s79">3 </span><span class="s33">(</span>x<span class="s52">q </span><span class="s33">) </span><span class="s38"></span></p><p class="s33" style="padding-top: 7pt;padding-left: 16pt;text-indent: 0pt;line-height: 15pt;text-align: left;"><span class="s39"></span>( <i>f </i>(<i>x</i>) <span class="s38"> </span><i>f</i><span class="s31">ˆ</span> (<i>x</i>))<span class="s46">2</span></p><p class="s30" style="padding-top: 11pt;text-indent: 0pt;line-height: 11pt;text-align: left;">K <span class="s33">(</span>d <span class="s33">(</span>x<span class="s52">q</span><span class="s41"> </span><span class="s33">, </span>x<span class="s33">))</span></p><p class="s44" style="text-indent: 0pt;line-height: 5pt;text-align: left;">q</p><p style="text-indent: 0pt;text-align: left;"/><p class="s41" style="padding-left: 24pt;text-indent: 0pt;line-height: 13pt;text-align: center;"><span class="s84">2 </span>x<span class="s40"></span>x <span class="s45">的</span>k<span class="s45">个近邻</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 8pt;padding-left: 26pt;text-indent: 0pt;text-align: left;">准则 <span class="s6">2 </span>或许是最令人满意的，因为它允许每个训练样例都对<span class="s21">x</span><span class="s36">q</span>的分类产生影响。然而这</p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 107%;text-align: left;">种方法所需的计算量随着训练样例数量线性增长。准则 <span class="s6">3 </span>很好地近似了准则 <span class="s6">2 </span>并且具有如下 优点：计算开销独立于训练样例总数，而仅依赖于所考虑的最近邻数<span class="s21">k</span>。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 20pt;line-height: 107%;text-align: left;">如果使用上面的准则 <span class="s6">3</span>，并使用与第 <span class="s6">4 </span>章相同的推理方式重新推导梯度下降法则，可以 得到以下训练法则：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s38" style="padding-top: 5pt;text-indent: 0pt;text-align: right;"><span class="s30">w</span><span class="s52">i </span> <span class="s119"></span></p><p class="s30" style="padding-top: 3pt;padding-left: 14pt;text-indent: 0pt;line-height: 20pt;text-align: left;"><span class="s39"></span><span class="s121"> </span>K <span class="s33">(</span>d <span class="s33">(</span>x<span class="s52">q</span><span class="s41"> </span><span class="s33">, </span>x<span class="s33">))( </span>f <span class="s33">(</span>x<span class="s33">) </span><span class="s38"> </span>f<span class="s31">ˆ</span><span class="s33"> (</span>x<span class="s33">))</span>a <span class="s52">j</span><span class="s41"> </span><span class="s33">(</span>x<span class="s33">)</span></p><p class="s41" style="text-indent: 0pt;line-height: 9pt;text-align: left;">x<span class="s40"></span>x<span class="s180">q</span><span class="s45">的</span>k<span class="s45">个近邻</span></p><p style="padding-top: 5pt;padding-left: 55pt;text-indent: 0pt;text-align: left;">（<span class="s6">8.7</span>）</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s38" style="padding-top: 2pt;padding-left: 26pt;text-indent: 131pt;text-align: left;"><span class="s6">////////// </span><span class="s30">w</span><span class="s52">i </span> <span class="s30">w</span><span class="s52">i </span> <span class="s30">w</span><span class="s52">i</span><span class="s41"> </span><span class="s6">//////////</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 106%;text-align: justify;">注意这个新的法则和公式（<span class="s6">8.6</span>）给出的法则的差异是，实例<span class="s21">x</span>对权值更新的贡献现在乘 上了一个<span style=" color: #00F;">距离惩罚项</span><span class="s58">K</span><span class="s63">(</span><span class="s58">d</span><span class="s63">(</span><span class="s58">x</span><span class="s59">q</span><span class="s63">, </span><span class="s58">x</span><span class="s63">))</span>，<span style=" color: #00F;">并且仅对</span><span class="s58">k</span><span style=" color: #00F;">个最邻近的训练实例的误差求和</span>。事实上，如果 要使一个线性函数拟合固定的训练样例集合，那么有一些比梯度下降更高效的方法，它们直 接求解所需要的系数<span class="s21">w</span><span class="s35">0</span><span class="s10"></span><span class="s21">w</span><span class="s36">n</span>。<span class="s6">Atkeson et al.</span>（<span class="s6">1997a</span>）和<span class="s6">Bishop</span>（<span class="s6">1995</span>）调查了几个这样的方 法。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">8.3.2 <span class="s25">局部加权回归的说明</span></h3><p style="padding-top: 10pt;padding-left: 5pt;text-indent: 21pt;line-height: 110%;text-align: justify;">上面我们考虑了使用一个线性函数在查询实例<span class="s21">x</span><span class="s36">q</span>邻域内逼近<span class="s21">f</span>。关于局部加权回归的文 献中，在对训练样例距离加权方面包含大量的可选方法，还包含大量的目标函数局部逼近方 法。在大多数情况下是通过一个常量、线性函数或二次函数来局部逼近目标函数。更复杂的 函数形式不太常见，原因是（<span class="s6">1</span>）对每个查询实例用更复杂的函数来拟合，其代价十分高昂；</p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 14pt;text-align: left;">（<span class="s6">2</span>）在足够小的实例空间子域上，使用这些简单的近似已能相当好地模拟目标函数。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-top: 8pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">8.4 <span class="s17">径向基函数</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">另一种函数逼近的方法是使用径向基函数（<span class="s6">radial basis function</span>），这种方法与距离加权 回归和人工神经网络都有着紧密联系（<span class="s6">Powell 1987</span>；<span class="s6">Broomhead &amp; Lowe 1988</span>；<span class="s6">Moody &amp; Darken 1989</span>）。在这种方法中，待学习的假设是一个以下形式的函数，</p><p class="s41" style="padding-top: 2pt;text-indent: 0pt;line-height: 6pt;text-align: right;">k</p><p class="s42" style="text-indent: 0pt;line-height: 18pt;text-align: left;">0       <span class="s135"></span><span class="s136">  </span><i>u      u             u</i></p><p style="text-indent: 0pt;text-align: left;"/><p class="s30" style="padding-left: 152pt;text-indent: 0pt;line-height: 15pt;text-align: left;">f<span class="s31">ˆ </span><span class="s33">(</span>x<span class="s33">) </span><span class="s38"> </span>w <span class="s38"> </span>w K <span class="s33">(</span>d <span class="s33">(</span>x <span class="s33">, </span>x<span class="s33">))</span></p><p class="s41" style="padding-top: 1pt;text-indent: 0pt;text-align: right;">u <span class="s40"></span><span class="s42">1</span></p><p style="padding-top: 9pt;padding-left: 89pt;text-indent: 0pt;text-align: left;">（<span class="s6">8.8</span>）</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;line-height: 136%;text-align: left;"><span class="p">其中每个</span>x<span class="s36">u</span><span class="p">是</span>X<span class="p">中一个实例，核函数</span>K<span class="s36">u</span><span class="s6">(</span>d<span class="s6">(</span>x<span class="s36">u</span><span class="s6">, </span>x<span class="s6">))</span><span class="p">被定义为随距离</span>d<span class="s6">(</span>x<span class="s36">u</span><span class="s6">, </span>x<span class="s6">)</span><span class="p">的增大而减小。这 里的</span>k<span class="p">是用户提供的常量，用来指定要包含的核函数的数量。尽管 </span><span class="s30">f</span><span class="s31">ˆ</span><span class="s33"> </span><span class="s6">(</span>x<span class="s6">)</span><span class="p">是对</span>f<span class="s6">(</span>x<span class="s6">)</span><span class="p">的全局逼近，</span></p><p class="s6" style="padding-top: 2pt;padding-left: 5pt;text-indent: 0pt;text-align: left;"><span class="p">但来自每个</span><i>K</i><span class="s36">u</span>(<i>d</i>(<i>x</i><span class="s36">u</span>, <i>x</i>)) <span class="p">项的贡献被局部化到点</span><i>x</i><span class="s36">u</span><span class="p">附近的区域。一种很常见的做法是选择高斯 函数（</span>Gaussian function<span class="p">）（见表 </span>5-4<span class="p">）作为每个核函数</span><i>K</i><span class="s36">u</span>(<i>d</i>(<i>x</i><span class="s36">u</span>, <i>x</i>))<span class="p">，高斯函数的中心点为</span><i>x</i><span class="s36">u</span><span class="p">，</span></p><p class="s41" style="text-indent: 0pt;line-height: 7pt;text-align: left;">u</p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">方差是<span class="s119"> </span><span class="s46">2</span><span class="s42"> </span>。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s41" style="padding-left: 159pt;text-indent: 0pt;line-height: 9pt;text-align: center;"><span class="s40"> </span><u>1 </u>d <span class="s209">2 </span><span class="s42">( </span>x <span class="s42">, </span>x<span class="s42">)</span></p><p class="s21" style="padding-top: 2pt;text-indent: 0pt;text-align: right;">K<span class="s36">u</span><span class="s6">(</span>d<span class="s6">(</span>x<span class="s36">u</span><span class="s6">, </span>x<span class="s6">)) = </span><span class="s30">e</span></p><p class="s44" style="text-indent: 0pt;line-height: 5pt;text-align: left;">u</p><p style="text-indent: 0pt;text-align: left;"/><p class="s42" style="padding-left: 3pt;text-indent: 0pt;line-height: 10pt;text-align: left;">2<span class="s181"> </span><span class="s209">2</span><span class="s189"> </span><span class="s215">u</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">下面我们来集中讨论这个常见的<span style=" color: #00F;">高斯核函数</span>。根据<span class="s6">Hartman et al.</span>（<span class="s6">1990</span>）所指出的，公 式（<span class="s6">8.8</span>）这样的函数形式能够以任意小的误差逼近任何函数，只要以上高斯核的数量<span class="s21">k</span>足够 大，并且可以分别指定每个核的宽度<span class="s10"></span><span class="s46">2</span>。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 27pt;text-indent: 0pt;text-align: left;"><span class="p">公式（</span>8.8<span class="p">）给出的函数可以被看作是描述了一个两层的网络，第一层计算不同的</span><i>K</i><span class="s36">u</span>(<i>d</i>(<i>x</i><span class="s36">u</span>,</p><p class="s6" style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><i>x</i>))<span class="p">，第二层计算第一层单元值的线性组合。图 </span>8-2 <span class="p">画出了一个径向基函数网络的例子。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 13pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="547" height="1" alt="image" src="机器学习/Image_345.png"/></span></p><p class="s48" style="padding-left: 15pt;text-indent: 0pt;text-align: left;">插图——原书页码： <span class="s21">239</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 14pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="531" height="1" alt="image" src="机器学习/Image_346.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 37pt;text-indent: 123pt;text-align: left;">图 <span class="h4">8-2 </span>一个径向基函数网络</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-left: 37pt;text-indent: 0pt;line-height: 117%;text-align: justify;">每个隐藏单元产生一个激发（<span class="s16">activation</span>），它由以某个实例<span class="s56">x</span><span class="s65">u</span>为中心的高斯函数决定。所以，除非 <span class="s56">x</span>靠近<span class="s56">x</span><span class="s65">u</span>，否则它的激发接近于 <span class="s16">0</span>。输出单元产生的输出是隐藏单元激发的线性组合。尽管这里画出 的网络仅有一个输出，但是也可以包含多个输出。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s41" style="text-indent: 0pt;line-height: 7pt;text-align: left;">u</p><p style="text-indent: 0pt;text-align: left;"/><p class="s21" style="padding-left: 5pt;text-indent: 21pt;line-height: 151%;text-align: justify;"><span class="p">给定了目标函数的训练样例集合，一般分两个阶段来训练</span><span class="s6">RBF</span><span class="s63">(radial basis function)</span><span class="p">网 络。首先，决定隐藏单元的数量</span>k<span class="p">，并通过选取用来定义核函数</span>K<span class="s36">u</span><span class="s6">(</span>d<span class="s6">(</span>x<span class="s36">u</span><span class="s6">, </span>x<span class="s6">))</span><span class="p">的</span>x<span class="s36">u</span><span class="p">、</span><span class="s119"> </span><span class="s46">2</span><span class="s42"> </span><span class="p">值定义</span></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 0pt;text-align: justify;">每个隐藏单元。第二，使用式（<span class="s6">8.5</span>）给出的全局误差准则来训练权值<span class="s21">w</span><span class="s36">u</span>，使网络拟合训练 数据程度最大化。因为核函数在第二阶段是保持不变的，所以线性权值<span class="s21">w</span><span class="s36">u</span>可以被非常高效地 训练得到。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 5pt;text-indent: 21pt;line-height: 108%;text-align: justify;"><span class="p">人们已经提出了几种方法来选取适当的隐藏单元或者说核函数的数量。一种方法是为每 一个训练样例</span><span class="s6">&lt;</span>x<span class="s36">i</span><span class="s6">, </span>f<span class="s6">(</span>x<span class="s36">i</span><span class="s6">)&gt;</span><span class="p">分配一个高斯核函数，此高斯函数的中心点被设为</span>x<span class="s36">i</span><span class="p">。所有高斯函数 的宽度</span><span class="s10"></span><span class="s46">2</span><span class="p">可被赋为同样的值。通过这种方法，</span>RBF<span class="p">网络学习目标函数的全局逼近，其中每个</span></p><p class="s21" style="padding-top: 5pt;padding-left: 6pt;text-indent: 0pt;line-height: 145%;text-align: justify;"><span class="p">训练样例</span><span class="s6">&lt;</span>x<span class="s36">i</span><span class="s6">, </span>f<span class="s6">(</span>x<span class="s36">i</span><span class="s6">)&gt;</span><span class="p">都只在</span>x<span class="s36">i</span><span class="p">的邻域内影响 </span><span class="s30">f</span><span class="s31">ˆ </span><span class="p">的值。这样选择核函数的一个优点是它允许</span><span class="s6">RBF </span><span class="p">网络精确地拟合训练数据。也就是说，对于任意</span>m<span class="p">个训练样例集合，为了合并</span>m<span class="p">个高斯核函 数的权值</span>w<span class="s35">0</span><span class="s10"></span>w<span class="s36">m</span><span class="p">可以被设置为使得对于每一个训练样例</span><span class="s6">&lt;</span>x<span class="s36">i</span><span class="s6">, </span>f<span class="s6">(</span>x<span class="s36">i</span><span class="s6">)&gt;</span><span class="p">都满足 </span><span class="s30">f</span><span class="s31">ˆ</span><span class="s33"> </span><span class="s6">(</span>x<span class="s36">i</span><span class="s6">)=</span>f<span class="s6">(</span>x<span class="s36">i</span><span class="s6">)</span><span class="p">。</span></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 108%;text-align: left;">第二种方法是选取一组数量少于训练样例数量的核函数。这种方法可以比第一种方法更 有效，特别是在训练样例的数量巨大的时候。核函数被分布在整个实例空间<span class="s21">X</span>上，它们的中 心之间有均匀的间隔。或者也可以非均匀地分布核函数中心，特别是在实例本身在<span class="s21">X</span>上非均 匀分布的时候。在后一种情况下，可以随机选取训练样例的一个子集作为核函数的中心，从 而对实例的基准分布进行采样。或者，我们可以标识出实例的原始聚类（<span class="s6">prototypical cluster</span>）， 然后以每个聚类为中心加入一个核函数。这种方式的核函数布置可以通过非监督的聚类算法 来实现，其中把训练实例（不包含目标值）拟合到混合高斯。<span class="s6">6.12.1 </span>节讨论的<span class="s6">EM</span>算法提供 了一种从<span class="s21">k</span>个高斯函数的混合中选择均值，以最佳拟合观测到实例的方法。在<span class="s6">EM</span>算法中，均 值的选取方法是：对给定的<span class="s21">k</span>个估计的均值，使观测到实例<span class="s21">x</span><span class="s36">i</span>的概率最大化。注意在无监督 的聚类方法中，实例的目标函数值<span class="s21">f</span><span class="s6">(</span><span class="s21">x</span><span class="s36">i</span><span class="s6">)</span>不参与核函数中心的计算。目标值的惟一作用是决定 输出层的权值<span class="s21">w</span><span class="s36">u</span>。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 110%;text-align: justify;">概而言之，用多个局部核函数的线性组合表示的径向基函数网络提供了一种目标函数的 全局逼近。仅当输入 <span class="s21">x </span>落入某个核函数的中心和宽度所定义的区域内时，这个核函数的值才 是不可忽略的。因此，<span class="s6">RBF </span>网络可以被看作目标函数的多个局部逼近的平滑线性组合。<span class="s6">RBF </span>网络的一个关键优点是，与反向传播算法训练的前馈网络相比，它的训练更加高效。这是因 为 <span class="s6">RBF </span>网络的输入层和输出层可以被分别训练。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-top: 7pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">8.5 <span class="s17">基于案例的推理</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 107%;text-align: left;"><span class="s21">k</span><span class="s6">-</span>近邻算法和局部加权回归都是基于实例的方法，它们具有三个共同的关键特性。第 <span class="s6">1</span>， <span style=" color: #F00;">它们是消极学习方法，都把在训练数据上的泛化推迟至遇到一个新的查询实例时。第 </span><span class="s19">2</span><span style=" color: #F00;">，它 们通过分析相似的实例来分类新的查询实例，而忽略与查询极其不同的实例。第 </span><span class="s19">3</span><span style=" color: #F00;">，它们把 实例表示为 </span><span class="s22">n </span><span style=" color: #F00;">维欧氏空间中的实数点</span>。基于案例的推理（<span class="s6">Case-based reasoning</span>，<span class="s6">CBR</span>）这种 学习范型基于前两个原则，但不包括第 <span class="s6">3 </span>个。在 <span class="s6">CBR </span>中，一般使用更丰富的符号描述来表 示实例；相应地，用来检索实例的方法也更加复杂。<span class="s6">CBR </span>已被应用于解决很多问题，比如， 根据数据库中存储的以前的设计图纸，来进行机械设备的总体设计（<span class="s6">Sycara et al. 1992</span>） <span class="s63">(solidworks, proe </span><span style=" color: #00F;">等三维软件的设计原理以及应用吗？？？</span><span class="s63">)</span>；根据以前的裁决来对新的法律 案件进行推理（<span class="s6">Ashley 1990</span>）；通过对以前的相似问题的解决方案的复用或合并，来解决规 划和调度问题（<span class="s6">Veloso 1992</span>）。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 27pt;text-indent: 0pt;text-align: left;">作为以后讨论的基础，让我们考虑基于案例的推理系统的一个例子。<span class="s6">CADET</span>系统</p><p style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;line-height: 107%;text-align: left;">（<span class="s6">Sycara et al. 1992</span>）采用基于案例的推理来辅助简单机械设备（例如水龙头）的总体设计。 它使用一个数据库，其中包含大约 <span class="s6">75 </span>个以前的设计或设计片断，来推荐符合新的设计规格 的总体设计。内存中每一个实例是通过它的结构和定性的功能来表示的。相应的，新的设计 问题是通过所要求的功能和结构来表示的。图 <span class="s6">8-3 </span>画出了这个问题。图的上半部分显示了一 个典型的存储案例，被称为<span class="s6">T</span>型接头管。它的功能被表示为输入和输出点的流量和温度间的 定性关系。在右侧的功能描述中，标有“<span class="s6">+</span>”的箭头表明箭头头部的变量随着箭头尾部的变 量上升。例如，输出流量<span class="s21">Q</span><span class="s35">3</span>随着输入流量<span class="s21">Q</span><span class="s35">1</span>增长。类似地，“<span class="s6">-</span>”标记表明箭头头部的变量随 着箭头尾部的变量下降。这幅图的下半部分画出了一个新的设计问题，它通过新设计中所要 求的功能来描述。这个功能描绘了一种水龙头的行为特征。这里<span class="s21">Q</span><span class="s36">c</span>指进入龙头的冷水流量， <span class="s21">Q</span><span class="s36">h</span>指热水的输入流量，<span class="s21">Q</span><span class="s36">m</span>指流出龙头的单一混合流量。类似地，<span class="s21">T</span><span class="s36">c</span>、<span class="s21">T</span><span class="s36">h</span>和<span class="s21">T</span><span class="s36">m</span>分别指热水、冷 水和混合水流的温度。变量<span class="s21">C</span><span class="s36">t</span>表示输入到龙头的温度控制信号，<span class="s21">C</span><span class="s36">f</span>表示对水流的控制信号。</p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">注意，所要求的功能描述中指出，这些控制信号<span class="s21">C</span><span class="s36">t</span>和<span class="s21">C</span><span class="s36">f</span>用来影响水流<span class="s21">Q</span><span class="s36">c</span>和<span class="s21">Q</span><span class="s36">h</span>，从而间接影响 龙头的输出流量<span class="s21">Q</span><span class="s36">m</span>和温度<span class="s21">T</span><span class="s36">m</span>。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 13pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="547" height="1" alt="image" src="机器学习/Image_347.png"/></span></p><p class="s48" style="padding-left: 15pt;text-indent: 0pt;text-align: left;">插图——原书页码： <span class="s21">241</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">A stored case: T-junction tube- <span class="p">一个存储的案例：</span>T <span class="p">型接头管</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 26pt;text-indent: 0pt;line-height: 190%;text-align: left;">Structure-<span class="p">结构 </span>Function-<span class="p">功能</span></p><p class="s6" style="padding-top: 2pt;padding-left: 26pt;text-indent: 0pt;text-align: left;">A problem specification: Water faucet- <span class="p">一个问题的规格说明：水龙头</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 26pt;text-indent: 0pt;line-height: 190%;text-align: left;">Structure-<span class="p">结构 </span>Function-<span class="p">功能</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 14pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="531" height="1" alt="image" src="机器学习/Image_348.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 24pt;text-indent: 0pt;text-align: center;">图 <span class="h4">8-3 </span>一个存储的案例和一个新问题</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-left: 37pt;text-indent: 0pt;line-height: 125%;text-align: left;">上半部分描绘了 <span class="s16">CADET </span>案例库中一个典型的设计片断。它的功能是通过 <span class="s16">T </span>型接头变量间的定性依 赖关系图表示的（在正文中具体描述）。下半部分显示了一个典型的设计问题。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 110%;text-align: justify;">给定新设计问题的功能说明，<span class="s6">CADET </span>从它的案例库中搜索存储的例，使它的功能描述 和新设计问题相匹配。如果发现了一个精确的匹配，表明某个存储案例精确实现了所要求的 功能，那么可以返回这个案例作为新设计问题的建议方案。如果没有发现精确的匹配， <span class="s6">CADET </span>可能找到匹配所需功能的不同子图的案例。例如，在图 <span class="s6">8-3 </span>中 <span class="s6">T </span>型接头的功能匹配 了水龙头功能图的一个子图。更一般地讲， <span class="s6">CADET </span>在两个功能图间搜索同构子图</p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: left;">（<span class="s6">isomorphisms subgraph</span>），以发现一个案例的某部分，使它匹配设计规格说明的相应部分。 此外，系统可以加工原始的功能说明图，产生等价的子图以匹配更多的案例。它使用关于物 理感应的一般知识来创建这样的加工过的功能图。例如，利用一种重写规则可以把这个感应：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s276" style="padding-top: 7pt;padding-left: 24pt;text-indent: 0pt;text-align: center;"><span class="s21">A </span>⎯⎯<span class="s277"></span><span class="s40"> </span><span class="s109"> </span><span class="s21">B</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 8pt;padding-left: 26pt;text-indent: 0pt;text-align: left;">重写为</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s276" style="padding-top: 3pt;padding-left: 24pt;text-indent: 0pt;text-align: center;"><span class="s21">A </span>⎯⎯<span class="s277"></span><span class="s40"> </span> <span class="s21">x </span>⎯⎯<span class="s277"></span><span class="s40"> </span><span class="s109"> </span><span class="s21">B</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 8pt;padding-left: 6pt;text-indent: 21pt;line-height: 107%;text-align: justify;">这个重写规则可以被解释为：如果 <span class="s21">B </span>随 <span class="s21">A </span>上升，那么一定可以找到某个 <span class="s21">x</span>，满足 <span class="s21">B </span>随 <span class="s21">x </span>上升而且 <span class="s21">x </span>随 <span class="s21">A </span>上升。这里 <span class="s21">x </span>是一个全称量化的变量，它在功能图与这个案例库匹配时约束 到确定值。事实上，图 <span class="s6">8-3 </span>中的水龙头的功能图就是应用这个重写规则从原来的功能说明中 加工得到的。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 113%;text-align: justify;">通过检索匹配不同子图的多个案例，有时可以拼接得到整个设计。一般来说，从多个检 索到的案例产生最终方案的过程可以很复杂。为了合并存储案例中的检索到的部分，可能需</p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 110%;text-align: justify;">要从头设计系统的各个部分。也可能需要回溯以前的设计子目标，从而丢弃前面检索到的案 例。<span class="s6">CADET </span>合并和自适应已检索到案例并形成最终设计的能力很有限，它主要依赖用户来 做自适应阶段的处理。正如 <span class="s6">Sycara et al.</span>（<span class="s6">1992</span>）所描述的，<span class="s6">CADET </span>是一个研究用的原型系 统，用来探索基于案例的推理在总体设计中的潜在作用。它不具备用来把这些抽象的总体设 计提炼成最终设计的分析算法。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;"><span class="p">对于</span>CADET<span class="p">的问题框架和基于实例的方法（例如</span>k-<span class="p">近邻算法）的一般框架，分析它们 之间的对应之处是有益的。在</span>CADET<span class="p">中每个存储的训练样例描绘了一个功能图以及实现该 功能的结构。新的查询对应新的功能图。因此，我们可以把</span>CADET<span class="p">的问题映射到标准的学 习问题定义中。其中实例空间</span>X<span class="p">定义为所有功能图的空间。目标函数</span><i>f</i><span class="p">映射到实现这些功能的 结构。每个存储训练样例</span>&lt;<i>x</i>, <i>f</i>(<i>x</i>)&gt;<span class="p">是一个序偶，描述某个功能图</span><i>x</i><span class="p">和实现</span><i>x</i><span class="p">的结构</span><i>f</i>(<i>x</i>)<span class="p">。系统必 须学习训练案例，以输出满足功能图查询输入</span><i>x</i><span class="s36">q</span><span class="p">的结构</span><i>f</i>(<i>x</i><span class="s36">q</span>)<span class="p">。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 107%;text-align: justify;">上面关于 <span class="s6">CADET </span>系统简要描述，说明了基于案例的推理系统区别于 <span class="s6">k-</span>近邻这样的方法 的若干一般特征：</p><p style="padding-top: 6pt;padding-left: 49pt;text-indent: -21pt;line-height: 107%;text-align: left;"><span class="s10"> </span><span style=" color: #F00;">实例或案例可以用丰富的符号描述表示</span>，就像 <span class="s6">CADET </span>中使用的功能图。这可能 需要不同于欧氏距离的相似性度量，比如两个功能图的最大可共享子图的大小。</p><p style="padding-top: 1pt;padding-left: 49pt;text-indent: -21pt;line-height: 110%;text-align: justify;"><span class="s10"> </span><span style=" color: #F00;">检索到的多个案例可以合并形成新问题的解决方案</span>。这与 <span class="s21">k</span><span class="s6">-</span>近邻方法相似—— 多个相似的案例用来构成对新查询的回答。然而，合并多个检索到的案例的过 程与 <span class="s21">k</span><span class="s6">-</span>近邻有很大不同，它依赖于知识推理而不是统计方法。</p><p style="padding-left: 49pt;text-indent: -21pt;line-height: 110%;text-align: left;"><span class="s10"> </span><span style=" color: #F00;">案例检索、基于知识的推理和问题求解间是紧密耦合在一起的</span>。例如 <span class="s6">CADET </span>系统在尝试找到匹配的案例过程中，它使用有关物理感应的一般知识重写了功 能图。人们已经开发出很多其他的系统，这些系统更加完整地把基于案例的推 理集成到基于搜索的问题求解系统中。<span class="s6">ANAPRON</span>（<span class="s6">Golding &amp; Rosenbloom 1991</span>） 和 <span class="s6">Prodigy/Analogy</span>（<span class="s6">Veloso 1992</span>）是两个例子。</p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 21pt;line-height: 112%;text-align: left;">概括地讲，基于案例的推理是一种基于实例的学习方法，在这种方法中，实例（案例） 可以是丰富的关系描述；而且在该方法中，为了解决当前查询，案例检索和合并过程可能依 赖于知识推理和搜索密集的问题求解方法。目前关于基于案例的推理研究的一个课题是，改 进索引案例的方法。这里的中心问题是句法相似度量（例如，功能图之间的子图同构）仅能 近似地指出特定案例与特定问题的相关度。当 <span class="s6">CBR </span>系统试图复用检索到的案例时，它可能 遇到句法相似度量中没有捕捉到的难点。例如，在 <span class="s6">CADET </span>中，检索到的多个设计片断可能 彼此不兼容，使得它们无法被合并到一个统一的最终设计中。一般当这种情况发生时，<span class="s6">CBR </span>系统可回溯搜索另外的案例以适应现有的案例，或者求助于其他的问题求解方法。重要的是， 当检测到这样的难点时，它们也提供了用来改进相似性度量（或等价的，案例库索引结构） 的训练数据。确切地讲，如果根据相似性度量检索到了一个案例，但在进一步的分析中发现 这个案例与当前的设计是无关的，那么这个相似性度量会被改进，以便对于以后的类似查询 拒绝这个案例。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 55pt;text-indent: 0pt;text-align: left;">8.6 <span class="s17">对消极学习和积极学习的评论</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 110%;text-align: justify;">在这一章中我们考虑了三种消极学习（<span class="s6">lazy learning</span>）方法：<span class="s21">k</span><span class="s6">-</span>近邻算法、局部加权回归 和基于案例的推理。<span style=" color: #00F;">之所以称这些方法是消极的，是因为它们延迟了如何从训练数据中泛化 的决策，直到遇到一个新的查询</span>。本章讨论了一种积极学习方法：<span style=" color: #00F;">学习径向基函数网络的方</span></p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 113%;text-align: justify;"><span style=" color: #00F;">法。之所以称这种方法是积极的，是因为它在见到新的查询之前就做好了泛化的工作——在 训练时提交了定义其目标函数逼近的网络结构和权值</span>。根据同样的理解，本书其他章节讨论 的所有其他算法都是积极学习算法（例如，反向传播算法、<span class="s6">C4.5</span>）。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 113%;text-align: left;">在算法能力方面，消极方法和积极方法有明显差异吗？我们先区分两种差异：计算时间 的差异，和对新查询的分类差异。在计算时间方面消极方法和积极方法显然有差异。例如， 消极方法在训练时一般需要较少的计算，但在预测新查询的目标值时需要更多的计算时间。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 113%;text-align: justify;">更基本的问题是，在归纳偏置方面消极和积极方法是否有实质性的差异呢？在这方面两 种方法的关键差异是：</p><p style="padding-top: 5pt;padding-left: 28pt;text-indent: 0pt;text-align: left;"><span class="s10"> </span>消极方法在决定如何从训练数据<span class="s21">D</span>中泛化时考虑查询实例<span class="s21">x</span><span class="s36">q</span>。</p><p style="padding-left: 49pt;text-indent: -21pt;text-align: left;"><span class="s10"> </span>积极方法不能做到这一点，因为在见到查询实例<span class="s21">x</span><span class="s36">q</span>前，它们已经选取了对目 标函数的（全局）逼近。</p><p style="padding-top: 8pt;padding-left: 5pt;text-indent: 21pt;line-height: 110%;text-align: left;">这个区别会影响学习器的泛化精度吗？如果要求消极的和积极的学习器采用同一个假 设空间<span class="s21">H</span>，那么答案是肯定的。为了说明这一点，考虑由线性函数组成的假设空间。前面讨 论的局部加权回归算法是基于这样的假设空间的消极学习方法。对于每个新查询<span class="s21">x</span><span class="s36">q</span>，它根据 <span class="s21">x</span><span class="s36">q</span>附近的训练样例选择一个新的假设从训练数据中泛化。相反，一个使用同样的线性函数假 设空间的积极学习器必须在见到查询之前选择对目标函数的逼近。所以积极学习器必须提交 单个的线性函数假设，以覆盖整个实例空间和所有未来的查询。<span style=" color: #00F;">消极学习方法有效地使用了 更丰富的假设空间，因为它使用很多不同的局部线性函数来形成对目标函数的隐含的全局逼 近。</span>注意其他的一些学习器和假设空间也符合同样的情况。例如反向传播算法的消极版本， 可以对每个独立的查询点学习不同的神经网络。这与第 <span class="s6">4 </span>章讨论的反向传播算法的积极版本 形成对照。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 113%;text-align: justify;">上面一段的核心观点是，<span style=" color: #00F;">消极的学习器可以通过很多局部逼近的组合（隐含地）表示目 标函数，然而积极的学习器必须在训练时提交单个的全局逼近。因此积极学习的和消极学习 之间的差异意味着对目标函数的全局逼近和局部逼近的差异</span>。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 109%;text-align: justify;">使用多个局部逼近的积极方法，可以产生与消极方法的局部逼近同样的效果吗？径向基 函数网络可以被看作向这个目标的尝试。<span class="s6">RBF </span>学习方法是在训练时提交目标函数全局逼近 的积极方法。然而，一个 <span class="s6">RBF </span>网络把这个全局函数表示为多个局部核函数的线性组合。不 过，因为 <span class="s6">RBF </span>学习方法必须在知道查询点之前提交假设，所以它们创建的局部逼近不能达 到像消极学习方法中那样特别针对查询点。代替地，<span class="s6">RBF </span>网络是从以训练样例为中心的局 部逼近中被“积极”建立的，或者说是以训练样例的聚类为中心，不是以未知的未来查询点 为中心。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 112%;text-align: justify;">概而言之，消极学习方法可以对于每一个查询实例选择不同的假设（或目标函数的局部 逼近）。使用同样假设空间的积极方法是更加受限制的，因为它们必须提交一个覆盖整个实 例空间的单一假设。当然，积极的方法可以使用合并了多个局部逼近的假设空间，就象 <span class="s6">RBF </span>网络一样。然而，即使是这些合并的局部逼近，也不能使积极方法完全具有消极方法那种针 对未知查询作出假设的能力。</p><h2 style="padding-left: 55pt;text-indent: 0pt;line-height: 19pt;text-align: left;">8.7 <span class="s17">小结和补充读物</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 27pt;text-indent: 0pt;text-align: left;">这一章的要点包括：</p><p class="s10" style="padding-top: 6pt;padding-left: 49pt;text-indent: -21pt;line-height: 111%;text-align: left;"> <span class="p">基于实例的学习方法不同于其他的函数逼近方法，因为它们推迟处理训练样例， 直到必须分类一个新查询实例时。因此，它们不必形成一个明确的假设来定义 整个实例空间上的完整目标函数。相反，它们可以对每个查询实例形成一个不 同的目标函数局部逼近。</span></p><p class="s10" style="padding-left: 49pt;text-indent: -21pt;line-height: 112%;text-align: left;"> <span class="p">基于实例的方法的优点包括：通过一系列不太复杂的局部逼近来模拟复杂目标 函数的能力；不会损失训练样例中蕴含的任何信息（因为事例本身被直接地存 储起来）。主要的实践问题包括：分类新实例的效率（所有的处理都在查询期 进行而不是事先准备好）；难以选择用来检索相关实例的合适的距离度量（特 别是当实例是用复杂的符号表示描述的时候）；无关特征对距离度量的负作用。</span></p><p class="s21" style="padding-left: 49pt;text-indent: -21pt;line-height: 107%;text-align: justify;"><span class="s10"> </span>k<span class="s6">-</span><span class="p">近邻是用来逼近实数值或离散值目标函数的基于实例算法，它假定实例对应于 </span>n <span class="p">维欧氏空间中的点。一个新查询的目标函数值是根据 </span>k <span class="p">个与其最近的训练样例 的值估计得到的。</span></p><p style="padding-top: 1pt;padding-left: 49pt;text-indent: -21pt;line-height: 110%;text-align: justify;"><span class="s10"> </span>局部加权回归法是 <span class="s21">k</span><span class="s6">-</span>近邻方法的推广，在这种方法中，为每个查询实例建立一 个明确的目标函数的局部逼近。目标函数的局部逼近可以基于像常数、线性函 数或二次函数这样的大量的函数形式，也可以基于空间局部化的核函数。</p><p style="padding-left: 49pt;text-indent: -21pt;line-height: 107%;text-align: justify;"><span class="s10"> </span>径向基函数（<span class="s6">RBF</span>）网络是一类由空间局部化核函数构成的人工神经网络。它可 被看作是基于实例的方法（每个核函数的影响是被局部化的）和神经网络方法</p><p style="padding-top: 1pt;padding-left: 49pt;text-indent: 0pt;line-height: 113%;text-align: left;">（在训练期形成了对目标函数的全局逼近，而不是在查询期形成局部逼近）的 混合。<span style=" color: #00F;">径向基函数网络已被成功地应用到很多课题，比如视觉场景分析</span></p><p style="padding-left: 49pt;text-indent: 0pt;text-align: left;">（<span class="s6">interpreting visual scenes</span>），其中假定空间局部的影响是很合理的。</p><p class="s10" style="padding-top: 1pt;padding-left: 49pt;text-indent: -21pt;line-height: 112%;text-align: justify;"> <span class="p">基于案例的推理也是一种基于实例的学习方法，但这种方法使用复杂的逻辑描 述而不是欧氏空间中的点来表示实例。给定实例的符号描述，人们已经提出了 大量的方法用于把训练样例映射成新实例的目标函数值。基于案例的推理方法 已经应用到很多实际问题中，比如模拟法律推理，以及在复杂的生产和运输规 划问题中引导搜索。</span></p><p class="s6" style="padding-top: 7pt;padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;"><i>k</i>-<span class="p">近邻算法是机器学习中被分析得最透彻的算法之一，原因一部分是由于它出现的较 早，另外也由于它的简明性。</span>Cover &amp; Hart<span class="p">（</span>1967<span class="p">）提出了早期的理论结果，</span>Duda &amp; Hart</p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 107%;text-align: left;">（<span class="s6">1973</span>）提供了一个很好的概观。<span class="s6">Bishop</span>（<span class="s6">1995</span>）讨论了 <span class="s6">k-</span>近邻算法以及它与概率密度估计 的关系。<span class="s6">Atkeson et al.</span>（<span class="s6">1997</span>）对局部加权回归方法给出了一个非常好的纵览。<span class="s6">Atkeson et al.</span></p><p style="padding-left: 26pt;text-indent: -21pt;text-align: left;">（<span class="s6">1997b</span>）调查了这些方法在机器人控制方面的应用。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">Bishop<span class="p">（</span>1995<span class="p">）提供了一个对径向基函数的全面讨论。其他论述由 </span>Powell<span class="p">（</span>1987<span class="p">）和 </span>Poggio &amp; Girosi<span class="p">（</span>1990<span class="p">）给出。本书的 </span>6.12 <span class="p">小节讨论了 </span>EM <span class="p">算法和它在选择混合高斯均值方 面的应用。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 26pt;text-indent: 0pt;text-align: left;">Kolodner<span class="p">（</span>1993<span class="p">）提供了对基于案例的推理的一般介绍。以下文献给出了其他的一些关</span></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">于近来的研究成果的纵览和汇集：<span class="s6">Aamodt et al</span>（<span class="s6">.</span></p><p class="s6" style="padding-top: 1pt;padding-left: 4pt;text-indent: 0pt;text-align: left;">1994<span class="p">），</span>Aha et al<span class="p">（</span>.</p><p class="s6" style="padding-top: 1pt;padding-left: 4pt;text-indent: 0pt;text-align: left;">1991<span class="p">），</span>Haton et al<span class="p">（</span>.</p><p class="s6" style="padding-top: 1pt;padding-left: 4pt;text-indent: 0pt;text-align: left;">1995<span class="p">），</span></p><p class="s6" style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;line-height: 107%;text-align: left;">Riesbeck &amp; Schank<span class="p">（</span>1989<span class="p">），</span>Schank et al<span class="p">（</span>. Wess et al.<span class="p">（</span>1994<span class="p">）。</span></p><p class="s6" style="padding-top: 1pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">1994<span class="p">），</span>Veloso and Aamodt<span class="p">（</span>1995<span class="p">），</span>Watson<span class="p">（</span>1995<span class="p">），</span></p><p style="padding-left: 27pt;text-indent: 0pt;text-align: left;">习题</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 27pt;text-indent: 0pt;text-align: left;">8.1 <span class="p">对于公式（</span>8.7<span class="p">）中的目标函数的一个距离加权局部线性逼近，推导梯度下降法则。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 5pt;text-indent: 21pt;text-align: justify;"><span class="s6">8.2 </span><span class="p">思考以下为解决局部加权回归中的距离度量的另一种方法。如下建立一个虚拟的训 练样例集合</span>D<span class="s10"></span><span class="p">：对于原始训练数据集合</span>D<span class="p">中的每一个训练样例</span><span class="s6">&lt;</span>x<span class="s6">, </span>f<span class="s6">(</span>x<span class="s6">)&gt;</span><span class="p">，在</span>D<span class="s10"></span><span class="p">中创建出一定 数量（可能是分数）的</span><span class="s6">&lt;</span>x<span class="s6">, </span>f<span class="s6">(</span>x<span class="s6">)&gt;</span><span class="p">的拷贝，其中拷贝的数量是</span>K<span class="s6">(</span>d<span class="s6">(</span>x<span class="s36">q</span><span class="s6">, </span>x<span class="s6">))</span><span class="p">。现在训练一个线性逼 近来最小化以下误差准则：</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s42" style="text-indent: 0pt;line-height: 7pt;text-align: left;">4</p><p style="text-indent: 0pt;text-align: left;"/><p class="s30" style="padding-top: 3pt;padding-left: 48pt;text-indent: 0pt;line-height: 21pt;text-align: center;">E <span class="s38"> </span><u>1 </u><span class="s39"></span><span class="s33">( </span>f <span class="s33">(</span>x<span class="s33">) </span><span class="s38"> </span>f<span class="s31">ˆ</span><span class="s33"> (</span>x<span class="s33">))</span><span class="s46">2</span></p><p class="s41" style="padding-left: 48pt;text-indent: 0pt;line-height: 10pt;text-align: center;"><span class="s84">2</span><span class="s33"> </span>x<span class="s40"></span>D<span class="s40"></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;line-height: 110%;text-align: justify;">这里的想法是对靠近查询实例的训练样例产生较多的拷贝，距离远的拷贝较少。推导出 这个误差准则的梯度下降法则。把这个法则表示成在 <span class="s21">D </span>的成员上的求和，而不是在 <span class="s21">D</span><span class="s10"></span>的成 员上求和，并把它和公式（<span class="s6">8.6</span>）和（<span class="s6">8.7</span>）中的法则进行比较。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">8.3 <span class="p">决策树学习算法 </span>ID3<span class="p">（见第 </span>3 <span class="p">章）是积极的学习方法，提出这种算法的一个消极版 本。与本来的积极算法相比，你的消极算法有什么优点和缺点？</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 26pt;text-indent: 0pt;text-align: left;">参考文献</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s8" style="padding-left: 198pt;text-indent: 0pt;line-height: 24pt;text-align: left;">第<span class="h1">9</span>章 遗传算法</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 51pt;text-indent: 21pt;line-height: 113%;text-align: justify;">遗传算法提供了一种大致基于模拟进化的学习方法。其中的假设常被描述为 二进制位串，位串的含义依赖于具体的应用。然而，假设也可以被描述为符号表 达式或者甚至是计算机程序。 对合适假设的搜索是从若干初始假设的群体 </p><p style="padding-left: 51pt;text-indent: 0pt;line-height: 110%;text-align: justify;">（<span class="s71">population</span>）或汇集（<span class="s71">collection</span>）开始的。当前群体的成员通过模仿生物进化 的方式来产生下一代群体，比如说随机变异（<span class="s71">mutation</span>）和交叉（<span class="s71">crossover</span>）。在 每一步，根据给定的适应度（<span class="s71">fitness</span>）度量评估当前群体中的假设，而后使用概 率方法选出适应度最高的假设作为产生下一代的种子。遗传算法已被成功地应用 到多种学习任务和最优化问题中。例如，遗传算法已被用于学习机器人控制的规 则集，以及优化人工神经网络的拓扑结构和学习参数。这一章既覆盖了用位串描 述假设的遗传算法（<span class="s71">genetic algorithms</span>），也覆盖了用计算机程序描述假设的遗传 编程（<span class="s71">genetic programming</span>）。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-top: 9pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">9.1 <span class="s17">动机</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 109%;text-align: left;">遗传算法（<span class="s6">GA</span>）提供了一种受生物进化启发的学习方法。它不再是从一般到特殊或从 简单到复杂地搜索假设，而是通过变异和重组当前已知的最好假设来生成后续的假设。在每 一步，被称为当前群体（<span class="s6">population</span>）的一组假设被更新，方法是通过使用目前适应度最高 的假设的后代替代群体的某个部分。这个过程形成了对假设的生成并测试（<span class="s6">generate-and-test</span>） 柱状搜索（<span class="s6">beam-search</span>），其中若干个最佳当前假设的变体最有可能在下一步被考虑。<span class="s6">GA </span>的普及和发展得益于以下因素：</p><p class="s10" style="padding-top: 5pt;padding-left: 66pt;text-indent: -21pt;line-height: 107%;text-align: left;"> <span class="p">在生物系统中进化被认为是一种成功的自适应方法，并且具有很好的鲁棒 性。</span></p><p class="s10" style="padding-top: 1pt;padding-left: 66pt;text-indent: -21pt;line-height: 107%;text-align: left;"> <span class="s6">GA </span><span class="p">搜索的假设空间中，假设的各个部分相互作用，每一部分对总的假设适 应度的影响难以建模。</span></p><p class="s10" style="padding-top: 1pt;padding-left: 66pt;text-indent: -21pt;line-height: 107%;text-align: left;"> <span class="p">遗传算法易于并行化，且可降低由于使用超强计算机硬件的带来的昂贵费 用。</span></p><p style="padding-top: 8pt;padding-left: 6pt;text-indent: 21pt;line-height: 110%;text-align: justify;">这一章描述了遗传算法，举例演示了它的用法，并分析了它搜索的假设空间的特性。我 们也描述了它的一个变体，称为遗传编程，在这种方法中，整个计算机程序向着某个适应度 准则进化。遗传算法和遗传编程是进化计算（<span class="s6">evolutionary computation</span>）领域的中的两种流 行方法。在本章的最后一节我们将接触一些研究生物进化的课题，包括鲍德温效应（<span class="s6">Baldwin effect</span>），它描述了个体的学习能力与整个群体进化速度之间有趣的相互作用。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-top: 7pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">9.2 <span class="s17">遗传算法</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 6pt;text-indent: 21pt;line-height: 107%;text-align: left;">GA <span class="p">研究的问题是搜索一个候选假设的空间，以确定最佳的假设。在 </span>GA <span class="p">中，“最佳假 设”被定义为是使“适应度（</span>fitness<span class="p">）”最优的假设，适应度是为当前问题预先定义的数字</span></p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 113%;text-align: justify;">度量。例如，如果学习任务是在给定一个未知函数的输入输出训练样例后逼近这个函数，那 么适应度可被定义为假设在训练数据上的精度。如果任务是学习下国际象棋的策略，那么适 应度可被定义为该个体在当前群体中与其他个体对弈的胜率。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 113%;text-align: justify;">尽管遗传算法的不同实现在细节上有所不同，但它们都具有以下的共同结构：算法迭代 更新一个假设池，这个假设池称为群体。在每一次迭代中，根据适应度函数评估群体中的所 有成员。然后从当前群体中用概率方法选取适应度最高的个体产生新的一代。在这些被选中 的个体中，一部分保持原样地进入下一代群体，其他的被用作产生后代个体的基础，其中应 用象交叉和变异这样的遗传方法。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 110%;text-align: justify;">表 <span class="s6">9-1 </span>描述了一个遗传算法原型。算法的输入包括：用来排序候选假设的适应度函数； 定义算法终止时适应度的阈值；要维持的群体大小；和决定如何产生后继群体的参数：每一 代群体中被淘汰的比例和变异率。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 15pt;text-indent: 0pt;text-align: center;">表 <span class="h4">9-1 </span>遗传算法原型</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-left: 37pt;text-indent: 18pt;line-height: 16pt;text-align: justify;">算法中维持一个包含<span class="s56">p</span>个假设的群体。在每一次迭代中，后继群体<span class="s56">P</span><span class="s65">S</span>的形成通过两种途径：根 据假设的适应度用概率方法选择个体，以及加入新假设。新假设通过两种方法得到：对最高适应度 假设对应用交叉算子；对通过选择和交叉产生的新一代群体中的部分假设进行单点变异。重复这个 迭代过程，直到发现适应度足够好的假设。典型的交叉和变异算子定义在后面的表格中。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 14pt;text-indent: 0pt;line-height: 2pt;text-align: left;"><span><img width="551" height="2" alt="image" src="机器学习/Image_349.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 68pt;text-indent: -48pt;text-align: left;">GA(<i>Fitness</i>, <i>Fitness</i>_<i>threshold</i>, <i>p</i>, <i>r</i>, <i>m</i>)</p><p class="s21" style="padding-top: 5pt;padding-left: 68pt;text-indent: 0pt;line-height: 94%;text-align: left;">Fitness<span class="p">：适应度评分函数，为给定假设赋予一个评估得分。 </span>Fitness<span class="s6">_</span>threshold<span class="p">：指定终止判据的阈值。 </span>p<span class="p">：群体中包含的假设数量。 </span>r<span class="p">：每一步中通过交叉取代群体成员的比例。</span></p><p class="s21" style="padding-left: 68pt;text-indent: 0pt;line-height: 13pt;text-align: left;">m<span class="p">：变异率。</span></p><p style="padding-left: 60pt;text-indent: 0pt;line-height: 14pt;text-align: left;"><span class="s10"> </span>初始化群体：<span class="s21">P</span><span class="s10"></span>随机产生的 <span class="s21">p </span>个假设</p><p class="s21" style="padding-left: 60pt;text-indent: 0pt;line-height: 14pt;text-align: left;"><span class="s10"> </span><span class="p">评估：对于 </span>P <span class="p">中的每一个 </span>h<span class="p">，计算 </span>Fitness<span class="s6">(</span>h<span class="s6">)</span></p><ul id="l24"><li style="padding-left: 81pt;text-indent: -21pt;line-height: 14pt;text-align: left;"><p class="s6" style="display: inline;"><span class="p">当</span>[ <span class="s33">max </span><i>Fitness</i>(<i>h</i>)]&lt;<i>Fitness</i>_<i>threshold</i><span class="p">，做：</span></p></li></ul><p class="s41" style="padding-left: 105pt;text-indent: 0pt;line-height: 7pt;text-align: left;">h</p><p style="padding-top: 1pt;padding-left: 59pt;text-indent: 0pt;text-align: left;">产生新的一代<span class="s21">P</span><span class="s36">S</span>：</p><p class="s21" style="padding-left: 59pt;text-indent: 0pt;text-align: left;"><span class="s6">1</span><span class="p">． 选择：用概率方法选择</span>P<span class="p">的</span><span class="s6">(1-</span>r<span class="s6">)</span>p<span class="p">个成员加入</span>P<span class="s36">S</span><span class="p">。从</span>P<span class="p">中选择假设</span>h<span class="s36">i</span><span class="p">的概率</span></p><p class="s6" style="padding-left: 59pt;text-indent: 0pt;text-align: left;">Pr(<i>h</i><span class="s36">i</span>)<span class="p">通过下面公式计算：</span></p><p class="s33" style="padding-top: 8pt;text-indent: 0pt;text-align: right;">Pr(<i>h</i><span class="s52">i </span>) <span class="s38"></span></p><p class="s30" style="padding-left: 1pt;text-indent: 0pt;text-align: center;">Fitness<span class="s33">(</span>h<span class="s52">i</span><span class="s41"> </span><span class="s33">)</span></p><p style="padding-left: 1pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="108" height="1" alt="image" src="机器学习/Image_350.png"/></span></p><p class="s41" style="text-indent: 0pt;line-height: 7pt;text-align: left;">p</p><p style="text-indent: 0pt;text-align: left;"/><p class="s30" style="padding-left: 1pt;text-indent: 0pt;text-align: center;"><span class="s39"></span><span class="s176">j</span><span class="s41"> </span><span class="s40"></span><span class="s42">1 </span>Fitness<span class="s33">(</span>h<span class="s52">j</span><span class="s41"> </span><span class="s33">)</span></p><p class="s6" style="padding-top: 2pt;padding-left: 60pt;text-indent: 0pt;text-align: left;">2<span class="p">． 交叉：根据上面给出的</span>Pr(<i>h</i><span class="s36">i</span>)<span class="p">，从</span><i>P</i><span class="p">中按概率选择</span><i>r</i><span class="s10"></span><i>p</i>/2 <span class="p">对假设。对于每一对 假设</span>&lt;<i>h</i><span class="s35">1</span>, <i>h</i><span class="s35">2</span>&gt;<span class="p">应用交叉算子产生两个后代。把所有的后代加入</span><i>P</i><span class="s36">S</span><span class="p">。</span></p><p style="padding-left: 59pt;text-indent: 0pt;text-align: left;"><span class="s6">3</span>． 变异：使用均匀的概率从<span class="s21">P</span><span class="s36">S</span>中选择<span class="s21">m</span>百分比的成员。对于选出的每个成员， 在它的表示中随机选择一个位取反。</p><p class="s21" style="padding-top: 1pt;padding-left: 59pt;text-indent: 0pt;text-align: left;"><span class="s6">4</span><span class="p">． 更新：</span>P<span class="s10"></span>P<span class="s36">S</span><span class="p">。</span></p><p class="s21" style="padding-left: 60pt;text-indent: 0pt;line-height: 14pt;text-align: left;"><span class="s6">5</span><span class="p">． 评估：对于 </span>P <span class="p">中的每一个 </span>h <span class="p">计算 </span>Fitness<span class="s6">(</span>h<span class="s6">)</span></p><p style="padding-left: 27pt;text-indent: 33pt;line-height: 14pt;text-align: left;"><span class="s10"> </span>从 <span class="s21">P </span>中返回适应度最高的假设。</p><p style="padding-left: 13pt;text-indent: 0pt;line-height: 2pt;text-align: left;"><span><img width="552" height="2" alt="image" src="机器学习/Image_351.png"/></span></p><p style="padding-top: 7pt;padding-left: 6pt;text-indent: 21pt;line-height: 113%;text-align: left;">在这个算法的每一次迭代中，基于当前的群体产生新一代的假设。首先，从当前的群体 中选择一定数量的假设包含在下一代中。这些假设是用概率方法选择的，其中选择假设<span class="s21">h</span><span class="s36">i</span>的</p><p style="padding-left: 6pt;text-indent: 0pt;text-align: left;">概率是通过下式计算的：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s33" style="padding-left: 6pt;text-indent: 0pt;text-align: left;">Pr(<i>h</i><span class="s52">i </span>) <span class="s38"></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="padding-left: 1pt;text-indent: 0pt;text-align: center;">Fitness<span class="s33">(</span>h<span class="s52">i</span><span class="s41"> </span><span class="s33">)</span></p><p style="padding-left: 1pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="108" height="1" alt="image" src="机器学习/Image_352.png"/></span></p><p class="s41" style="text-indent: 0pt;line-height: 7pt;text-align: left;">p</p><p style="text-indent: 0pt;text-align: left;"/><p class="s30" style="padding-left: 1pt;text-indent: 0pt;text-align: center;"><span class="s39"></span><span class="s176">j</span><span class="s41"> </span><span class="s40"></span><span class="s42">1 </span>Fitness<span class="s33">(</span>h<span class="s52">j</span><span class="s41"> </span><span class="s33">)</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 0pt;text-align: left;">（<span class="s6">9.1</span>）</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;line-height: 113%;text-align: justify;">因此，一个假设被选择的概率与它自己的适应度成正比，并且与当前群体中其他竞争假 设的适应度成反比。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 112%;text-align: justify;">在当前代的这些成员已被选入下一代群体后，再使用一种交叉操作产生其他的成员。交 叉操作将在下一节被具体定义，它从当前代中取两个双亲假设，并通过重新组合双亲的各部 分产生两个后代假设。双亲假设是从当前群体中按概率选出的，也使用公式（<span class="s6">9.1</span>）的概率 函数。在通过这种交叉操作产生新的成员后，新一代群体已经包含了所需数量的成员。接下 来，从这些成员中随机选出一定比例（<span class="s21">m</span>），并进行随机变异。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">因此，这种 <span class="s6">GA </span>算法执行一种随机的、并行柱状假设搜索，根据适应度函数发现较好的 假设。在下面的小节中我们将更详尽地描述这个算法中使用的假设表示和遗传算子。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">9.2.1 <span class="s25">表示假设</span></h3><p class="s6" style="padding-top: 10pt;padding-left: 5pt;text-indent: 21pt;line-height: 109%;text-align: justify;">GA <span class="p">中假设经常被表示为二进制位串，这样可以很方便地用变异和交叉遗传算子来操 作。使用这样的位串表示的假设可能非常复杂。例如，</span>if-then <span class="p">规则就可以很容易地用这种方 式表示，做法是选择规则的一种编码，其中为每个规则的前件和后件分配特定的子串。 </span>Holland<span class="p">（</span>1986<span class="p">）；</span>Grefenstette<span class="p">（</span>1988<span class="p">）；</span>DeJong et al.<span class="p">（</span>1993<span class="p">）中描述了 </span>GA <span class="p">系统中这种规则 表示的例子。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: left;">为了说明如何把 <span class="s6">if-then </span>规则编码成位串，首先考虑怎样使用位串描述单个属性的值约 束。例如考虑属性 <span class="s21">Outlook</span>，它的值可以取以下 <span class="s6">3 </span>个值中的任一个：<span class="s21">Sunny</span>，<span class="s21">Overcast </span>或 <span class="s21">Rain</span>。 表示 <span class="s21">Outlook </span>约束的一个明显的方法是，使用一个长度为 <span class="s6">3 </span>的位串，每位对应一个可能值。 若某位为 <span class="s6">1 </span>表示这个属性可以取对应的值。例如，串 <span class="s6">010 </span>表示 <span class="s21">Outlook </span>必须取第二个值的约 束，或者说 <span class="s21">Outlook</span><span class="s6">=</span><span class="s21">Overcast</span>。类似的，串 <span class="s6">011 </span>表示更一般的约束，<span class="s21">Outlook </span>可以取两个可能 值，或者说（<span class="s21">Outlook</span><span class="s6">=</span><span class="s21">Overcast</span><span class="s10"></span><span class="s21">Rain</span>）。注意 <span class="s6">111 </span>表示最一般的约束，表明我们不关心这个 属性取哪个值。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 110%;text-align: justify;">有了表示单个属性约束的方法，那么对多个属性约束的合取可以很容易地表示为对应位 串的连接。例如，考虑第二个属性 <span class="s21">Wind</span>，它可以取两个值 <span class="s21">Strong </span>或 <span class="s21">Weak</span>。那么像下面的规 则前件：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 24pt;text-indent: 0pt;text-align: center;">(<i>Outlook</i>=<i>Overcast</i><span class="s10"></span><i>Rain</i>)<span class="s10"></span>(<i>Wind</i>=<i>Strong</i>)</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 26pt;text-indent: 0pt;text-align: left;">可被表示为长度为 <span class="s6">5 </span>的位串：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 160pt;text-indent: 0pt;text-align: center;">Outlook Wind</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 160pt;text-indent: 0pt;text-align: center;">011 10</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 27pt;text-indent: 0pt;text-align: left;"><span class="p">规则的后件（例如 </span>PlayTennis<span class="s6">=</span>yes<span class="p">）可以用相似的方式表示。于是，整个规则表示可以</span></p><p style="padding-left: 6pt;text-indent: 0pt;text-align: left;">通过把描述规则前件和后件的位串连接起来。例如，下面的规则</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 139pt;text-indent: 0pt;text-align: left;">IF <i>Wind</i>=<i>Strong </i>THEN <i>PlayTennis</i>=<i>yes</i></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 27pt;text-indent: 0pt;text-align: left;">将被表示为以下的位串：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><table style="border-collapse:collapse;margin-left:130.332pt" cellspacing="0"><tr style="height:25pt"><td style="width:50pt"><p class="s96" style="padding-top: 3pt;padding-left: 2pt;text-indent: 0pt;text-align: left;">Outlook</p></td><td style="width:45pt"><p class="s96" style="padding-top: 3pt;padding-left: 13pt;text-indent: 0pt;text-align: left;">Wind</p></td><td style="width:59pt"><p class="s96" style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: left;">PlayTennis</p></td></tr><tr style="height:25pt"><td style="width:50pt"><p class="s98" style="padding-top: 7pt;padding-left: 12pt;text-indent: 0pt;text-align: left;">111</p></td><td style="width:45pt"><p class="s98" style="padding-top: 7pt;padding-left: 3pt;text-indent: 0pt;text-align: center;">10</p></td><td style="width:59pt"><p class="s98" style="padding-top: 7pt;padding-left: 7pt;text-indent: 0pt;text-align: center;">10</p></td></tr></table><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 6pt;text-indent: 20pt;line-height: 111%;text-align: left;">其中，前三位描述了对 <span class="s21">Outlook </span>的“不关心（<span class="s6">don’t care</span>）”约束，接下来两位描述了对 <span class="s21">Wind </span>的约束，最后两位描述了规则的后件（这里假定 <span class="s21">PlayTennis </span>可以取两个值 <span class="s21">Yes </span>或 <span class="s21">No</span>）。 注意，表示规则的位串对假设空间中的每个属性有一个子串，即使该属性不被规则的前件所 约束。这样得到了一个固定长度的规则位串表示，其中在特定位置的子串描述对特定属性的 约束。有了单个规则的表示方法，我们可以简单地把单个规则的位串表示连接起来，从而表 示规则集。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 109%;text-align: justify;">在为某个假设空间设计位串编码时，有必要让每个句法合法的位串表示一个有意义的假 设。比如，若使用上一段的规则编码方式，那么位串 <span class="s6">111 10 11 </span>表示了一个规则，它的后件 不约束目标属性 <span class="s21">PlayTennis</span>。如果要避免考虑这个假设，可以采用不同的编码方式（例如， 仅分配一个位给后件 <span class="s21">PlayTennis</span>，表示它的值是 <span class="s21">Yes </span>或 <span class="s21">No</span>）；或改变遗传算子以明确避免建 立这样的位串；或干脆把很低的适应度赋给这样的串。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 107%;text-align: justify;">在一些 <span class="s6">GA </span>中，假设是用符号描述来表示的，而不是用位串。例如，在 <span class="s6">9.5 </span>节中，我们 讨论了一个把假设编码为计算机程序的遗传算法。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">9.2.2 <span class="s25">遗传算子</span></h3><p style="padding-top: 10pt;padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">在 <span class="s6">GA </span>中通过一系列算子（<span class="s6">operators</span>）来决定后代，算子对当前群体中选定的成员进行 重组和变异。表 <span class="s6">9-1 </span>中列出了用来操作位串的典型 <span class="s6">GA </span>算子。这些算子是生物进化中的遗传 过程的理想化形式。最常见的两个算子是交叉（<span class="s6">crossover</span>）和变异（<span class="s6">mutation</span>）。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 108%;text-align: justify;">交叉算子从两个双亲串中通过复制选定位产生两个新的后代。每个后代的第 <span class="s21">i </span>位是从它 的某个双亲的第 <span class="s21">i </span>位复制来的。至于双亲中的哪一个在第 <span class="s21">i </span>位起作用，这是由另外一个称为 交叉掩码（<span class="s6">crossover mask</span>）的位串决定的。下面演示一下这个过程，考虑表 <span class="s6">9-2 </span>中最上边的 单点（<span class="s6">single-point</span>）交叉算子。先考虑其中上面一个后代。这个后代从第一个双亲中取前 <span class="s6">5 </span>位，其余的 <span class="s6">6 </span>位来自第二个双亲，因为交叉掩码 <span class="s6">11111000000 </span>为每个位指定这些选择。第二 个后代使用同样的交叉掩码，但交换了双亲的角色。所以，它包含了第一个后代没有用过的 位。在单点交叉中，交叉掩码总是这样组成的，它以连续的 <span class="s21">n </span>个 <span class="s6">1 </span>开始，后面跟随必要个数 的 <span class="s6">0 </span>直至结束。这样的结果是后代中前 <span class="s21">n </span>位来自第一个双亲，余下的位来自第二个双亲。每 次应用单点交叉算子时，交叉点 <span class="s21">n </span>是随机选取的，然后再产生交叉掩码并应用。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 48pt;text-indent: 0pt;text-align: center;">表 <span class="h4">9-2 </span>遗传算法常见算子</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-left: 37pt;text-indent: 18pt;line-height: 132%;text-align: left;">这些算子形成用位串表示的后代假设。交叉算子从两个双亲中产生两个后代，使用交叉掩码来 决定哪一个双亲作用于相应的位。变异从单一的双亲中产生单一的后代，通过随机选取一位并取反。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 34pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="519" height="1" alt="image" src="机器学习/Image_353.png"/></span></p><p class="s48" style="padding-left: 57pt;text-indent: 0pt;text-align: left;">插图——原书页码： <span class="s21">254</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;line-height: 190%;text-align: left;">initial strings –<span class="p">初始串 </span>Crossover Mask-<span class="p">交叉掩码 </span>Offspring-<span class="p">后代</span></p><p class="s6" style="padding-top: 2pt;padding-left: 26pt;text-indent: 0pt;line-height: 190%;text-align: left;">Single-point crossover:-<span class="p">单点交叉 </span>Two-point crossover:-<span class="p">两点交叉 </span>Uniform crossover-<span class="p">均匀交叉 </span>Point mutation:-<span class="p">点变异</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 14pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="531" height="1" alt="image" src="机器学习/Image_354.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;text-align: justify;">在两点交叉（<span class="s6">two-point crossover</span>）中，后代的产生通过把一个双亲串的中间片段替换第 二个双亲串的中间片段。换句话来讲，交叉掩码以<span class="s21">n</span><span class="s35">0</span>个 <span class="s6">0 </span>开始，后面跟随<span class="s21">n</span><span class="s35">1</span>个 <span class="s6">1</span>，再跟随必 要数量的 <span class="s6">0 </span>结束。每次应用两点交叉算子时，通过随机选取两个整数<span class="s21">n</span><span class="s35">0</span>和<span class="s21">n</span><span class="s35">1</span>来产生掩码。例 如，在表 <span class="s6">9-2 </span>显示的例子中，是使用<span class="s21">n</span><span class="s35">0</span><span class="s6">=2 </span>和<span class="s21">n</span><span class="s35">1</span><span class="s6">=5 </span>的掩码来产生后代的。和上面一样，通过 转换两个双亲的角色来产生这两个后代。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 110%;text-align: left;">均匀交叉（<span class="s6">uniform crossover</span>）合并了从两个双亲以均匀概率抽取的位，如表 <span class="s6">9-2 </span>所示。 在这种情况下，产生一个随机的位串作为交叉掩码，每一位的选取都是随机的并且独立于其 他位。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 110%;text-align: left;">除了通过组合双亲的各部分产生后代的重组算子，另一种类型的算子从单一的双亲产生 后代。确切地讲，变异（<span class="s6">mutation</span>）算子用于对位串产生随机的小变化，方法是选取一个位， 然后取反。变异经常是在应用了交叉之后进行的，像表 <span class="s6">9-1 </span>中的原型算法那样。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 109%;text-align: justify;">一些 <span class="s6">GA </span>系统应用了其他的算子，特别是一些专门针对系统中特定假设表示的算子。例 如，<span class="s6">Grefenstette et al.</span>（<span class="s6">1991</span>）描述了一个学习机器人控制规则集的系统。它除了使用变异 和交叉算子，还使用了一个算子以使规则特化。<span class="s6">Janikow</span>（<span class="s6">1993</span>）描述了一个学习规则集的 系统，其中使用了多种直接泛化和特化规则的算子（例如直接把一个属性条件替换为“不关 心”（<span class="s6">don’t care</span>））。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 51pt;text-indent: 0pt;text-align: left;">9.2.3 <span class="s25">适应度函数和假设选择</span></h3><p style="padding-top: 10pt;padding-left: 6pt;text-indent: 21pt;line-height: 112%;text-align: left;">适应度函数定义了候选假设的排名准则，并且是以概率方法选择下一代群体的准则。如 果任务是学习分类的规则，那么适应度函数中会有一项用来评价每个规则对训练样例集合的 分类精度。适应度函数中也可能包含其他的准则，例如规则的复杂度和一般性（<span class="s6">generality</span>）。 更一般地讲，当位串被解释为复杂的过程时（例如，当位串表示一系列规则，这些规则要被 链接在一起控制一个机器人设备），适应度函数可以测量生成的过程总体性能而不是单个规 则的性能。</p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 108%;text-align: justify;">在表 <span class="s6">9-1 </span>中显示的<span class="s6">GA</span>原型中，选择某假设的概率是通过它的适应度与当前群体中其他 成员的适应度的比值得到的，如公式（<span class="s6">9.1</span>）所示。这种方法有时被称为适应度比例选择（<span class="s6">fitness proportionate selection</span>），或称为轮盘赌<span class="s9">①</span>选择（<span class="s6">roulette wheel selection</span>）。人们也提出了其他 使用适应度来选择假设的方法。例如锦标赛选择（<span class="s6">tournament selection</span>），它先从当前群体中 随机选取两个假设，再按照事先定义的概率<span class="s6">p</span>选择适应度较高的假设，按照概率 <span class="s6">1-</span><span class="s21">p</span>选择适 应度较低的假设。锦标赛选择常常比适应度比例法得到更加多样化的群体（<span class="s6">Goldberg and Deb 1991</span>）。在另一种被称为排名选择（<span class="s6">rank selection</span>）的方法中，当前群体中的假设先按适应 度排序。然后，选择某假设的概率与它在这个排序列表中的位置成比例，而不是与它的适应 度成比例。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">9.3 <span class="s17">示例</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 109%;text-align: justify;">遗传算法可以被看作通用的最优化方法，它搜索一个巨大的候选对象空间，根据适应度 函数查找表现最好的对象。尽管不保证发现最优的对象，但 <span class="s6">GA </span>经常成功地发现具有较高适 应度的对象。<span class="s6">GA </span>已经被应用到机器学习以外的大量最优化问题，包括像电路布线和任务调 度这样的问题。在机器学习领域，<span class="s6">GA </span>不仅被应用到函数逼近问题，还应用到像选取人工神 经网络的拓扑结构这样的任务。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 26pt;text-indent: 0pt;text-align: left;">为了说明 <span class="s6">GA </span>在概念学习方面的应用，我们简要概述一下 <span class="s6">DeJong et al</span>（<span class="s6">.</span></p><p class="s6" style="padding-top: 1pt;padding-left: 4pt;text-indent: 0pt;text-align: left;">1993<span class="p">）的 </span>GABIL</p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 0pt;line-height: 107%;text-align: justify;">系统。<span class="s6">GABIL </span>使用 <span class="s6">GA </span>来学习以命题规则的析取集合表示的布尔概念。在对几个概念学习 问题的实验中，发现在泛化精度方面 <span class="s6">GABIL </span>与其他的学习算法大体相当，这里的其他算法 包括决策树学习算法 <span class="s6">C4.5 </span>和规则学习系统 <span class="s6">AQ14</span>。这个研究中的学习任务既有人为设计的 用来研究系统泛化精度的学习任务，又有乳腺癌诊断这样的现实问题。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;"><span class="s6">GABIL </span>使用的算法就是表 <span class="s6">9-1 </span>中描述的算法。在 <span class="s6">DeJong et al.</span>（<span class="s6">1993</span>）报告的实验中， 决定通过交叉替换父代比例的参数 <span class="s21">r </span>被设置为 <span class="s6">0.06</span>。决定变异率的参数 <span class="s21">m </span>被设置为 <span class="s6">0.001</span>。 这是这些参数的典型设置。群体大小 <span class="s21">p </span>从 <span class="s6">100 </span>到 <span class="s6">1000 </span>不等，视特定学习任务而定。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 26pt;text-indent: 0pt;text-align: left;">GA <span class="p">在 </span>GABIL <span class="p">中的具体应用可以被概括为以下几点：</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 109%;text-align: justify;">表示 在<span class="s6">GABIL</span>中每个假设对应于一个命题规则的析取集，并按照 <span class="s6">9.2.1 </span>节描述的方 法编码。确切地讲，规则前件的假设空间由对一个固定的属性集的约束的合取组成，就像前 面描述的那样。为了表示规则集，单个规则的位串表示被连接起来。例如，考虑这样一个假 设空间，其中规则的前件是对两个布尔属性<span class="s21">a</span><span class="s35">1</span>和<span class="s21">a</span><span class="s35">2</span>的约束的合取。规则的后件是用单个的位 描述的，表示目标属性<span class="s21">c</span>的预测值。于是，由两个规则组成的假设：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 119pt;text-indent: 0pt;text-align: left;"><span class="s6">IF </span>a<span class="s35">1</span><span class="s6">=</span>T <span class="s10"></span>a<span class="s35">2</span><span class="s6">=</span>F <span class="s6">THEN </span>c<span class="s6">=</span>T<span class="p">；</span><span class="s6">IF </span>a<span class="s35">2</span><span class="s6">=</span>T <span class="s6">THEN </span>c<span class="s6">=</span>F</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 0pt;text-align: justify;">将被表示为串：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 26pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="193" height="1" alt="image" src="机器学习/Image_355.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s13" style="padding-top: 2pt;padding-left: 6pt;text-indent: 18pt;line-height: 132%;text-align: left;">①<span class="s14">译注： 轮盘赌是指一种赌博者打赌转盘上旋转的小球将停止于盘上哪一个槽内的游戏，这里的含义 是概率大的假设占据盘上较大的扇区，因而被选中的机会较大。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><table style="border-collapse:collapse;margin-left:108.03pt" cellspacing="0"><tr style="height:19pt"><td style="width:22pt"><p class="s96" style="padding-top: 3pt;padding-left: 3pt;text-indent: 0pt;text-align: left;">a<span class="s97">1</span></p></td><td style="width:32pt"><p class="s96" style="padding-top: 3pt;padding-left: 9pt;text-indent: 0pt;text-align: left;">a<span class="s97">2</span></p></td><td style="width:43pt"><p class="s96" style="padding-top: 3pt;padding-right: 9pt;text-indent: 0pt;text-align: center;">c</p></td><td style="width:41pt"><p class="s96" style="padding-top: 3pt;padding-left: 23pt;text-indent: 0pt;text-align: left;">a<span class="s97">1</span></p></td><td style="width:29pt"><p class="s96" style="padding-top: 3pt;padding-left: 9pt;text-indent: 0pt;text-align: left;">a<span class="s97">2</span></p></td><td style="width:17pt"><p class="s96" style="padding-top: 3pt;padding-left: 9pt;text-indent: 0pt;text-align: left;">c</p></td></tr><tr style="height:18pt"><td style="width:22pt"><p class="s98" style="padding-left: 2pt;text-indent: 0pt;text-align: left;">10</p></td><td style="width:32pt"><p class="s98" style="padding-left: 8pt;text-indent: 0pt;text-align: left;">01</p></td><td style="width:43pt"><p class="s98" style="padding-left: 14pt;text-indent: 0pt;text-align: left;">1</p></td><td style="width:41pt"><p class="s98" style="padding-left: 23pt;text-indent: 0pt;text-align: left;">11</p></td><td style="width:29pt"><p class="s98" style="padding-left: 8pt;text-indent: 0pt;text-align: left;">10</p></td><td style="width:17pt"><p class="s98" style="padding-left: 9pt;text-indent: 0pt;text-align: left;">0</p></td></tr></table><p style="padding-top: 1pt;padding-left: 7pt;text-indent: 21pt;line-height: 113%;text-align: left;">注意位串的长度随着假设中规则的数量增长。由于位串长度的可变性，需要对交叉算子 作少许修改，这将在下面描述。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 7pt;text-indent: 21pt;line-height: 108%;text-align: left;">遗传算子 <span class="s6">GABIL</span>使用表 <span class="s6">9-2 </span>中的标准变异算子，随机选取一个位，并用它的反码取 代这一位。<span class="s6">GABIL</span>使用的交叉算子是表 <span class="s6">9-2 </span>描述的两点交叉算子的一个相当标准的扩展。确 切地讲，为了适应编码规则集的位串的长度可变性，并且限制系统以使交叉仅发生在位串的 相似片段间，采取了下面的办法。首先在第一个双亲串上随机选取两个交叉点，它们之间划 分出了一个位串片段。由于位串表示的是一个规则集，我们可以标记出其中每个规则的边界。 这个位串片段可能跨越若干个规则边界。然后令<span class="s21">d</span><span class="s35">1</span>表示片段的最左一位到它左侧第一个规则 边界的距离。<span class="s21">d</span><span class="s35">2</span>表示片段的最右一位到它左侧第一个规则边界的距离。接下来，在第二个双 亲上随机选取交叉点，只要选择的交叉点具有同样的<span class="s21">d</span><span class="s35">1</span>和<span class="s21">d</span><span class="s35">2</span>值。例如，如果两个双亲串是</p><p style="text-indent: 0pt;text-align: left;"><br/></p><table style="border-collapse:collapse;margin-left:5.25023pt" cellspacing="0"><tr style="height:37pt"><td style="width:124pt"><p class="s96" style="padding-top: 3pt;padding-right: 9pt;text-indent: 0pt;line-height: 13pt;text-align: right;">a<span class="s97">1</span></p><p class="s96" style="padding-right: 8pt;text-indent: 0pt;line-height: 15pt;text-align: right;">h<span class="s97">1</span><span class="s95">： </span><span class="s98">10</span></p></td><td style="width:29pt"><p class="s96" style="padding-top: 3pt;padding-left: 9pt;text-indent: 0pt;text-align: left;">a<span class="s97">2</span></p><p class="s98" style="padding-top: 2pt;padding-left: 8pt;text-indent: 0pt;text-align: left;">01</p></td><td style="width:42pt"><p class="s96" style="padding-top: 3pt;padding-left: 9pt;text-indent: 0pt;text-align: left;">c</p><p class="s98" style="padding-top: 2pt;padding-left: 9pt;text-indent: 0pt;text-align: left;">1</p></td><td style="width:46pt"><p class="s96" style="padding-top: 3pt;padding-left: 28pt;text-indent: 0pt;text-align: left;">a<span class="s97">1</span></p><p class="s98" style="padding-top: 2pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">11</p></td><td style="width:29pt"><p class="s96" style="padding-top: 3pt;padding-left: 9pt;text-indent: 0pt;text-align: left;">a<span class="s97">2</span></p><p class="s98" style="padding-top: 2pt;padding-left: 8pt;text-indent: 0pt;text-align: left;">10</p></td><td style="width:17pt"><p class="s96" style="padding-top: 3pt;padding-left: 9pt;text-indent: 0pt;text-align: left;">c</p><p class="s98" style="padding-top: 2pt;padding-left: 9pt;text-indent: 0pt;text-align: left;">0</p></td></tr><tr style="height:22pt"><td style="width:124pt"><p class="s95" style="padding-top: 1pt;padding-left: 2pt;text-indent: 0pt;text-align: left;">和</p></td><td style="width:29pt"/><td style="width:42pt"/><td style="width:46pt"/><td style="width:29pt"/><td style="width:17pt"/></tr><tr style="height:20pt"><td style="width:124pt"><p class="s96" style="padding-top: 4pt;padding-right: 9pt;text-indent: 0pt;text-align: right;">a<span class="s97">1</span></p></td><td style="width:29pt"><p class="s96" style="padding-top: 4pt;padding-left: 9pt;text-indent: 0pt;text-align: left;">a<span class="s97">2</span></p></td><td style="width:42pt"><p class="s96" style="padding-top: 4pt;padding-left: 9pt;text-indent: 0pt;text-align: left;">c</p></td><td style="width:46pt"><p class="s96" style="padding-top: 4pt;padding-left: 28pt;text-indent: 0pt;text-align: left;">a<span class="s97">1</span></p></td><td style="width:29pt"><p class="s96" style="padding-top: 4pt;padding-left: 9pt;text-indent: 0pt;text-align: left;">a<span class="s97">2</span></p></td><td style="width:17pt"><p class="s96" style="padding-top: 4pt;padding-left: 9pt;text-indent: 0pt;text-align: left;">c</p></td></tr><tr style="height:19pt"><td style="width:124pt"><p class="s96" style="padding-left: 74pt;text-indent: 0pt;line-height: 14pt;text-align: left;">h<span class="s97">2</span><span class="s95">： </span><span class="s98">01</span></p></td><td style="width:29pt"><p class="s98" style="padding-left: 8pt;text-indent: 0pt;text-align: left;">11</p></td><td style="width:42pt"><p class="s98" style="padding-left: 9pt;text-indent: 0pt;text-align: left;">0</p></td><td style="width:46pt"><p class="s98" style="padding-left: 27pt;text-indent: 0pt;text-align: left;">10</p></td><td style="width:29pt"><p class="s98" style="padding-left: 8pt;text-indent: 0pt;text-align: left;">01</p></td><td style="width:17pt"><p class="s98" style="padding-left: 9pt;text-indent: 0pt;text-align: left;">0</p></td></tr></table><p style="padding-top: 1pt;padding-left: 8pt;text-indent: 0pt;text-align: left;">并且为第一个双亲选取交叉点位置是第 <span class="s6">1 </span>和第 <span class="s6">8 </span>位，如下所示：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><table style="border-collapse:collapse;margin-left:77.2489pt" cellspacing="0"><tr style="height:18pt"><td style="width:53pt"><p class="s96" style="padding-top: 3pt;padding-left: 34pt;text-indent: 0pt;text-align: left;">a<span class="s97">1</span></p></td><td style="width:28pt"><p class="s96" style="padding-top: 3pt;padding-left: 8pt;text-indent: 0pt;text-align: left;">a<span class="s97">2</span></p></td><td style="width:42pt"><p class="s96" style="padding-top: 3pt;padding-left: 9pt;text-indent: 0pt;text-align: left;">c</p></td><td style="width:45pt"><p class="s96" style="padding-top: 3pt;padding-left: 28pt;text-indent: 0pt;text-align: left;">a<span class="s97">1</span></p></td><td style="width:30pt"><p class="s96" style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: left;">a<span class="s97">2</span></p></td><td style="width:17pt"><p class="s96" style="padding-top: 3pt;padding-left: 8pt;text-indent: 0pt;text-align: left;">c</p></td></tr><tr style="height:19pt"><td style="width:53pt"><p class="s96" style="padding-left: 2pt;text-indent: 0pt;line-height: 14pt;text-align: left;">h<span class="s97">1</span><span class="s95">： </span><span class="s98">1[0</span></p></td><td style="width:28pt"><p class="s98" style="padding-left: 7pt;text-indent: 0pt;text-align: left;">01</p></td><td style="width:42pt"><p class="s98" style="padding-left: 9pt;text-indent: 0pt;text-align: left;">1</p></td><td style="width:45pt"><p class="s98" style="padding-left: 27pt;text-indent: 0pt;text-align: left;">11</p></td><td style="width:30pt"><p class="s98" style="padding-left: 7pt;text-indent: 0pt;text-align: left;">1]0</p></td><td style="width:17pt"><p class="s98" style="padding-left: 8pt;text-indent: 0pt;text-align: left;">0</p></td></tr></table><p style="padding-top: 1pt;padding-left: 8pt;text-indent: 0pt;text-align: left;">其中“<span class="s6">[</span>”和“<span class="s6">]</span>”表示交叉点，那么<span class="s21">d</span><span class="s35">1</span><span class="s6">=1 </span>并且<span class="s21">d</span><span class="s35">2</span><span class="s6">=3</span>。所以，允许选取的第二个双亲交叉点的 位置有<span class="s6">&lt;1, 3&gt;</span>，<span class="s6">&lt;1, 8&gt;</span>和<span class="s6">&lt;6, 8&gt;</span>。如果恰巧选取了<span class="s6">&lt;1</span>，<span class="s6">3&gt;</span>，</p><p style="text-indent: 0pt;text-align: left;"><br/></p><table style="border-collapse:collapse;margin-left:77.2489pt" cellspacing="0"><tr style="height:18pt"><td style="width:52pt"><p class="s96" style="padding-top: 3pt;padding-left: 34pt;text-indent: 0pt;text-align: left;">a<span class="s97">1</span></p></td><td style="width:30pt"><p class="s96" style="padding-top: 3pt;padding-left: 9pt;text-indent: 0pt;text-align: left;">a<span class="s97">2</span></p></td><td style="width:41pt"><p class="s96" style="padding-top: 3pt;padding-left: 8pt;text-indent: 0pt;text-align: left;">c</p></td><td style="width:46pt"><p class="s96" style="padding-top: 3pt;padding-left: 28pt;text-indent: 0pt;text-align: left;">a<span class="s97">1</span></p></td><td style="width:29pt"><p class="s96" style="padding-top: 3pt;padding-left: 9pt;text-indent: 0pt;text-align: left;">a<span class="s97">2</span></p></td><td style="width:17pt"><p class="s96" style="padding-top: 3pt;padding-left: 9pt;text-indent: 0pt;text-align: left;">c</p></td></tr><tr style="height:19pt"><td style="width:52pt"><p class="s96" style="padding-left: 2pt;text-indent: 0pt;line-height: 14pt;text-align: left;">h<span class="s97">2</span><span class="s95">： </span><span class="s98">0[1</span></p></td><td style="width:30pt"><p class="s98" style="padding-left: 6pt;text-indent: 0pt;text-align: left;">1]1</p></td><td style="width:41pt"><p class="s98" style="padding-left: 8pt;text-indent: 0pt;text-align: left;">0</p></td><td style="width:46pt"><p class="s98" style="padding-left: 27pt;text-indent: 0pt;text-align: left;">10</p></td><td style="width:29pt"><p class="s98" style="padding-left: 8pt;text-indent: 0pt;text-align: left;">01</p></td><td style="width:17pt"><p class="s98" style="padding-left: 9pt;text-indent: 0pt;text-align: left;">0</p></td></tr></table><p style="padding-top: 1pt;padding-left: 8pt;text-indent: 0pt;text-align: left;">那么结果生成的两个后代是</p><p style="text-indent: 0pt;text-align: left;"><br/></p><table style="border-collapse:collapse;margin-left:77.2493pt" cellspacing="0"><tr style="height:18pt"><td style="width:52pt"><p class="s96" style="padding-top: 3pt;padding-left: 34pt;text-indent: 0pt;text-align: left;">a<span class="s97">1</span></p></td><td style="width:29pt"><p class="s96" style="padding-top: 3pt;padding-left: 9pt;text-indent: 0pt;text-align: left;">a<span class="s97">2</span></p></td><td style="width:17pt"><p class="s96" style="padding-top: 3pt;padding-left: 9pt;text-indent: 0pt;text-align: left;">c</p></td></tr><tr style="height:19pt"><td style="width:52pt"><p class="s96" style="padding-left: 2pt;text-indent: 0pt;line-height: 14pt;text-align: left;">h<span class="s97">3</span><span class="s95">： </span><span class="s98">11</span></p></td><td style="width:29pt"><p class="s98" style="padding-left: 8pt;text-indent: 0pt;text-align: left;">10</p></td><td style="width:17pt"><p class="s98" style="padding-left: 9pt;text-indent: 0pt;text-align: left;">0</p></td></tr></table><p style="padding-top: 1pt;padding-left: 8pt;text-indent: 0pt;text-align: left;">和</p><p style="text-indent: 0pt;text-align: left;"><br/></p><table style="border-collapse:collapse;margin-left:77.249pt" cellspacing="0"><tr style="height:18pt"><td style="width:52pt"><p class="s96" style="padding-top: 3pt;padding-left: 34pt;text-indent: 0pt;text-align: left;">a<span class="s97">1</span></p></td><td style="width:29pt"><p class="s96" style="padding-top: 3pt;padding-left: 9pt;text-indent: 0pt;text-align: left;">a<span class="s97">2</span></p></td><td style="width:42pt"><p class="s96" style="padding-top: 3pt;padding-left: 9pt;text-indent: 0pt;text-align: left;">c</p></td><td style="width:46pt"><p class="s96" style="padding-top: 3pt;padding-left: 28pt;text-indent: 0pt;text-align: left;">a<span class="s97">1</span></p></td><td style="width:29pt"><p class="s96" style="padding-top: 3pt;padding-left: 9pt;text-indent: 0pt;text-align: left;">a<span class="s97">2</span></p></td><td style="width:39pt"><p class="s96" style="padding-top: 3pt;padding-left: 9pt;text-indent: 0pt;text-align: left;">c</p></td><td style="width:41pt"><p class="s96" style="padding-top: 3pt;padding-left: 25pt;text-indent: 0pt;text-align: left;">a<span class="s97">1</span></p></td><td style="width:28pt"><p class="s96" style="padding-top: 3pt;padding-left: 7pt;text-indent: 0pt;text-align: left;">a<span class="s97">2</span></p></td><td style="width:17pt"><p class="s96" style="padding-top: 3pt;padding-left: 9pt;text-indent: 0pt;text-align: left;">c</p></td></tr><tr style="height:19pt"><td style="width:52pt"><p class="s96" style="padding-left: 2pt;text-indent: 0pt;line-height: 14pt;text-align: left;">h<span class="s97">4</span><span class="s95">： </span><span class="s98">00</span></p></td><td style="width:29pt"><p class="s98" style="padding-left: 8pt;text-indent: 0pt;text-align: left;">01</p></td><td style="width:42pt"><p class="s98" style="padding-left: 9pt;text-indent: 0pt;text-align: left;">1</p></td><td style="width:46pt"><p class="s98" style="padding-left: 27pt;text-indent: 0pt;text-align: left;">11</p></td><td style="width:29pt"><p class="s98" style="padding-left: 8pt;text-indent: 0pt;text-align: left;">11</p></td><td style="width:39pt"><p class="s98" style="padding-left: 9pt;text-indent: 0pt;text-align: left;">0</p></td><td style="width:41pt"><p class="s98" style="padding-left: 24pt;text-indent: 0pt;text-align: left;">10</p></td><td style="width:28pt"><p class="s98" style="padding-left: 7pt;text-indent: 0pt;text-align: left;">01</p></td><td style="width:17pt"><p class="s98" style="padding-left: 9pt;text-indent: 0pt;text-align: left;">0</p></td></tr></table><p style="padding-top: 1pt;padding-left: 8pt;text-indent: 0pt;line-height: 113%;text-align: left;">如此例所示，这种交叉方法中后代可以包含与双亲不同数量的规则，同时保证了按这种方式 产生的位串表示良定义的（<span class="s6">well-defined</span>）规则集。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 8pt;text-indent: 0pt;line-height: 113%;text-align: left;">适应度函数 每个规则集的适应度是根据它在训练数据上的分类精度计算的。确切地讲， 度量适应度的函数是：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 20pt;text-indent: 0pt;text-align: center;">Fitness<span class="s6">(</span>h<span class="s6">)=(</span>correct<span class="s6">(</span>h<span class="s6">))</span><span class="s46">2</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 29pt;text-indent: 0pt;text-align: left;"><span class="p">其中，</span>correct<span class="s6">(</span>h<span class="s6">)</span><span class="p">是假设 </span>h <span class="p">分类所有训练样例的正确率。</span></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 107%;text-align: justify;">在比较 <span class="s6">GABIL </span>和像 <span class="s6">C4.5 </span>和 <span class="s6">ID5R </span>这样的决策树学习算法以及规则学习算法 <span class="s6">AQ14 </span>的实 验中，根据对不同学习任务的测试，<span class="s6">DeJong et al.</span>（<span class="s6">1993</span>）报告了这些系统具有大体相当的 性能。例如，对人为设计的 <span class="s6">12 </span>个问题，<span class="s6">GABIL </span>达到了 <span class="s6">92.1%</span>的平均泛化精度，而其他系统 的的性能是在 <span class="s6">91.2%</span>到 <span class="s6">96.6%</span>之间。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">9.3.1 <span class="s25">扩展</span></h3><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">DeJong et al<span class="p">（</span>.</p><p class="s6" style="padding-top: 1pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">1993<span class="p">）中也探索了对 </span>GABIL <span class="p">基本设计的两个有趣的扩展。在一组实验中，</span></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: justify;">他们研究了另外两个新的遗传算子，这两个算子受到了很多符号学习方法中常见的泛化算子 的启发。第一个算子为 <span class="s21">AddAlternative</span>，它泛化对某个特定属性的约束，方法是把这个属性 对应的子串中的一个 <span class="s6">0 </span>改为 <span class="s6">1</span>。例如，如果一个属性的约束使用串 <span class="s6">10010 </span>表示，那么这个算 子可能把它改为 <span class="s6">10110</span>。这个算子在每一代群体中对选定的成员按照 <span class="s6">0.01 </span>的概率应用。第二 个算子为 <span class="s21">DropCondition</span>，它采用一种更加极端的泛化措施，把一个特定属性的所有位都替 换为 <span class="s6">1</span>。这个算子相当于通过完全撤销属性约束来泛化规则，它按照概率 <span class="s6">0.60 </span>在每一代中应</p><p style="padding-left: 6pt;text-indent: 0pt;text-align: left;">用。<span class="s6">DeJong et al</span>（<span class="s6">.</span></p><p class="s6" style="padding-left: 3pt;text-indent: 0pt;text-align: left;">1993<span class="p">）中报告了这个改进的系统对于上面所说的人为设计任务达到了 </span>95.2%</p><p style="padding-top: 1pt;padding-left: 27pt;text-indent: -21pt;text-align: left;">的平均泛化精度，相比较基本的 <span class="s6">GA </span>为 <span class="s6">92.1%</span>。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 113%;text-align: justify;">在上面的实验中，两个算子对每一代群体中的每个假设是以同样的概率应用的。在另一 个实验中，对假设的位串表示进行了扩展，使其包含另外两位以决定是否可以对该假设应用 这两个算子。在这个扩展的表示中，一个典型的规则集假设的位串为</p><p style="text-indent: 0pt;text-align: left;"><br/></p><table style="border-collapse:collapse;margin-left:106.025pt" cellspacing="0"><tr style="height:19pt"><td style="width:22pt"><p class="s96" style="padding-top: 3pt;padding-left: 3pt;text-indent: 0pt;text-align: left;">a<span class="s97">1</span></p></td><td style="width:28pt"><p class="s96" style="padding-top: 3pt;padding-left: 8pt;text-indent: 0pt;text-align: left;">a<span class="s97">2</span></p></td><td style="width:42pt"><p class="s96" style="padding-top: 3pt;padding-left: 9pt;text-indent: 0pt;text-align: left;">c</p></td><td style="width:47pt"><p class="s96" style="padding-top: 3pt;padding-left: 28pt;text-indent: 0pt;text-align: left;">a<span class="s97">1</span></p></td><td style="width:28pt"><p class="s96" style="padding-top: 3pt;padding-left: 9pt;text-indent: 0pt;text-align: left;">a<span class="s97">2</span></p></td><td style="width:38pt"><p class="s96" style="padding-top: 3pt;padding-left: 9pt;text-indent: 0pt;text-align: left;">c</p></td><td style="width:65pt"><p class="s96" style="padding-top: 3pt;padding-left: 23pt;text-indent: 0pt;text-align: left;">AA DC</p></td></tr><tr style="height:18pt"><td style="width:22pt"><p class="s98" style="padding-left: 2pt;text-indent: 0pt;text-align: left;">01</p></td><td style="width:28pt"><p class="s98" style="padding-left: 8pt;text-indent: 0pt;text-align: left;">11</p></td><td style="width:42pt"><p class="s98" style="padding-left: 9pt;text-indent: 0pt;text-align: left;">0</p></td><td style="width:47pt"><p class="s98" style="padding-left: 27pt;text-indent: 0pt;text-align: left;">10</p></td><td style="width:28pt"><p class="s98" style="padding-left: 8pt;text-indent: 0pt;text-align: left;">01</p></td><td style="width:38pt"><p class="s98" style="padding-left: 9pt;text-indent: 0pt;text-align: left;">0</p></td><td style="width:65pt"><p class="s98" style="padding-left: 27pt;text-indent: 0pt;text-align: left;">1 0</p></td></tr></table><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 0pt;line-height: 107%;text-align: justify;">其中最后的两个位表示在这种情况下可以对该串应用 <span class="s21">AddAlternative </span>算子，而不可以应用 <span class="s21">DropCondition </span>算子。这两个新的位定义了部分的 <span class="s6">GA </span>搜索策略，而且它们本身也和串中的 其他位一起被同样的交叉和变异算子修改和进化。<span class="s6">DeJong et al.</span>（<span class="s6">1993</span>）报告了这种方法的 结果优劣参半（也就是对某些问题提高了性能，对其他问题降低了性能），它例示了 <span class="s6">GA </span>在 原则上是如何使其假设的搜索方法进化的。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 6pt;text-indent: 0pt;text-align: justify;">9.4 <span class="s17">假设空间搜索</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 109%;text-align: justify;">如上所示，<span class="s6">GA </span>采用一种随机化的柱状搜索来寻找有最大适应度的假设。这种搜索与本 书中已考虑的其他学习方法的搜索完全不同。例如，比较 <span class="s6">GA </span>使用的搜索空间和神经网络反 向传播算法使用的搜索空间：在反向传播算法中，梯度下降搜索从一个假设平滑移动到一个 非常相似的新假设。与此不同，<span class="s6">GA </span>搜索的移动可能非常突然，使用和双亲根本不同的后代 替换双亲假设。注意 <span class="s6">GA </span>搜索因此不太可能像梯度下降方法那样具有陷入局部最小值的问 题。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 110%;text-align: left;">在一些 <span class="s6">GA </span>应用中，一个实践上的难题是拥挤（<span class="s6">crowding</span>）问题。拥挤是这样一种现象， 群体中某一个体适应度大大高于其他个体，因此它迅速繁殖，以至于这个个体和与它相似的 个体占据了群体的绝大部分。拥挤的不良影响是降低了群体的多样性（<span class="s6">diversity</span>），从而减慢 了 <span class="s6">GA </span>的进一步进化。人们已经探索了若干降低拥挤的策略。一种方法是修改选择函数，使 用像锦标赛选择或排名选择这样的准则取代适应度比例轮盘赌选择。一个相关的策略是“适 应度共享（<span class="s6">fitness sharing</span>）”，其中根据群体中与某个体相似的个体数量，减小该个体的适应</p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 110%;text-align: justify;">度。第三种方法是对可重组生成后代的个体种类进行限制。例如，通过只允许最相似的个体 重组，可以在群体中促成相似的个体聚类，或多个亚种（<span class="s6">subspecies</span>）。一种相关的方法是按 空间分布个体，并且仅允许相邻的个体重组。这些技术很多都是受到了生物进化的启示。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 6pt;text-indent: 0pt;text-align: justify;">9.4.1 <span class="s25">群体进化和模式理论</span></h3><p style="padding-top: 10pt;padding-left: 6pt;text-indent: 20pt;line-height: 107%;text-align: justify;">不妨思考一个有趣的问题：是否能用数学的方法刻画 <span class="s6">GA </span>中群体随时间进化的过程？ <span class="s6">Holland</span>（<span class="s6">1975</span>）的模式原理（<span class="s6">schema theorem</span>）提供了一种刻画方法。它基于描述位串集合 的模式（<span class="s6">schema</span>，或 <span class="s6">pattern</span>）。精确地讲，一个模式是由若干 <span class="s6">0</span>、<span class="s6">1 </span>和<span class="s6">*</span>组成的任意串。“<span class="s6">*</span>” 表示一个不关心的位。例如模式 <span class="s6">0*10 </span>表示的位串集合中只包含 <span class="s6">0010 </span>和 <span class="s6">0110</span>。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">单个位串可以被看作与它匹配的每个模式的代表。例如，位串 <span class="s6">0010 </span>可以被认为 <span class="s6">2</span><span class="s46">4</span>个相 异模式的代表，例如 <span class="s6">00**</span>，<span class="s6">0*10</span>，<span class="s6">****</span>等。类似地，一个位串的群体可以被看作：位串所 代表的模式的集合，以及与每个模式关联的个体数量。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;"><span class="p">模式理论根据每个模式的实例数量来刻画 </span><span class="s6">GA </span><span class="p">中群体的进化。令 </span>m<span class="s6">(</span>s<span class="s6">, </span>t<span class="s6">)</span><span class="p">表示群体中的模 式 </span>s <span class="p">在时间 </span>t<span class="p">（也就是在第 </span>t <span class="p">代期间）的实例数量。模式理论根据 </span>m<span class="s6">(</span>s<span class="s6">, </span>t<span class="s6">)</span><span class="p">和模式、群体及 </span><span class="s6">GA </span><span class="p">参数的其他属性，来描述 </span>m<span class="s6">(</span>s<span class="s6">, </span>t<span class="s6">+1)</span><span class="p">的期望值。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="5" height="1" alt="image" src="机器学习/Image_356.png"/></span></p><p class="s6" style="padding-left: 5pt;text-indent: 21pt;line-height: 156%;text-align: justify;">GA<span class="p">中群体的进化依赖于几个步骤，即选择步、重组步和变异步。先从只考虑选择步的 影响开始。使用</span><i>f</i>(<i>h</i>)<span class="p">表示位串个体</span><i>h</i><span class="p">的适应度，并用 </span><span class="s30">f </span>(<i>t</i>)<span class="p">表示在时间</span><i>t</i><span class="p">群体中所有个体的平均</span></p><p class="s21" style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: justify;"><span class="p">适应度。设</span>n<span class="p">为群体中个体的总数量。使用</span>h<span class="s10"></span>s<span class="s6">∩</span>p<span class="s36">t</span><span class="p">表示个体</span>h<span class="p">既是模式</span>s<span class="p">的一个代表，又是时 间</span>t<span class="p">群体的一个成员。最后，令 </span><span class="s30">u</span><span class="s33">ˆ </span><span class="s6">(</span>s<span class="s6">, </span>t<span class="s6">)</span><span class="p">表示在时间</span>t<span class="p">群体中模式</span>s<span class="p">的实例的平均适应度。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: left;"><span class="p">我们感兴趣的是 </span><i>m</i>(<i>s</i>, <i>t</i>+1)<span class="p">的期望值，用 </span><i>E</i>[<i>m</i>(<i>s</i>, <i>t</i>+1)]<span class="p">来表示。可以使用公式（</span>9.1<span class="p">）中给 出的概率分布来计算 </span><i>E</i>[<i>m</i>(<i>s</i>, <i>t</i>+1)]<span class="p">，并使用目前的符号把它重新表示成如下形式：</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s41" style="text-indent: 0pt;line-height: 7pt;text-align: left;">n</p><p style="text-indent: 0pt;text-align: left;"/><p class="s91" style="padding-left: 133pt;text-indent: 0pt;line-height: 18pt;text-align: center;"><span class="s115">Pr(</span><span class="s30">h</span><span class="s33">) </span><span class="s38"> </span>f <span class="s92">(</span>h<span class="s92">)     </span></p><p class="s106" style="text-indent: 0pt;line-height: 19pt;text-align: right;"><span class="s41">i</span><span class="s40"></span><span class="s42">1</span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="5" height="1" alt="image" src="机器学习/Image_357.png"/></span></p><p class="s91" style="padding-top: 2pt;text-indent: 0pt;line-height: 19pt;text-align: right;"><span class="s114"> </span>f <span class="s92">(</span>h<span class="s92">)</span></p><p class="s30" style="text-indent: 0pt;line-height: 12pt;text-align: right;">nf <span class="s33">(</span>t<span class="s33">)</span></p><p class="s30" style="text-indent: 0pt;text-align: left;">f <span class="s33">(</span>h<span class="s52">i</span><span class="s41"> </span><span class="s33">)</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 6pt;text-indent: 21pt;line-height: 107%;text-align: left;">现在如果根据这个概率分布选择新群体的一个成员，那么选到模式 <span class="s21">s </span>的一个代表的概率 是：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="padding-top: 10pt;text-indent: 0pt;text-align: right;"><span class="s33">Pr(</span>h <span class="s38"> </span>s<span class="s33">) </span><span class="s38"></span></p><p class="s121" style="padding-top: 6pt;padding-left: 2pt;text-indent: 0pt;line-height: 21pt;text-align: center;"></p><p class="s41" style="padding-left: 1pt;text-indent: 0pt;line-height: 8pt;text-align: center;">h<span class="s40"></span>s<span class="s40"> </span>p<span class="s180">t</span></p><p class="s91" style="padding-top: 3pt;padding-left: 1pt;text-indent: 0pt;text-align: left;"> f <span class="s92">(</span>h<span class="s92">)</span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="5" height="1" alt="image" src="机器学习/Image_358.png"/></span></p><p class="s30" style="padding-top: 3pt;padding-left: 1pt;text-indent: 0pt;text-align: left;">nf <span class="s33">(</span>t<span class="s33">)</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;line-height: 12pt;text-align: right;">（<span class="s6">9.2</span>）</p><p style="text-indent: 0pt;text-align: left;"><span><img width="5" height="1" alt="image" src="机器学习/Image_359.png"/></span></p><p class="s91" style="padding-left: 134pt;text-indent: 0pt;line-height: 18pt;text-align: center;"><span class="s114"></span><span class="s38"> </span>u<span class="s92">ˆ (</span>s<span class="s92">, </span>t <span class="s92">) </span><span class="s204">m</span><span class="s33">(</span><span class="s30">s</span><span class="s33">, </span><span class="s30">t</span><span class="s33">)</span></p><p class="s30" style="padding-left: 123pt;text-indent: 0pt;line-height: 12pt;text-align: center;">nf <span class="s33">(</span>t<span class="s33">)</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 26pt;text-indent: 0pt;text-align: left;">上面的第二步根据以下的定义而得：</p><p class="s41" style="text-indent: 0pt;line-height: 19pt;text-align: right;"><span class="s106"></span>h<span class="s40"></span>s<span class="s40"></span><span class="s42"> </span>p</p><p style="text-indent: 0pt;text-align: left;"><span><img width="84" height="1" alt="image" src="机器学习/Image_360.png"/></span></p><p class="s30" style="text-indent: 0pt;line-height: 8pt;text-align: right;">u<span class="s33">ˆ(</span>s<span class="s33">, </span>t<span class="s33">) </span><span class="s38"> </span><span class="s278">t</span></p><p class="s30" style="padding-top: 4pt;padding-left: 3pt;text-indent: 0pt;text-align: left;">f <span class="s33">(</span>h<span class="s33">)</span></p><p class="s30" style="padding-left: 137pt;text-indent: 0pt;line-height: 12pt;text-align: center;">m<span class="s33">(</span>s<span class="s33">, </span>t<span class="s33">)</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: left;">公式（<span class="s6">9.2</span>）给出了 <span class="s6">GA </span>选择的一个假设是模式 <span class="s21">s </span>的实例的概率。所以，对于产生整个 新一代的 <span class="s21">n </span>次独立选择步，得到的 <span class="s21">s </span>的实例的期望数量就是这个概率的 <span class="s21">n </span>倍。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="text-indent: 0pt;text-align: right;">E<span class="s6">[</span>m<span class="s6">(</span>s<span class="s6">, </span>t<span class="s6">+1)]=</span></p><p class="s30" style="padding-top: 3pt;padding-left: 4pt;text-indent: 0pt;text-align: center;">u<span class="s33">ˆ(</span>s<span class="s33">, </span>t<span class="s33">)</span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="40" height="4" alt="image" src="机器学习/Image_361.png"/></span></p><p class="s30" style="padding-top: 3pt;padding-left: 7pt;text-indent: 0pt;text-align: center;">f <span class="s33">(</span>t<span class="s33">)</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="text-indent: 0pt;text-align: left;"><i>m</i>(<i>s</i>, <i>t</i>) <span class="p">（</span>9.3<span class="p">）</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="5" height="1" alt="image" src="机器学习/Image_362.png"/></span></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;line-height: 156%;text-align: left;">公式（<span class="s6">9.3</span>）表明，在 <span class="s21">t</span><span class="s6">+1 </span>代中模式 <span class="s21">s </span>的实例期望数量，与在时间 <span class="s21">t </span>这个模式的实例的平 均适应度 <span class="s30">u</span><span class="s33">ˆ </span><span class="s6">(</span><span class="s21">s</span><span class="s6">, </span><span class="s21">t</span><span class="s6">)</span>成正比，并与时间 <span class="s21">t </span>中群体的所有成员的平均适应度 <span class="s30">f </span><span class="s6">(</span><span class="s21">t</span><span class="s6">)</span>成反比。因此，我</p><p style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;line-height: 107%;text-align: justify;">们可以期望，在后继的各代中高于平均适应度的模式出现频率会升高。如果我们把 <span class="s6">GA </span>看作， 在对个体空间进行显式搜索的同时，对可能模式空间进行着虚拟的并行搜索，那么公式（<span class="s6">9.3</span>） 指出适应度高的模式的影响力会随着时间增加。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">然而上面的分析仅考虑 <span class="s6">GA </span>中选择步的影响，所以也应该考虑交叉和变异步的影响。模 式理论仅考虑这些算子可能造成的负面影响（例如，随机变异可能降低 <span class="s21">s </span>的代表数量，独立 于 <span class="s30">u</span><span class="s33">ˆ </span><span class="s6">(</span><span class="s21">s</span><span class="s6">,</span><span class="s21">t</span><span class="s6">)</span>），并且仅考虑单点交叉的情况。所以完整的模式理论给出了模式 <span class="s21">s </span>的期望频率的下 界，如下所示：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s38" style="text-indent: 0pt;line-height: 12pt;text-align: left;">⎛</p><p style="text-indent: 0pt;text-align: left;"/><p class="s33" style="padding-top: 3pt;padding-left: 96pt;text-indent: 0pt;line-height: 17pt;text-align: left;"><i>E</i>[<i>m</i>(<i>s</i>, <i>t </i><span class="s38"></span> 1)] <span class="s38"></span> <u><i>u</i></u><u>ˆ</u><u>(</u><u><i>s</i></u><u>, </u><u><i>t </i></u><u>)</u> <i>m</i>(<i>s</i>, <i>t</i>)<span class="s38">⎜</span><span class="s100">1</span> <span class="s38"></span> <i>p</i></p><p class="s91" style="padding-top: 3pt;padding-left: 5pt;text-indent: 0pt;line-height: 11pt;text-align: left;">d <span class="s92">(</span>s<span class="s92">) </span><span class="s38">⎞</span></p><p class="s38" style="padding-left: 28pt;text-indent: 0pt;line-height: 5pt;text-align: left;">⎟<span class="s100">(</span><span class="s33">1 </span><span class="s33"> </span><span class="s30">p</span></p><p class="s41" style="padding-top: 10pt;padding-left: 5pt;text-indent: 0pt;line-height: 9pt;text-align: left;"><span class="s93">)</span>o<span class="s42">( </span>s <span class="s42">)</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 36pt;text-indent: 0pt;line-height: 10pt;text-align: left;">（<span class="s6">9.4</span>）</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 177pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="5" height="1" alt="image" src="机器学习/Image_363.png"/></span></p><p class="s30" style="text-indent: 0pt;text-align: right;">f <span class="s33">(</span>t<span class="s33">)</span></p><p class="s134" style="padding-left: 34pt;text-indent: 0pt;line-height: 16pt;text-align: left;">⎝ <span class="s244">c </span><span class="s30">l </span><span class="s38"></span><span class="s33">1 </span>⎠<span class="s38"> </span><span class="s244">m</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 8pt;padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: left;">这里，<span class="s21">p</span><span class="s36">c</span>是对任意个体应用单点交叉算子的概率，<span class="s21">p</span><span class="s36">m</span>是对任意个体的任意位使用变异算 子进行变异的概率。<span class="s21">o</span><span class="s6">(</span><span class="s21">s</span><span class="s6">)</span>是模式<span class="s21">s</span>中确定位（<span class="s6">defined bits</span>）的个数，<span class="s6">0 </span>和 <span class="s6">1 </span>是确定的位，<span class="s6">*</span>不是。 <span class="s21">d</span><span class="s6">(</span><span class="s21">s</span><span class="s6">)</span>是模式<span class="s21">s</span>中最左边的确定位和最右边的确定位间的距离。最后，<span class="s21">l</span>是在群体中个体位串长 度。注意，公式（<span class="s6">9.4</span>）中的最左一项与公式（<span class="s6">9.3</span>）是一样的，这一项描述了选择步骤的影 响。中间一项描述了单点交叉算子的影响，特别值得注意的是，这一项描述了代表<span class="s21">s</span>的任意 个体在应用了交叉算子后还表示<span class="s21">s</span>的概率。最右一项描述了代表模式<span class="s21">s</span>的任意个体在应用了变 异算子后还表示<span class="s21">s</span>的概率。单点交叉和变异的影响随着模式中确定位的数量<span class="s21">o</span><span class="s6">(</span><span class="s21">s</span><span class="s6">)</span>和确定位间的 距离<span class="s21">d</span><span class="s6">(</span><span class="s21">s</span><span class="s6">)</span>增长。因此，可以模式理论可以被粗略地解释为：更高适应度的模式的影响力趋向 增大，尤其是包含较少数量的确定位（也就是包含大量的<span class="s6">*</span>）的模式和这些确定位在位串中 彼此靠近的模式。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 109%;text-align: left;">对 <span class="s6">GA </span>中的群体进化过程，模式理论可能是被引用得最广泛的刻画方式。它不完备的一 面是无法考虑交叉和变异的（大概的）正面影响。最近人们已经提出了很多新的理论分析， 包括基于马尔可夫链模型（<span class="s6">Markov chain model</span>）和统计力学模型（<span class="s6">statistical mechanics models</span>）的分析。例如可以参见 <span class="s6">Whitley &amp; Vose</span>（<span class="s6">1995</span>）和 <span class="s6">Mitchell</span>（<span class="s6">1996</span>）。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-top: 7pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">9.5 <span class="s17">遗传编程</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 27pt;text-indent: 0pt;text-align: left;">遗传编程（<span class="s6">Genetic Programming</span>，<span class="s6">GP</span>）是进化计算的一种形式，其中进化群体中的个</p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 107%;text-align: left;">体是计算机程序而不是位串。<span class="s6">Koza</span>（<span class="s6">1992</span>）描述了基本的遗传编程方法并且给出了很多简 单的可以被 <span class="s6">GP </span>成功学习的程序。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">9.5.1 <span class="s25">程序表示</span></h3><p class="s6" style="padding-top: 10pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">GP <span class="p">操作的程序一般被表示为程序的解析（</span>parse<span class="p">）树。每个函数调用被表示为树的一个</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-top: 3pt;padding-left: 6pt;text-indent: 0pt;text-align: left;"><span class="p">节点，函数的参数通过它的子结点给出。例如，图 </span>9-1 <span class="p">画出了函数 </span>sin(<i>x</i>)+</p><p style="text-indent: 0pt;text-align: left;"><span><img width="52" height="23" alt="image" src="机器学习/Image_364.png"/></span></p><p class="s30" style="padding-top: 3pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">x <span class="s46">2 </span><span class="s38"> </span>y <span class="p">的树表示。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">为了应用遗传编程到某个特定的领域，用户必须定义待考虑的原子函数（<span class="s6">primitive functions</span>）</p><p style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;line-height: 107%;text-align: left;">（例如，<span class="s6">sin</span>，<span class="s6">cos</span>，开方，<span class="s6">+</span>，<span class="s6">-</span>，指数），以及端点（<span class="s6">terminals</span>）（例如 <span class="s21">x</span>、<span class="s21">y </span>以及常数）。接下 来，遗传编程算法使用进化搜索，来探索使用这些原子描述的程序的巨大空间。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 112%;text-align: justify;">与在遗传算法中一样，原型的遗传编程算法维护由多个个体（在这里是程序树）组成的 群体。在每一步迭代中，它使用选择、交叉和变异产生新一代个体。群体中某个体程序的适 应度一般通过在训练数据上执行这个程序来决定。交叉操作是这样进行的：在一个双亲程序 中随机选择一个子树，然后用另一个双亲的子树替代这个子树。图 <span class="s6">9-2 </span>演示了一个典型的交 叉操作。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 13pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="547" height="1" alt="image" src="机器学习/Image_365.png"/></span></p><p class="s48" style="padding-left: 15pt;text-indent: 0pt;text-align: left;">插图——原书页码： <span class="s21">262</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 14pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="531" height="1" alt="image" src="机器学习/Image_366.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 150pt;text-indent: 0pt;text-align: left;">图 <span class="h4">9-1 </span>遗传编程中的程序树表示</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-left: 37pt;text-indent: 0pt;text-align: left;">任意程序可以表示为它们的解析树。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 13pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="547" height="1" alt="image" src="机器学习/Image_367.png"/></span></p><p class="s48" style="padding-left: 15pt;text-indent: 0pt;text-align: left;">插图——原书页码： <span class="s21">263</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 14pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="531" height="1" alt="image" src="机器学习/Image_368.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 37pt;text-indent: 96pt;text-align: left;">图 <span class="h4">9-2 </span>对两个双亲程序树进行交叉操作</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-left: 37pt;text-indent: 0pt;line-height: 132%;text-align: left;">双亲程序树显示在上方，孩子树在下方。交叉点（上边加粗显示的节点）是随机选取的。然后以这 些交叉点为根的子树互换以产生孩子树。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">Koza<span class="p">（</span>1992<span class="p">）描述了应用 </span>GP <span class="p">到多个任务的实验。在他的实验中，根据适应度概率选择 当前群体的 </span>10%<span class="p">不加改变的保留到下一代。再根据适应度概率从当前群体中选择程序对， 应用交叉操作产生新一代的其余部分。在这个实验系列中没有使用变异算子。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">9.5.2 <span class="s25">示例</span></h3><p class="s6" style="padding-top: 10pt;padding-left: 6pt;text-indent: 21pt;line-height: 109%;text-align: justify;">Koza<span class="p">（</span>1992<span class="p">）给出的一个示例是学习一个算法来堆砌图 </span>9-3 <span class="p">所示的字块。这个任务是开 发一个通用的算法来把字块堆叠成单个栈（</span>stack<span class="p">），拼出单词“</span>universal<span class="p">”，无论这些字块初 始的结构如何。可执行的动作是每次只允许移动一个字块。确切地讲，在栈中最上面的字块 可以被移到桌面上，或者桌面上的字块可以被移动到栈顶。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 13pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="547" height="1" alt="image" src="机器学习/Image_369.png"/></span></p><p class="s48" style="padding-left: 15pt;text-indent: 0pt;text-align: left;">插图——原书页码： <span class="s21">264</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 14pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="531" height="1" alt="image" src="机器学习/Image_370.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 37pt;text-indent: 128pt;text-align: left;">图 <span class="h4">9-3 </span>一个字块堆叠问题</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-left: 37pt;text-indent: 0pt;line-height: 132%;text-align: left;">这个遗传编程的任务是发现一个程序，可以把有任意初始结构的字块变换成一个栈拼出单词 “<span class="s16">universal</span>”。并提供了 <span class="s16">166 </span>种初始结构来评估候选程序的适应度（摘自 <span class="s16">Koza 1992</span>）。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 107%;text-align: left;">在大多数 <span class="s6">GP </span>应用中，问题表示方法的选择对于顺利地解决问题起着非常重要的作用。 在 <span class="s6">Koza </span>的设计中，用以组成程序的原子函数包含下面的三个端点参数：</p><p style="padding-top: 5pt;padding-left: 28pt;text-indent: 0pt;text-align: left;"><span class="s10"> </span><span class="s6">CS</span>（<span class="s6">current stack</span>）：当前栈，指栈顶字块的名字，或没有当前栈时为 <span class="s21">F</span>。</p><p class="s6" style="padding-top: 1pt;padding-left: 49pt;text-indent: -21pt;line-height: 107%;text-align: left;"><span class="s10"> </span>TB<span class="p">（</span>top correct bloack<span class="p">）：最上正确字块，指该字块和它以下字块均为正确 顺序的字块。</span></p><ul id="l25"><li style="padding-top: 1pt;padding-left: 49pt;text-indent: -21pt;line-height: 107%;text-align: left;"><p style="display: inline;"><span class="s6">NN</span>（<span class="s6">next necessary</span>）：下一个所需字块，指为了拼成单词“<span class="s6">universal</span>”，栈 内紧邻 <span class="s6">TB </span>之上的所需字块的名字，或者当不再需要字块时为 <span class="s21">F</span>。</p></li></ul><p style="padding-top: 7pt;padding-left: 5pt;text-indent: 21pt;line-height: 110%;text-align: justify;">可以看出，选择这样的端点参数对于描述此任务的字块操纵程序提供了一种自然的表 示。相反，设想如果把每个字块的 <span class="s21">x</span>、<span class="s21">y </span>坐标定义为端点参数，那么要实现这个任务相对要 困难得多。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 26pt;text-indent: 0pt;text-align: left;">除了这些端点参数，这个应用中的程序语言还包括下面的原子函数：</p><p style="padding-top: 6pt;padding-left: 28pt;text-indent: 0pt;text-align: left;"><span class="s10"> </span>（<span class="s6">MS x</span>）（<span class="s6">move to stack</span>）：移动到栈。如果子块 <span class="s6">x </span>在桌面上，这个操作把</p><p class="s6" style="padding-top: 1pt;padding-left: 48pt;text-indent: 0pt;text-align: center;">x <span class="p">移动到栈顶并且返回 </span>T<span class="p">。否则，它什么也不做并且返回 </span>F<span class="p">。</span></p><p style="padding-top: 1pt;padding-left: 49pt;text-indent: -21pt;line-height: 107%;text-align: left;"><span class="s10"> </span>（<span class="s6">MT x</span>）（<span class="s6">move to table</span>）：移动到桌面。如果字块 <span class="s6">x </span>是在栈中某个位置， 这个操作把栈顶的字块移动到桌面并且返回 <span class="s6">T</span>。否则返回 <span class="s6">F</span>。</p><p style="padding-left: 28pt;text-indent: 0pt;text-align: left;"><span class="s10"> </span>（<span class="s6">EQ x y</span>）（<span class="s6">equal</span>）：相等，如果 <span class="s6">x </span>等于 <span class="s6">y </span>返回 <span class="s6">T</span>，否则返回 <span class="s6">F</span>。</p><p style="padding-top: 1pt;padding-left: 28pt;text-indent: 0pt;text-align: left;"><span class="s10"> </span>（<span class="s6">NOT x</span>）：如果 <span class="s6">x=F </span>返回 <span class="s6">T</span>，如果 <span class="s6">x=T </span>返回 <span class="s6">F</span>。</p><p style="padding-top: 1pt;padding-left: 26pt;text-indent: 1pt;text-align: left;"><span class="s10"> </span>（<span class="s6">DU x y</span>）（<span class="s6">do until</span>）：反复执行表达式 <span class="s6">x </span>直到表达式 <span class="s6">y </span>返回 <span class="s6">T</span>。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 110%;text-align: left;">为了评估任意给定程序的适应度，<span class="s6">Koza </span>提供了 <span class="s6">166 </span>个训练问题，表示了很多种不同的 初始字块结构，问题的难度各异。任意给定程序的适应度就是它解决了的训练问题的数量。 群体被初始化为 <span class="s6">300 </span>个随机程序的集合。经过了 <span class="s6">10 </span>代后，系统发现了下面的程序解决了所</p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 14pt;text-align: left;">有 <span class="s6">166 </span>个问题。</p><p style="padding-top: 5pt;padding-left: 27pt;text-indent: -4pt;line-height: 40pt;text-align: center;">（<span class="s6">EQ</span>（<span class="s6">DU</span>（<span class="s6">MT CS</span>）（<span class="s6">NOT CS</span>））（<span class="s6">DU</span>（<span class="s6">MS NN</span>）（<span class="s6">NOT NN</span>））） 注意这个程序包含了两个 <span class="s6">DU</span>（也就是“<span class="s6">Do Until</span>”）语句的序列。第一个 <span class="s6">DU </span>语句循环</p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 10pt;text-align: left;">地把当前的栈顶字块移动到桌面直到把栈移空。然后，第二个“<span class="s6">Do Until</span>”语句循环地把下</p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 0pt;line-height: 107%;text-align: left;">一个所需字块从桌面移动到栈顶。这里最外层的 <span class="s6">EQ </span>表达式起到的作用是提供一个合法的句 法来排列这两个“<span class="s6">Do Until</span>”循环。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 9pt;padding-left: 26pt;text-indent: 0pt;text-align: left;">多少有些令人惊奇，仅仅经过了几代，这个 <span class="s6">GP </span>就发现了能解决所有 <span class="s6">166 </span>个训练问题的</p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 113%;text-align: justify;">程序。系统的这个能力很大程度上依赖于提供的基本参数和原子函数，以及用来评估适应度 的训练样例集合。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 6pt;text-indent: 0pt;text-align: justify;">9.5.3 <span class="s25">遗传编程说明</span></h3><p style="padding-top: 10pt;padding-left: 6pt;text-indent: 21pt;line-height: 111%;text-align: left;">正如上面的例子所演示的，遗传编程把遗传算法扩展到对完整的计算机程序的进化。尽 管它必须要搜索巨大的假设空间，但已经证实在相当数量的应用中遗传编程产生了令人着迷 的结果。<span class="s6">O’Reilly and Oppacher</span>（<span class="s6">1994</span>）比较了 <span class="s6">GP </span>算法和其他搜索计算机程序空间的算法， 例如爬山法（<span class="s6">hill climbing</span>）和模拟退火法（<span class="s6">simulated annealing</span>）。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 109%;text-align: left;">当然上面的 <span class="s6">GP </span>算法例子是相当简单的，<span class="s6">Koza et al.</span>（<span class="s6">1996</span>）概括了 <span class="s6">GP </span>算法在一些更复 杂的任务中的应用，例如设计电子滤波电路和分类蛋白质分子片段。滤波电路设计问题提供 了一个相当复杂的问题。这里，程序的进化是从简单的固定种子电路转变为最终的电路设计。 <span class="s6">GP </span>算法中组建程序的原子函数通过插入或删除电路零件和导线连接来编辑这个种子电路。 每个程序的适应度是这样计算的：先模拟这个电路的输出（使用 <span class="s6">SPICE </span>电路仿真器），然后 看这个电路与期望的设计的适应度的差距。精确地讲，适应度分值是对于 <span class="s6">101 </span>个不同的输入 频率，计算实际电路输出和期望电路输出间误差量的和。在这个例子中，维护的群体大小是 <span class="s6">640,000</span>，选择产生 <span class="s6">10%</span>的后代群体，交叉产生 <span class="s6">89%</span>，变异产生 <span class="s6">1%</span>。系统是在一台 <span class="s6">64 </span>节点 的并行处理机上执行的。在最初的随机产生的群体中，电路是如此的不合理以至于 <span class="s6">98%</span>的 电路行为无法被 <span class="s6">SPICE </span>仿真器仿真。在第一代之后无法仿真的电路的百分比下降到 <span class="s6">84.9%</span>， 第二代后下降到 <span class="s6">75.0%</span>，再下降到后来各代中平均 <span class="s6">9.6%</span>。在初始群体中最好电路的适应度 分值是 <span class="s6">159</span>，与此相比，<span class="s6">20 </span>代后分值是 <span class="s6">39</span>，<span class="s6">137 </span>代后分值是 <span class="s6">0.8</span>。<span class="s6">137 </span>代后的最佳电路达到 的性能与要求的非常相近。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 113%;text-align: justify;">在大多数情况下，表示方法的选择和适应度函数的选择对遗传编程的性能是至关重要 的。由于这个原因，目前研究的一个活跃领域是自动发现和合并子程序，改善最初的原子函 数集合，从而允许系统动态地改变用以构建个体的原子。例如可以参见 <span class="s6">Koza</span>（<span class="s6">1994</span>）。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 6pt;text-indent: 0pt;text-align: justify;">9.6 <span class="s17">进化和学习模型</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 113%;text-align: justify;">在很多自然系统中，生物个体在它们一生当中都在学习如何更好地适应环境。同时，生 物和社会过程允许它们的物种在一个包含很多代的时期内适应环境。关于进化系统的一个有 趣问题是：“单一个体生命期间的学习，与整个物种较长时期内由进化促成的学习，它们的 关系是什么？”</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 6pt;text-indent: 0pt;text-align: justify;">9.6.1 <span class="s25">拉马克进化</span></h3><p style="padding-top: 10pt;padding-left: 5pt;text-indent: 21pt;line-height: 111%;text-align: left;">科学家拉马克（<span class="s6">Lamarck</span>）在十九世纪末提出，多代的进化直接受到了个别生物体在它 们生命期间的经验的影响。确切地讲，他提出个别生物体的经验直接影响其后代的遗传结构： 如果一个个体在生命期内学会了避开某种有毒食物，它便能把这种特征遗传给它的后代。这 是一个很吸引人的猜想，因为比起忽略个体经验的“生成并测试（<span class="s6">generate-and-test</span>）”过程</p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: justify;">（如<span class="s6">GA</span>和<span class="s6">GP</span>中那样），它可能获得更高效的进化过程。尽管这个理论很有吸引力，但目前 的科学证据与拉马克模型彻底冲突。目前被接受的观点是，个体的遗传结构事实上不受它的 双亲的生存经验的影响。尽管这是明显的生物学上的事实，但近来的计算机研究已经表明，</p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 107%;text-align: left;">拉马克过程有时可以提高计算机遗传算法的效率（参见<span class="s6">Grefenstette 1991</span>；<span class="s6">Ackley &amp; Littman 1994</span>；<span class="s6">Hart &amp; Belew 1995</span>）。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">9.6.2 <span class="s25">鲍德温效应</span></h3><p style="padding-top: 10pt;padding-left: 5pt;text-indent: 21pt;line-height: 110%;text-align: justify;">尽管拉马克进化模型没有被生物进化过程所接受，人们已经提出了其他的机制，通过这 些机制个体学习可以改变进化进程。其中一种被称为鲍德温效应（<span class="s6">Baldwin effect</span>），是根据 首先提出这种思想的 <span class="s6">J. M. Baldwin</span>（<span class="s6">1896</span>）的作者名字命名的。鲍德温效应基于以下现象：</p><p class="s10" style="padding-top: 4pt;padding-left: 66pt;text-indent: -21pt;line-height: 112%;text-align: left;"> <span class="p">如果一个物种在一个变化的环境中进化，那么进化的压力会支持有学习能力 的个体。例如，如果在进化环境中出现了一个新的捕食者，那么能学会避开 捕食者的个体，会比不能学会此能力的个体更成功。在效果上，这种学习的 能力可以使个体在其生命期间执行一种小的局部搜索，以最大化它的适应 度。相反，不学习的个体的适应度完全取决于它的遗传结构，会处于相对的 劣势。</span></p><p style="padding-left: 66pt;text-indent: -21pt;line-height: 110%;text-align: left;"><span class="s10"> </span>那些能够学习很多特性（<span class="s6">trait</span>）的个体，会较少地依赖于遗传代码来硬性地 规定其特性。结果，这些个体可以依赖个体学习克服遗传代码中的“丢失的” 或“并非最优的”特性，从而支持更加多样化的基因池（<span class="s6">gene pool</span>）。接下 来，这个更加多样化的基因池可以促进适应性更快速地进化。因此，个体的 学习能力具有间接加速整个群体进化适应的作用。</p><p style="padding-top: 7pt;padding-left: 5pt;text-indent: 21pt;line-height: 113%;text-align: justify;">例如，设想某个物种的环境中发生了某个新的变化，比如出现一个新的捕食者。这样的 变化会有利于能学会避开捕食者的个体。随着群体中自我提高的个体的比例的增长，群体会 支持更加多样化的基因池，允许进化过程（即使是非拉马克的“生成并测试”过程）适应得 更快。接下来，这种加速的适应可以使标准的进化过程更快地进化出一种遗传特征（非学到 的特征）来避开捕食者（例如，一种对捕食者的本能惧怕）。因此鲍德温效应提供了一种间 接的机制，使个体的学习可以正面影响进化速度。通过提高物种的生存力和遗传多样性，个 体学习会加快进化进程，从而增加这个物种进化出更好地适应新环境的遗传特性的机会。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 111%;text-align: left;">人们一直努力开发研究鲍德温效应的计算模型。例如，<span class="s6">Hinton &amp; Nowlan</span>（<span class="s6">1987</span>）对一 个简单神经网络的群体进行了试验，在一个网络个体的“生命期” 间，它的一些权值是固 定的，而其他的权是可以被训练的。这个个体的遗传结构决定了哪些权值是可以被训练的， 那些是固定的。在实验中，当不允许个体学习时，群体不能随着实践提高它的适应度。然而， 当允许个体学习时，群体迅速地提高它的适应度。在群体进化初期的各代中，具有很多可训 练权值的个体占据较大的比例。但随着进化的进行，群体向着遗传给定权值和较少依赖个体 学习权值的方向进化，正确的固定权值的数量趋于增长。<span class="s6">Belew</span>（<span class="s6">1990</span>），<span class="s6">Harvey</span>（<span class="s6">1993</span>）和 <span class="s6">French &amp; Messinger</span>（<span class="s6">1994</span>）报告了对鲍德温效应的其他计算性研究。<span class="s6">Mitchell</span>（<span class="s6">1996</span>）中有 一个关于这个主题的精彩综述。《遗传计算》（<span class="s21">Evolutionary Computation</span>）杂志的一期特刊</p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 14pt;text-align: left;">（<span class="s6">Turney et al. 1997</span>）包含了几篇有关鲍德温效应的文章。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-top: 8pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">9.7 <span class="s17">并行遗传算法</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 6pt;text-indent: 21pt;line-height: 107%;text-align: left;">GA <span class="p">很自然地适合并行实现，而且已经探索出了很多并行化的方法。粗粒度（</span>coarse grain<span class="p">） 并行方法把群体细分成相对独立的个体群，称为类属（</span>deme<span class="p">）。然后为每个类属分配给一个 不同的计算节点，在每个节点进行标准的 </span>GA <span class="p">搜索。类属之间的通信和交叉发生的频率与类</span></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: justify;">属内相比较低。类属之间的交换通过迁移（<span class="s6">migration</span>）来进行，也就是某些个体从一个类属 复制或交换到其他的类属。这个过程模拟了以下的生物进化方式，即自然界中异体受精可能 发生在分离的物种子群体之间。这种方法的一个好处是它减少了非并行 <span class="s6">GA </span>经常碰到的拥挤 问题，在非并行算法中，由于过早出现支配整个群体的基因型，使系统陷入局部最优。<span class="s6">Tanese</span></p><p style="padding-left: 26pt;text-indent: -21pt;text-align: left;">（<span class="s6">1989</span>）和 <span class="s6">Cohoon et al.</span>（<span class="s6">1987</span>）描述了粗粒度并行 <span class="s6">GA </span>算法的例子。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 109%;text-align: justify;">相对于粗粒度并行实现，细粒度（<span class="s6">fine-grained</span>）实现一般给群体中的每个个体分配一个 处理器。然后相邻的个体间发生重组。人们已经提出了几个相邻模型，从平面网格到超环结 构。<span class="s6">Spiessens &amp; Manderick</span>（<span class="s6">1991</span>）描述了这样的系统的实例。<span class="s6">Stender</span>（<span class="s6">1993</span>）中可以得到 关于并行 <span class="s6">GA </span>算法的论文集。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-top: 7pt;padding-left: 6pt;text-indent: 0pt;text-align: justify;">9.8 <span class="s17">小结和补充读物</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 27pt;text-indent: 0pt;text-align: left;">这一章的要点包括：</p><p style="padding-top: 6pt;padding-left: 66pt;text-indent: -21pt;line-height: 107%;text-align: left;"><span class="s10"> </span>遗传算法（<span class="s6">GA</span>）进行一种随机化的并行爬山搜索，来发现使预先定义的适 应度函数最优的假设。</p><p class="s6" style="padding-top: 1pt;padding-left: 66pt;text-indent: -21pt;line-height: 111%;text-align: left;"><span class="s10"> </span>GA <span class="p">所采取的搜索是基于对生物进化的模拟。</span>GA <span class="p">维护一个由竞争假设组成 的多样化群体。在每一次迭代中，选出群体中适应度最高的成员来产生后代， 替代群体中适应度最差的成员。假设常被编码成位串，可以通过交叉算子组 合，位串上也可能发生随机的变异。</span></p><p class="s10" style="padding-left: 66pt;text-indent: -21pt;line-height: 110%;text-align: justify;"> <span class="s6">GA </span><span class="p">阐明了如何把学习过程看成最优化过程的一个特例。具体来说，学习任 务就是根据预先定义的适应度函数发现最优的假设。这表明其他的最优化技 术，例如模拟退火法，也可以应用到机器学习问题。</span></p><p class="s6" style="padding-left: 66pt;text-indent: -21pt;line-height: 107%;text-align: justify;"><span class="s10"> </span>GA <span class="p">已经被普遍应用到机器学习外的最优化问题中，例如设计优化问题。当 把 </span>GA <span class="p">应用到学习任务时，它特别适合假设很复杂的任务（例如，假设是机 器人控制的规则集或计算机程序）和最优化的目标是假设的间接函数的任务</span></p><p style="padding-top: 1pt;padding-left: 66pt;text-indent: 0pt;text-align: left;">（例如，要求得到的规则集可以成功地控制一个机器人）。</p><p style="padding-top: 1pt;padding-left: 66pt;text-indent: -21pt;line-height: 109%;text-align: left;"><span class="s10"> </span>遗传编程是遗传算法的一个变体，在遗传编程中，被操作的假设是计算机程 序而不是位串。交叉和变异操作被推广以应用于程序而不是位串。人们已经 演示了遗传编程学习针对某些任务的程序，比如模拟机器人控制（<span class="s6">Koza 1992</span>）和识别视觉场景（<span class="s6">visual scenes</span>）中的物体（<span class="s6">Teller and Veloso 1994</span>）。</p><p style="padding-top: 7pt;padding-left: 5pt;text-indent: 21pt;line-height: 108%;text-align: left;">在计算机科学的早期，人们就开始探索基于进化的计算方法（例如 <span class="s6">Box 1957 </span>和 <span class="s6">Bledsoe 1961</span>）。<span class="s6">60 </span>年代提出了几个不同的进化方法，后来又被进一步研究。<span class="s6">Rechenberg</span>（<span class="s6">1965</span>，<span class="s6">1973</span>） 开发的进化策略用来优化工程设计中的数字参数，<span class="s6">Schwefel</span>（<span class="s6">1975</span>，<span class="s6">1977</span>，<span class="s6">1995</span>）和其他一 些人继续研究了这种策略。<span class="s6">Folgel &amp; Owens &amp; Walsh</span>（<span class="s6">1966</span>）开发了进化编程，作为进化有 限状态机的一种方法，大量的研究者继续探索了这种方法（例如 <span class="s6">Fogel &amp; Atmar 1993</span>）。 <span class="s6">Holland</span>（<span class="s6">1962</span>，<span class="s6">1975</span>）提出的遗传算法包含了维护个体的组成大群体的概念，并且强调在 这样的系统中交叉是一个关键的操作。<span class="s6">Koza</span>（<span class="s6">1992</span>）介绍了遗传编程，把遗传算法的搜索 策略应用到由计算机程序组成的假设中。随着计算机硬件不断地变得更快和更便宜，对进化 方法的兴趣也不断增长。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 20pt;line-height: 107%;text-align: left;">使用 <span class="s6">GA </span>学习规则集的一种方法是由 <span class="s6">K. DeJong </span>和他的学生在 <span class="s6">Pittsburgh </span>大学开发的（参 见 <span class="s6">Smith 1980</span>）。在这种方法中，每个规则集是竞争假设组成的群体的一个成员，就像本章</p><p style="padding-left: 6pt;text-indent: 0pt;text-align: left;">讨论的 <span class="s6">GABIL </span>系统中的一样。<span class="s6">Holland </span>和他的学生（<span class="s6">Holland 1986</span>）在 <span class="s6">Michigan </span>大学开发了</p><p style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;line-height: 107%;text-align: left;">一种不同的方法，其中每个规则是群体的一个成员，而群体本身是一个规则集。<span class="s6">Wrigh</span>（<span class="s6">t </span>从生物学角度分析了变异、繁殖、交叉繁殖和进化选择的作用。</p><p class="s6" style="padding-top: 1pt;padding-left: 3pt;text-indent: 0pt;text-align: left;">1977<span class="p">）</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">Mitchel<span class="p">（</span>l</p><p class="s6" style="padding-top: 1pt;padding-left: 4pt;text-indent: 0pt;text-align: left;">1996<span class="p">）和 </span>Goldberg<span class="p">（</span>1989<span class="p">）是讨论遗传算法这一主题的两本教材。</span>Forres<span class="p">（</span>t</p><p class="s6" style="padding-top: 1pt;padding-left: 4pt;text-indent: 0pt;text-align: left;">1993<span class="p">）</span></p><p style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;line-height: 108%;text-align: justify;">概括了 <span class="s6">GA </span>中的技术问题，<span class="s6">Goldberg</span>（<span class="s6">1994</span>）概括了最近的几个应用。<span class="s6">Koza</span>（<span class="s6">1992</span>）关于遗 传编程的专著是对遗传算法扩展到操作计算机程序的标准参考。发表新成果的主要会议是遗 传算法国际会议（<span class="s6">ICGA</span>）。其他相关的会议包括自适应行为仿真会议（<span class="s6">CSAB</span>），人工神经 网络和遗传算法国际会议（<span class="s6">ICANNGA</span>），以及 <span class="s6">IEEE </span>进化计算国际会议（<span class="s6">ICEC</span>）。目前也有 遗传编程方面的年会（<span class="s6">Koza et al. 1996b</span>）。《进化计算杂志》（<span class="s21">Evolutionary Computation Journal</span>）是这个领域最新研究成果的一个来源。《机器学习》（<span class="s21">Machine Learning</span>）杂志的一 些特刊也是针对 <span class="s6">GA </span>的。</p><p style="padding-left: 27pt;text-indent: 0pt;text-align: left;">习题</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 107%;text-align: justify;"><span class="s6">9.1 </span>为第 <span class="s6">3 </span>章中描述的 <span class="s21">PlayTennis </span>问题设计一个遗传算法，学习合取的分类规则。精确 地描述出其中对假设的位串编码和一组交叉算子。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 20pt;line-height: 107%;text-align: justify;"><span class="s6">9.2 </span>实现练习 <span class="s6">9.1 </span>中的简单 <span class="s6">GA</span>。用不同的群体大小 <span class="s21">p</span>、每一代中被淘汰的比例 <span class="s21">r </span>和变异 率 <span class="s21">m </span>进行试验。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">9.3 <span class="p">把 </span>GP <span class="p">发现的程序（在第 </span>9.5.2 <span class="p">节中描述）重新表示为树。然后将树的两个拷贝作为 两个双亲，在其上应用 </span>GP <span class="p">的交叉算子。说明其中交叉算子的操作过程。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 5pt;text-indent: 21pt;line-height: 109%;text-align: justify;">9.4 <span class="p">考虑把 </span>GA <span class="p">应用到对人工神经网络（特别是与反向传播算法训练的网络一致的前馈 网络，见第 </span>4 <span class="p">章）寻找一组合适的权值。考虑一个 </span>3<span class="s10"></span>2<span class="s10"></span>1 <span class="p">的分层前馈网络。描述一种把网 络权值编码成位串的方法，并描述一套适当的交叉算子。提示：不要在位串上允许所有可能 的交叉操作。指出在训练网络权值方面，使用 </span>GA <span class="p">与反向传播算法相比的一个优点和一个缺 点。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 27pt;text-indent: 0pt;text-align: left;">参考文献</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s8" style="padding-left: 122pt;text-indent: 0pt;line-height: 24pt;text-align: left;">第<span class="h1">10</span>章 学习规则集合</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 109%;text-align: justify;">对学习到的假设，最具有表征力的和最能为人类所理解的表示方法之一为 <span class="s6">if-then </span>规则 的集合。本章探索了若干能学习这样的规则集合的算法。其中最重要的一种是学习包含变量 的规则集合，或称为一阶 <span class="s6">Horn </span>子句集合。由于一阶 <span class="s6">Horn </span>子句集合可被解释为<span style=" color: #00F;">逻辑编程语 言 </span><span class="s63">Prolog </span><span style=" color: #00F;">中的程序，学习的过程经常被称为归纳逻辑编程（</span><span class="s63">ILP</span><span style=" color: #00F;">）</span>。本章考察了多种学习规 则集合的途径，其中一种途径基于机器定理证明器中演绎操作的逆转。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">10.1 <span class="s17">介绍</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">在许多情况下，有必要学习一个目标函数，它表示为共同定义该函数的若干 <span class="s6">if-then </span>规 则的集合。如第 <span class="s6">3 </span>章所示，学习规则集合的一种办法是首先学习到决策树，然后将此树转换</p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 112%;text-align: left;">为一等效的规则集合。另一种方法是在第 <span class="s6">9 </span>章介绍的遗传算法，它用位串编码每个规则集合， 然后用遗传搜索算子来探索整个假设空间。本章我们讨论一族不同的算法，它直接学习规则 集合，这族算法与前面的算法相比有两点关键的不同。首先，它们可学习包含变量的一阶规 则集合，这一点很重要，因为一阶子句的表示能力比命题规则要强得多。第二，这里讨论的 算法使用序列覆盖算法，一次学习一个规则，以递增地方式形成最终的规则集合。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;"><span class="p">作为一阶规则集合的例子，考虑以下两个规则，它们共同描述了目标概念 </span>Ancestor<span class="p">。这 里我们使用谓词 </span>Parent<span class="s6">(</span>x<span class="s6">,</span>y<span class="s6">)</span><span class="p">来表示 </span>y <span class="p">是 </span>x <span class="p">的父亲或母亲，而谓词 </span>Ancestor<span class="s6">(</span>x<span class="s6">,</span>y<span class="s6">)</span><span class="p">表示 </span>y <span class="p">是 </span>x <span class="p">的 任意代的祖先。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><table style="border-collapse:collapse;margin-left:24.2439pt" cellspacing="0"><tr style="height:24pt"><td style="width:29pt"><p class="s98" style="padding-top: 3pt;padding-left: 2pt;text-indent: 0pt;text-align: left;">IF</p></td><td style="width:137pt"><p class="s96" style="padding-top: 3pt;padding-left: 16pt;text-indent: 0pt;text-align: left;">Parent<span class="s98">(</span>x<span class="s98">,</span>y<span class="s98">)</span></p></td><td style="width:42pt"><p class="s98" style="padding-top: 3pt;padding-left: 7pt;text-indent: 0pt;text-align: left;">THEN</p></td><td style="width:67pt"><p class="s96" style="padding-top: 3pt;padding-left: 7pt;text-indent: 0pt;text-align: left;">Ancestor<span class="s98">(</span>x<span class="s98">,</span>y<span class="s98">)</span></p></td></tr><tr style="height:24pt"><td style="width:29pt"><p class="s98" style="padding-top: 7pt;padding-left: 2pt;text-indent: 0pt;text-align: left;">IF</p></td><td style="width:137pt"><p class="s96" style="padding-top: 4pt;padding-left: 16pt;text-indent: 0pt;text-align: left;">Parent<span class="s98">(</span>x<span class="s98">,</span>z<span class="s98">)</span><span class="s95">∧</span>Ancestor<span class="s98">(</span>z<span class="s98">,</span>y<span class="s98">)</span></p></td><td style="width:42pt"><p class="s98" style="padding-top: 7pt;padding-left: 7pt;text-indent: 0pt;text-align: left;">THEN</p></td><td style="width:67pt"><p class="s96" style="padding-top: 7pt;padding-left: 7pt;text-indent: 0pt;text-align: left;">Ancestor<span class="s98">(</span>x<span class="s98">,</span>y<span class="s98">)</span></p></td></tr></table><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;line-height: 108%;text-align: justify;">注意以上两个规则很紧凑地描述了一个递归函数，它很难用决策树或其他的命题的方法 来表示。为说明一阶规则的强大的表示能力，可以考虑通用的编程语言 <span class="s6">Prolog</span>。在 <span class="s6">Prolog </span>中，程序是一阶规则的集合，如上所示的那样（这种形式的规则也被称为 <span class="s6">Horn </span>子句）。实 际上，如果稍稍修改上面两个规则的语法，就可以得到一个合法的 <span class="s6">Prolog </span>程序，它用来计 算 <span class="s21">Ancestor </span>关系。因此，一个可以学习这种规则集合的通用算法，可被看作是从样例中自 动推导出 <span class="s6">Prolog </span>程序的算法。本章介绍了在给定适当的训练例集合时，能够学习这种规则 的学习算法。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 109%;text-align: justify;">实践中基于一阶表示的学习系统已成功地应用于各种问题，如在质谱仪中学习哪一个化 学药品能粘合碎片 (<span class="s6">Buchanan </span>1976; <span class="s6">Lindsay </span>1980)，学习哪一个化学亚结构会产生诱导有 机体突变的放射性物质（一个关于致癌物质的属性）（<span class="s6">Srinivasan et al</span>. 1994），以及学习有 限单元网以分析物理结构中的应力（<span class="s6">Dolsak </span>&amp; <span class="s6">Muggleton </span>1992）。在每个应用中，假设的表 示必须包含关系断言，它可由一阶表示来简单地表达，却很难用命题表示来描述。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 113%;text-align: left;">在本章中，我们先介绍能够学习命题规则集的算法，即不含变量的规则。在这种框架中， 搜寻假设空间以学习到析取规则集合的算法比较易于理解。然后，我们考虑了将这些算法扩 展到一阶规则。接下来讨论了归纳逻辑的两种通用途径，以及归纳和演绎推理的基本关系。</p><h2 style="padding-left: 12pt;text-indent: 0pt;line-height: 19pt;text-align: left;">10.2 <span class="s17">序列覆盖算法</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 11pt;text-indent: 21pt;line-height: 111%;text-align: justify;">这里考虑的一族算法，其学习规则集的策略为：学习一个规则，移去它覆盖的数据，再 重复这一过程。这样的算法被称为序列覆盖（<span class="s6">sequential covering</span>）算法。想象我们已有了 一个子程序 <span class="s6">learn</span>-<span class="s6">one</span>-<span class="s6">rule</span>，它的输入为一组正例和反例，然后输出单个规则，它能够覆盖 许多正例，并且覆盖很少的反例。我们要求这一输出的规则有较高的精确度，但不必有较高 的覆盖度。较高的精确度说明它所做出的预测应为正确的。可接受较低的覆盖度，表示它不 必对每个训练样例都作出预测。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 11pt;text-indent: 21pt;line-height: 111%;text-align: justify;">有了这样一个学习单个规则的 <span class="s6">learn</span>-<span class="s6">one</span>-<span class="s6">rule </span>子程序，要学习规则集，一个明显的方法 是在所有可用训练样例上执行 <span class="s6">learn</span>-<span class="s6">one</span>-<span class="s6">rule</span>，再移去由其学到的规则覆盖的正例，再在剩 余的训练样例上执行它以学习第二个规则。该过程可重复若干次，直到最后学习到析取规则 集，它们共同覆盖正例，覆盖程度达到所希望的比例。算法被称为序列覆盖算法是因为它按 次序学习到一组规则，它们共同覆盖了全部正例。最终的规则集可被排序，这样分类新实例 时可先应用精度最高的规则。序列覆盖算法的一个原型在表 10-1 中陈述。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 12pt;text-indent: 21pt;line-height: 113%;text-align: justify;">序列覆盖算法是广泛使用的学习析取规则集算法的其中之一。它将学习析取规则集的问 题化简为一系列更简单的问题，每个子问题只需学到单个合取规则。由于它执行的是一种贪 婪搜索，形成序列化的规则且没有回溯，所以它不能保证找到能覆盖样例的最小的或最佳的 规则。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 12pt;text-indent: 21pt;line-height: 111%;text-align: justify;">如何设计 <span class="s6">learn</span>-<span class="s6">one</span>-<span class="s6">rule </span>程序以达到序列覆盖算法的要求？我们需要一个算法能够形成 有较高精度的规则，但不必覆盖所有的正例。在本节中展示了各种算法，并描述了它们在学 术研究上已探索的主要差别。本节只考虑命题规则。后面的节中将把这些算法扩展到一阶 <span class="s6">Horn </span>子句。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 128pt;text-indent: 0pt;text-align: left;">表 <span class="h4">10-1 </span>学习析取的规则集的序列覆盖算法。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s16" style="padding-left: 43pt;text-indent: 21pt;line-height: 125%;text-align: left;">learn-one-rule <span class="s14">必须返回单个的能覆盖某些 </span>Examples <span class="s14">的规则。</span>performance <span class="s14">是用户提供的子程序， 以评估规则的质量。当算法再也不能学习到一个性能超过给定阈值 </span>Threshold <span class="s14">的规则时，该算法终 止。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 2pt;text-align: left;"><span><img width="570" height="2" alt="image" src="机器学习/Image_371.png"/></span></p><p class="s16" style="padding-top: 1pt;padding-left: 11pt;text-indent: 0pt;text-align: left;">Sequential-covering(<i>Target</i>_<i>attribute</i>, <i>Attributes</i>, <i>Examples</i>, <i>Threshold</i>)</p><p class="s56" style="padding-top: 2pt;padding-left: 11pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span>Learned<span class="s16">_</span>rules<span class="s14">←</span><span class="s16">{}</span></p><p class="s56" style="padding-top: 3pt;padding-left: 11pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span>Rule<span class="s14">←</span><span class="s16">learn-one-rule(</span>Target<span class="s16">_</span>attribute<span class="s16">, </span>Attributes<span class="s16">, </span>Examples<span class="s16">)</span></p><p class="s16" style="padding-top: 3pt;padding-left: 12pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span><span class="s14">当 </span>performance(<i>Rule</i>, <i>Examples</i>) &gt; <i>Threshold</i><span class="s14">，做：</span></p><p class="s56" style="padding-top: 3pt;padding-left: 30pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span>Learned<span class="s16">_</span>rules<span class="s14">←</span>Learned<span class="s16">_</span>rules <span class="s16">+ </span>Rule</p><p class="s56" style="padding-top: 3pt;padding-left: 29pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span>Examples<span class="s14">←</span>Examples<span class="s16">-{</span><span class="s14">被 </span>Rule <span class="s14">正确分类的样例</span><span class="s16">}</span></p><p class="s56" style="padding-top: 3pt;padding-left: 29pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span>Rule<span class="s14">←</span><span class="s16">learn-one-rule(</span>Target<span class="s16">_</span>attribute<span class="s16">, </span>Attributes<span class="s16">, </span>Examples<span class="s16">)</span></p><p class="s56" style="padding-top: 3pt;padding-left: 12pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span>Learned<span class="s16">_</span>rules<span class="s14">←按照在 </span>Examples <span class="s14">上的 </span><span class="s16">performance </span><span class="s14">排序的 </span>Lea<span class="s16">r</span>ned<span class="s16">_</span>rules</p><p class="s56" style="padding-top: 3pt;padding-left: 11pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span><span class="s14">返回 </span>Learned<span class="s16">_</span>rules</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 2pt;text-align: left;"><span><img width="570" height="2" alt="image" src="机器学习/Image_372.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 12pt;text-indent: 0pt;text-align: left;">10.2.1 <span class="s25">一般到特殊柱状搜索</span></h3><p style="padding-top: 10pt;padding-left: 11pt;text-indent: 21pt;line-height: 107%;text-align: justify;">实现 <span class="s6">learn</span>-<span class="s6">one</span>-<span class="s6">rule </span>的一个有效途径是将假设空间搜索过程设计为与 <span class="s6">ID</span>3 算法中相似的 方式，但在每一步只沿着最有希望的分支向下。如图 10-1 所示的搜索树，搜索开始于最一</p><p style="padding-left: 11pt;text-indent: 0pt;line-height: 110%;text-align: left;">般的规则前件（即能匹配所有实例的空测试），然后贪婪地加入那些在训练样例上性能改进 最大的属性测试。一旦该测试被加入，该过程重复，贪婪地加入第二个属性测试，依此类推。 如 <span class="s6">ID</span>3 那样，该过程通过贪婪地增加新的属性测试来获得假设，直到该假设的性能到达一 可接受的程度。与 <span class="s6">ID</span>3 不同的是，此 <span class="s6">learn</span>-<span class="s6">one</span>-<span class="s6">rule </span>的实现在每一步沿着单个分支－－即产 生最佳性能的属性-值对，而不是用增长子树的办法覆盖所选属性的所有可能值。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 11pt;text-indent: 21pt;line-height: 109%;text-align: justify;">这种实现 <span class="s6">learn</span>-<span class="s6">one</span>-<span class="s6">rule </span>的途径执行的是对可能存在的规则的一般到特殊搜索，以得到 一个有较高精度但不一定完全覆盖数据的规则。如在决策树学习中那样，有许多方法可以定 义选择“最佳”分支的度量标准。与在 <span class="s6">ID</span>3 中类似，我们可定义最佳分支为它覆盖的样例 有最低的熵（回忆式 3.3）。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 19pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="547" height="1" alt="image" src="机器学习/Image_373.png"/></span></p><p class="s48" style="padding-left: 21pt;text-indent: 0pt;text-align: left;">插图——原书页码： <span class="s21">277</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 20pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="531" height="1" alt="image" src="机器学习/Image_374.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 64pt;text-indent: 28pt;text-align: left;">图 <span class="h4">10-1 Learn-one-rule </span>从一般到特殊过程中的规则前件搜索</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-left: 43pt;text-indent: 21pt;line-height: 132%;text-align: left;">在每一步，最佳规则的前件被以各种可能方式特化。规则后件是由满足前件的样例所决定的。 该图显示的是宽度为 <span class="s16">1 </span>的柱状搜索。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 11pt;text-indent: 21pt;line-height: 110%;text-align: justify;">上面推荐的一般到特殊搜索是一种不带回溯的贪婪深度优先搜索。如其他贪婪搜索一 样，它所带来的危险是每一步可能作出了次优的选择。为减小这种风险，可将此算法扩展为 一种柱状搜索（<span class="s6">beam search</span>），即每一步算法保留 <span class="s21">k </span>个最佳候选的列表，在每一搜索步对这 <span class="s21">k </span>个最佳候选生成分支（特化），并且结果集再被削减至 <span class="s21">k </span>个最可能成员。柱状搜索跟踪当 前最高分值假设的最有希望的替代者，以使每一步中它们的所有后继都被考虑到。该一般到</p><p style="padding-left: 95pt;text-indent: -83pt;line-height: 190%;text-align: left;">特殊柱状搜索用于 <span class="s6">CN</span>2 程序，它由 <span class="s6">Clark </span>&amp; <span class="s6">Niblett</span>（1989）提出。该算法在表 10-2 中描述。 表 <span class="h4">10-2 learn-one-rule </span>的一种实现是一般到特殊柱状搜索。</p><p class="s14" style="padding-top: 4pt;padding-left: 43pt;text-indent: 21pt;line-height: 125%;text-align: left;">当前假设的边缘表示为变量 <span class="s56">Candidate</span><span class="s16">_</span><span class="s56">hypotheses</span>。该算法与 <span class="s16">Clark &amp; Niblett</span>（<span class="s16">1989</span>）描述的 <span class="s16">CN2 </span>程序相类似。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 2pt;text-align: left;"><span><img width="570" height="2" alt="image" src="机器学习/Image_375.png"/></span></p><p class="s16" style="padding-top: 1pt;padding-left: 12pt;text-indent: 0pt;line-height: 126%;text-align: left;">Learn-one-rule(<i>Target</i>_<i>attribute</i>, <i>Attributes</i>, <i>Examples</i>, <i>k</i>) <span class="s14">返回一个覆盖若干样例的规则。实施一般到特殊贪婪柱状搜索以得到最佳规则，由 </span>performance <span class="s14">度量来引导。 </span><span class="s55">n </span><span class="s14">初始化 </span><i>Best</i>_<i>hypothesis </i><span class="s14">为最一般的假设</span><span class="s57"></span></p><p class="s56" style="padding-left: 12pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span><span class="s14">初始化 </span>Candidate<span class="s16">_</span>hypotheses <span class="s14">为集合</span><span class="s16">{</span>Best<span class="s16">_</span>hypothesis<span class="s16">}</span></p><p class="s56" style="padding-top: 3pt;padding-left: 12pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span><span class="s14">当 </span>Candidate<span class="s16">_</span>hypotheses <span class="s14">不空，做以下操作：</span></p><p class="s16" style="padding-top: 3pt;padding-left: 30pt;text-indent: 0pt;text-align: left;">1.<span class="s14">生成紧邻更特殊的候选假设</span></p><p class="s56" style="padding-top: 4pt;padding-left: 48pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><span class="s55">n </span>All<span class="s16">_</span>constraints<span class="s14">←所有形式为</span><span class="s16">(</span>a<span class="s16">=</span>v<span class="s16">)</span><span class="s14">的约束集合，其中 </span>a <span class="s14">为 </span>Attributes <span class="s14">的成员，而 </span>v <span class="s14">为出现在 当前 </span>Examples <span class="s14">集合中的 </span>a <span class="s14">值</span></p><p class="s56" style="padding-top: 2pt;padding-left: 48pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span>New<span class="s16">_</span>candidate<span class="s16">_</span>hypothese<span class="s14">←</span></p><p class="s56" style="padding-top: 3pt;padding-left: 93pt;text-indent: -18pt;line-height: 126%;text-align: left;"><span class="s14">对 </span>Candidate<span class="s16">_</span>hypotheses <span class="s14">中每个 </span>h<span class="s14">， 对 </span>All<span class="s16">_</span>constraints <span class="s14">中每个 </span>c</p><p class="s14" style="padding-left: 102pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span>通过加入约束 <span class="s56">c </span>创建一个 <span class="s56">h </span>的特化式</p><p class="s56" style="padding-top: 3pt;padding-left: 48pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span><span class="s14">从 </span>New<span class="s16">_</span>candidate<span class="s16">_</span>hypothese <span class="s14">中移去任意重复的、不一致的或非极大特殊化的假设</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 2pt;text-align: left;"><span><img width="570" height="2" alt="image" src="机器学习/Image_376.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 2pt;text-align: left;"><span><img width="570" height="2" alt="image" src="机器学习/Image_377.png"/></span></p><p class="s16" style="padding-left: 30pt;text-indent: 0pt;text-align: left;">2.<span class="s14">更新 </span><i>Best</i>_<i>hypothesis</i></p><p class="s56" style="padding-top: 3pt;padding-left: 48pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span><span class="s14">对 </span>New<span class="s16">_</span>candidate<span class="s16">_</span>hypotheses <span class="s14">中所有 </span>h <span class="s14">做以下操作：</span></p><p class="s16" style="padding-top: 3pt;padding-left: 67pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span><span class="s14">如果</span>(performance(<i>h</i>, <i>Examples</i>, <i>Target</i>_<i>attribute</i>)</p><p class="s16" style="padding-top: 4pt;padding-left: 93pt;text-indent: 0pt;text-align: left;">&gt; performance(<i>Best</i>_<i>hypothesis</i>, <i>Examples</i>, <i>Target</i>_<i>attribute</i>))</p><p class="s56" style="padding-top: 2pt;padding-left: 20pt;text-indent: 0pt;text-align: center;"><span class="s14">则 </span>Best<span class="s16">_</span>hypothesis<span class="s14">←</span>h</p><p class="s16" style="padding-top: 3pt;padding-left: 30pt;text-indent: 0pt;text-align: left;">3.<span class="s14">更新 </span><i>Candidate</i>_<i>hypotheses</i></p><p class="s56" style="padding-top: 3pt;padding-left: 48pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span>Candidate<span class="s16">_</span>hypotheses<span class="s14">←</span>New<span class="s16">_</span>candidate<span class="s16">_</span>hypotheses <span class="s14">中 </span>k <span class="s14">个最佳成员，按照 </span><span class="s16">performance </span><span class="s14">度量</span></p><p class="s55" style="padding-top: 3pt;padding-left: 12pt;text-indent: 0pt;text-align: left;">n <span class="s14">返回一个如下形式的规则：</span></p><p class="s56" style="padding-top: 3pt;padding-left: 48pt;text-indent: 0pt;text-align: left;"><span class="s14">“如果 </span>Best<span class="s16">_</span>hypothesis<span class="s14">，则 </span>prediction<span class="s14">”</span></p><p class="s56" style="padding-top: 3pt;padding-left: 12pt;text-indent: 35pt;text-align: left;"><span class="s14">其中 </span>prediction <span class="s14">为在与 </span>Best<span class="s16">_</span>hypothesis <span class="s14">匹配的 </span>Examples <span class="s14">中最频繁的 </span>Target<span class="s16">_</span>attribute <span class="s14">值</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s16" style="padding-top: 7pt;padding-left: 12pt;text-indent: 0pt;text-align: left;">performance(<i>h</i>, <i>Examples</i>, <i>Target</i>_<i>attribute</i>)</p><p class="s56" style="padding-top: 2pt;padding-left: 12pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span>h<span class="s16">_</span>examples<span class="s14">←与 </span>h <span class="s14">匹配的 </span>Examples <span class="s14">子集</span></p><p class="s56" style="padding-top: 3pt;padding-left: 12pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span><span class="s14">返回</span><span class="s16">-</span>Entropy<span class="s16">(</span>h<span class="s16">_</span>examples<span class="s16">)</span><span class="s14">，其中 </span>Entropy <span class="s14">是关于 </span>Target<span class="s16">_</span>attribute <span class="s14">的熵</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 2pt;text-align: left;"><span><img width="570" height="2" alt="image" src="机器学习/Image_378.png"/></span></p><p style="padding-top: 6pt;padding-left: 11pt;text-indent: 21pt;line-height: 111%;text-align: left;">下面是对表 10-2 中的 <span class="s6">learn</span>-<span class="s6">one</span>-<span class="s6">rule </span>算法的一些说明。首先，注意在算法主循环中考虑 的每个假设是属性-值约束的合取。每个合取假设对应于待学习规则的候选前件集合，它由 其覆盖的样例的熵来评估。搜索过程不断特化候选假设，直到到达一个极大特殊假设，它包 含所有可用的属性。由该算法输出的规则为搜索过程中遇到的性能最佳（<span class="s6">performance </span>最大） 的规则－－不一定是搜索最终产生的假设。规则的后件输出只在算法的最后一步产生，在其 前件（表示为变量 <span class="s6">Best</span>_<span class="s6">hypothesis</span>）确定之后，算法构造出的规则后件用于预测在规则前件 所能覆盖的样例中最常见的目标属性值。最后，还应注意尽管使用了柱状搜索以减小风险， 贪婪搜索仍可能产生次优的规则。然而，即使这样，序列覆盖算法仍能学到一组规则，它们 共同覆盖训练样例，因为它对剩余的未覆盖样例重复调用了 <span class="s6">learn</span>-<span class="s6">one</span>-<span class="s6">rule</span>。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 12pt;text-indent: 0pt;text-align: left;">10.2.2 <span class="s25">几种变型</span></h3><p style="padding-top: 10pt;padding-left: 11pt;text-indent: 21pt;line-height: 110%;text-align: justify;">序列覆盖算法以及 <span class="s6">learn</span>-<span class="s6">one</span>-<span class="s6">rule </span>算法可学习 <span class="s6">if</span>-<span class="s6">then </span>规则集以覆盖训练样例。该途径有 许多变型。比如，某些情况下可能希望程序只学习覆盖正例的规则，并且对该规则没有覆盖 的实例“默认”地赋予其反例分类。比如，这种方法适用于学习目标概念“可能怀有双胞胎 的孕妇”。在这种情况下，正例在整个群体中所占比例很小，所以规则集如果只标定正例的 类别，而对所有其他样例默认分类为反例，规则集会更为简洁易懂。这一方法对应于 <span class="s6">Prolog </span>中的“失败否定”策略，其中不能证明为真的表达式都默认为假。为了学习这样的只预测单 个目标值的规则，需要修改 <span class="s6">learn</span>-<span class="s6">one</span>-<span class="s6">rule </span>算法以接受附加的输入变量，指定感兴趣的目标 值。一般到特殊柱状搜索如以前一样处理，只要修改评估假设的 <span class="s6">performance </span>子程序。注意 <span class="s6">performance </span>定义为负熵已不再适用于此新的设定，因为它把唯独覆盖反例的假设赋予了最 大分值，与唯独覆盖正例的假设一样。这种情况下使用该假设覆盖正例比例的度量标准则更 为适合。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 12pt;text-indent: 20pt;line-height: 107%;text-align: left;">算法的另一变型是一族称为 <span class="s6">AQ </span>的算法（<span class="s6">Michalsk </span>1969, <span class="s6">Michalski et al</span>. 1986），它 比上面讨论所基于的 <span class="s6">CN</span>2 算法更早。如 <span class="s6">CN</span>2 一样，<span class="s6">AQ </span>学习析取规则集，以覆盖目标函数。 然而，<span class="s6">AQ </span>与上面给出的算法有以下不同：首先 <span class="s6">AQ </span>的覆盖算法与序列覆盖算法不同，因为 它明确地寻找覆盖一特定目标值的规则，然后对每个目标值学习一析取规则集。第二，<span class="s6">AQ </span>算法学习单个规则的方法也不同于 <span class="s6">learn</span>-<span class="s6">one</span>-<span class="s6">rule</span>。当它对每个规则执行一般到特殊柱状搜 索时，它围绕单个正例来进行搜索。确切地说，它在搜索中只考虑被该正例满足的属性，以</p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 113%;text-align: left;">得到逐渐特殊的假设。每次学一个新规则时，它从那些未覆盖的样例中也选择一个新的正例， 作为种子以指引新析取项的搜索。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">10.3 <span class="s17">学习规则集：小结</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 113%;text-align: left;">上面讨论的序列覆盖算法和第 3 章中的决策树学习算法提供了几种学习规则集的方法。 本节考虑这些规则学习算法设计中的关键思想。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 110%;text-align: left;">首先，序列覆盖算法每次学习一个规则，移去覆盖的样例然后在剩余样例上重复这一过 程。相反，如 <span class="s6">ID</span>3 那样的决策树算法使用单个搜索过程来搜索可接受决策树，每步并行学 习整个析取项的集合。因此，我们也可将 <span class="s6">ID</span>3 这样的算法称为并行覆盖算法，对应于 <span class="s6">CN</span>2 这样的序列覆盖算法。哪一种算法比较好？答案关键在于搜索中最基本步骤之间的差别。 <span class="s6">ID</span>3 在每一搜索步中根据它对数据产生的划分选择不同的属性。相反，<span class="s6">CN</span>2 选择的是不同的 属性-值对，方法是通过比较它们覆盖的数据子集。要看出这种差别的意义所在，需要比较 两种算法为学习到相同的规则集合所作出的不同选择的次数。为了学习到 <span class="s21">n </span>个规则的集合， 每个规则前件包合 <span class="s21">k </span>个属性值测试，序列覆盖算法需要执行 <span class="s21">n</span>·<span class="s21">k </span>次基本搜索步，为每个规 则的每个前件做独立的选择，而并行覆盖算法的独立选择次数远远少于此，因为在决策树中 每个决策结点的选择都对应了与该结点相关联的多个规则的前件选择。换言之，如果决策结 点测试一个有 <span class="s21">m </span>种可能值的属性，每次决策结点的选择都对应了对 <span class="s21">m </span>个相应的规则中每个 规则的前件选择（见习题 10.1）。这样，序列覆盖算法（如 <span class="s6">CN</span>2）作出的独立选择次数高于 <span class="s6">ID</span>3 这样的并行覆盖算法。但哪一种算法更好的问题依然存在。其解答依赖于有多少训练数 据是可用的。如果数据非常丰富，那么它可以支持序列覆盖算法所要求的较大数量的独立选 择。然而若数据较缺乏，对于不同规则前件的决策“共享”则更有效。另一考虑在于特定的 任务中是否希望不同的规则测试相同的属性。在并行覆盖决策树学习算法中会出现这样的情 况。在序列覆盖算法中则不存在。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 109%;text-align: justify;">不同方法的第二个相异之处在于 <span class="s6">learn</span>-<span class="s6">one</span>-<span class="s6">rule </span>搜索的方向。在上面描述的算法中，搜 索是从一般到特殊的。其他已讨论的算法（如第 2 章中的 <span class="s6">Find</span>-<span class="s6">S</span>）是从特殊到一般的。在 此情况下，从一般到特殊搜索的一个优点在于只有一个极大一般假设可作为搜索起始点，而 在多数假设空间中有很多特殊假设（如对每个实例有一假设）。因为有许多极大特殊假设， 就不能确知选择哪一个作为搜索的开始点。执行从特殊到一般搜索的一个称为 <span class="s6">Golem </span>(<span class="s6">Muggleton </span>&amp; <span class="s6">Feng </span>1990)的程序解决此问题的方法是随机选择多个正例，以此为初始来进 行搜索。在多个随机选择中的最佳假设作为最后结果。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 110%;text-align: left;">第三个要考虑的是 <span class="s6">learn</span>-<span class="s6">one</span>-<span class="s6">rule </span>是为一个生成再测试（<span class="s6">generate then test</span>）搜索，范围 为所有合法的假设，如我们推荐的实现中那样；还是一个样例驱动（<span class="s6">example</span>-<span class="s6">driven</span>）搜索， 以使训练样例个体约束假设的生成。样例驱动搜索算法包括第 2 章的 <span class="s6">Find</span>-<span class="s6">S</span>、候选消除、 <span class="s6">AQ </span>算法，以及本章后面要讨论的 <span class="s6">Cigol </span>算法。在这些算法中，对假设的生成或修正是由单 独的训练样例驱动的，而且结果是一个已修正的假设，使对此单个样例的性能得到改善。这 不同于表 10-2 中 <span class="s6">learn</span>-<span class="s6">one</span>-<span class="s6">rule </span>算法的生成再测试搜索，其中后续的假设的生成只基于假设 表示的语法。在这些候选假设生成之后再分析训练数据，然后基于这些假设在全部样例上的 性能来进行选择。生成再测试的一个重要优点是搜索中每一步的选择都基于在许多样例上的 假设性能，因此噪声数据的影响被最小化。相反，样例驱动算法基于单个的样例改进假设， 它更容易被一些噪声训练样例影响，因此对训练数据中差错的鲁棒性较差。</p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 111%;text-align: left;">第四个要考虑的是是否需要对规则进行后修剪以及怎样修剪。如在决策树学习中一样， <span class="s6">learn</span>-<span class="s6">one</span>-<span class="s6">rule </span>也有可能形成在训练数据上性能很好，但在以后的数据中很差的规则。解决 的办法也是在得到每个规则后进行后修剪。确切地讲，可以移去某些前件，只要这导致不同 于训练样例的用于修剪的一个样例集合上的性能提高，对于后修剪更详细的讨论见第</p><p style="padding-left: 6pt;text-indent: 0pt;text-align: left;">3.7.1.2 节。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: left;">最后要考虑的是在 <span class="s6">learn</span>-<span class="s6">one</span>-<span class="s6">rule </span>时指引搜索方向的规则性能（<span class="s6">performance</span>）的定义。 已有了各种不同的评价函数，某些常用的评估函数包括：</p><p style="padding-top: 6pt;padding-left: 49pt;text-indent: -21pt;line-height: 14pt;text-align: left;"><span class="s10"> </span>相对频率（<span class="s6">Relative frequency</span>）。令<span class="s21">n</span>代表规则所匹配的样例数目，令<span class="s21">n</span><span class="s36">c</span>代表其中 它能正确分类的数目。规则性能的相对频率估计为：</p><p style="text-indent: 0pt;text-align: left;"><span><img width="17" height="1" alt="image" src="机器学习/Image_379.png"/></span></p><p class="s30" style="padding-top: 1pt;padding-left: 202pt;text-indent: 0pt;line-height: 110%;text-align: center;">n<span class="s52">c </span>n</p><p style="padding-left: 50pt;text-indent: 0pt;line-height: 11pt;text-align: left;">相对频率被用于在 <span class="s6">AQ </span>程序中评估规则。</p><p style="padding-left: 49pt;text-indent: -21pt;line-height: 93%;text-align: left;"><span class="s10"> </span>精度的<span class="s21">m</span><span class="s6">-</span>估计（<span class="s21">m</span><span class="s6">-estimate of accuracy</span>）。该精度估计偏向于规则所期望的默认 精度。它在数据比较缺乏，并且规则必须在很少的样例上评估时常用。令<span class="s21">n</span><span class="s36">c</span>和<span class="s21">n </span>如上定义，并令<span class="s21">p</span>为从整个数据集中随机抽取的样例与该规则赋予的分类相同的 先验概率（例如，如果 <span class="s6">100 </span>个样例中有 <span class="s6">12 </span>个与该规则的预测值相同，那么<span class="s21">p</span><span class="s6">=0.12</span>）。 最后，令<span class="s21">m</span>为权重，或称对此先验概率<span class="s21">p</span>进行加权的等效样例数目。对规则精度 的<span class="s21">m</span><span class="s6">-</span>估计为：</p><p style="text-indent: 0pt;text-align: left;"><span><img width="52" height="1" alt="image" src="机器学习/Image_380.png"/></span></p><p class="s30" style="padding-top: 1pt;padding-left: 189pt;text-indent: 0pt;text-align: center;">n<span class="s52">c </span><span class="s38"> </span>mp n <span class="s38"> </span>m</p><p style="padding-left: 50pt;text-indent: 0pt;line-height: 12pt;text-align: justify;">注意如果 <span class="s21">m </span>被设为 <span class="s6">0</span>，则 <span class="s21">m </span>估计变为上面的相对频率估计。当 <span class="s21">m </span>上升时，需要</p><p style="padding-left: 50pt;text-indent: 0pt;line-height: 14pt;text-align: justify;">更多的样例来克服这个预先假定的精度 <span class="s21">p</span>。<span class="s21">m</span><span class="s6">-</span>估计度量由 <span class="s6">Cestnik &amp; Bratko</span></p><p style="padding-left: 50pt;text-indent: 0pt;line-height: 14pt;text-align: justify;">（<span class="s6">1991</span>）提出，它已用于某些版本的 <span class="s6">CN2 </span>算法。它也用于第 <span class="s6">6.9.1 </span>节讨论的朴 素贝叶斯分类器。</p><p style="padding-left: 49pt;text-indent: -21pt;line-height: 14pt;text-align: left;"><span class="s10"> </span>熵<span class="s6">(entropy)</span>。这是在表 <span class="s6">10-2 </span>中使用的 <span class="s6">performance </span>子程序中使用的度量。令 <span class="s21">S </span>为 匹配规则前件的样例集合。熵衡量的是该样例集合中目标函数的均一性。这里</p><p style="padding-left: 49pt;text-indent: 0pt;line-height: 12pt;text-align: justify;">使用熵的负值，以使较佳的规则拥有较高的分值：</p><p class="s41" style="padding-top: 2pt;padding-left: 24pt;text-indent: 0pt;line-height: 6pt;text-align: center;">c</p><ul id="l26"><li style="padding-left: 148pt;text-indent: -9pt;line-height: 18pt;text-align: left;"><p class="s30" style="display: inline;">Entropy<span class="s33">(</span>S <span class="s33">) </span><span class="s38"> </span><span class="s124"></span><span class="s135"> </span>p<span class="s52">i</span><span class="s41"> </span><span class="s33">log </span><span class="s79">2 </span><span class="s42"> </span>p<span class="s52">i</span></p></li></ul><p class="s41" style="padding-left: 24pt;text-indent: 0pt;line-height: 7pt;text-align: center;">i<span class="s40"></span><span class="s42">1</span></p><p style="padding-left: 50pt;text-indent: 0pt;line-height: 92%;text-align: justify;">其中<span class="s21">c</span>为目标函数可取的不同值数量，<span class="s21">p</span><span class="s36">i</span>为<span class="s21">S</span>中目标函数取第<span class="s21">i</span>个值的样例所占比 例。与统计意义测试相结合，熵度量用于<span class="s6">CN2 </span>算法（<span class="s6">Clark &amp; Niblett 1989</span>），它 也是许多决策树学习算法中信息增益度量的基础。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">10.4 <span class="s17">学习一阶规则</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 109%;text-align: left;">前面讨论的算法针对学习命题规则集（即无变量的规则）。本节中将考虑带有变量的规 则，确切地讲为一阶 <span class="s6">Horn </span>子句。之所以考虑这样的规则，是因为它们比命题规则更有表征 能力。对于一阶段规则的归纳学习通常被称为归纳逻辑编程（<span class="s6">Inductive Logic Programming</span>， 简写 <span class="s6">ILP</span>），因为这一过程可看作从样例中自动推论出 <span class="s6">Prolog </span>程序。<span class="s6">Prolog </span>是一个通用的、 图灵等价的编程语言，其中程序被表示为一组 <span class="s6">Horn </span>子句。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">10.4.1 <span class="s25">一阶 </span>Horn <span class="s25">子句</span></h3><p style="padding-top: 10pt;padding-left: 6pt;text-indent: 21pt;line-height: 113%;text-align: left;">为说明一阶表示比命题（无变量）表示的优越之处，考虑一个学习任务，目标概念很简 单，为 <span class="s21">Daughter</span>(<span class="s21">x</span>,<span class="s21">y</span>)，定义在所有的人 <span class="s21">x </span>和 <span class="s21">y </span>上。<span class="s21">Danghter</span>(<span class="s21">x</span>,<span class="s21">y</span>)的值在 <span class="s21">x </span>是 <span class="s21">y </span>的女儿时为</p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 107%;text-align: justify;">真，否则为假。假定每个人被描述为属性 <span class="s21">Name</span>, <span class="s21">Mother</span>, <span class="s21">Father</span>, <span class="s21">Male </span>和 <span class="s21">Female</span>。因此每 个训练样例将包含以这些属性进行的描述的两个人，以及目标属性 <span class="s21">Daughter </span>的值。例如， 下面为一个正例，其中 <span class="s21">Sharon </span>为 <span class="s21">Bob </span>的女儿。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><table style="border-collapse:collapse;margin-left:24.2482pt" cellspacing="0"><tr style="height:19pt"><td style="width:82pt"><p class="s95" style="padding-top: 1pt;padding-left: 2pt;text-indent: 0pt;text-align: left;">&lt;<span class="s96">Name</span><span class="s281">1</span>=<span class="s96">Sharon</span>,</p></td><td style="width:85pt"><p class="s96" style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">Mother<span class="s281">1</span><span class="s95">=</span>Louise<span class="s95">,</span></p></td><td style="width:97pt"><p class="s96" style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">Father<span class="s281">1</span><span class="s95">=</span>Bob<span class="s95">,</span></p></td></tr><tr style="height:16pt"><td style="width:82pt"><p class="s96" style="padding-left: 2pt;text-indent: 0pt;line-height: 14pt;text-align: left;">Male<span class="s281">1</span><span class="s95">=</span>False<span class="s95">,</span></p></td><td style="width:85pt"><p class="s96" style="padding-left: 6pt;text-indent: 0pt;line-height: 14pt;text-align: left;">Female<span class="s281">1</span><span class="s95">=</span>True<span class="s95">,</span></p></td><td style="width:97pt"/></tr><tr style="height:16pt"><td style="width:82pt"><p class="s96" style="padding-left: 2pt;text-indent: 0pt;line-height: 14pt;text-align: left;">Name<span class="s281">2</span><span class="s95">=</span>Bob<span class="s95">,</span></p></td><td style="width:85pt"><p class="s96" style="padding-left: 6pt;text-indent: 0pt;line-height: 14pt;text-align: left;">Mother<span class="s281">2</span><span class="s95">=</span>Nora<span class="s95">,</span></p></td><td style="width:97pt"><p class="s96" style="padding-left: 27pt;text-indent: 0pt;line-height: 14pt;text-align: left;">Father<span class="s281">2</span><span class="s95">=</span>Victor<span class="s95">,</span></p></td></tr><tr style="height:19pt"><td style="width:82pt"><p class="s96" style="padding-left: 2pt;text-indent: 0pt;line-height: 14pt;text-align: left;">Male<span class="s281">2</span><span class="s95">=</span>True<span class="s95">,</span></p></td><td style="width:85pt"><p class="s96" style="padding-left: 6pt;text-indent: 0pt;line-height: 14pt;text-align: left;">Female<span class="s281">2</span><span class="s95">=</span>False<span class="s95">,</span></p></td><td style="width:97pt"><p class="s96" style="padding-left: 6pt;text-indent: 0pt;line-height: 14pt;text-align: left;">Daughter<span class="s281">1,2</span><span class="s95">=</span>True<span class="s95">&gt;</span></p></td></tr></table><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 6pt;text-indent: 21pt;line-height: 110%;text-align: justify;">其中每个属性名上的下标是为了区分这两个人。现在，如果搜集许多这样的目标概念 <span class="s21">Daughter</span><span class="s253">1,2</span>的训练样例，并将它们提供给一个命题规则学习器，如<span class="s6">CN</span>2 和<span class="s6">C</span>4.5，结果将为一 组非常特殊的规则如：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 27pt;text-indent: 0pt;text-align: left;"><span class="s6">IF </span>(<span class="s21">Father</span><span class="s253">1</span>=<span class="s21">Bob</span>)∧(<span class="s21">Name</span><span class="s253">2</span>=<span class="s21">Bob</span>)∧(<span class="s21">Female</span><span class="s253">1</span>=<span class="s21">True</span>)</p><p class="s21" style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;"><span class="s6">THEN </span>Daughter<span class="s253">1,2</span><span class="p">=</span>True</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 113%;text-align: justify;">虽然这个规则是正确的，但它过于特殊了，因此它对今后的分类几乎毫无用处。问题在 于，命题表示方法不能够描述属性值之间实质关系。与此不同，使用一阶表示的程序将学到 下面的一般规则：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 27pt;text-indent: 0pt;line-height: 190%;text-align: left;"><span class="s6">IF </span>Father<span class="p">(</span>y<span class="p">,</span>x<span class="p">) ∧</span>Female<span class="p">(</span>y<span class="p">) </span><span class="s6">THEN </span>Daughter<span class="p">(</span>x<span class="p">,</span>y<span class="p">) 其中 </span>x <span class="p">和 </span>y <span class="p">为变量，它们可指代任意人。</span></p><p style="padding-top: 2pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">一阶 <span class="s6">Horn </span>子句还可指定前件中的变量不出现在后件中的规则。例如对 <span class="s21">GrandDaughter</span></p><p style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">的规则为：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 27pt;text-indent: 0pt;text-align: left;"><span class="s6">IF </span>Father<span class="p">(</span>y<span class="p">,</span>z<span class="p">) ∧</span>Mother<span class="p">(</span>z<span class="p">,</span>y<span class="p">) ∧</span>Female<span class="p">(</span>y<span class="p">)</span></p><p class="s21" style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;"><span class="s6">THEN </span>GrandDaughter<span class="p">(</span>x<span class="p">,</span>y<span class="p">)</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 107%;text-align: justify;">注意该规则中的变量 <span class="s21">z</span>，它指代 <span class="s21">y </span>的父亲，在规则后件中没有出现。当一个变量只在前 件中出现时，假定它是被存在量化（<span class="s6">existentially quantified</span>）的，即只要存在该变量的一个 约束能满足对应的文字，那么规则前件就满足。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 109%;text-align: left;">还可能在规则的后件和前件中使用相同的谓词，描述递归的规则。如在本章开头的两个 规则提供了概念 <span class="s21">Ancestor</span>(<span class="s21">x</span>,<span class="s21">y</span>)的递归定义。以下将描述的 <span class="s6">ILP </span>学习方法已可以学习几种简 单的递归函数，包括如上面的 <span class="s21">Ancestor </span>函数以及其他一些函数，如对列表中元素进行排序； 从列表中移去一特定元素；拼接两个列表。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">10.4.2 <span class="s25">术语</span></h3><p style="padding-top: 10pt;padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">在继续介绍学习 <span class="s6">Horn </span>子句集的算法之前，先介绍一些形式逻辑中的基本术语。所有的 表达式由常量（如 <span class="s21">Bob</span>, <span class="s21">Louise</span>）、变量（如 <span class="s21">x</span>,<span class="s21">y</span>）、谓词符号（如 <span class="s21">Married</span>, <span class="s21">Greater</span>_<span class="s21">Than</span>） 以及函数符号（如 <span class="s21">age</span>）组成。谓词和函数的区别在于谓词只能取值真或假，而函数的取值 可为任意常量。这里使用小写符号表示函数，大写符号表示谓词。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 26pt;text-indent: 0pt;text-align: left;">对于这些符号，可如下构造表达式：项（<span class="s6">term</span>）是任意常量、任意变量、或应用到任意</p><p style="padding-left: 11pt;text-indent: 0pt;line-height: 107%;text-align: justify;">项上的任意函数（例如：<span class="s21">Bob</span>, <span class="s21">x</span>, <span class="s21">age</span>(<span class="s21">Bob</span>)等）。一个文字（<span class="s6">literal</span>）是应用到项上的任意谓 词或其否定。如 <span class="s21">Married </span>(<span class="s21">Bob</span>, <span class="s21">Louise</span>), <span class="s10"></span><span class="s21">Greater</span>_<span class="s21">Than</span>(<span class="s21">age</span>(<span class="s21">Sue</span>),20)等。如果一文字包含 一否定符号（<span class="s10"></span>），将其称为负文字（<span class="s6">negative literal</span>），否则为正文字（<span class="s6">positive literal</span>）。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 12pt;text-indent: 21pt;line-height: 107%;text-align: left;">一个子句（<span class="s6">clause</span>）是多个文字的任意析取，其中所有的变量假定为全称量化的。<span class="s6">Horn </span>子句（<span class="s6">Horn clause</span>）为包含至多一个正文字的子句，例如：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s38" style="padding-top: 2pt;padding-left: 31pt;text-indent: 0pt;text-align: center;"><span class="s30">H </span> <span class="s30">L</span><span class="s79">1 </span> <span class="s101">L</span><span class="s30">L</span><span class="s52">n</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s109" style="padding-top: 2pt;padding-left: 32pt;text-indent: 0pt;text-align: left;"><span class="p">其中 </span><span class="s21">H </span><span class="p">为文字，而 </span><span class="s38"></span><span class="s30">L</span><span class="s79">1</span><span class="s42"> </span><span class="s101">L</span><span class="s38"></span><span class="s30">L</span><span class="s52">n</span><span class="s41"> </span><span class="p">为负文字 。由于等 式 </span><span class="s108">(</span><span class="s107">B </span> <span class="s107">A</span><span class="s108">) </span> <span class="s108">(</span><span class="s107">B </span> <span class="s107">A</span><span class="s108">) </span><span class="p">和</span></p><p class="s109" style="padding-left: 13pt;text-indent: 0pt;text-align: left;"><span class="s108">( </span><span class="s107">A </span> <span class="s107">B</span><span class="s108">) </span> <span class="s108">(</span><span class="s107">A </span> <span class="s107">B</span><span class="s108">) </span><span class="p">，上面的 </span><span class="s6">Horn </span><span class="p">子句可被写为如下形式：</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="padding-top: 2pt;padding-left: 31pt;text-indent: 0pt;text-align: center;">H <span class="s38"> </span><span class="s33">(</span>L<span class="s79">1 </span><span class="s38"></span><span class="s101">L </span>L<span class="s52">n</span><span class="s41"> </span><span class="s33">)</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 33pt;text-indent: 0pt;text-align: left;">它与我们前面的规则等价，按照 <span class="s6">if</span>-<span class="s6">then </span>的写法如下：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="padding-top: 2pt;padding-left: 28pt;text-indent: 0pt;text-align: center;"><span class="s33">IF </span>L<span class="s79">1</span><span class="s42"> </span><span class="s38"></span><span class="s101">L</span><span class="s38"> </span>L<span class="s52">n</span><span class="s41"> </span><span class="s33">, THEN </span>H</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 2pt;padding-left: 32pt;text-indent: 0pt;text-align: left;">无法写法如何，<span class="s6">Horn </span>子句的前件 <span class="s30">L</span><span class="s79">1</span><span class="s42"> </span><span class="s38"></span><span class="s101">L </span><span class="s38"> </span><span class="s30">L</span><span class="s52">n</span></p><p style="padding-top: 2pt;padding-left: 3pt;text-indent: 0pt;text-align: left;">被称为子句体（<span class="s6">body</span>）或者子句先行词</p><p style="padding-top: 1pt;padding-left: 12pt;text-indent: 0pt;line-height: 107%;text-align: left;">（<span class="s6">antecedents</span>）。文字 <span class="s21">H </span>后件称为子句头（<span class="s6">head</span>）或子句推论（<span class="s6">consequent</span>）。为参考方便， 这些定义以及本章后将介绍的概念在表 10-3 中列出。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 31pt;text-indent: 0pt;text-align: center;">表 <span class="h4">10-3 </span>一阶逻辑中的基本定义</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 2pt;text-align: left;"><span><img width="570" height="2" alt="image" src="机器学习/Image_381.png"/></span></p><p class="s14" style="padding-top: 1pt;padding-left: 33pt;text-indent: -21pt;line-height: 12pt;text-align: left;"><span class="s55">n </span>每个合式公式由常量（<span class="s16">constant</span>，如 <span class="s56">Mary</span>、<span class="s16">23</span>、或 <span class="s56">Joe</span>）、变量（<span class="s16">variable</span>，如 <span class="s56">x</span>）、谓词（<span class="s16">predicate</span>， 如在 <span class="s56">Female</span><span class="s16">(</span><span class="s56">Mary</span><span class="s16">)</span>中的 <span class="s56">Female</span>）和函数（<span class="s16">function</span>，如 <span class="s56">age</span>，在 <span class="s56">age</span><span class="s16">(</span><span class="s56">Mary</span><span class="s16">)</span>）构成。</p><p class="s16" style="padding-top: 2pt;padding-left: 12pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span><span class="s14">项（</span>term<span class="s14">）为任意常量、任意变量、或任意应用到项集合上的函数。例如 </span><i>Mary</i>, <i>x</i>, <i>age</i>(<i>Mary</i>), <i>age</i>(<i>x</i>)<span class="s14">。</span></p><p class="s16" style="padding-top: 3pt;padding-left: 33pt;text-indent: -21pt;line-height: 12pt;text-align: left;"><span class="s55">n </span><span class="s14">文字（ </span>literal <span class="s14">）是应 用到 项集合 上的 任意谓 词或 其否定 。例 如 </span><i>Female</i>(<i>Mary</i>), <span class="s57"></span><i>Female</i>(<i>x</i>),</p><p class="s56" style="padding-left: 33pt;text-indent: 0pt;line-height: 12pt;text-align: left;">Greater<span class="s16">_</span>than<span class="s16">(</span>age<span class="s16">(</span>Mary<span class="s16">), 20)</span><span class="s14">。</span></p><p class="s16" style="padding-top: 3pt;padding-left: 12pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span><span class="s14">基本文字（</span>ground literal<span class="s14">）是不包含任何变量的文字（如</span><span class="s57"></span><i>Female</i>(<i>Joe</i>)<span class="s14">）。</span></p><p class="s16" style="padding-top: 3pt;padding-left: 12pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span><span class="s14">负文字（</span>negative literal<span class="s14">）是包含否定谓词的文字（如</span><span class="s57"></span><i>Female</i>(<i>Joe</i>)<span class="s14">）。</span></p><p class="s16" style="padding-top: 3pt;padding-left: 12pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span><span class="s14">正文字（</span>positive literal<span class="s14">）是不包含否定符号的文字（如 </span><i>Female</i>(<i>Joe</i>)<span class="s14">）。</span></p><p class="s14" style="padding-top: 3pt;padding-left: 11pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span>子句（<span class="s16">clause</span>）是多个文字的析取式，<span class="s56">M</span><span class="s64">1</span>∨<span class="s16">…</span><span class="s56">M</span><span class="s65">n</span>，其中的所有变量是全称量化的。</p><p class="s55" style="padding-top: 2pt;padding-left: 12pt;text-indent: 0pt;text-align: left;">n <span class="s16">Horn </span><span class="s14">子句是一个如下形式的表达式：</span></p><p class="s30" style="padding-top: 4pt;padding-left: 10pt;text-indent: 0pt;text-align: center;">H <span class="s38"> </span><span class="s33">(</span>L<span class="s79">1 </span><span class="s38"></span><span class="s101">L </span>L<span class="s52">n</span><span class="s41"> </span><span class="s33">)</span></p><p class="s14" style="padding-top: 3pt;padding-left: 33pt;text-indent: 0pt;line-height: 13pt;text-align: left;">其中 <span class="s56">H</span>, <span class="s56">L</span><span class="s155">1</span>⋯<span class="s56">L</span><span class="s65">n</span><span class="s67"> </span>为正文字。 <span class="s56">H </span>被称为 <span class="s16">Horn </span>子句的头 (<span class="s16">head</span>)或推论（ <span class="s16">consequent </span>）。文字合取式 </p><p class="s14" style="padding-left: 35pt;text-indent: 0pt;line-height: 17pt;text-align: left;"><span class="s30">L</span><span class="s79">1 </span><span class="s38"> </span><span class="s30">L</span><span class="s79">2 </span><span class="s38"></span><span class="s101">L</span><span class="s38"> </span><span class="s30">L</span><span class="s52">n</span><span class="s41"> </span>被称为<span class="s16">Horn</span>子句的体（<span class="s16">body</span>）或者先行词（<span class="s16">antecedents</span>）。</p><p class="s14" style="padding-top: 5pt;padding-left: 33pt;text-indent: -21pt;line-height: 12pt;text-align: left;"><span class="s55">n </span>对任意文字 <span class="s56">A </span>和 <span class="s56">B</span>，表达式<span class="s16">(</span><span class="s56">A</span>←<span class="s56">B</span><span class="s16">)</span>等价于<span class="s16">(</span><span class="s56">A</span>∨<span class="s57"></span><span class="s56">B</span><span class="s16">)</span>，而表达式<span class="s57"> </span><span class="s16">(</span><span class="s56">A</span>∧<span class="s56">B</span><span class="s16">)</span>等价于<span class="s16">(</span><span class="s57"></span><span class="s56">A</span>∨<span class="s57"></span><span class="s56">B</span><span class="s16">)</span>。因此，一个 <span class="s16">Horn </span>子句可被等效地写作下面的析取式：</p><p class="s38" style="padding-top: 4pt;padding-left: 10pt;text-indent: 0pt;text-align: center;"><span class="s30">H </span> <span class="s30">L</span><span class="s79">1 </span> <span class="s101">L</span> <span class="s30">L</span><span class="s52">n</span></p><p class="s16" style="padding-top: 4pt;padding-left: 12pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><span class="s55">n </span><span class="s14">置换（</span>substitution<span class="s14">）是一个将某些变量替换为某些项的函数。例如置换</span>{<i>x</i>/3, <i>y</i>/<i>z</i>}<span class="s14">把变量 </span><i>x </i><span class="s14">替换为项 </span>3</p><p class="s14" style="padding-left: 12pt;text-indent: 21pt;line-height: 12pt;text-align: left;">并且把变量 <span class="s56">y </span>替换为项 <span class="s56">z</span>。给定一个置换<span class="s177">θ</span>和一文字 <span class="s56">L</span>，我们使用 <span class="s56">L</span><span class="s177">θ</span>代表应用置换<span class="s177">θ</span>到 <span class="s56">L </span>得到的结果。</p><p class="s14" style="padding-top: 2pt;padding-left: 12pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span>两个文字<span class="s56">L</span><span class="s64">1</span>和<span class="s56">L</span><span class="s64">2</span>的合一置换（<span class="s16">unifying substitution</span>）为一个置换<span class="s177">θ</span>，使得<span class="s56">L</span><span class="s64">1</span><span class="s177">θ</span><span class="s16">=</span><span class="s56">L</span><span class="s64">2</span><span class="s177">θ</span>。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 2pt;text-align: left;"><span><img width="570" height="2" alt="image" src="机器学习/Image_382.png"/></span></p><h2 style="padding-left: 12pt;text-indent: 0pt;line-height: 19pt;text-align: left;">10.5 <span class="s17">学习一阶规则集：</span>FOIL</h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 12pt;text-indent: 21pt;line-height: 107%;text-align: justify;">有许多算法已被提出用于学习一阶规则或 <span class="s6">Horn </span>子句。本节中将介绍 <span class="s6">FOIL </span>程序（<span class="s6">Quinlan </span>1990），它使用的方法非常类似于前面介绍的序列覆盖和 <span class="s6">learn</span>-<span class="s6">one</span>-<span class="s6">rule </span>算法。实际上，<span class="s6">FOIL </span>是这些较早的算法在一阶表示上的自然扩展。形式化地讲，由 <span class="s6">FOIL </span>学习的假设为一阶规则 集，其中的规则类似于 <span class="s6">Horn </span>子句，但有两个不同：首先由 <span class="s6">FOIL </span>学习的规则比一般的 <span class="s6">Horn </span>子句更受限，因为文字不允许包含函数符号（这减小了假设空间搜索的复杂度）。其次，<span class="s6">FOIL </span>规则比 <span class="s6">Horn </span>子句更有表征力，因为规则体中的文字也可为负文字。<span class="s6">FOIL </span>已被应用于多种问 题领域。例如，它已用于学习快速排序算法 <span class="s6">Quicksort </span>的递归定义，以及学习从合法棋盘状 态中区分出非法状态。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 12pt;text-indent: 21pt;line-height: 109%;text-align: justify;"><span class="s6">FOIL </span>算法在表 10-4 中列出。注意外层循环对应于前面描述的序列覆盖算法。它每次学 习一个新规则，然后将此规则覆盖的正例移去，然后学习下一规则。算法的内层循环是前面 的 <span class="s6">learn</span>-<span class="s6">one</span>-<span class="s6">rule </span>的另一种形式，它已被扩展以适合处理一阶规则。还要注意 <span class="s6">FOIL </span>和前面 算法的一些微小的不同。确切地讲，<span class="s6">FOIL </span>只搜寻那些预测目标文字何时为 <span class="s21">True </span>的规则，而 前面的算法既搜寻预测何时为 <span class="s21">True </span>的规则，也搜寻预测何时为 <span class="s21">False </span>的规则。<span class="s6">FOIL </span>还应用 了一个简单的爬山搜索，而不是柱状搜索（即它执行的搜索等价于宽度为 1 的柱状搜索）。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 165pt;text-indent: 0pt;text-align: left;">表 <span class="h4">10-4 </span>基本的 <span class="h4">FOIL </span>算法。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s56" style="padding-left: 43pt;text-indent: 21pt;line-height: 125%;text-align: left;"><span class="s14">其中给出了生成候选文字 </span>Candidate<span class="s16">-</span>literal <span class="s14">的方法和 </span><span class="s16">FOIL </span><span class="s14">增益 </span>Foil<span class="s16">_</span>Gain <span class="s14">的定义。该基本算 法可稍做修改以更好地处理有噪声数据，如文中所描述的。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 2pt;text-align: left;"><span><img width="570" height="2" alt="image" src="机器学习/Image_383.png"/></span></p><p class="s16" style="padding-top: 1pt;padding-left: 11pt;text-indent: 0pt;text-align: left;">FOIL(<i>Target</i>_<i>predicate</i>, <i>Predicates</i>, <i>Examples</i>)</p><p class="s56" style="padding-top: 2pt;padding-left: 11pt;text-indent: 0pt;line-height: 126%;text-align: left;"><span class="s55">n </span>Pos<span class="s14">←</span>Examples <span class="s14">中 </span>Target<span class="s16">_</span>predicate <span class="s14">为 </span>True <span class="s14">的成员 </span><span class="s55">n </span>Neg<span class="s14">←</span>Examples <span class="s14">中 </span>Target<span class="s16">_</span>predicate <span class="s14">为 </span>False <span class="s14">的成员 </span><span class="s55">n </span>Learned<span class="s16">_</span>rules<span class="s14">←</span><span class="s16">{}</span></p><p class="s14" style="padding-left: 38pt;text-indent: -26pt;line-height: 126%;text-align: left;"><span class="s55">n </span>当 <span class="s56">Pos </span>不空，做以下操作 学习一个新规则 <span class="s56">NewRule</span></p><p class="s56" style="padding-left: 39pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span>NewRule<span class="s14">←没有前件的谓词 </span>Target<span class="s16">_</span>predicate <span class="s14">规则</span></p><p class="s56" style="padding-top: 3pt;padding-left: 39pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span>NewRuleNeg<span class="s14">←</span>Neg</p><p class="s14" style="padding-top: 3pt;padding-left: 66pt;text-indent: -27pt;line-height: 126%;text-align: left;"><span class="s55">n </span>当 <span class="s56">NewRuleNeg </span>不空，做以下操作 增加一个新文字以特化 <span class="s56">NewRule</span></p><p class="s56" style="padding-left: 63pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span>Candidate<span class="s16">_</span>literals<span class="s14">←对 </span>NewRule <span class="s14">生成候选新文字，基于 </span>Predicates</p><p class="s56" style="padding-top: 3pt;padding-left: 63pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span>Best<span class="s16">_</span>literal<span class="s14">←</span></p><p class="s241" style="padding-top: 7pt;padding-left: 6pt;text-indent: 0pt;text-align: center;">arg max</p><p class="s282" style="padding-left: 6pt;text-indent: 0pt;text-align: center;">L<span class="s283"></span>Candidate <span class="s284">_ </span>literals</p><p class="s240" style="padding-top: 7pt;text-indent: 0pt;text-align: left;">Foil <span class="s241">_ </span>Gain<span class="s241">(</span>L<span class="s241">, </span>NewRule<span class="s241">)</span></p><p class="s56" style="padding-top: 4pt;padding-left: 63pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span><span class="s14">把 </span>Best<span class="s16">_</span>literal <span class="s14">加入到 </span>NewRule <span class="s14">的前件</span></p><p class="s56" style="padding-top: 3pt;padding-left: 63pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span>NewRuleNeg<span class="s14">←</span>NewRuleNeg <span class="s14">中满足 </span>NewRule <span class="s14">前件的子集</span></p><p class="s56" style="padding-top: 3pt;padding-left: 39pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span>Learned<span class="s16">_</span>rules<span class="s14">←</span>Learned<span class="s16">_</span>rules<span class="s16">+</span>NewRule</p><p class="s56" style="padding-top: 3pt;padding-left: 39pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span>Pos<span class="s14">←</span>Pos<span class="s16">-{</span><span class="s14">被 </span>NewRule <span class="s14">覆盖的 </span>Pos <span class="s14">成员</span><span class="s16">}</span></p><p class="s56" style="padding-top: 3pt;padding-left: 12pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span><span class="s14">返回 </span>Learned<span class="s16">_</span>rules</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 2pt;text-align: left;"><span><img width="570" height="2" alt="image" src="机器学习/Image_384.png"/></span></p><p style="padding-top: 6pt;padding-left: 11pt;text-indent: 21pt;line-height: 109%;text-align: justify;">为理解由 <span class="s6">FOIL </span>执行的假设空间搜索，最好将其看作是层次化的。<span class="s6">FOIL </span>外层循环中每 次将加入一个新的规则到其析取式假设 <span class="s21">Learned</span>_<span class="s21">rules </span>中去。每个新规则的效果是通过加入 一个析取项泛化当前的析取假设（即增加其分类为正例的实例数）。在这一层次上看，这是 一个假设空间中的特殊到一般的搜索过程，它开始于最特殊的空析取式，在假设足够一般以</p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 111%;text-align: justify;">至覆盖所有正例时终止。<span class="s6">FOIL </span>的内层循环执行的是一较细粒度的搜索，以确定每个新规则 的确切定义。该内层循环在另一假设空间中搜索，它包含文字的合取，以找到一个合取式形 成新规则的前件。在这个假设空间中，它执行的是一般到特殊的爬山搜索，开始于最一般的 前件（空前件），然后增加文字以使规则特化直到其避开所有的反例。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: left;">在 <span class="s6">FOIL </span>和前面的序列覆盖和 <span class="s6">learn</span>-<span class="s6">one</span>-<span class="s6">rule </span>算法之间有两个最实质的不同，它来源于 此算法对一阶规则处理的需求。这些不同在于：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: left;">1．在学习每个新规则的一般到特殊搜索中，<span class="s6">FOIL </span>使用了不同的细节步骤来生成规则的 候选特化式。这一不同是为了处理规则前件中含有的变量。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 20pt;line-height: 107%;text-align: left;">2．<span class="s6">FOIL </span>使用的性能度量 <span class="s21">Foil</span>_<span class="s21">Gain </span>不同于表 10-2 中的熵度量。这是为了区分规则变 量的不同约束，以及由于 <span class="s6">FOIL </span>只搜寻覆盖正例的规则。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;text-align: justify;">下面两节将更详细地考虑这两个不同之处。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 6pt;text-indent: 0pt;text-align: justify;">10.5.1 FOIL <span class="s25">中的候选特化式生成</span></h3><p style="padding-top: 10pt;padding-left: 6pt;text-indent: 21pt;line-height: 107%;text-align: left;">为了生成当前规则的候选特化式，<span class="s6">FOIL </span>生成数个不同的新文字，每个可被单独地加到 规则前件中。更精确地讲，假定当前规则为：</p><p style="padding-left: 27pt;text-indent: 134pt;line-height: 28pt;text-align: left;"><span class="s21">P</span>(<span class="s21">x</span><span class="s253">1</span>, <span class="s21">x</span><span class="s253">2</span>, ⋯, <span class="s21">x</span><span class="s36">k</span>) ←<span class="s21">L</span><span class="s253">1</span>⋯<span class="s21">L</span><span class="s36">n </span>其中<span class="s21">L</span><span class="s253">1</span>⋯<span class="s21">L</span><span class="s36">n</span>为当前规则前件中的文字，而<span class="s21">P</span>(<span class="s21">x</span><span class="s253">1</span>, <span class="s21">x</span><span class="s253">2</span>, ⋯<span class="s21">x</span><span class="s36">k</span>)为规则头（或后件）。<span class="s6">FOIL</span>生</p><p style="padding-left: 5pt;text-indent: 0pt;text-align: justify;">成该规则的候选特化式的方法是考虑符合下列形式的新文字<span class="s21">L</span><span class="s36">n</span><span class="s253">+1</span>：</p><p class="s21" style="padding-top: 5pt;padding-left: 49pt;text-indent: -21pt;line-height: 14pt;text-align: left;"><span class="s10"> </span>Q<span class="s6">(</span>v<span class="s35">1</span><span class="s6">,…,</span>v<span class="s36">r</span><span class="s6">)</span><span class="p">，其中</span>Q<span class="p">为在</span>Predicates<span class="p">中出现的任意谓词名，并且</span>v<span class="s36">i</span><span class="p">既可为新变量， 也可为已在规则中有的变量。</span>v<span class="s36">i</span><span class="p">中至少一个必须是当前规则中已有的变量。</span></p><p class="s21" style="padding-left: 28pt;text-indent: 0pt;line-height: 13pt;text-align: left;"><span class="s10"> </span>Equal<span class="s6">(</span>x<span class="s36">j</span><span class="s6">, </span>x<span class="s36">k</span><span class="s6">)</span><span class="p">，其中</span>x<span class="s36">j</span><span class="p">和</span>x<span class="s36">k</span><span class="p">为规则中已有的变量。</span></p><p class="s10" style="padding-left: 28pt;text-indent: 0pt;line-height: 14pt;text-align: left;"> <span class="p">上述两种文字的否定。</span></p><p style="padding-top: 7pt;padding-left: 6pt;text-indent: 21pt;line-height: 107%;text-align: left;">为说明这一点，考虑待学习的规则是预测目标文字 <span class="s21">GrandDanghter</span>(<span class="s21">x</span>,<span class="s21">y</span>)，其中描述样 例的其他谓词包括 <span class="s21">Father </span>和 <span class="s21">Female</span>。<span class="s6">FOIL </span>中的一般到特殊搜索开始于最一般的规则：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 134pt;text-indent: 0pt;text-align: center;">GrandDaughter<span class="p">(</span>x<span class="p">, </span>y<span class="p">)←</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 107%;text-align: justify;">它断言对任意 <span class="s21">x </span>和 <span class="s21">y</span>，<span class="s21">GrandDaughter </span>都为真。为特化这一初始规则，上面的过程生成 下列文字作为将添加到规则前件中的候选文字： <span class="s21">Equal</span>(<span class="s21">x</span>,<span class="s21">y</span>), <span class="s21">Female</span>(<span class="s21">x</span>), <span class="s21">Female</span>(<span class="s21">y</span>), <span class="s21">Father</span>(<span class="s21">x</span>,<span class="s21">y</span>), <span class="s21">Father</span>(<span class="s21">y</span>,<span class="s21">x</span>), <span class="s21">Father</span>(<span class="s21">x</span>,<span class="s21">z</span>), <span class="s21">Father</span>(<span class="s21">z</span>,<span class="s21">x</span>), <span class="s21">Father</span>(<span class="s21">y</span>,<span class="s21">z</span>), <span class="s21">Father</span>(<span class="s21">z</span>,<span class="s21">y</span>)，以及这 些文字的否定（例如：<span class="s10"></span><span class="s21">Equal</span>(<span class="s21">x</span>,<span class="s21">y</span>)）。注意这里 <span class="s21">z </span>是一新变量，而 <span class="s21">x </span>和 <span class="s21">y </span>是当前规则中已有 的。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 107%;text-align: left;">现在假定在上述文字中 <span class="s6">FOIL </span>贪婪地选择了 <span class="s21">Father</span>(<span class="s21">y</span>, <span class="s21">z</span>)作为最有希望的文字，得到一 个较特殊的规则：</p><p style="padding-left: 27pt;text-indent: 113pt;line-height: 28pt;text-align: left;"><span class="s21">GrandDaughter </span>(<span class="s21">x</span>, <span class="s21">y</span>)←<span class="s21">Father</span>(<span class="s21">y</span>,<span class="s21">z</span>) 在生成为进一步特化该规则的候选文字时，<span class="s6">FOIL </span>现要考虑的文字除上一步所有文字之</p><p style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: justify;">外，还要加上文字，<span class="s21">Female</span>(<span class="s21">z</span>), <span class="s21">Equal</span>(<span class="s21">z</span>,<span class="s21">x</span>), <span class="s21">Equal</span>(<span class="s21">z</span>,<span class="s21">y</span>), <span class="s21">Father</span>(<span class="s21">z</span>,<span class="s21">w</span>), <span class="s21">Father</span>(<span class="s21">w</span>,<span class="s21">z</span>)，以</p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 107%;text-align: left;">及它们的否定。之所以加上这些文字是因为在前一步变量 <span class="s21">z </span>被加到规则中，所以 <span class="s6">FOIL </span>要考 虑增加另一个新变量 <span class="s21">w</span>。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 20pt;line-height: 107%;text-align: left;">如果 <span class="s6">FOIL </span>这时选择了 <span class="s21">Father </span>(<span class="s21">z</span>,<span class="s21">x</span>)，然后在下一循环选择了文字 <span class="s21">Female</span>(<span class="s21">y</span>)，将得到 下面的规则。它只覆盖正例，因此，终止了进一步搜索该规则的特化式的过程：</p><p style="padding-left: 27pt;text-indent: 50pt;line-height: 28pt;text-align: left;"><span class="s21">GrandDaughter</span>(<span class="s21">x</span>, <span class="s21">y</span>) ←<span class="s21">Father</span>(<span class="s21">y</span>, <span class="s21">z</span>)∧<span class="s21">Father</span>(<span class="s21">z</span>,<span class="s21">x</span>)∧<span class="s21">Female</span>(<span class="s21">y</span>) 这时，<span class="s6">FOIL </span>将会移去被该新规则覆盖的所有样例。如果还有未覆盖的正例，算法将开</p><p style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">始下一个一般到特殊搜索以获得新的规则。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">10.5.2 <span class="s25">引导 </span>FOIL <span class="s25">的搜索</span></h3><p style="padding-top: 10pt;padding-left: 5pt;text-indent: 21pt;line-height: 109%;text-align: left;">要在每一步中从候选文字中选择最有希望的文字，<span class="s6">FOIL </span>在训练数据上测量规则的性能。 在此过程中，它考虑当前规则中每个变量的可能的约束。为说明这一过程，再次考虑学习目 标文字 <span class="s21">GrandDaughter</span>(<span class="s21">x</span>,<span class="s21">y</span>)的规则集的例子。假定训练数据包含下列的简单的断言集合， 其中使用约定的 <span class="s21">P</span>(<span class="s21">x</span>,<span class="s21">y</span>)可被读作“<span class="s21">x </span>的 <span class="s21">P </span>是 <span class="s21">y</span>”。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 26pt;text-indent: 0pt;line-height: 107%;text-align: left;">GrandDaughter<span class="p">(</span>Victor<span class="p">, </span>Sharon<span class="p">) </span>Father<span class="p">(</span>Sharon<span class="p">, </span>Bob<span class="p">) </span>Father<span class="p">(</span>Tom<span class="p">, </span>Bob<span class="p">) </span>Female<span class="p">(</span>Sharon<span class="p">) </span>Father<span class="p">(</span>Bob<span class="p">, </span>Victor<span class="p">)</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: left;">对这个封闭的世界还要作一假定，即任何涉及到谓词 <span class="s21">GrandDaughter</span>, <span class="s21">Father</span>, <span class="s21">Female </span>及常量 <span class="s21">Victor</span>，<span class="s21">Sharon</span>，<span class="s21">Bob </span>和 <span class="s21">Tom </span>的文字，若它们没有在上面列出，则被假定为 <span class="s21">False</span>（如， 我们可以隐含地断言<span class="s10"></span><span class="s21">GrandDaughter</span>(<span class="s21">Tom</span>,<span class="s21">Bob</span>)，<span class="s10"></span><span class="s21">GrandDaughter</span>(<span class="s21">Victor</span>, <span class="s21">Victor</span>)等）。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: left;">为选择当前规则的最佳特化式，<span class="s6">FOIL </span>考虑规则变量约束到训练样例中各常量的每种不 同的方式。例如，在初始步规则为：</p><p class="s21" style="padding-left: 26pt;text-indent: 145pt;line-height: 28pt;text-align: left;">GrandDanghter<span class="p">(</span>x<span class="p">,</span>y<span class="p">)← 规则变量没有被任何前件约束，因此可以约束到四个常量 </span>Victor<span class="p">, </span>Sharon<span class="p">, </span>Bob <span class="p">和 </span>Tom</p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 0pt;line-height: 107%;text-align: left;">的任意组合。这里使用记号{<span class="s21">x</span>/<span class="s21">Bob</span>, <span class="s21">y</span>/<span class="s21">Sharon</span>}代表特定的变量约束，即将每个变量映射到 一常量的置换。4 个常量对此初始规则可产生 10 种可能的约束。而约束{<span class="s21">x</span>/<span class="s21">Victor</span>, <span class="s21">y</span>/<span class="s21">Sharon</span>} 对应的是正例约束，因为训练数据中包含断言 <span class="s21">GrandDaughter</span>(<span class="s21">Victor</span>, <span class="s21">Sharon</span>)。在此例中， 其他 15 种规则允许的约束（例如约束{<span class="s21">x</span>/<span class="s21">Bob</span>, <span class="s21">y</span>/<span class="s21">Tom</span>}）组成了规则的否定论据，因为训练 数据中没有它们相应的断言。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 110%;text-align: justify;">在每一阶段，规则的评估基于这些正例和反例变量约束，而我们倾向于选择的是拥有较 多正例约束而较少反例约束的规则。当新文字加入到规则中，约束的集合将改变。注意当一 文字加入后，它引入了一个新变量，那么规则的约束长度将增长。例如，若 <span class="s21">Father</span>(<span class="s21">y</span>,<span class="s21">z</span>)加 入到上述规则，那么初始的约束{<span class="s21">x</span>/<span class="s21">Victor</span>, <span class="s21">y</span>/<span class="s21">Sharon</span>}将变为更长的{<span class="s21">x</span>/<span class="s21">Victor</span>, <span class="s21">y</span>/<span class="s21">Sharon</span>, <span class="s21">z</span>/<span class="s21">Bob</span>}。还要注意如果新变量可约束到多个不同的常量，那么与扩展后规则相匹配的约束的 数目将大于与原始规则匹配的数目。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 107%;text-align: justify;"><span class="s6">FOIL </span>使用评估函数以估计增加新文字的效用，它基于加入新文字前后的正例和反例约 束数目。更精确地讲，考虑某规则 <span class="s21">R</span>，和一个可能被加到 <span class="s21">R </span>的规则体的候选文字 <span class="s21">L</span>。令 <span class="s21">R</span>´ 为加入文字 <span class="s21">L </span>到规则 <span class="s21">R </span>后生成的规则。<span class="s21">Foil</span>_<span class="s21">Gain</span>(<span class="s21">L</span>,<span class="s21">R</span>)的值定义为：</p><p class="s38" style="padding-top: 1pt;padding-left: 128pt;text-indent: 0pt;line-height: 10pt;text-align: left;">⎛ <span class="s30">p p </span>⎞</p><p class="s30" style="text-indent: 0pt;line-height: 22pt;text-align: left;"><span class="s160">p</span>  <span class="s38"></span>n  <span class="s116">⎟</span><span class="s33"> </span><span class="p">（10.1）</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s33" style="padding-left: 29pt;text-indent: 0pt;line-height: 15pt;text-align: left;"><i>Foil </i>_ <i>Gain</i>(<i>L</i>, <i>R</i>) <span class="s38"></span> <i>t</i><span class="s94">⎜</span><span class="s38">⎜</span> log<span class="s79">2</span></p><p class="s38" style="text-indent: 0pt;line-height: 11pt;text-align: right;">⎝</p><p class="s42" style="text-indent: 0pt;line-height: 7pt;text-align: left;">2</p><p style="text-indent: 0pt;text-align: left;"/><p class="s208" style="padding-left: 1pt;text-indent: 0pt;line-height: 11pt;text-align: left;">           1 <span class="s38"> </span><span class="s33">log</span></p><p class="s30" style="padding-left: 3pt;text-indent: 0pt;line-height: 14pt;text-align: left;">p<span class="s79">1 </span><span class="s38"> </span>n<span class="s79">1</span></p><p class="s208" style="padding-left: 1pt;text-indent: 0pt;line-height: 5pt;text-align: left;">          0       </p><p class="s38" style="padding-left: 36pt;text-indent: 0pt;line-height: 9pt;text-align: left;">⎟</p><p class="s42" style="padding-left: 10pt;text-indent: 0pt;line-height: 11pt;text-align: left;">0 0 <span class="s38">⎠</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">其中<span class="s21">p</span><span class="s253">0</span>为规则<span class="s21">R</span>的正例约束数目，<span class="s21">n</span><span class="s253">0</span>为<span class="s21">R</span>的反例约束数目，<span class="s21">p</span><span class="s253">1</span>是规则<span class="s21">R</span>´的正例约束数，<span class="s21">n</span><span class="s253">1</span>为 规则<span class="s21">R</span>´的反例约束数目。最后，<span class="s21">t</span>是在加入文字<span class="s21">L</span>到<span class="s21">R</span>后仍旧能覆盖的规则<span class="s21">R</span>的正例约束数。 当加入<span class="s21">L</span>引入了一个新变量到<span class="s21">R</span>中时，只要在<span class="s21">R</span>´的约束中的某些约束扩展了原始的约束，它 们仍然能被覆盖。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 10pt;padding-left: 26pt;text-indent: 0pt;text-align: left;">该 <span class="s21">Foil</span>_<span class="s21">Gain </span>函数可以用信息论来简单地解释。按照信息论的理论，<span class="s38"> </span><span class="s33">log </span><span class="s79">2</span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="51" height="1" alt="image" src="机器学习/Image_385.png"/></span></p><p class="s30" style="padding-top: 3pt;padding-left: 15pt;text-indent: 0pt;line-height: 19pt;text-align: left;">p<span class="s79">0</span><span class="s42"> </span><span class="s151">是</span></p><p class="s30" style="padding-left: 3pt;text-indent: 0pt;line-height: 14pt;text-align: left;">p<span class="s79">0 </span><span class="s38"> </span>n<span class="s79">0</span></p><p style="padding-top: 8pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">为了对规则 <span class="s21">R </span>能覆盖的任意正例约束编码所需的最小位数。相似的，<span class="s38"> </span><span class="s33">log </span><span class="s79">2</span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="47" height="1" alt="image" src="机器学习/Image_386.png"/></span></p><p class="s30" style="padding-top: 2pt;padding-left: 3pt;text-indent: 10pt;text-align: left;">p<span class="s79">1 </span>p<span class="s79">1 </span><span class="s38"> </span>n<span class="s79">1</span></p><p style="padding-top: 8pt;text-indent: 0pt;text-align: left;">是对规</p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 107%;text-align: justify;">则 <span class="s21">R</span>´能覆盖的任意正例约束编码的最小位数。由于 <span class="s21">t </span>是 <span class="s21">R </span>能覆盖的正例约束中仍保留在 <span class="s21">R</span>´ 中的约束，<span class="s21">Foil</span>_<span class="s21">Gain</span>(<span class="s21">L</span>,<span class="s21">R</span>)可被看作：为了编码 <span class="s21">R </span>的所有正例约束的分类所需的全部位数由 于 <span class="s21">L </span>带来的减少。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 6pt;text-indent: 0pt;text-align: justify;">10.5.3 <span class="s25">学习递归规则集</span></h3><p style="padding-top: 10pt;padding-left: 6pt;text-indent: 21pt;line-height: 111%;text-align: justify;">在上面的讨论中，我们忽略了加入到规则体中的子句为目标谓词本身（即在规则头中出 现的谓词）的可能性。然而，如果在 <span class="s21">Predicates </span>的输入列表中包含目标谓词，<span class="s6">FOIL </span>在生成 候选文字时必须考虑它。这允许它产生递归的规则——即在规则头和规则体中使用相同谓词 的规则。例如，回忆 <span class="s21">Ancestor </span>关系的递归定义。由下面的规则集表示：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 26pt;text-indent: 0pt;text-align: left;"><span class="s6">IF </span>Parent<span class="p">(</span>x<span class="p">,</span>y<span class="p">) </span><span class="s6">THEN </span>Ancestor<span class="p">(</span>x<span class="p">,</span>y<span class="p">)</span></p><p class="s21" style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;"><span class="s6">IF </span>Parent<span class="p">(</span>x<span class="p">,</span>z<span class="p">)∧</span>Ancestor<span class="p">(</span>z<span class="p">,</span>y<span class="p">) </span><span class="s6">THEN </span>Ancestor<span class="p">(</span>x<span class="p">,</span>y<span class="p">)</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 107%;text-align: left;">给定适当的训练样例集，这两个规则的学习可按照类似于上面 <span class="s21">GrandDaughter </span>的步骤。 注意只要 <span class="s21">Ancestor </span>包含在 <span class="s21">Predicates </span>列表中，后者决定了在生成新文字时要考虑的谓词，上 面第二个规则就包含在 <span class="s6">FOIL </span>的每次的搜索中。当然该特定规则是否能被学习到取决于这些 特定的子句在 <span class="s6">FOIL </span>的贪婪搜索渐进特殊的规则中能比其他候选评分更高。<span class="s6">Cameron</span>-<span class="s6">Jones </span>&amp; <span class="s6">Quinlan</span>（1993）讨论了几个例子，其中 <span class="s6">FOIL </span>能成功地发现递归的规则集。他们还讨论了可 能产生的重要问题，比如如何避免在学习规则集中产生无限递归。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><ol id="l27"><ol id="l28"><ol id="l29"><li style="padding-left: 48pt;text-indent: -42pt;text-align: justify;"><h3 style="display: inline;">FOIL <span class="s25">小结</span></h3><p style="padding-top: 10pt;padding-left: 5pt;text-indent: 21pt;line-height: 109%;text-align: left;">概括的说，<span class="s6">FOIL </span>扩展了 <span class="s6">CN</span>2 的序列覆盖算法，以处理类似于 <span class="s6">Horn </span>子句的一阶规则学 习问题。为学习这样的规则，<span class="s6">FOIL </span>执行一般到特殊搜索，每步增加一个新的文字到规则前 件中去。新的文字可为规则前件或后件中已有的变量，或者可是一新变量。在每一步，它使 用式 10.1 中的 <span class="s21">Foil</span>_<span class="s21">Grain </span>函数在候选新文字中进行选择。如果新文字可指向目标谓词，那 么原则上 <span class="s6">FOIL </span>可学习到递归规则集。虽然这产生了另一复杂性，即避免规则集的无限递归， 但 <span class="s6">FOIL </span>已在某些情况下成功地用于学习递归规则集。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 110%;text-align: justify;">在训练数据无噪声的情况下，<span class="s6">FOIL </span>可持续地增加新文字到规则中，直到它不覆盖任何 反例。为处理有噪声数据，搜索的终止需要在规则精度、覆盖度和复杂性之间作出折中。 <span class="s6">FOIL </span>使用最小描述长度的方法来使规则增长终止，新的文字只在它们的描述长度短于它们</p><p style="padding-left: 6pt;text-indent: 0pt;text-align: left;">所解释的数据的描述长度时才被加入。该策略的细节由 <span class="s6">Quinlan</span>（1990）给出。另外。<span class="s6">FOIL</span></p><p style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">对每个学到的规则进行后修剪，使用第 3 章决策树中相同的规则后修剪策略。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">10.6 <span class="s17">作为逆演绎的归纳</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 106%;text-align: justify;">归纳逻辑编程有另一种完全不同的途径，它基于一个简单的事实：即归纳是演绎的逆过 程。一般来说，机器学习涉及的是如何建立能解释观察数据的理论。给定某些数据<span class="s21">D</span>和一些 不完整的背景知识<span class="s21">B</span>，学习过程可被描述为生成一个假设<span class="s21">h</span>，它与<span class="s21">B</span>一起解释了<span class="s21">D</span>。更精确地 讲，假定如通常那样训练数据<span class="s21">D</span>为训练样例的集合，每个样例形式为〈<span class="s21">x</span><span class="s36">i</span>, <span class="s21">f</span>(<span class="s21">x</span><span class="s36">i</span>)〉。这里 <span class="s21">x</span><span class="s36">i</span>代 表第<span class="s21">i</span>个训练实例，而<span class="s21">f</span>(<span class="s21">x</span><span class="s36">i</span>)代表它的目标值。那么学习过程就是为了发现一个假设<span class="s21">h</span>，使每个 训练实例<span class="s21">x</span><span class="s36">i</span>的分类<span class="s21">f</span>(<span class="s21">x</span><span class="s36">i</span>)是从假设<span class="s21">h</span>、<span class="s21">x</span><span class="s36">i</span>的描述、及系统知道的任意背景知识<span class="s21">B</span>中演绎派生。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="padding-top: 2pt;padding-left: 27pt;text-indent: 1pt;text-align: left;"><span class="s33">(</span><span class="s38"></span>x<span class="s52">i </span><span class="s33">, </span>f <span class="s33">(</span>x<span class="s52">i </span><span class="s33">)</span><span class="s38"> </span><span class="s38"> </span>D<span class="s33">)(</span>B <span class="s38"> </span>h <span class="s38"> </span>x<span class="s52">i </span><span class="s33">) </span><span class="p">├ </span><span class="s21">f</span><span class="p">(</span><span class="s21">x</span><span class="s36">i</span><span class="p">) （10.2）</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;text-align: justify;">表达式<span class="s21">X</span>├<span class="s21">Y</span>读作“<span class="s21">Y</span>从<span class="s21">X</span>中演绎派生”，或者为“<span class="s21">X</span>涵蕴（<span class="s6">entail</span>）<span class="s21">Y</span>”。表达式 10.2 描述 了学习到的假设<span class="s21">h</span>必须满足的约束，即对每个训练实例<span class="s21">x</span><span class="s36">i</span>，目标分类<span class="s21">f</span>(<span class="s21">x</span><span class="s36">i</span>)必须从<span class="s21">B</span>、<span class="s21">h</span>和<span class="s21">x</span><span class="s36">i</span>中演 绎派生。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: left;">考虑一个例子，其中待学习的目标概念是“两个人&lt;<span class="s21">u</span>,<span class="s21">v</span>&gt;中 <span class="s21">u </span>的孩子是 <span class="s21">v</span>”，它表示了谓 词 <span class="s21">Child</span>(<span class="s21">u</span>,<span class="s21">v</span>)。假定给出了单个正例 <span class="s21">Child</span>(<span class="s21">Bob</span>, <span class="s21">Sharon</span>)，其中实例描述为文字 <span class="s21">Male </span>(<span class="s21">Bob</span>), <span class="s21">Female</span>(<span class="s21">Sharon</span>)和 <span class="s21">Father</span>(<span class="s21">Sharon</span>, <span class="s21">Bob</span>)。进一步假定有背景知识 <span class="s21">Parent</span>(<span class="s21">u</span>,<span class="s21">v</span>)←<span class="s21">Father</span>(<span class="s21">u</span>,<span class="s21">v</span>)。 可将此情形按式 10.2 描述如下：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 26pt;text-indent: 0pt;text-align: left;">x<span class="s36">i</span><span class="p">: </span>Male<span class="p">(</span>Bob<span class="p">), </span>Female<span class="p">(</span>Sharon<span class="p">), </span>Father<span class="p">(</span>Sharon<span class="p">, </span>Bob<span class="p">) </span>f<span class="p">(</span>x<span class="s36">i</span><span class="p">): </span>Child<span class="p">(</span>Bob<span class="p">, </span>Sharon<span class="p">)</span></p><p style="padding-left: 26pt;text-indent: 0pt;line-height: 186%;text-align: left;"><span class="s21">B</span>: <span class="s21">Parent</span>(<span class="s21">u</span>,<span class="s21">v</span>)←<span class="s21">Father</span>(<span class="s21">u</span>,<span class="s21">v</span>) 在此情况下，许多假设中满足约束 <span class="s33">(</span><span class="s30">B </span><span class="s38"> </span><span class="s30">h </span><span class="s38"> </span><span class="s30">x</span><span class="s52">i</span><span class="s41"> </span><span class="s33">) </span>├ <span class="s21">f</span>(<span class="s21">x</span><span class="s36">i</span>) 的两个假设为：</p><p class="s21" style="padding-left: 26pt;text-indent: 0pt;line-height: 14pt;text-align: left;">h<span class="s253">1</span><span class="p">: </span>Child<span class="p">(</span>u<span class="p">,</span>v<span class="p">) ←</span>Father<span class="p">(</span>v<span class="p">,</span>u<span class="p">)</span></p><p class="s21" style="padding-top: 1pt;padding-left: 26pt;text-indent: 0pt;text-align: left;">h<span class="s253">2</span><span class="p">: </span>Child<span class="p">(</span>u<span class="p">,</span>v<span class="p">) ←</span>Parent<span class="p">(</span>v<span class="p">,</span>u<span class="p">)</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 20pt;text-align: left;">注意目标文字<span class="s21">Child</span>(<span class="s21">Bob</span>, <span class="s21">Sharon</span>)是由<span class="s21">h</span>∧<span class="s21">x</span><span class="s36">i</span><span class="s41"> </span>涵蕴，不需要背景知识<span class="s21">B</span>。然而对于假设<span class="s21">h</span><span class="s253">2</span>， 情况有些不同。目标<span class="s21">Child </span>(<span class="s21">Bob</span>, <span class="s21">Sharon</span>)是从<span class="s21">B</span>∧<span class="s21">h</span><span class="s253">2</span>∧<span class="s21">x</span><span class="s36">i</span>中派生，而不是单独的<span class="s21">h</span><span class="s253">2</span>∧<span class="s21">x</span><span class="s36">i</span>中派生。 该例说明了背景知识的作用，即针对给定的训练数据扩展可接受的假设集合。它还说明新的 谓词（如<span class="s21">Parent</span>）怎样引入到假设（如<span class="s21">h</span><span class="s253">2</span>）中，即使此谓词不在原来的实例<span class="s21">x</span><span class="s36">i</span>描述中。这一 基于背景知识扩展谓词集合的过程，通常称为建设性归纳(<span class="s6">constructive induction</span>)。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 113%;text-align: justify;">式 10.2 的意义在于它把学习问题置于演绎推理和形式逻辑的框架之下。对于命题逻辑 和一阶逻辑，有一些已理解得很好的算法可自动演绎。有趣的是，有可能利用演绎推理的逆 过程，以使归纳泛化的过程自动化。对“归纳可由反转的演绎实现”这一观点的洞悉首先出 现于 19 世纪的经济学家 <span class="s6">W</span>.<span class="s6">S</span>.<span class="s6">Jevons</span>，他写到：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-left: 27pt;text-indent: 21pt;line-height: 132%;text-align: justify;">归纳实际上是演绎的逆操作，而且不能想象没有其中一个时，另一个会存在。因此不会有哪一 个更重要的问题。谁会问加法和减法中哪一个是比较重要的数学操作呢？但同时，在一操作和它的逆 操作之间，其难度有很大的差异；⋯⋯必须承认，归纳分析在难度和复杂度方面都远远大于任何演绎</p><p class="s14" style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">问题。（<span class="s16">Jevons 1874</span>）</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 110%;text-align: justify;">本章的剩余部分将探究这种把归纳看成逆演绎的观点。我们在这里所感兴趣的是一般问 题是设计一个逆涵蕴算子(<span class="s6">inverse entailment operator</span>)。一个逆涵蕴算子<span class="s21">O</span>(<span class="s21">B</span>, <span class="s21">D</span>)使用训练 数据<span class="s21">D</span>={&lt;<span class="s21">x</span><span class="s36">i</span>, <span class="s21">f</span>(<span class="s21">x</span><span class="s36">i</span>)&gt;}和背景知识<span class="s21">B</span>作为输入，并且输出一假设<span class="s21">h</span>满足式 10.2。</p><p class="s30" style="padding-top: 10pt;padding-left: 27pt;text-indent: 68pt;text-align: left;"><span class="s21">O</span><span class="p">(</span><span class="s21">B</span><span class="p">, </span><span class="s21">D</span><span class="p">)=</span><span class="s21">h</span><span class="p">其中 </span><span class="s33">(</span><span class="s38"></span>x<span class="s52">i</span><span class="s41"> </span><span class="s33">, </span>f <span class="s33">(</span>x<span class="s52">i</span><span class="s41"> </span><span class="s33">)</span><span class="s38"> </span><span class="s38"> </span>D<span class="s33">)(</span>B <span class="s38"> </span>h <span class="s38"> </span>x<span class="s52">i</span><span class="s41"> </span><span class="s33">) </span><span class="p">├ </span><span class="s21">f</span><span class="p">(</span><span class="s21">x</span><span class="s36">i</span><span class="p">)</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="padding-left: 6pt;text-indent: 21pt;line-height: 111%;text-align: justify;"><span class="p">当然会有很多不同的假设</span><span class="s21">h</span><span class="p">满足 </span><span class="s33">(</span><span class="s38"></span>x<span class="s52">i</span><span class="s41"> </span><span class="s33">, </span>f <span class="s33">(</span>x<span class="s52">i</span><span class="s41"> </span><span class="s33">)</span><span class="s38"> </span><span class="s38"> </span>D<span class="s33">)(</span>B <span class="s38"> </span>h <span class="s38"> </span>x<span class="s52">i</span><span class="s41"> </span><span class="s33">) </span><span class="p">├ </span><span class="s21">f</span><span class="p">(</span><span class="s21">x</span><span class="s36">i</span><span class="p">)。在</span><span class="s6">ILP</span><span class="p">中选择 假设的常用启发式规则为依赖于最小描述长度准则（见 6.6 节）。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="padding-left: 5pt;text-indent: 21pt;line-height: 111%;text-align: justify;"><span class="p">将学习任务形式化为寻找一个假设</span><span class="s21">h</span><span class="p">使其满足 </span><span class="s33">(</span><span class="s38"></span>x<span class="s52">i</span><span class="s41"> </span><span class="s33">, </span>f <span class="s33">(</span>x<span class="s52">i</span><span class="s41"> </span><span class="s33">)</span><span class="s38"> </span><span class="s38"> </span>D<span class="s33">)(</span>B <span class="s38"> </span>h <span class="s38"> </span>x<span class="s52">i</span><span class="s41"> </span><span class="s33">) </span><span class="p">├ </span><span class="s21">f</span><span class="p">(</span><span class="s21">x</span><span class="s36">i</span><span class="p">)， 有许多有吸引力的特点：</span></p><p style="padding-top: 6pt;padding-left: 49pt;text-indent: -21pt;line-height: 14pt;text-align: left;"><span class="s10"> </span>这种公式包含了一种普遍的学习定义方法，即寻找某个一般概念，它与给定的 训练样例相拟合。其中训练样例对应没有背景知识 <span class="s21">B </span>时的特殊情况。</p><p style="padding-left: 49pt;text-indent: -21pt;line-height: 13pt;text-align: left;"><span class="s10"> </span>此公式通过引入背景知识<span class="s21">B</span>，可以对何时一个假设可被称作“拟合”训练数据进</p><p class="s21" style="padding-left: 49pt;text-indent: 0pt;text-align: justify;"><span class="p">行更充分的定义。至此为止，我们一直都仅仅基于假设和数据的描述来确定一 假设（如神经网络）是否拟合数据，而不依赖于待学习的任务领域。相反，这 种形式允许领域特定的背景信息</span>B<span class="p">成为“拟合”定义的一部分。确切地讲，</span>h<span class="p">只 在</span>f<span class="s6">(</span>x<span class="s36">i</span><span class="s6">)</span><span class="p">从</span>B<span class="p">∧</span>h<span class="p">∧</span>x<span class="s36">i</span><span class="p">中演绎派生时，拟合训练样例</span><span class="s6">&lt;</span>x<span class="s36">i</span><span class="s6">,</span>f<span class="s6">(</span>x<span class="s36">i</span><span class="s6">)&gt;</span><span class="p">。</span></p><p style="padding-left: 49pt;text-indent: -21pt;line-height: 13pt;text-align: left;"><span class="s10"> </span>通过引入背景知识 <span class="s21">B</span>，该公式要求学习算法使用这一背景信息来引导 <span class="s21">h </span>的搜索，</p><p style="padding-left: 49pt;text-indent: 0pt;line-height: 14pt;text-align: justify;">而不是只搜索语法合法的假设空间。下面章节中描述的逆归结过程就以这种形 式使用了背景知识。</p><p style="padding-top: 6pt;padding-left: 26pt;text-indent: 0pt;text-align: left;">同时，按照这种公式的归纳逻辑编程遇到了几种实践上的困难。</p><p class="s30" style="padding-top: 8pt;padding-left: 49pt;text-indent: -21pt;line-height: 94%;text-align: left;"><span class="s10"> </span><span class="p">对 </span><span class="s33">(</span><span class="s38"></span>x<span class="s52">i</span><span class="s41"> </span><span class="s33">, </span>f <span class="s33">(</span>x<span class="s52">i</span><span class="s41"> </span><span class="s33">)</span><span class="s38"> </span><span class="s38"> </span>D<span class="s33">)(</span>B <span class="s38"> </span>h <span class="s38"> </span>x<span class="s52">i</span><span class="s41"> </span><span class="s33">) </span><span class="p">├ </span><span class="s21">f</span><span class="p">(</span><span class="s21">x</span><span class="s36">i</span><span class="p">)的要求实质上不能处理有噪声数据。 问题在于，该表达式不允许在观察到实例</span><span class="s21">x</span><span class="s36">i</span><span class="p">和其目标值</span><span class="s21">f</span><span class="s6">(</span><span class="s21">x</span><span class="s36">i</span><span class="s6">)</span><span class="p">中出现差错的可能性。 这样的差错可能产生对</span><span class="s21">h</span><span class="p">的不一致约束。不幸的是，多数形式逻辑框架完全没有 能力在给定不一致断言时区分出真和假来。</span></p><p class="s30" style="padding-top: 1pt;padding-left: 49pt;text-indent: -21pt;text-align: left;"><span class="s10"> </span><span class="p">一阶逻辑语言的表征力太强，而且满足 </span><span class="s33">(</span><span class="s38"></span>x<span class="s52">i</span><span class="s41"> </span><span class="s33">, </span>f <span class="s33">(</span>x<span class="s52">i</span><span class="s41"> </span><span class="s33">)</span><span class="s38"> </span><span class="s38"> </span>D<span class="s33">)(</span>B <span class="s38"> </span>h <span class="s38"> </span>x<span class="s52">i</span><span class="s41"> </span><span class="s33">) </span><span class="p">├ </span><span class="s21">f</span><span class="p">(</span><span class="s21">x</span><span class="s36">i</span><span class="p">) 的假设数量太多，以至于假设空间的搜索在一般情形下是难以执行的。许多近 期的工作已寻求受限形式的一阶表达式或其他二阶知识，以改进假设空间搜索 的易处理性。</span></p><p style="padding-left: 49pt;text-indent: -21pt;text-align: left;"><span class="s10"> </span>尽管直觉上背景知识可有助于限制假设的搜索，在多数 <span class="s6">ILP </span>系统中（包括所有 本章讨论的），假设空间搜索的复杂度会随着背景知识的增加而增高。（然而， 可见第 <span class="s6">11 </span>和 <span class="s6">12 </span>章中一些算法使用背景知识来减小而不是增加样本复杂度。）</p><p style="padding-top: 7pt;padding-left: 5pt;text-indent: 21pt;line-height: 113%;text-align: justify;">在下一节，我们考查了一个很普遍的逆涵蕴算子，它通过反转的演绎推理规则来构造假 设。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">10.7 <span class="s17">逆归结</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 109%;text-align: justify;">自动演绎的一般方法是用 <span class="s6">Robinson</span>（1965）提出的归结规则（<span class="s6">resolution rule</span>）。归结规 则是一阶逻辑中一个合理且完备的演绎推理规则。因此，可以想到这样的问题：是否可以通 过反转归结规则来形成逆涵蕴算子。回答是肯定的，而且正是这个算子形成了 <span class="s6">Cigol </span>程序的 基础。（<span class="s6">Muggleton </span>&amp; <span class="s6">Buntine </span>1988）。</p><p style="padding-left: 33pt;text-indent: 0pt;text-align: left;">介绍归结规则最容易的方法是以命题表示的形式，它可以被扩展到一阶表示中。令 <span class="s21">L</span></p><p style="padding-top: 1pt;padding-left: 12pt;text-indent: 0pt;text-align: left;">为任意一个命题文字，并令 <span class="s21">P </span>和 <span class="s21">R </span>为任意命题子句。归结规则为：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><table style="border-collapse:collapse;margin-left:147pt" cellspacing="0"><tr style="height:20pt"><td style="width:43pt"><p class="s96" style="padding-top: 2pt;padding-left: 1pt;text-indent: 0pt;text-align: center;">P</p></td><td style="width:43pt"><p class="s95" style="padding-left: 14pt;text-indent: 0pt;line-height: 14pt;text-align: left;">∨</p></td><td style="width:49pt"><p class="s96" style="padding-top: 2pt;padding-right: 5pt;text-indent: 0pt;text-align: center;">L</p></td></tr><tr style="height:23pt"><td style="width:43pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s221" style="padding-top: 3pt;padding-left: 15pt;text-indent: 0pt;text-align: left;"><span class="s96">L</span></p></td><td style="width:43pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s95" style="padding-top: 1pt;padding-left: 14pt;text-indent: 0pt;text-align: left;">∨</p></td><td style="width:49pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s96" style="padding-top: 4pt;padding-right: 5pt;text-indent: 0pt;text-align: center;">R</p></td></tr><tr style="height:19pt"><td style="width:43pt;border-top-style:solid;border-top-width:1pt"><p class="s96" style="padding-top: 3pt;padding-left: 1pt;text-indent: 0pt;text-align: center;">P</p></td><td style="width:43pt;border-top-style:solid;border-top-width:1pt"><p class="s95" style="padding-left: 14pt;text-indent: 0pt;text-align: left;">∨</p></td><td style="width:49pt;border-top-style:solid;border-top-width:1pt"><p class="s96" style="padding-top: 3pt;padding-right: 5pt;text-indent: 0pt;text-align: center;">R</p></td></tr></table><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 12pt;text-indent: 21pt;line-height: 110%;text-align: left;">它可理解为：给定线上的两个子句，得到线下的子句。直觉上归结规则是理所当然的。 给定两个断言 <span class="s21">P</span>∨<span class="s21">L </span>和<span class="s10"></span><span class="s21">L</span>∨<span class="s21">R</span>，显然 <span class="s21">L </span>或<span class="s10"></span><span class="s21">L </span>中必有一个为假。因此，<span class="s21">P </span>或 <span class="s21">R </span>中必有一个为 真。因此结论 <span class="s21">P</span>∨<span class="s21">R </span>肯定是满足的。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 11pt;text-indent: 21pt;line-height: 107%;text-align: justify;">命题归结算子的一般形式在表 10-5 中描述。给定两个子句<span class="s21">C</span><span class="s253">1</span>和<span class="s21">C</span><span class="s253">2</span>，归结算子首先确定 文字<span class="s21">L</span>是否以正文字形式出现在一个子句中，并以负文字形式出现在另一子句中。然后得到 如上公式中的结论。例如，图 10-2 左侧的归结算子。给定子句<span class="s21">C</span><span class="s253">1</span>和<span class="s21">C</span><span class="s253">2</span>，第一步确定文字 <span class="s21">L</span>=<span class="s10"></span><span class="s21">KnowMaterial</span>，它在<span class="s21">C</span><span class="s253">1</span>中出现，而它的负文字<span class="s10"></span>(<span class="s10"></span><span class="s21">KnowMaterial</span>)= <span class="s21">KnowMaterial</span>在<span class="s21">C</span><span class="s253">2</span>中 出现。所以结论是一子句，其形式为文字<span class="s21">C</span><span class="s253">1</span>-{<span class="s21">L</span>}=<span class="s21">PassExam</span>和<span class="s21">C</span><span class="s253">2</span>-{<span class="s10"></span><span class="s21">L</span>}=<span class="s10"></span><span class="s21">Study</span>的联合。举另 一个例子，应用归结规则到子句<span class="s21">C</span><span class="s253">1</span>=<span class="s21">A</span>∨<span class="s21">B</span>∨<span class="s21">C</span>∨<span class="s10"></span><span class="s21">D</span>和<span class="s21">C</span><span class="s253">2</span>=<span class="s10"></span><span class="s21">B</span>∨<span class="s21">E</span>∨<span class="s21">F</span>得到结果为子句<span class="s21">A</span>∨<span class="s21">C</span>∨</p><p class="s21" style="padding-left: 12pt;text-indent: 0pt;text-align: left;"><span class="s10"></span>D<span class="p">∨</span>E<span class="p">∨</span>F<span class="p">。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 157pt;text-indent: 0pt;text-align: left;">表 <span class="h4">10-5 </span>归结算子（命题形式）。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-left: 64pt;text-indent: 0pt;text-align: left;">给定子句<span class="s56">C</span><span class="s64">1</span>和<span class="s56">C</span><span class="s64">2</span>。归结算子构造出一子句<span class="s56">C</span>使<span class="s56">C</span><span class="s64">1</span>∧<span class="s56">C</span><span class="s64">2</span>├<span class="s56">C</span>。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 2pt;text-align: left;"><span><img width="570" height="2" alt="image" src="机器学习/Image_387.png"/></span></p><p class="s14" style="padding-left: 12pt;text-indent: 0pt;text-align: left;"><span class="s16">1. </span>给定初始子句<span class="s56">C</span><span class="s64">1</span>和<span class="s56">C</span><span class="s64">2</span>，从子句<span class="s56">C</span><span class="s64">1</span>中寻找一个文字<span class="s56">L</span>，并且<span class="s57"></span><span class="s56">L</span>出现在<span class="s56">C</span><span class="s64">2</span>中。</p><p class="s14" style="padding-top: 3pt;padding-left: 33pt;text-indent: -21pt;line-height: 12pt;text-align: left;"><span class="s16">2. </span>通过合并<span class="s56">C</span><span class="s64">1</span>和<span class="s56">C</span><span class="s64">2</span>中的除了<span class="s56">L</span>和<span class="s57"></span><span class="s56">L</span>外的所有文字，形成归结式<span class="s56">C</span>。更精确地，出现在结果<span class="s56">C</span>中的文字集合 为：</p><p class="s33" style="padding-top: 4pt;padding-left: 10pt;text-indent: 0pt;text-align: center;"><i>C </i><span class="s38"> </span>(<i>C</i><span class="s79">1 </span><span class="s38"></span>{<i>L</i>}) <span class="s38"> </span>(<i>C</i><span class="s79">2</span><span class="s42"> </span><span class="s38"></span>{<span class="s38"></span><i>L</i>})</p><p class="s14" style="padding-top: 2pt;padding-left: 21pt;text-indent: 12pt;text-align: left;">其中∪表示集合并，“－”表示集合差。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 2pt;text-align: left;"><span><img width="570" height="2" alt="image" src="机器学习/Image_388.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 19pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="547" height="1" alt="image" src="机器学习/Image_389.png"/></span></p><p class="s48" style="padding-left: 21pt;text-indent: 0pt;text-align: left;">插图——原书页码： <span class="s21">295</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 20pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="531" height="1" alt="image" src="机器学习/Image_390.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 64pt;text-indent: 100pt;text-align: left;">图 <span class="h4">10-2 </span>归结和逆归结的例子</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-left: 43pt;text-indent: 21pt;line-height: 117%;text-align: left;">左边为应用归结规则（演绎的）从给定子句<span class="s56">C</span><span class="s64">1</span>和<span class="s56">C</span><span class="s64">2</span>中推理出子句<span class="s56">C</span>。右边为其逆过程的应用（归 纳的），从<span class="s56">C</span>和<span class="s56">C</span><span class="s64">1</span>中推论出<span class="s56">C</span><span class="s64">2</span>。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 11pt;text-indent: 21pt;line-height: 107%;text-align: justify;">很容易用归结算子的逆转来形成一执行归纳推理的逆涵蕴算子<span class="s21">O</span>(<span class="s21">C</span>, <span class="s21">C</span><span class="s253">1</span>)。一般来说， 逆涵蕴算子必须在给定归结式<span class="s21">C</span>和一初始子句<span class="s21">C</span><span class="s253">1</span>时推导出另一初始子句<span class="s21">C</span><span class="s253">2</span>。考虑一个例子， 给定归结式<span class="s21">C</span>=<span class="s21">A</span>∨<span class="s21">B</span>且初始子句<span class="s21">C</span><span class="s253">1</span>=<span class="s21">B</span>∨<span class="s21">D</span>。如何推导出子句<span class="s21">C</span><span class="s253">2</span>以使<span class="s21">C</span><span class="s253">1</span>∧<span class="s21">C</span><span class="s253">2</span>├<span class="s21">C</span>？首先，注意由 归结算子的定义，任意出现在<span class="s21">C</span>中但不在<span class="s21">C</span><span class="s253">1</span>中的文字必须已在<span class="s21">C</span><span class="s253">2</span>中出现。在这个例子中，它 表示<span class="s21">C</span><span class="s253">2</span>必须包含文字<span class="s21">A</span>。其次，在<span class="s21">C</span><span class="s253">1</span>中出现但不在<span class="s21">C</span>中的文字必为归结规则移去了的文字，</p><p style="padding-left: 12pt;text-indent: 0pt;line-height: 107%;text-align: left;">因此它的负文字必须在<span class="s21">C</span>2 中。在此例中，它表示<span class="s21">C</span><span class="s253">2</span>必须包含文字<span class="s10"></span><span class="s21">D</span>。因此<span class="s21">C</span><span class="s253">2</span>=<span class="s21">A</span>∨<span class="s10"></span><span class="s21">D</span>。读 者可以很容易地验证，应用归结规则到<span class="s21">C</span><span class="s253">1</span>和<span class="s21">C</span><span class="s253">2</span>确实产生了所希望的归结式<span class="s21">C</span>。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 11pt;text-indent: 21pt;line-height: 107%;text-align: justify;">注意在上例中<span class="s21">C</span><span class="s253">2</span>有另一种可能的解。确切地讲，<span class="s21">C</span><span class="s253">2</span>可以是更特殊的子句<span class="s21">A</span>∨<span class="s10"></span><span class="s21">D</span>∨<span class="s21">B</span>。此 解与第一个解的不同在于<span class="s21">C</span><span class="s253">2</span>中包含了一个<span class="s21">C</span><span class="s253">1</span>中出现的文字。从中可得到的一般论点在于，逆 归结是不确定的，即可能有多个子句<span class="s21">C</span><span class="s253">2</span>使<span class="s21">C</span><span class="s253">1</span>和<span class="s21">C</span><span class="s253">2</span>产生归结式<span class="s21">C</span>。在其中进行选择的一个启发 式方法为偏好更短的子句，或等价地，假定<span class="s21">C</span><span class="s253">2</span>与<span class="s21">C</span><span class="s253">1</span>没有共同的文字。如果引入这种对短子句 的偏好，对逆归结过程的一般描述见表 10-6。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 152pt;text-indent: 0pt;text-align: left;">表 <span class="h4">10-6 </span>逆归结算子（命题形式）。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-left: 64pt;text-indent: 0pt;text-align: left;">给定两子句<span class="s56">C</span>和<span class="s56">C</span><span class="s64">1</span>，它计算出<span class="s56">C</span><span class="s64">2</span>使<span class="s56">C</span><span class="s155">1</span>∧<span class="s56">C</span><span class="s155">2</span>├<span class="s56">C</span>。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 2pt;text-align: left;"><span><img width="570" height="2" alt="image" src="机器学习/Image_391.png"/></span></p><p class="s14" style="padding-left: 12pt;text-indent: 0pt;text-align: left;"><span class="s16">1. </span>给定初始子句<span class="s56">C</span><span class="s64">1</span>和<span class="s56">C</span>，寻找一个文字<span class="s56">L</span>，它出现在子句<span class="s56">C</span><span class="s64">1</span>中但不出现在<span class="s56">C</span>中。</p><p class="s14" style="padding-top: 2pt;padding-left: 11pt;text-indent: 0pt;text-align: left;"><span class="s16">2. </span>通过包含下列的文字，形成第二个子句<span class="s56">C</span><span class="s64">2</span>：</p><p class="s33" style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: center;"><i>C</i><span class="s79">2 </span><span class="s38"> </span>(<i>C </i><span class="s38"> </span>(<i>C</i><span class="s79">1 </span><span class="s38"></span>{<i>L</i>})) <span class="s38"></span>{<span class="s38"></span><i>L</i>}</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 2pt;text-align: left;"><span><img width="570" height="2" alt="image" src="机器学习/Image_392.png"/></span></p><p style="padding-top: 6pt;padding-left: 11pt;text-indent: 21pt;line-height: 109%;text-align: justify;">我们可以基于如逆归结这样的逆涵蕴算子开发出规则学习算法来。确切地讲，学习算法 可使用逆涵蕴来构造出假设，此假设与背景知识一起涵蕴训练数据。一种策略是使用序列覆 盖算法，循环地以这种方法学习<span class="s6">Horn</span>子句集。在每次循环中，算法选择没有被以前学习到 的子句覆盖的一个训练样例&lt;<span class="s21">x</span><span class="s36">i</span>,<span class="s21">f</span>(<span class="s21">x</span><span class="s36">i</span>)&gt;。然后应用归结规则来生成满足 <span class="s33">(</span><span class="s30">B </span><span class="s38"> </span><span class="s30">h </span><span class="s38"> </span><span class="s30">x</span><span class="s52">i</span><span class="s41"> </span><span class="s33">) </span>├ <span class="s21">f</span>(<span class="s21">x</span><span class="s36">i</span>) 的候选假设<span class="s21">h</span><span class="s36">i</span>，其中<span class="s21">B</span>为背景知识加上以前循环中学到的任意子句。注意这是一个样例驱动 的搜索，因为每个候选假设的建立是为了覆盖一特定样例。当然如果存在多个候选假设，那 么在其中选择的策略是选取在其他样例上也有最高精度的假设。<span class="s6">Cigol</span>程序使用了结合这种 序列覆盖算法的逆归结，以此与用户进行交互以获得训练样例并引导其在可能的归纳推理步 的巨大空间中的搜索。然而<span class="s6">Cigol</span>使用了一阶表示而不是命题表示。下面我们描述为处理一 阶表示所需对归纳规则的扩展。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 12pt;text-indent: 0pt;text-align: left;">10.7.1 <span class="s25">一阶归结</span></h3><p style="padding-top: 10pt;padding-left: 12pt;text-indent: 21pt;line-height: 110%;text-align: left;">归结规则可以很容易地扩展到一阶表示中。如命题逻辑中一样，它需要输入两个子句， 输出第三个子句。它与命题归结的关键不同在于，这一过程如今要基于合一（<span class="s6">unifying</span>）置 换操作。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 11pt;text-indent: 21pt;text-align: justify;">定义置换(<span class="s6">substitution</span>)为变量到项的任意映射。例如，置换<span class="s47">θ</span>={<span class="s21">x</span>/<span class="s21">Bob</span>, <span class="s21">y</span>/<span class="s21">z</span>}表示变量 <span class="s21">x </span>替换为项 <span class="s21">Bob</span>，而变量 <span class="s21">y </span>替换为项 <span class="s21">z</span>。使用符号 <span class="s21">W</span><span class="s47">θ</span>代表应用到一置换<span class="s47">θ</span>到某表达式 <span class="s21">W </span>的结 果。例如，若 <span class="s21">L </span>是文字 <span class="s21">Father</span>(<span class="s21">x</span>, <span class="s21">Bill</span>)，且<span class="s47">θ</span>为上述的置换，则 <span class="s21">L</span><span class="s47">θ</span>=<span class="s21">Father</span>(<span class="s21">Bob</span>, <span class="s21">Bill</span>)。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 11pt;text-indent: 21pt;text-align: justify;">如果<span class="s21">L</span><span class="s253">1</span><span class="s47">θ</span>=<span class="s21">L</span><span class="s253">2</span><span class="s47">θ</span>，则称<span class="s47">θ</span>为两文字<span class="s21">L</span><span class="s253">1</span>和<span class="s21">L</span><span class="s253">2</span>的合一置换（<span class="s6">unifying substitution</span>）。例如，若 <span class="s21">L</span><span class="s253">1</span>=<span class="s21">Father</span>(<span class="s21">x</span>,<span class="s21">y</span>)，<span class="s21">L</span><span class="s253">2</span>=<span class="s21">Father</span>(<span class="s21">Bill</span>, <span class="s21">z</span>)，且<span class="s47">θ</span>={<span class="s21">x</span>/<span class="s21">Bill</span>, <span class="s21">z</span>/<span class="s21">y</span>}，那么<span class="s47">θ</span>是<span class="s21">L</span><span class="s253">1</span>和<span class="s21">L</span><span class="s253">2</span>的合一置换，因 为<span class="s21">L</span><span class="s253">1</span><span class="s47">θ</span>=<span class="s21">L</span><span class="s253">2</span><span class="s47">θ</span>=<span class="s21">Father</span>(<span class="s21">Bill</span>, <span class="s21">y</span>)。合一置换的意义是：在归结的命题形式中，两子句<span class="s21">C</span><span class="s253">1</span>和<span class="s21">C</span><span class="s253">2</span>的 归结式的获得是通过确定一在<span class="s21">C</span><span class="s253">1</span>中的子句<span class="s21">L</span>并且<span class="s10"></span><span class="s21">L</span>在<span class="s21">C</span><span class="s253">2</span>中。在一阶归结中，它推广为从子句 <span class="s21">C</span><span class="s253">1</span>中寻找一文字<span class="s21">L</span><span class="s253">1</span>和在<span class="s21">C</span><span class="s253">2</span>中寻找文字<span class="s21">L</span><span class="s253">2</span>，使得可找到对于<span class="s21">L</span><span class="s253">1</span>和<span class="s10"></span><span class="s21">L</span><span class="s253">2</span>的某合一置换<span class="s47">θ</span>（即，使<span class="s21">L</span><span class="s253">1 </span><span class="s47">θ</span>=<span class="s10"></span><span class="s21">L</span><span class="s253">2</span><span class="s47">θ</span>）。归结规则然后按下面的等式建立归结式<span class="s21">C</span>：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s33" style="padding-top: 2pt;padding-left: 120pt;text-indent: 0pt;text-align: left;"><i>C </i><span class="s38"> </span>(<i>C</i><span class="s79">1 </span><span class="s38"></span>{<i>L</i><span class="s79">1</span>})<span class="s119"> </span><span class="s38"> </span>(<i>C</i><span class="s79">2 </span><span class="s38"></span>{<i>L</i><span class="s79">2</span><span class="s42"> </span>})<span class="s119"></span></p><p style="padding-top: 3pt;padding-left: 34pt;text-indent: 0pt;text-align: left;">(10.3)</p><p style="padding-left: 32pt;text-indent: 0pt;text-align: center;">归结规则 的一般描 述见表 10-7 。为说明 它，假定 <span class="s21">C</span><span class="s253">1</span>=<span class="s21">White</span>(<span class="s21">x</span>)← <span class="s21">Swan</span>(<span class="s21">x</span>)及 </p><p class="s21" style="padding-top: 1pt;padding-left: 11pt;text-indent: 0pt;text-align: left;">C<span class="s253">2</span><span class="p">=</span>Swan<span class="p">(</span>Fred<span class="p">)。为应用 归结规 则首 先将 </span>C<span class="s253">1 </span><span class="p">等 价 地表示 为子 句的形 式 </span>C<span class="s253">1</span><span class="p">=</span>White<span class="p">(</span>x<span class="p">)∨ </span></p><p style="padding-top: 1pt;padding-left: 11pt;text-indent: 0pt;text-align: left;"><span class="s10"></span><span class="s21">Swan</span>(<span class="s21">x</span>)。然后可应用归结规则。第一步，先找到<span class="s21">C</span><span class="s253">1</span>中的文字<span class="s21">L</span><span class="s253">1</span>=<span class="s10"></span><span class="s21">Swan</span>(<span class="s21">x</span>)和<span class="s21">C</span><span class="s253">2</span>中的文字 <span class="s21">L</span><span class="s253">2</span>=<span class="s21">Swan</span>(<span class="s21">Fred</span>)。如果选择合一置换<span class="s47">θ</span>={<span class="s21">x</span>/<span class="s21">Fred</span>}，则两个子句满足<span class="s21">L</span><span class="s253">1</span><span class="s47">θ</span>=<span class="s10"></span><span class="s21">L</span><span class="s253">2</span><span class="s47">θ</span>=<span class="s10"></span><span class="s21">Swan</span>(<span class="s21">Fred</span>)。 因此，结论<span class="s21">C</span>为(<span class="s21">C</span><span class="s253">1</span>-{<span class="s21">L</span><span class="s253">1</span>})<span class="s47">θ</span>=<span class="s21">White</span>(<span class="s21">Fred</span>)和(<span class="s21">C</span><span class="s253">2</span>-{<span class="s21">L</span><span class="s253">2</span>})<span class="s47">θ</span>=<span class="s10"></span>，即<span class="s21">C</span>=<span class="s21">White</span>(<span class="s21">Fred</span>)。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 31pt;text-indent: 0pt;text-align: center;">表 <span class="h4">10-7 </span>归结规则（一阶形式）</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 2pt;text-align: left;"><span><img width="570" height="2" alt="image" src="机器学习/Image_393.png"/></span></p><p class="s14" style="padding-left: 12pt;text-indent: 0pt;text-align: left;"><span class="s16">1.      </span>寻找<span class="s56">C</span><span class="s64">1</span>中的文字<span class="s56">L</span><span class="s64">1</span>，<span class="s56">C</span><span class="s64">2</span>中的文字<span class="s56">L</span><span class="s64">2</span>，以及置换<span class="s177">θ</span>，使得<span class="s56">L</span><span class="s155">1</span><span class="s177">θ</span>=<span class="s57"></span><span class="s56">L</span><span class="s155">2</span><span class="s177">θ</span>。</p><p class="s14" style="padding-top: 4pt;padding-left: 33pt;text-indent: -21pt;line-height: 11pt;text-align: left;"><span class="s16">2.      </span>通过包含<span class="s56">C</span><span class="s64">1</span><span class="s177">θ</span>和<span class="s56">C</span><span class="s155">2</span><span class="s177">θ</span>中除了<span class="s56">L</span><span class="s155">1</span><span class="s177">θ</span>和<span class="s57"></span><span class="s56">L</span><span class="s155">2</span><span class="s177">θ</span>以外的文字，形成归结式<span class="s56">C</span>。更精确地讲，出现在结论<span class="s56">C</span>中的 文字集合为：</p><p class="s33" style="padding-top: 3pt;padding-left: 141pt;text-indent: 0pt;text-align: left;"><i>C </i><span class="s38"> </span>(<i>C</i><span class="s79">1 </span><span class="s38"></span>{<i>L</i><span class="s79">1</span>})<span class="s119"> </span><span class="s38"> </span>(<i>C</i><span class="s79">2 </span><span class="s38"></span>{<i>L</i><span class="s79">2</span><span class="s42"> </span>})<span class="s119"></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 2pt;text-align: left;"><span><img width="570" height="2" alt="image" src="机器学习/Image_394.png"/></span></p><h3 style="padding-top: 10pt;padding-left: 12pt;text-indent: 0pt;text-align: left;">10.7.2 <span class="s25">逆归结：一阶情况</span></h3><p style="padding-top: 10pt;padding-left: 11pt;text-indent: 21pt;line-height: 107%;text-align: left;">我们可以用分析法推导出逆归结算子，方法是通过对定义归结规则的式 10.3 进行代数 操作。首先，注意式 10.3 中的合一置换<span class="s47">θ</span>可被惟一地分解为<span class="s47">θ</span><span class="s253">1</span>和<span class="s47">θ</span><span class="s253">2</span>，其中<span class="s47">θ</span>=<span class="s47">θ</span><span class="s253">1</span><span class="s47">θ</span><span class="s253">2</span>，<span class="s47">θ</span><span class="s253">1</span>包 含涉及子句<span class="s21">C</span><span class="s253">1</span>中变量的所有置换，而<span class="s47">θ</span><span class="s253">2</span>包含涉及<span class="s21">C</span><span class="s253">2</span>中变量的所有置换。该分解的合理性在 于<span class="s21">C</span><span class="s253">1</span>和<span class="s21">C</span><span class="s253">2</span>总是开始于不同的变量名（因为它们是不同的全称量化陈述）。使用<span class="s47">θ</span>的这种分解， 可将式 10.3 重新表达为：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s33" style="padding-top: 2pt;padding-left: 148pt;text-indent: 0pt;text-align: left;"><i>C </i><span class="s38"> </span>(<i>C</i><span class="s79">1 </span><span class="s38"></span>{<i>L</i><span class="s79">1</span>})<span class="s119"></span><span class="s79">1 </span><span class="s38"> </span>(<i>C</i><span class="s79">2 </span><span class="s38"></span>{<i>L</i><span class="s79">2 </span>})<span class="s119"> </span><span class="s79">2</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 11pt;text-indent: 21pt;line-height: 107%;text-align: left;">记住这里的减号“-”代表集合差。现在如果限制逆归结算子为推理出的<span class="s21">C</span><span class="s253">2</span>中没有与<span class="s21">C</span><span class="s253">1</span>共 同的文字（表示偏好最短的<span class="s21">C</span><span class="s253">2</span>子句），那么可将上式写为：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s33" style="padding-left: 149pt;text-indent: 0pt;text-align: left;"><i>C </i><span class="s38"> </span>(<i>C</i><span class="s79">1 </span><span class="s38"></span>{<i>L</i><span class="s79">1</span>})<span class="s119"></span><span class="s79">1 </span><span class="s38"> </span>(<i>C</i><span class="s79">2 </span><span class="s38"></span>{<i>L</i><span class="s79">2 </span>})<span class="s119"> </span><span class="s79">2</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 32pt;text-indent: 0pt;line-height: 8pt;text-align: left;">最后可使用归结规则的定义 <span class="s30">L</span></p><p class="s38" style="padding-top: 4pt;padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;"> <span class="s30">L </span><span class="s119"> </span><span class="s119"></span></p><p style="padding-top: 3pt;padding-left: 3pt;text-indent: 0pt;line-height: 9pt;text-align: left;"><span class="s277"></span><span class="s42">1 </span>，解出<span class="s21">C </span>来得到</p><p class="s42" style="padding-left: 14pt;text-indent: 0pt;line-height: 9pt;text-align: center;">2 1 1 2 <span class="s285">2</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 32pt;text-indent: 0pt;text-align: left;">逆归结：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="padding-top: 4pt;padding-left: 93pt;text-indent: 0pt;line-height: 9pt;text-align: left;">C <span class="s38"> </span><span class="s33">(</span>C <span class="s38"> </span><span class="s33">(</span>C</p><p class="s33" style="padding-top: 4pt;padding-left: 4pt;text-indent: 0pt;line-height: 10pt;text-align: left;"><span class="s38"></span>{<i>L </i>})<span class="s119"> </span>)<span class="s119"></span></p><p class="s38" style="padding-top: 3pt;padding-left: 3pt;text-indent: 0pt;line-height: 10pt;text-align: left;"><span class="s277"></span><span class="s42">1 </span><span class="s33">{</span><span class="s30">L </span><span class="s119"> </span><span class="s119"></span></p><p class="s40" style="padding-top: 3pt;padding-left: 3pt;text-indent: 0pt;line-height: 11pt;text-align: left;"><span class="s42">1</span><span class="s131">}</span></p><p style="padding-top: 4pt;padding-left: 23pt;text-indent: 0pt;line-height: 10pt;text-align: left;">（10.4）</p><p class="s42" style="padding-left: 102pt;text-indent: 0pt;line-height: 7pt;text-align: left;">2 1 1 1 2</p><p class="s42" style="padding-left: 39pt;text-indent: 0pt;line-height: 7pt;text-align: left;">1 1 2</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 11pt;text-indent: 21pt;line-height: 108%;text-align: left;">式 10.4 给出了一阶逻辑的逆归结规则。如在命题形式中，此逆涵蕴算子是非确定性的。 确切地讲，在应用它的过程中，一般可找到待归结的子句<span class="s21">C</span><span class="s253">1</span>和置换<span class="s47">θ</span><span class="s253">1</span>和<span class="s47">θ</span><span class="s253">2</span>的多种选择。每 一组选择都产生一个不同的<span class="s21">C</span><span class="s253">2</span>解。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 11pt;text-indent: 21pt;line-height: 109%;text-align: justify;">图 10-3 图示了此逆归结规则应用在一简单例子上的多个步骤。在图中，我们希望根据 给定的训练数据 <span class="s21">D</span>=<span class="s21">GrandChild </span>(<span class="s21">Bob</span>, <span class="s21">Shannon</span>)和背景 信息 <span class="s21">B</span>={<span class="s21">Father</span>(<span class="s21">Shannon</span>, <span class="s21">Tom</span>), <span class="s21">Father</span>(<span class="s21">Tom</span>, <span class="s21">Bob</span>)}，学习到目标谓词<span class="s21">GrandChild</span>(<span class="s21">y</span>,<span class="s21">x</span>)的规则。考虑图 10-3 中逆归结树的 最下面一步。这里，我们设置结论<span class="s21">C</span>为训练样例<span class="s21">GrandChild </span>(<span class="s21">Bob</span>, <span class="s21">Shannon</span>)，并且从背景 信息中选择子句<span class="s21">C</span><span class="s253">1</span>=<span class="s21">Father</span>(<span class="s21">Shannon</span>, <span class="s21">Tom</span>)。为应用逆归结算子，对于文字<span class="s21">L</span><span class="s253">1</span>只有一种选择，</p><p class="s253" style="padding-left: 249pt;text-indent: 0pt;line-height: 2pt;text-align: left;">-1 -1</p><p style="padding-left: 12pt;text-indent: 0pt;line-height: 12pt;text-align: left;">称为<span class="s21">Father </span>(<span class="s21">Shannon</span>,<span class="s21">Tom</span>)。假定我们选择逆置换<span class="s47">θ</span><span class="s253">1</span></p><p class="s40" style="padding-top: 1pt;text-indent: 0pt;line-height: 3pt;text-align: right;"><span class="s42">1</span></p><p style="padding-left: 3pt;text-indent: 0pt;line-height: 11pt;text-align: center;">={}且<span class="s47">θ</span><span class="s253">2</span></p><p class="s40" style="padding-top: 2pt;padding-left: 8pt;text-indent: 0pt;line-height: 3pt;text-align: center;"><span class="s42">1</span></p><p style="padding-left: 3pt;text-indent: 0pt;line-height: 12pt;text-align: left;">={<span class="s21">Shannon</span>/<span class="s21">x</span>}。在此情况下，</p><p class="s33" style="padding-left: 12pt;text-indent: 0pt;line-height: 15pt;text-align: left;"><span class="p">得到的子句</span><span class="s21">C</span><span class="s253">2 </span><span class="p">为子句 </span>(<i>C </i><span class="s38"> </span>(<i>C</i><span class="s120">1</span><span class="s42"> </span><span class="s38"></span>{<i>L</i><span class="s120">1</span>})<span class="s119"></span><span class="s120">1</span><span class="s42"> </span>)<span class="s119"> </span><span class="s120">2</span></p><p class="s33" style="padding-left: 10pt;text-indent: 0pt;line-height: 15pt;text-align: left;"><span class="s38"> </span>(<i>C</i><span class="s119"></span><span class="s79">1 </span>)<span class="s119"> </span><span class="s79">2</span></p><p class="s30" style="padding-left: 10pt;text-indent: 0pt;line-height: 13pt;text-align: left;"><span class="s38"> </span>GrandChild <span class="s33">(</span>Bob<span class="s33">, </span>x<span class="s33">) </span><span class="p">和子句</span></p><p class="s119" style="padding-top: 2pt;padding-left: 12pt;text-indent: 0pt;line-height: 10pt;text-align: left;"><span class="s33">{</span><span class="s38"></span><span class="s30">L </span> </p><p class="s33" style="padding-top: 1pt;padding-left: 3pt;text-indent: 0pt;line-height: 11pt;text-align: left;"><span class="s277"></span><span class="s42">1</span>} <span class="s38"> </span><span class="s38"></span><i>Father</i>(<i>x</i>,<i>Tom</i>) <span class="p">的联合。 因此结果 为子句 </span><span class="s107">GrandChild </span><span class="s108">(</span><span class="s107">Bob</span><span class="s108">, </span><span class="s107">x</span><span class="s108">) </span><span class="s109"></span></p><p class="s42" style="padding-left: 32pt;text-indent: 0pt;line-height: 7pt;text-align: left;">1 1 2</p><p class="s21" style="padding-top: 1pt;padding-left: 5pt;text-indent: 0pt;line-height: 118%;text-align: left;"><span class="s10"></span>Father<span class="s6">(</span>x<span class="s6">,</span>Tom<span class="s6">)</span><span class="p">，或等价的子句 </span><span class="s107">GrandChild </span><span class="s108">(</span><span class="s107">Bob</span><span class="s108">, </span><span class="s107">x</span><span class="s108">) </span><span class="s109"> </span><span class="s107">Father </span><span class="s108">(</span><span class="s107">x</span><span class="s108">,</span><span class="s107">Tom</span><span class="s108">) </span><span class="p">。注意这个一般规 则与</span>C<span class="s253">1</span><span class="p">一起涵蕴了训练样例</span>GrandChild<span class="p">(</span>Bob<span class="p">, </span>Shanon<span class="p">)。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s107" style="padding-left: 6pt;text-indent: 21pt;line-height: 106%;text-align: justify;"><span class="p">以相似的方式，推理得到的子句可作为第二个归结步中的结论 </span><span class="s21">C</span><span class="p">，如图 10-3 所示。在 这两步中的每一步中都可能有多个输出，这取决于对置换的选择（见习题 10.7）。在图 10-3 的例子中 ，特定的 选择产生 了直觉上 可满足的 最终 子 句 </span>GrandChild <span class="s108">( </span>y<span class="s108">, </span>x<span class="s108">) </span><span class="s109"> </span>Father <span class="s108">(</span>x<span class="s108">, </span>z<span class="s108">) </span><span class="s109"> </span>Father <span class="s108">(</span>z<span class="s108">, </span>y<span class="s108">) </span><span class="p">。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 13pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="547" height="1" alt="image" src="机器学习/Image_395.png"/></span></p><p class="s48" style="padding-left: 15pt;text-indent: 0pt;text-align: left;">插图——原书页码： <span class="s21">298</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 14pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="531" height="1" alt="image" src="机器学习/Image_396.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 58pt;text-indent: 110pt;text-align: left;">图 <span class="h4">10-3 </span>一个多步逆归结</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s155" style="text-indent: 0pt;line-height: 5pt;text-align: left;">1                                2</p><p style="text-indent: 0pt;text-align: left;"/><p class="s14" style="padding-left: 37pt;text-indent: 21pt;line-height: 123%;text-align: justify;">其中带方框的子句为推理步的结果。在每一步，<span class="s56">C</span>是位于底部的子句，<span class="s56">C</span><span class="s16">1 </span>是左边的子句，<span class="s56">C</span><span class="s16">2 </span>是右边带方框的子句。在这两个推理步中，<span class="s177">θ </span>都是空置换，而<span class="s177">θ </span><span class="s13">-1</span>置换显示在<span class="s56">C</span>2 下方。注意最终 的结论（最右上角的带方框子句）是<span class="s16">Horn</span>子句<span class="s56">GrandChild</span>(<span class="s56">y</span>, <span class="s56">x</span>) <span class="s57"></span><span class="s56">Father</span>(<span class="s56">x</span>, <span class="s56">z</span>)<span class="s57"></span><span class="s56">Father</span>(<span class="s56">z</span>, <span class="s56">y</span>)的另 一种形式。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">10.7.3 <span class="s25">逆归结小结</span></h3><p style="padding-top: 9pt;padding-left: 5pt;text-indent: 21pt;line-height: 109%;text-align: justify;">概括地讲，逆归结提供了一种一般的途径以自动产生满足约束 <span class="s33">(</span><span class="s30">B </span><span class="s38"> </span><span class="s30">h </span><span class="s38"> </span><span class="s30">x</span><span class="s52">i</span><span class="s41"> </span><span class="s33">) </span>├ <span class="s21">f</span>(<span class="s21">x</span><span class="s36">i</span>)的 假设<span class="s21">h</span>。这是通过逆转式 10.3 给出的归结规则得到的。从此归结规则中解出子句<span class="s21">C</span><span class="s253">2</span>，式 10.4 中的逆归结规则的很容易推导出。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 110%;text-align: justify;">给定一组开始子句，可通过重复应用此逆归结规则生成多个假设。注意逆归结规则具有 一优点， 它只生成 满足 <span class="s33">(</span><span class="s30">B </span><span class="s38"> </span><span class="s30">h </span><span class="s38"> </span><span class="s30">x</span><span class="s52">i</span><span class="s41"> </span><span class="s33">) </span>├ <span class="s21">f</span>(<span class="s21">x</span><span class="s36">i</span>) 的 假设 。相 反 ， <span class="s6">FOIL </span>的 生 成再测 试</p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: left;">（<span class="s6">generate-and-test</span>）搜索在每一搜索步生成多个假设，包括一些不满足此约束的。然后<span class="s6">FOIL </span>通过考虑数据<span class="s21">D</span>来在这些假设中作出选择。由于这一差异，我们可期望基于逆归结的搜索更 有针对性且更有效。然而实际未必如此。一个原因是逆归结算子在任意一步生成它的假设时， 只能考虑可用数据中的一小部分。而<span class="s6">FOIL</span>考虑所有的可用数据，在其按语法生成的假设中 进行选择。使用逆涵蕴和使用生成再测试两种搜索策略的差别仍是一个研究主题。<span class="s6">Srinivasan </span>等（1995）提供了对这两种方法的实验性比较。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s25" style="padding-left: 6pt;text-indent: 0pt;text-align: left;"><span class="h3">10.7.4 </span>泛化、<span class="s286">θ</span>包容和涵蕴</p><p style="padding-top: 10pt;padding-left: 6pt;text-indent: 21pt;line-height: 110%;text-align: justify;">前一节指出了归纳和逆涵蕴之间的联系。由于以前着重于讲述在假设搜索中的一般到特 殊序，那么有必要研究 <span class="s21">more</span>-<span class="s21">general</span>-<span class="s21">than </span>关系和逆涵蕴之间的联系。为说明此，考虑如下 的定义：</p><ul id="l30"><li style="padding-top: 5pt;padding-left: 49pt;text-indent: -21pt;line-height: 15pt;text-align: left;"><p class="s21" style="display: inline;">more<span class="s6">-</span>general<span class="s6">-</span>than<span class="p">。第 </span><span class="s6">2 </span><span class="p">章中的</span>more<span class="s6">-</span>general<span class="s6">-</span>than<span class="s6">-</span>or<span class="s6">-</span>equal<span class="s6">-</span>to<span class="p">关系（≥</span><span class="s36">g</span><span class="p">）定义为： 给定两布尔值函数</span>h<span class="s36">j</span><span class="s6">(</span>x<span class="s6">)</span><span class="p">和</span>h<span class="s36">k</span><span class="s6">(</span>x<span class="s6">)</span><span class="p">，我们称</span>h<span class="s36">j</span><span class="p">≥</span><span class="s36">g</span><span class="s41"> </span>h<span class="s36">k</span><span class="p">当且仅当 </span><span class="s33">(</span><span class="s38"></span><span class="s30">x</span><span class="s33">)</span><span class="s30">h</span><span class="s52">k</span><span class="s41"> </span><span class="s33">(</span><span class="s30">x</span><span class="s33">) </span><span class="s38"> </span><span class="s30">h</span><span class="s52">j</span><span class="s41"> </span><span class="s33">(</span><span class="s30">x</span><span class="s33">) </span><span class="p">。此</span></p></li></ul></li></ol></ol></ol><p style="padding-top: 2pt;padding-left: 49pt;text-indent: 0pt;line-height: 14pt;text-align: left;">≥<span class="s36">g</span>关系被用于许多学习算法中以引导假设空间的搜索。</p><p style="padding-left: 49pt;text-indent: -21pt;line-height: 14pt;text-align: left;"><span class="s10"> </span><span class="s47">θ</span><span class="s6">-</span>包容（<span class="s47">θ</span><span class="s6">-subsumption</span>）。考虑两个子句<span class="s21">C</span><span class="s36">j</span>和<span class="s21">C</span><span class="s36">k</span>，它们的形式都是<span class="s21">H</span>∨<span class="s21">L</span><span class="s35">1</span>∨<span class="s6">…</span><span class="s21">L</span><span class="s36">n</span>， 其中<span class="s21">H</span>为一正文字，而<span class="s21">L</span><span class="s36">i</span>为任意文字。称子句<span class="s21">C</span><span class="s36">j</span><span class="s47">θ</span><span class="s6">-</span>包容子句<span class="s21">C</span><span class="s36">k</span>，当且仅当存在一</p><p style="padding-top: 1pt;padding-left: 49pt;text-indent: 0pt;text-align: left;">个置换使 <span class="s30">C </span><span class="s52">j</span><span class="s119"> </span><span class="s38"> </span><span class="s30">C</span><span class="s52">k</span>（这里我们将任意子句<span class="s21">C</span>描述为其析取式中各文字的集合）。 该定义见<span class="s6">Plotkin</span>（<span class="s6">1970</span>）。</p><p style="padding-left: 49pt;text-indent: -21pt;line-height: 89%;text-align: left;"><span class="s10"> </span>涵蕴（<span class="s6">entailment</span>）考虑两子句<span class="s21">C</span><span class="s36">j</span>和<span class="s21">C</span><span class="s36">k</span>。子句<span class="s21">C</span><span class="s36">j</span>被称为涵蕴子句<span class="s21">C</span><span class="s36">k</span>（写作<span class="s21">C</span><span class="s36">j</span>├<span class="s21">C</span><span class="s36">k</span>） 当且仅当<span class="s21">C</span><span class="s36">k</span>从<span class="s21">C</span><span class="s36">j</span>中演绎派生。</p><p style="padding-top: 6pt;padding-left: 6pt;text-indent: 21pt;text-align: justify;">这三个定义之间有什么内在联系？首先，将≥<span class="s36">g</span>的定义重新表示为一阶形式，如另两个 定义一样。如果对某目标概念<span class="s21">c</span>(<span class="s21">x</span>)考虑一布尔值假设<span class="s21">h</span>(<span class="s21">x</span>)，其中<span class="s21">h</span>(<span class="s21">x</span>)表示为文字的合取，那 么可重新表示此假设为子句：</p><p style="padding-left: 27pt;text-indent: 171pt;line-height: 28pt;text-align: left;"><span class="s21">c</span>(<span class="s21">x</span>)←<span class="s21">h</span>(<span class="s21">x</span>) 这里我们遵循通常的<span class="s6">Prolog</span>解释，即<span class="s21">x</span>若不能被证明为正例时，则<span class="s21">x</span>被分类为反例。因此，</p><p style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">可看出前面定义的≥<span class="s36">g</span>应用于<span class="s6">Horn</span>子句的前件（或规则体）。<span class="s6">Horn</span>子句隐含的后件为目标概念</p><p class="s21" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">c<span class="p">(</span>x<span class="p">)。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;text-align: left;">≥<span class="s36">g</span>定义和<span class="s47">θ</span>-包容定义之间的关系是什么？注意如果<span class="s21">h</span><span class="s253">1</span>≥<span class="s36">g </span><span class="s21">h</span><span class="s253">2</span>，则子句<span class="s21">C</span><span class="s253">1</span>:<span class="s21">c</span>(<span class="s21">x</span>) ←<span class="s21">h</span><span class="s253">1</span>(<span class="s21">x</span>) 是<span class="s47">θ</span>-包容子句<span class="s21">C</span><span class="s253">2</span>:<span class="s21">c</span>(<span class="s21">x</span>) ←<span class="s21">h</span><span class="s253">2</span>(<span class="s21">x</span>)。更进一步，即使在子句有不同的头部时，<span class="s47">θ</span><span class="s6">-</span>包容也可成立。 例如，下面的情形中子句<span class="s21">A</span><span class="s47">θ</span>-包容子句<span class="s21">B</span>：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 26pt;text-indent: 0pt;text-align: left;">A<span class="p">: </span>Mother<span class="p">(</span>x<span class="p">,</span>y<span class="p">) ← </span>Father<span class="p">(</span>x<span class="p">, </span>z<span class="p">)∧</span>Spouse<span class="p">(</span>z<span class="p">, </span>y<span class="p">)</span></p><p class="s21" style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">B<span class="p">: </span>Mother<span class="p">(</span>x<span class="p">, </span>Louise<span class="p">) ← </span>Father<span class="p">(</span>x<span class="p">, </span>Bob<span class="p">) ∧</span>Spouse<span class="p">(</span>Bob<span class="p">, </span>y<span class="p">) ∧</span>Female<span class="p">(</span>x<span class="p">)</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;text-align: justify;">因为如果选择<span class="s47">θ</span>={<span class="s21">y</span>/<span class="s21">Louise</span>, <span class="s21">z</span>/<span class="s21">Bob</span>}则 <span class="s30">A</span><span class="s119"> </span><span class="s38"> </span><span class="s30">B </span>。这里的关键区别在于≥<span class="s36">g</span>隐含假定了两 个子句的头部是相同的，而<span class="s47">θ</span><span class="s6">-</span>包容可在子句头部不同时成立。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;text-align: justify;">最后，<span class="s47">θ</span>-包容是涵蕴的一种特殊形式。即，如果子句 <span class="s21">A</span><span class="s47">θ</span>-包容子句 <span class="s21">B</span>，则 <span class="s21">A</span>├<span class="s21">B</span>。然 而，我们可找到这样的 <span class="s21">A </span>和 <span class="s21">B</span>，使 <span class="s21">A</span>├<span class="s21">B </span>但 <span class="s21">A </span>并不<span class="s47">θ</span>-包容 <span class="s21">B</span>。例如下面两个子句：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 27pt;text-indent: 0pt;text-align: left;">A<span class="p">: </span>Elephant<span class="p">(</span>father<span class="p">_</span>of<span class="p">(</span>x<span class="p">)) ←</span>Elephant<span class="p">(</span>x<span class="p">)</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 26pt;text-indent: 0pt;text-align: left;">B<span class="p">: </span>Elephant<span class="p">(</span>father<span class="p">_</span>of<span class="p">(</span>father<span class="p">_</span>of<span class="p">(</span>y<span class="p">))) ←</span>Elephant<span class="p">(</span>y<span class="p">)</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;text-align: justify;">其中 <span class="s21">father</span>_<span class="s21">of</span>(<span class="s21">x</span>)为一函数，代表 <span class="s21">x </span>的父亲。注意虽然 <span class="s21">B </span>可由 <span class="s21">A </span>得到证明，却不存在置 换<span class="s47">θ</span>使 <span class="s21">A</span><span class="s47">θ</span>-包容 <span class="s21">B</span>。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 110%;text-align: justify;">如这些例子所示，前面对 <span class="s21">more</span>-<span class="s21">general</span>-<span class="s21">than </span>的定义是<span class="s47">θ</span>-包容的一种特殊情况，而<span class="s47">θ</span>- 包容又是涵蕴的特殊情况。因此，通过泛化和特化假设来搜索假设空间比用一般的逆涵蕴算 子来搜索更为局限。不幸的是，逆涵蕴这种最一般的形式可产生无法处理的搜索。然后中间 的<span class="s47">θ</span>-包容的定义提供了位于 <span class="s21">more</span>-<span class="s21">general</span>-<span class="s21">then </span>和涵蕴中间的一种概念。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">10.7.5 Progol</h3><p style="padding-top: 9pt;padding-left: 6pt;text-indent: 21pt;line-height: 110%;text-align: justify;">虽然对于生成候选假设，逆归结是一种很吸引人的方法。在实践中它很容易导致候选假 设的组合爆炸。另一种途径是只使用逆涵蕴来生成一个最特殊假设，它与背景信息一起涵蕴 观察的数据。然后，这个最特殊假设可用于确定假设空间的一般到特殊搜索边界，与 <span class="s6">FOIL </span>中使用的搜索一样，但有一更多的限制：只考虑比此边界更一般的假设。该方法被用于 <span class="s6">Progol </span>系统，它的算法可概述如下：</p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 107%;text-align: justify;">1．用户指定使用一个受限的一阶表示语言为假设空间<span class="s47">Ｈ</span>。这些限制用“模态声明（<span class="s6">mode declaration</span>）”来描述，它允许用户指定要考虑的谓词和函数符号，以及它们的参考类型和格 式。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;text-align: justify;">2．<span class="s6">Progol</span>使用序列覆盖法来从<span class="s47">Ｈ</span>中学习一组覆盖数据的表达式。对于每个还没被这些 学到的表达式覆盖的样例&lt;<span class="s21">x</span><span class="s36">i</span>,<span class="s21">f</span>(<span class="s21">x</span><span class="s36">i</span>)&gt;，它首先寻找<span class="s47">Ｈ</span>中最特殊的假设<span class="s21">h</span><span class="s36">i</span>，使 <span class="s33">(</span><span class="s30">B </span><span class="s38"> </span><span class="s30">h </span><span class="s38"> </span><span class="s30">x</span><span class="s52">i</span><span class="s41"> </span><span class="s33">) </span>├ <span class="s21">f</span>(<span class="s21">x</span><span class="s36">i</span>)。更精确地讲，它先找到能通过应用<span class="s21">k</span>次归结规则涵蕴<span class="s21">f</span>(<span class="s21">x</span><span class="s36">i</span>)的假设，在其中计算出最特 殊的假设，从而近似得到<span class="s21">h</span><span class="s36">i</span>。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 108%;text-align: justify;">3．然后<span class="s6">Progol</span>在这个由最一般假设和第２步中得到的特殊边界<span class="s21">h</span><span class="s36">i</span>所界定的假设空间中执 行了一般到特殊搜索。在此假设集合中，它寻找有最小描述长度（由文字的数量度量）的假 设。该部分的搜索是由像<span class="s21">A</span><span class="s9">*</span>那样的启发式规则引导的，它的修剪操作可在没有修剪掉最短假 设的风险下进行。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 26pt;text-indent: 0pt;text-align: left;">细节的 <span class="s6">Progol </span>算法见 <span class="s6">Muggleton</span>（1992，1995）。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">10.8 <span class="s17">小结和补充读物</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 27pt;text-indent: 0pt;text-align: left;">本章的要点包括：</p><p style="padding-top: 6pt;padding-left: 49pt;text-indent: -21pt;text-align: left;"><span class="s10"> </span>序列覆盖算法学习析取的规则集，方法是先学习单个精确的规则，然后移去被 此规则覆盖的正例，再在剩余样例上重复这一过程。它提供了一个学习规则集 的有效的贪婪算法，可作为由顶向下的决策树学习算法（如 <span class="s6">ID3</span>）的替代算法。 决策树算法可被看作并行覆盖，与序列覆盖相对应。</p><p style="padding-left: 49pt;text-indent: -21pt;text-align: left;"><span class="s10"> </span>在序列覆盖算法中，已研究了多种方法以学习单个的规则。这些方法的不同在 于它们考查规则前件空间的策略不同。一个很流行的、在 <span class="s6">CN2 </span>程序中使用的方 法是执行一般到特殊的柱状搜索，渐进地生成并测试更特殊的规则，直到找到 一个足够精确的规则。其他的方法从特殊到一般进行假设搜索，使用样例驱动 而不是生成并测试，并且应用了不同的统计量度的规则精度来指引搜索。</p><p style="padding-left: 49pt;text-indent: -21pt;line-height: 94%;text-align: left;"><span class="s10"> </span>一阶规则集（即包含变量的规则）提供了一种表征能力很强的表示。例如，编 程语言 <span class="s6">Prolog </span>使用一阶 <span class="s6">Horn </span>子句序列来表示一般的程序。因此，学习一阶 <span class="s6">Horn </span>子句的问题也常被称为归纳逻辑编程的问题。</p><p style="padding-left: 49pt;text-indent: -21pt;line-height: 94%;text-align: left;"><span class="s10"> </span>学习一阶规则集的方法是将 <span class="s6">CN2 </span>中的序列覆盖算法由命题形式扩展到一阶表 示。该方法在 <span class="s6">FOIL </span>程序中例示，它可学习包括简单递归规则集在内的一阶规则 集。</p><p style="padding-top: 1pt;padding-left: 49pt;text-indent: -21pt;line-height: 14pt;text-align: left;"><span class="s10"> </span>学习一阶规则的另一方法基于一个发现：即归纳是演绎的逆转。换言之，归纳 的问题是寻找一个假设 <span class="s21">h </span>满足下面的约束。</p><p class="s21" style="padding-left: 50pt;text-indent: 67pt;line-height: 94%;text-align: left;"><span class="s33">(</span><span class="s38"></span><span class="s30">x</span><span class="s52">i</span><span class="s41"> </span><span class="s33">, </span><span class="s30">f </span><span class="s33">(</span><span class="s30">x</span><span class="s52">i</span><span class="s41"> </span><span class="s33">)</span><span class="s38"> </span><span class="s38"> </span><span class="s30">D</span><span class="s33">)(</span><span class="s30">B </span><span class="s38"> </span><span class="s30">h </span><span class="s38"> </span><span class="s30">x</span><span class="s52">i</span><span class="s41"> </span><span class="s33">) </span><span class="p">├ </span>f<span class="p">(</span>x<span class="s36">i</span><span class="p">) 其中</span>B<span class="p">是一般背景信息，</span>x<span class="s35">1</span><span class="s6">…</span>x<span class="s36">n</span><span class="p">是训练数据</span>D<span class="p">中实例的描述，而</span>f<span class="s6">(</span>x<span class="s35">1</span><span class="s6">)…</span>f<span class="s6">(</span>x<span class="s36">n</span><span class="s6">)</span><span class="p">为训练 实例的目标值。</span></p><p style="padding-left: 49pt;text-indent: -21pt;line-height: 94%;text-align: left;"><span class="s10"> </span>一些程序遵循了归纳是演绎的逆转的观点，通过运用熟知的演绎推理的逆操作 来搜索假设。例如 <span class="s6">Cigol </span>使用的逆归结是归结算子的逆转，而归结是普遍用于机 器定理证明的一种推理规则。<span class="s6">Progol </span>结合了逆涵蕴策略和一般到特殊策略来搜 索假设空间。</p><p style="padding-top: 8pt;padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">学习关系描述的早期工作包括 <span class="s6">Winston</span>（1970）的著名的程序，它学习如 “<span class="s6">arch</span>”这样 的概念的网络式描述。<span class="s6">Banerji </span>(1964, 1969)的工作和 <span class="s6">Michalski </span>的 <span class="s6">AQ </span>算法系列工作（如 <span class="s6">Michalski </span>1969; <span class="s6">Michalski et al</span>. 1986）是最早将逻辑表示用于学习问题的研究之一。<span class="s6">Plotkin</span></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: justify;">（1970）的<span class="s47">θ</span>-包容定义较早地对归纳和演绎之间的关系进行了形式化。<span class="s6">Vere</span>（1975）也研 究了学习的逻辑表示问题，且 <span class="s6">Buchanan</span>（1976）的 <span class="s6">META</span>-<span class="s6">DENDRAL </span>程序可学习到关系描 述以表示分子结构中可在质谱仪中被分割的部分。该程序成功地发现了一些有用的规则，它 们在化学学术领域被公布。<span class="s6">Mitchell</span>（1979）的候选消除变型空间算法被应用于同样的化学 结构的关系描述。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: left;">随着 80 年代工中 <span class="s6">Prolog </span>语言的普遍化，研究人员开始深入研究 <span class="s6">Horn </span>子句表示的关系 描述。较早的学习 <span class="s6">Horn </span>子句的工作包括 <span class="s6">Shapiro</span>(1983)的 <span class="s6">MIS </span>和 <span class="s6">Sammut </span>&amp; <span class="s6">Banerji</span>（1986） 的 <span class="s6">Marvin</span>。这里讨论的 <span class="s6">Quinlan</span>（1990）的 <span class="s6">FOIL </span>算法出现后，很快随之产生了多个应用一 阶规则的一般到特殊搜索的算法，包括 <span class="s6">MFOIL</span>（<span class="s6">Dzeroski </span>1991）、<span class="s6">FOCL</span>(<span class="s6">Pazzani et al</span>. 1991)、 <span class="s6">CLAUDIEN</span>(<span class="s6">De Raedt </span>&amp; <span class="s6">Bruynooghe </span>1993)和 <span class="s6">MARKUS</span>（<span class="s6">Grobelnik </span>1992）。<span class="s6">FOCL </span>算法在 第 12 章中描述。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 109%;text-align: justify;">学习 <span class="s6">Horn </span>子句的另一条研究路线是通过逆涵蕴，是由 <span class="s6">Muggleton </span>&amp; <span class="s6">Buntine</span>（1988）提 出，它的基础是 <span class="s6">Sammut </span>&amp; <span class="s6">Banerji</span>（1986）和 <span class="s6">Muggleton</span>（1987）中类似的想法。此路线上 最近的工作着重于研究不同的搜索策略和限制假设空间以使学习过程更易于处理的方法。例 如 <span class="s6">Kietz </span>&amp; <span class="s6">Wrobel</span>（1992）使用在其 <span class="s6">RDT </span>程序中规则模式来限制学习过程中可考虑的表达 式的形式。<span class="s6">Muggleton </span>&amp; <span class="s6">Feng</span>（1992）讨论了将一阶表示限制为 <span class="s21">ij</span>-<span class="s6">determinate </span>文字。<span class="s6">Cohen</span></p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 107%;text-align: justify;">（1994）讨论了 <span class="s6">GRENDEL </span>程序，它接受一个显式的语言描述输入，以描述子句体，从而 允许用户显式地约束假设空间。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">Lavrac <span class="p">&amp; </span>Dzeroski<span class="p">（1994）提供了归纳逻辑编程的一个可读性很强的教材。近期其他有 用的专题报考和文集包括（</span>Bergadano <span class="p">&amp; </span>Gunetti <span class="p">1995；</span>Morik et al<span class="p">. 1993；</span>Muggleton <span class="p">1992, 1995</span>b<span class="p">）。</span>Wrobel<span class="p">（1996）的综述章也提供了该领域的一个好材料。</span>Bratko <span class="p">&amp; </span>Muggleton<span class="p">(1995) 概述了 </span>ILP <span class="p">在一些重要问题上的近期应用。一系列的 </span>ILP <span class="p">方面的年度专题讨论会也提供了近 期研究论文的很好来源（例如 </span>De Raedt <span class="p">1996）。</span></p><p style="padding-left: 27pt;text-indent: 0pt;text-align: left;">习题</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 110%;text-align: justify;">10.1 考虑一个如<span class="s6">CN</span>2 那样的序列覆盖算法和一个如<span class="s6">ID</span>3 那样的并行覆盖算法。两个算 法都被用于学习一目标概念，它定义在由<span class="s21">n</span>个布尔属性合取表示的实例上。如果<span class="s6">ID</span>3 学习到 深度为<span class="s21">d</span>的平衡决策树，它将包含 2<span class="s83">d</span>-1 个不同的决策结点，而且在建立其输出假设时作出 2<span class="s83">d</span>-1 次不同选择。如果该树被重新表示为一析取规则集，可形成多少规则？每个规则拥有 多少前件？一个序列覆盖算法为学习到同样的规则集需作出多少次不同的选择？如果给定 相同的训练数据，哪一个系统你认为更容易出现过度拟合？</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 26pt;text-indent: 0pt;text-align: left;">10.2 改进表 10-2 的 <span class="s6">learn</span>-<span class="s6">one</span>-<span class="s6">rule </span>算法，使它能学习前件中包含实数属性阈值的规则</p><p style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;line-height: 107%;text-align: left;">（如 <span class="s21">temprature</span>&gt;42）。指出新的算法可从表 10-2 中作哪些修改得到。提示：考虑在决策树 中这是怎样完成的。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">10.3 改进表 10-2 的 <span class="s6">learn</span>-<span class="s6">one</span>-<span class="s6">rule </span>算法，使它能学习的规则的前件中可包含类似于 <span class="s21">nationality</span>∈{<span class="s21">Canadian</span>, <span class="s21">Brazilian</span>}的约束，即离散值属性可取某指定集合中任意值。修改后 的程序应探索包含所有这样子集的假设空间。指出新的算法可从表 10-2 中作哪些修改得到。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">10.4 考虑实现 <span class="s6">Learn</span>-<span class="s6">one</span>-<span class="s6">rule </span>搜索假设空间时可选的策略，确切地讲，考虑下列搜索 过程属性：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 26pt;text-indent: 0pt;text-align: left;">（<span class="s6">a</span>）生成并测试 <span class="s6">vs</span>.数据驱动</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 26pt;text-indent: 0pt;text-align: left;">（<span class="s6">b</span>）一般到特殊 <span class="s6">vs</span>.特殊到一般</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 26pt;text-indent: 0pt;text-align: left;">（<span class="s6">c</span>）序列覆盖 <span class="s6">vs</span>.并行覆盖</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 113%;text-align: justify;">讨论表 10-1 和 10-2 中算法中所做选择的好处。对于搜索策略中的这三种属性，讨论选 择另一方案时的影响（正面的和负面的）。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 26pt;text-indent: 0pt;text-align: left;">10.5 应用命题形式的逆归结到子句<span class="s21">C</span>=<span class="s21">A</span>∨<span class="s21">B</span>，<span class="s21">C</span><span class="s253">1</span>=<span class="s21">A</span>∨<span class="s21">B</span>∨<span class="s21">G</span>。给出<span class="s21">C</span><span class="s253">2</span>的至少两种可能结果。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 107%;text-align: justify;">10.6 应用逆归结到子句<span class="s21">C</span>=<span class="s21">R</span>(<span class="s21">B</span>, <span class="s21">x</span>) ∨<span class="s21">P</span>(<span class="s21">x</span>, <span class="s21">A</span>)和<span class="s21">C</span><span class="s253">1</span>=<span class="s21">S</span>(<span class="s21">B</span>, <span class="s21">y</span>)∨<span class="s21">R</span>(<span class="s21">z</span>, <span class="s21">x</span>)。给出<span class="s21">C</span><span class="s253">2</span>的至少 四种可能结果。这里<span class="s21">A</span>和<span class="s21">B</span>为常量，<span class="s21">x</span>和<span class="s21">y</span>为变量。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 110%;text-align: justify;">10.7 考虑图 10-3 中最下面的逆归结步。若给定置换<span class="s47">θ</span><span class="s253">1</span>和<span class="s47">θ</span><span class="s253">2</span>的不同选择，推导出至少 两种可能产生的不同输出。如果用子句<span class="s21">Father</span>(<span class="s21">Tom</span>, <span class="s21">Bob</span>)替换了<span class="s21">Father</span>(<span class="s21">Shannon</span>, <span class="s21">Tom</span>)，推 导出此逆归结步的一个结果。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 26pt;text-indent: 0pt;text-align: left;">10.8 考虑本章中归纳问题的定义：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="padding-top: 2pt;padding-left: 133pt;text-indent: 0pt;text-align: left;"><span class="s33">(</span><span class="s38"></span>x<span class="s52">i</span><span class="s41"> </span><span class="s33">, </span>f <span class="s33">(</span>x<span class="s52">i</span><span class="s41"> </span><span class="s33">)</span><span class="s38"> </span><span class="s38"> </span>D<span class="s33">)(</span>B <span class="s38"> </span>h <span class="s38"> </span>x<span class="s52">i</span><span class="s41"> </span><span class="s33">) </span><span class="p">├ </span><span class="s21">f</span><span class="p">(</span><span class="s21">x</span><span class="s36">i</span><span class="p">)</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 26pt;text-indent: 0pt;text-align: left;">和前面第 2 章对归纳偏置的定义（式 2.1）之间的联系。其中归纳偏置<span class="s21">B</span><span class="s36">bias</span>定义为表达</p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">式</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="padding-top: 2pt;padding-left: 137pt;text-indent: 0pt;text-align: left;"><span class="s33">(</span><span class="s38"></span>x<span class="s52">i </span><span class="s38"> </span>X <span class="s33">)(</span>B<span class="s52">bias </span><span class="s38"> </span>D <span class="s38"> </span>x<span class="s52">i </span><span class="s33">) </span><span class="p">├ </span><span class="s21">L</span><span class="p">(</span><span class="s21">x</span><span class="s36">i</span><span class="s47">,</span><span class="s21">D</span><span class="p">)</span></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 108%;text-align: justify;">其中<span class="s21">L</span>(<span class="s21">x</span><span class="s36">i</span>,<span class="s21">D</span>)是学习器在从训练数据<span class="s21">D</span>上学习后赋予新实例<span class="s21">x</span><span class="s36">i</span>的分类，而<span class="s21">X</span>为整个实例空 间。注意第一个表达式是为了描述我们希望学习器输出的假设，而第二个表达式是为了描述 学习器从训练数据中泛化的策略。设计一学习器，其归纳偏置<span class="s21">B</span><span class="s36">bias</span>等于所提供的背景知识<span class="s21">B</span>。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s8" style="padding-left: 5pt;text-indent: 0pt;line-height: 24pt;text-align: center;">第<span class="h1">11</span>章 分析学习</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 112%;text-align: justify;">神经网络和决策树这样的学习方法需要一定数目的训练样例，以达到一定级别的泛化精 度。前面章节讨论的理论界限和实验结果反映出了这一事实。分析学习使用先验知识和演绎推 理来扩大训练样例提供的信息，因此它不受同样的界限所制约。本章考虑了一种称为基于解释 的学习（<span class="s6">EBL</span>）的分析学习方法。在基于解释的学习中，先验知识用于分析（或者解释）观察 到的学习样例是怎样满足目标概念的。然后这个解释被用于区分训练样例中哪些是相关的特 征，哪些是不相关的。这样样例就可基于逻辑推理进行泛化，而不是基于统计推理。基于解释 的学习已被成功地用于在各种规划和调度任务中学习搜索控制规则。本章考虑学习器的先验知 识正确并且完整时的基于解释的学习。下一章考虑先验知识只是近似正确时，将归纳学习和分 析学习结合起来。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">11.1 <span class="s17">介绍</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 112%;text-align: justify;">前面章节已考虑了各种归纳法，即通过确定能够经验地区分正例和反例的特征，来从观察 到的训练样例中泛化。决策树学习、神经网络学习、归纳逻辑编程、以及遗传算法是以这种方 式操作的归纳学习方法。这些归纳学习器在实践中的一个关键限制在于，它们在可用数据不足 时性能较差。实际上，如第 <span class="s6">7 </span>章所讨论的，理论分析显示从给定数目的训练样例中学习在精度 上存在基本的上下界。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 112%;text-align: justify;">是否能开发出这样的学习方法，它们不受可用训练数据的数量所带来的训练精度上的基本 限制所制约？答案是肯定的，只要我们能重新考虑一下学习问题的形成。一种办法是使学习算 法能接受显式的先验知识，加上训练数据的一同作为输入。基于解释的学习是这样的一种方 法。它使用先验知识来分析或解释每个训练样例，以推理出样例的哪些特征与目标函数相关， 哪些不相关。这些解释能使学习器比单独依靠数据进行泛化有更高的精度。如前一章所见到的 那样，归纳逻辑系统（如 <span class="s6">Cigol</span>）使用先验背景知识来指导学习。然而它们使用背景知识推理 出的特征扩大了输入实例的描述，因此增加了待搜索假设空间的复杂度。相反，基于解释的学 习使用先验知识来减小待搜索假设空间的复杂度，因此减小了样本复杂度并提高了学习器的泛 化精度。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 111%;text-align: justify;">为理解基于解释的学习的直观意义，考虑下国际象棋的学习任务。确切地讲，假定我们希 望程序学习识别棋局位置的重要类别，比如目标概念“黑棋将在两步内丢后的棋盘状态”。图 <span class="s6">11-1 </span>显示了此目标概念的一个正例。当然，归纳逻辑方法也能用于学习此目标概念。然而，由 于棋盘相当复杂（有 <span class="s6">32 </span>个子，可以在 <span class="s6">64 </span>个方格中），而且此概念所描述的特定模式相当微妙</p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 107%;text-align: left;">（包含了棋盘上不同子的相对位置），我们需要提供成千上万的类似于图 <span class="s6">11-1 </span>这样的训练样 例，才能期望归纳学习到的假设被正确地泛化。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 13pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="569" height="1" alt="image" src="机器学习/Image_397.png"/></span></p><p class="s48" style="padding-left: 15pt;text-indent: 0pt;text-align: left;">插图——原书页码： <span class="s21">308</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 14pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="553" height="1" alt="image" src="机器学习/Image_398.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 84pt;text-indent: 0pt;text-align: left;">图 <span class="h4">11-1 </span>目标概念“黑棋在两步内丢后的棋盘状态”的一个正例。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-left: 58pt;text-indent: 0pt;text-align: left;">注意白马同时攻击黑王和黑后。黑棋必须移动其王，从而白棋能吃掉黑后。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 111%;text-align: justify;">学习下棋任务的有趣之处在于，人类只要少数的训练样例就可学习到这样的目标概念。实 际上，多数人在看了图 <span class="s6">11-1 </span>这样一个样例之后就可提出一个目标概念的一般假设，如“黑后 和黑王同时被攻击的情况”，而不会得到诸如这样的假设（但也同样是一致假设）：“四个白 兵还在原位的棋盘状态”。人类是怎样从仅仅一个样例中成功地泛化的呢？</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 112%;text-align: justify;">回答是人类非常依赖于以他们关于棋子合法移动的先验知识来解释或分析训练样例。如果 问为什么图 <span class="s6">11-1 </span>的训练样例是“黑棋在两步内丢后”的正例，多数人会给出类似于下面的解 释：“因为白马同时攻击黑王和黑后，黑必须摆脱被将军的境遇，从而让白吃掉后。”该解释 的重要性在于它提供了所需的信息以从训练样例的细节中合理泛化到正确的一般假设。此解释 中提到的样例特征（如白马、黑王、黑后的位置）是与目标概念相关的，并且应该被包含在一 般假设中。相反，解释中没有提到的样例特征（如白棋的兵的状态）可被认为是不相关的细 节。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 113%;text-align: justify;">在此下棋例子中，学习器为建立假设，它需要的先验知识究竟是什么呢？很简单，是下棋 的合法规则：即马以及其他子的合法移动；对弈者必须交替移子；以及要赢棋必须捉住对方的 王。注意只给定这样的先验知识，在原则上就有可能对任意棋盘状态计算出最优的棋子移动。 然而，实践中这样的计算可能极为复杂，而且即使我们人类在掌握了此完整的下棋知识，仍不 能达到最优的对弈。因此，在下棋（以及其他搜索密集的问题，如调度和规划）这样的人类学 习中，包含了一个很长的发现先验知识的过程，它是由我们在下棋时遇到的特定样例所引导 的。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 111%;text-align: justify;">本章描述了能自动建立和学习这样的解释的学习算法。本章的剩余部分将更精确地定义分 析学习问题。下一节给出了一个特定的基于解释的学习算法，称为 <span class="s6">Prolog-EBG</span>。后续几节考 查了这种算法的一般特性，以及它与前面章节中讨论的归纳学习算法之间的联系。最后一节描 述了应用基于解释的学习以提高大状态空间搜索的性能。本章我们考虑了一种特殊情况，即生 成解释所基于的先验知识是完全正确的，如在下棋例子中人类有正确知识的情形。第 <span class="s6">12 </span>章将 考虑更一般的学习情况，即先验知识只是近似正确的情况。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">11.1.1 <span class="s25">归纳和分析学习问题</span></h3><p style="padding-top: 10pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">分析和归纳学习问题的重要区别在于，它们设想的学习问题的形式不同：</p><p class="s21" style="padding-top: 6pt;padding-left: 49pt;text-indent: -21pt;line-height: 92%;text-align: left;"><span class="s10"> </span><span class="p">在归纳学习中，学习器被给予一个假设空间</span>H<span class="p">，它必须从中选择一个输出假设。还 有一个训练样例集合</span>D<span class="s6">={&lt;</span>x<span class="s35">1</span><span class="s6">, </span>f<span class="s6">(</span>x<span class="s35">1</span><span class="s6">)&gt;, …&lt;</span>x<span class="s36">n</span><span class="s6">, </span>f<span class="s6">(</span>x<span class="s36">n</span><span class="s6">)&gt;}</span><span class="p">，其中</span>f<span class="s6">(</span>x<span class="s36">i</span><span class="s6">)</span><span class="p">为实例</span>x<span class="s36">i</span><span class="p">的目标值。学 习器所希望的输出为</span>H<span class="p">中与这些训练样例一致的假设</span>h<span class="p">。</span></p><p style="padding-top: 1pt;padding-left: 55pt;text-indent: -21pt;line-height: 94%;text-align: left;"><span class="s10"> </span>在分析学习中，学习器的输入包含与归纳学习同样的假设空间 <span class="s21">H </span>和训练样例 <span class="s21">D</span>。 学习器还有另一输入：一个领域理论<span class="s6">(domain theory)</span><span class="s21">B</span>，它由可用于解释训练样例 的背景知识组成。学习器的希望的输出为 <span class="s21">H </span>中的假设 <span class="s21">h</span>，它既与训练样例 <span class="s21">D </span>一 致，也与领域理论 <span class="s21">B </span>一致。</p><p style="padding-top: 7pt;padding-left: 11pt;text-indent: 20pt;line-height: 106%;text-align: justify;">为说明这一点，在下棋的例子中每个实例<span class="s21">x</span><span class="s36">i</span>可描述一特定棋盘状态，<span class="s21">f</span><span class="s6">(</span><span class="s21">x</span><span class="s36">i</span><span class="s6">)</span>的值在<span class="s21">x</span><span class="s36">i</span>是黑棋在 两步内丢后的棋盘状态时为真，否则为假。我们可如第 <span class="s6">10 </span>章那样定义假设空间<span class="s21">H</span>为<span class="s6">Horn</span>子句 集（即<span class="s6">if-then </span>规则），其中规则所使用的谓词表示棋盘上特定子的位置或相对位置。领域理论 <span class="s21">B</span>可由形式化的下棋规则组成，描述了合法的走棋、对弈者轮流行棋、以及捉住住对方王时获 胜等。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 11pt;text-indent: 21pt;line-height: 109%;text-align: justify;">注意在分析学习中，学习器必须输出一假设，既与训练数据一致，又与领域理论一致。当 <span class="s21">B </span>不涵蕴 <span class="s21">h </span>的否定时（即 <span class="s21">B</span>├<span class="s6">/</span><span class="s10"> </span><span class="s21">h</span>），我们称 <span class="s21">h </span>与领域理论 <span class="s21">B </span>一致（<span class="s6">consistent</span>）。此附加的一致 性约束，减少了当数据不能单独在 <span class="s21">H </span>中决定 <span class="s21">h </span>时学习器面临的歧义性。如果领域理论正确，其 最后效果就是提高了输出假设的精度。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 11pt;text-indent: 21pt;line-height: 109%;text-align: justify;"><span class="p">现详细介绍一下本章后面一直用到的分析学习问题的另一个例子。考虑一实例空间 </span>X<span class="p">，其 中每个实例都是一对物理对象。每对物理对象由谓词 </span>Color<span class="s6">, </span>Volume<span class="s6">, </span>Owner<span class="s6">, </span>Material<span class="s6">, </span>Type <span class="p">和 </span>Density <span class="p">描述，而两个对象之间的关系用谓词 </span>On <span class="p">描述。在此假设空间中，学习任务是学习目标 概念“两个物理对象，一个可被安全地叠放在另一个上”，表示为谓词 </span>SafeToStack<span class="s6">(</span>x<span class="s6">,</span>y<span class="s6">)</span><span class="p">。学习 此目标概念有实用的价值，例如一个机器人系统要在一有限空间中存放不同的物理对象。此分 析学习的完整定义在表 </span><span class="s6">11-1 </span><span class="p">中给出。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><h4 style="padding-left: 136pt;text-indent: 0pt;text-align: left;"><span class="p">表 </span>11-1 <span class="p">一个分析学习问题：</span><i>SafeToStack</i>(<i>x</i>, <i>y</i>)</h4><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 2pt;text-align: left;"><span><img width="570" height="2" alt="image" src="机器学习/Image_399.png"/></span></p><p class="s14" style="padding-left: 12pt;text-indent: 0pt;text-align: left;">已知：</p><p class="s56" style="padding-top: 5pt;padding-left: 33pt;text-indent: -21pt;line-height: 12pt;text-align: left;"><span class="s55">n </span><span class="s14">实例空间 </span>X<span class="s14">：每个实例描述了一对对象，描述为谓词 </span>Type<span class="s16">, </span>Color<span class="s16">, </span>Volume<span class="s16">, </span>Owner<span class="s16">, </span>Material<span class="s16">, </span>Density <span class="s14">和 </span>On<span class="s14">。</span></p><p class="s14" style="padding-top: 3pt;padding-left: 33pt;text-indent: -21pt;line-height: 94%;text-align: justify;"><span class="s55">n </span>假设空间 <span class="s56">H </span>：每个假设是一组 <span class="s16">Horn </span>子句规则。每个 <span class="s16">Horn </span>子句的头部为一个包含目标谓词 <span class="s56">SafeToStack </span>的文字。<span class="s16">Horn </span>子句体为文字的合取，这些文字基于描述实例的谓词，以及谓词 <span class="s56">LessThan</span><span class="s16">, </span><span class="s56">Equal</span><span class="s16">, </span><span class="s56">GreaterThan </span>和函数 <span class="s56">plus</span><span class="s16">, </span><span class="s56">minus </span>和 <span class="s56">times</span>。例如下面的 <span class="s16">Horn </span>子句是假设空间中的一员：</p><p class="s56" style="padding-top: 3pt;padding-left: 92pt;text-indent: 0pt;text-align: left;">SafeToStack<span class="s16">(</span>x<span class="s16">, </span>y<span class="s16">)</span><span class="s14">←</span>Volume<span class="s16">(</span>x<span class="s16">, </span>vx<span class="s16">)</span><span class="s14">∧</span>Volume<span class="s16">(</span>y<span class="s16">, </span>vy<span class="s16">) </span><span class="s14">∧</span>LessThan<span class="s16">(</span>vx<span class="s16">, </span>vy<span class="s16">)</span></p><p class="s56" style="padding-top: 3pt;padding-left: 11pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span><span class="s14">目标概念：</span>SafeToStack<span class="s16">(</span>x<span class="s16">,</span>y<span class="s16">)</span></p><p class="s56" style="padding-top: 3pt;padding-left: 33pt;text-indent: -21pt;line-height: 136%;text-align: left;"><span class="s55">n </span><span class="s14">训练样例：下面显示了一个典型的正例 </span>SafeToStack<span class="s16">(</span>Obj<span class="s16">1, </span>Obj<span class="s16">2)</span><span class="s14">： </span>On<span class="s16">(</span>Obj<span class="s16">1, </span>Obj<span class="s16">2) </span>Owner<span class="s16">(</span>Obj<span class="s16">1, </span>Fred<span class="s16">)</span></p><p class="s56" style="padding-left: 33pt;text-indent: 0pt;text-align: left;">Type<span class="s16">(</span>Obj<span class="s16">1, </span>Box<span class="s16">) </span>Owner<span class="s16">(</span>Obj<span class="s16">2, </span>Louise<span class="s16">)</span></p><p class="s56" style="padding-top: 4pt;padding-left: 33pt;text-indent: 0pt;text-align: left;">Type<span class="s16">(</span>Obj<span class="s16">2, </span>Endtable<span class="s16">) </span>Density<span class="s16">(</span>Obj<span class="s16">1, 0.3)</span></p><p class="s56" style="padding-top: 4pt;padding-left: 33pt;text-indent: 0pt;text-align: left;">Color<span class="s16">(</span>Obj<span class="s16">1, </span>Red<span class="s16">) </span>Material<span class="s16">(</span>Obj<span class="s16">1, </span>Cardboard<span class="s16">)</span></p><p class="s56" style="padding-top: 4pt;padding-left: 33pt;text-indent: 0pt;line-height: 139%;text-align: left;">Color<span class="s16">(</span>Obj<span class="s16">2, </span>Blue<span class="s16">) </span>Material<span class="s16">(</span>Obj<span class="s16">2, </span>Wood<span class="s16">) </span>Volume<span class="s16">(</span>Obj<span class="s16">1, 2)</span></p><p class="s14" style="padding-left: 11pt;text-indent: 0pt;line-height: 11pt;text-align: left;"><span class="s55">n </span>领域理论 <span class="s56">B</span>：</p><p class="s56" style="padding-top: 3pt;padding-left: 33pt;text-indent: 0pt;line-height: 125%;text-align: left;">SafeToStack<span class="s16">(</span>x<span class="s16">, </span>y<span class="s16">)</span><span class="s14">←</span><span class="s57"></span>Fragile<span class="s16">(</span>y<span class="s16">) </span>SafeToStack<span class="s16">(</span>x<span class="s16">, </span>y<span class="s16">) </span><span class="s14">←</span>Lighter<span class="s16">(</span>x<span class="s16">, </span>y<span class="s16">)</span></p><p class="s56" style="padding-left: 33pt;text-indent: 0pt;text-align: left;">Lighter<span class="s16">(</span>x<span class="s16">, </span>y<span class="s16">) </span><span class="s14">←</span>Weight<span class="s16">(</span>x<span class="s16">, </span>wx<span class="s16">) </span><span class="s14">∧</span>Weight<span class="s16">(</span>y<span class="s16">, </span>wy<span class="s16">) </span><span class="s14">∧</span>LessThan<span class="s16">(</span>wx<span class="s16">, </span>wy<span class="s16">)</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 2pt;text-align: left;"><span><img width="570" height="2" alt="image" src="机器学习/Image_400.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 2pt;text-align: left;"><span><img width="570" height="2" alt="image" src="机器学习/Image_401.png"/></span></p><p class="s56" style="padding-left: 33pt;text-indent: 0pt;line-height: 126%;text-align: left;">Weight<span class="s16">(</span>x<span class="s16">, </span>w<span class="s16">) </span><span class="s14">←</span>Volume<span class="s16">(</span>x<span class="s16">, </span>v<span class="s16">) </span><span class="s14">∧</span>Density<span class="s16">(</span>x<span class="s16">, </span>d<span class="s16">)</span><span class="s14">∧</span>Equal<span class="s16">(</span>w<span class="s16">, </span>times<span class="s16">(</span>v<span class="s16">, </span>d<span class="s16">)) </span>Weight<span class="s16">(</span>x<span class="s16">, 5) </span><span class="s14">←</span>Type<span class="s16">(</span>x<span class="s16">, </span>Endtable<span class="s16">)</span></p><p class="s56" style="padding-left: 33pt;text-indent: 0pt;text-align: left;">Fragile<span class="s16">(</span>x<span class="s16">) </span><span class="s14">←</span>Material<span class="s16">(</span>x<span class="s16">, </span>Glass<span class="s16">)</span></p><p class="s16" style="padding-top: 4pt;padding-left: 33pt;text-indent: 0pt;text-align: left;">…</p><p class="s14" style="padding-top: 2pt;padding-left: 11pt;text-indent: 0pt;text-align: left;">求解：</p><p class="s55" style="padding-top: 3pt;padding-left: 11pt;text-indent: 0pt;text-align: left;">n <span class="s56">H </span><span class="s14">中一个假设，与训练样例和领域理论一致。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 2pt;text-align: left;"><span><img width="570" height="2" alt="image" src="机器学习/Image_402.png"/></span></p><p style="padding-top: 6pt;padding-left: 11pt;text-indent: 21pt;line-height: 107%;text-align: justify;">如表 <span class="s6">11-1 </span>所示，我们选定的假设空间 <span class="s21">H </span>中每个假设为一个一阶 <span class="s6">if-then </span>规则集，或称 <span class="s6">Horn </span>子句（本章中遵循表 <span class="s6">10-3 </span>中列出的一阶 <span class="s6">Horn </span>子句的记号和术语）。例如，表中显示的 <span class="s6">Horn </span>子句假设的例子断言：当 <span class="s21">x </span>的体积 <span class="s21">Volume </span>小于（<span class="s21">LessThan </span>）<span class="s21">y </span>的体积 <span class="s21">Volume </span>时（在 <span class="s6">Horn </span>子句 中变量 <span class="s21">vx </span>和 <span class="s21">vy </span>分别表示 <span class="s21">x </span>和 <span class="s21">y </span>的体积值），则对象 <span class="s21">x </span>可安全堆叠（<span class="s21">SafeToStack</span>）在对象 <span class="s21">y </span>上。 注意 <span class="s6">Horn </span>子句假设可包含用于描述实例的任意谓词，以及几个附加的谓词和函数。表中还显 示了一个典型的正例 <span class="s21">SafeToStack</span><span class="s6">(</span><span class="s21">obj</span><span class="s6">1, </span><span class="s21">obj</span><span class="s6">2)</span>。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 11pt;text-indent: 21pt;line-height: 110%;text-align: justify;">为明确地表达此分析学习问题，还必须提供领域理论，以充分解释为什么观察到的正例满 足目标概念。在前面的下棋例子里，领域理论为棋子走法的知识，从中我们建立出为什么黑棋 会丢后的解释。在当前例子中，领域理论必须很容易解释为什么一个对象可放在另一个之上。 表中显示的领域理论包括断言：“可将 <span class="s21">x </span>安全地叠放在 <span class="s21">y </span>上，如果 <span class="s21">y </span>不是易碎的（<span class="s21">Fragile</span>）” 以及“对象 <span class="s21">x </span>是易碎的<span class="s6">(</span><span class="s21">Fragile</span><span class="s6">)</span>，当 <span class="s21">x </span>的材质<span class="s6">(</span><span class="s21">Material</span><span class="s6">)</span>是玻璃（<span class="s21">Glass</span>）时。”如学习到的假设 一样，领域理论由一组 <span class="s6">Horn </span>子句描述，它使系统原则上可以加入任何学习到的假设至后续的 领域理论中。注意领域理论包括如 <span class="s21">Lighter </span>和 <span class="s21">Fragile </span>这样的附加谓词，它们不在训练样例的描 述中，但是由更原子的实例属性如 <span class="s21">Material</span><span class="s6">, </span><span class="s21">Density </span>和 <span class="s21">Volume </span>使用领域理论中其他规则推理得 出。最后，注意表中显示的领域理论充分证明这里显示的正例满足目标概念 <span class="s21">SafeToStack</span>。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 12pt;text-indent: 0pt;text-align: left;">11.2 <span class="s17">用完美的领域理论学习：</span>Prolog-EBG</h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 12pt;text-indent: 21pt;line-height: 113%;text-align: justify;">如前所述，本章主要考虑的基于解释的学习是在领域理论很完美的情况下的，即领域理论 是正确的并且完整的。一个领域理论被称为正确的，当其中每个断言都是世界的真实描述。一 个领域理论被称为完整的（对应给定的目标概念和实例空间），当领域理论覆盖了实例空间中 所有正例。换言之，其完整性说明每个满足目标概念的实例都可由领域理论证明其满足性。注 意前面对完整性的定义不要求领域理论可证明反例不满足目标概念。然而，如果遵循通常 <span class="s6">Prolog </span>惯例，不能证明的断言可认定是假。因此该完整性定义可包含全部正例和反例。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 12pt;text-indent: 21pt;line-height: 113%;text-align: justify;">读者在此可能会问，对于学习器假定有这样的完美领域理论是否合理？而且，既然学习器 有了一个完美的领域理论，还有何必要再去学习？对于此问题可按以下两点回答：</p><p style="padding-top: 4pt;padding-left: 55pt;text-indent: -21pt;text-align: left;"><span class="s10"> </span>首先，某些情形下是有可能提供完美领域理论的。前面的下棋的问题就是这样的 一个例子，其中棋子的合法走子形成了一个完美的领域理论，（原则上）可用它 来推理最优的下棋策略。更进一步，虽然很容易写出构成领域理论的棋子合法步 子，要写出最优下棋策略仍然很难。在这种情况下，我们更希望将这样的领域理 论提供给学习器，并希望学习器形成目标概念的有帮助的描述（如：“可能丢后 的棋局状态”）。方法是通过对特殊训练样例进行考查和泛化。<span class="s6">11.4 </span>节描述了使用</p><p style="padding-top: 1pt;padding-left: 55pt;text-indent: 0pt;line-height: 14pt;text-align: left;">完美领域理论的基于解释的学习成功地应用到几个搜索密集的计划和优化问题 中，以自动改进性能。</p><p style="padding-left: 55pt;text-indent: -21pt;line-height: 94%;text-align: left;"><span class="s10"> </span>第二，在许多情况下不能够假定有完美的领域理论。比如很难为前面这个相对简 单的 <span class="s21">SafeToStack </span>问题给出完整而正确的领域理论。更实际的方法是假定必须使用 基于不完美领域理论的近似合理的解释，而不是基于完美知识作出确切证明。无</p><p style="padding-left: 55pt;text-indent: 0pt;text-align: left;">论怎样，我们可以通过考虑理想情况下的完美领域理论，开始了解在学习中使用 解释的目的。第 <span class="s6">12 </span>章我们将考虑从不完美领域理论中学习。</p><p style="padding-top: 7pt;padding-left: 11pt;text-indent: 21pt;line-height: 107%;text-align: justify;">本节展示了一个称为 <span class="s6">Prolog-EBG </span>的算法 <span class="s6">(Kedar-Cabelli &amp; McCarty 1987)</span>，使用它作为几种 基于解释的学习的代表。<span class="s6">Prolog-EBG </span>是一序列覆盖算法（见第 <span class="s6">10 </span>章）。换言之，它的过程是 学习单个 <span class="s6">Horn </span>子句规则，移去此规则覆盖的正例，再在剩余正例上重复这一过程，直到没有 未覆盖的正例为止。若给定一完整并正确的领域理论，<span class="s6">Prolog-EBG </span>保证输出一个假设（规则 集），它本身是正确的并能覆盖观察到的正例。对任意正例集合，由 <span class="s6">Prolog-EBG </span>输出的假设 包含一组对应于领域理论的目标概念的逻辑充分条件。<span class="s6">Prolog-EBG </span>是 <span class="s6">Mitchell et al.</span>（<span class="s6">1986</span>）介 绍的 <span class="s6">EBG </span>算法的改进，并且类似于 <span class="s6">Dejong &amp; Mooney</span>（<span class="s6">1986</span>）描述的 <span class="s6">EGGS </span>算法。<span class="s6">Prolog- EBG </span>算法在表 <span class="s6">11-2 </span>中列出。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 12pt;text-indent: 0pt;text-align: left;">11.2.1 <span class="s25">运行示例</span></h3><p style="padding-top: 10pt;padding-left: 12pt;text-indent: 20pt;line-height: 107%;text-align: justify;">为说明该算法，再次考虑表 <span class="s6">11-1 </span>给出的训练样例和领域理论。表 <span class="s6">11-2 </span>列出的 <span class="s6">Prolog-EBG </span>算法是一序列覆盖算法，它渐进地考虑训练数据。对每个新正例，若它还没被一学到的 <span class="s6">Horn </span>子句覆盖，算法通过下列步骤生成一新的 <span class="s6">Horn </span>子句：（<span class="s6">1</span>）解释新的正例，（<span class="s6">2</span>）分析该解释 以确定一合适的泛化，（<span class="s6">3</span>）通过加入一新的 <span class="s6">Horn </span>子句以覆盖该正例以及其他相似实例改进当 前假设。下面我们依次考查这三个步骤。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s37" style="padding-left: 12pt;text-indent: 0pt;text-align: left;">11.2.1.1 <span class="s20">解释训练样例</span></p><p style="padding-top: 8pt;padding-left: 12pt;text-indent: 21pt;line-height: 110%;text-align: justify;">处理每个新样例的第一步是按照领域理论建立一解释，以说明该正例如何满足目标概念。 当领域理论正确且完整时，此解释组成了训练样例满足目标概念的一个证明（<span class="s6">proof</span>）。如果 先验知识不完美，解释中的记号必须被扩展以允许近似的参数，而不是完美的证明。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 145pt;text-indent: 0pt;text-align: left;">表 <span class="h4">11-2 </span>基于解释的学习算法 <span class="h4">Prolog-EBG</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s16" style="padding-left: 64pt;text-indent: 0pt;text-align: left;"><span class="s14">对每个还没被学习到的 </span>Horn <span class="s14">子句集</span>(<i>LearnedRules</i>)<span class="s14">覆盖的正例，建立一个新 </span>Horn <span class="s14">子句。该新的</span></p><p class="s16" style="padding-top: 3pt;padding-left: 43pt;text-indent: 0pt;text-align: left;">Horn <span class="s14">子句的创建是通过（</span>1<span class="s14">）按领域理论解释训练样例，（</span>2<span class="s14">）分析此解释以确定样例的相关特征，</span></p><p class="s14" style="padding-top: 3pt;padding-left: 12pt;text-indent: 31pt;text-align: left;">（<span class="s16">3</span>）建立一新的 <span class="s16">Horn </span>子句，它在该组特征满足时得到目标概念。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 2pt;text-align: left;"><span><img width="570" height="2" alt="image" src="机器学习/Image_403.png"/></span></p><p class="s16" style="padding-top: 1pt;padding-left: 12pt;text-indent: 0pt;text-align: left;">Prolog-EBG(<i>TargetConcept</i>, <i>TrainingExamples</i>, <i>DomainTheory</i>)</p><p class="s55" style="padding-top: 2pt;padding-left: 12pt;text-indent: 0pt;text-align: left;">n <span class="s56">LearnedRules</span><span class="s14">←</span><span class="s16">{}</span></p><p class="s56" style="padding-top: 3pt;padding-left: 12pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span>Pos<span class="s14">←</span>TrainingExamples <span class="s14">中的正例</span></p><p class="s14" style="padding-top: 3pt;padding-left: 12pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span>对 <span class="s56">Pos </span>中没有被 <span class="s56">LearnedRules </span>覆盖的每个 <span class="s56">PositiveExample</span>，做以下操作：</p><p class="s16" style="padding-top: 3pt;padding-left: 12pt;text-indent: 0pt;text-align: left;">1. <span class="s14">解释</span></p><ul id="l31"><li style="padding-top: 3pt;padding-left: 33pt;text-indent: 0pt;text-align: left;"><p class="s56" style="display: inline;">Explanation <span class="s14">←一个以 </span>DomainTheory  <span class="s14">表示的解释（证明 ），说明为 何 </span>PositiveExample  <span class="s14">满足 </span></p><p class="s56" style="padding-left: 33pt;text-indent: 0pt;text-align: left;">TargetConcept</p><p class="s16" style="padding-top: 2pt;padding-left: 12pt;text-indent: 0pt;text-align: left;">2. <span class="s14">分析</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 2pt;text-align: left;"><span><img width="570" height="2" alt="image" src="机器学习/Image_404.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 2pt;text-align: left;"><span><img width="570" height="2" alt="image" src="机器学习/Image_405.png"/></span></p></li><li style="padding-top: 1pt;padding-left: 33pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><p class="s56" style="display: inline;">SuffcientConditions<span class="s14">←按照 </span>Explanation<span class="s14">，能够充分满足 </span>TargetConcept <span class="s14">的 </span>PositiveExample <span class="s14">的最一般 特征集合</span></p><p class="s16" style="padding-top: 2pt;padding-left: 12pt;text-indent: 0pt;text-align: left;">3. <span class="s14">改进</span></p></li><li style="padding-top: 3pt;padding-left: 48pt;text-indent: -14pt;text-align: left;"><p class="s56" style="display: inline;">LearnedRules<span class="s14">←</span>LearnedRules<span class="s16">+</span>NewHornClause<span class="s14">，其中 </span>NewHornClause <span class="s14">形式为：</span></p></li></ul><p class="s56" style="padding-top: 3pt;padding-left: 146pt;text-indent: 0pt;text-align: center;">TargetConcept<span class="s14">←</span>SufficientConditions</p><p class="s55" style="padding-top: 3pt;padding-left: 12pt;text-indent: 0pt;text-align: left;">n <span class="s14">返回 </span><span class="s56">LearnedRules</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 2pt;text-align: left;"><span><img width="570" height="2" alt="image" src="机器学习/Image_406.png"/></span></p><p style="padding-top: 6pt;padding-left: 11pt;text-indent: 21pt;line-height: 107%;text-align: justify;">对当前样例的解释见图 <span class="s6">11-2 </span>。注意其中底部的图形代表了表 <span class="s6">11-1 </span>中 的正例 <span class="s21">SafeToStack</span><span class="s6">(</span><span class="s21">Obj</span><span class="s6">1, </span><span class="s21">Obj</span><span class="s6">2)</span>。图中上部为对此样例构造的解释。注意此解释（或称证明）说明因为 <span class="s21">Obj</span><span class="s6">1 </span>比 <span class="s21">Obj</span><span class="s6">2 </span>更 轻（<span class="s21">Lighter</span>），所以 <span class="s21">Obj</span><span class="s6">1 </span>可以安全堆叠（<span class="s21">SafeToStack</span>）在 <span class="s21">Obj</span><span class="s6">2 </span>上。更进一 步，知道 <span class="s21">Obj</span><span class="s6">1 </span>更轻是因为它的重量（<span class="s21">Weight</span>）可以由其密度（<span class="s21">Density</span>）和体积（<span class="s21">Volume</span>）推 得，而且 <span class="s21">Obj</span><span class="s6">2 </span>的 重量（<span class="s21">Weight</span>）可从茶几（<span class="s21">Endtable</span>）的默认的重量（<span class="s21">Weight</span>）值得出。此解 释基于的特定 <span class="s6">Horn </span>子句在表 <span class="s6">11-1 </span>的领域理论中显示出。注意此解释只提到了 <span class="s21">Obj</span><span class="s6">1 </span>和 <span class="s21">Obj</span><span class="s6">2 </span>的 属性中的一小部分（即对应于图中阴影区域的属性）。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 11pt;text-indent: 21pt;line-height: 111%;text-align: justify;">虽然这里对于训练样例和领域理论只有一种解释，一般情况下可能有多种解释。这样，这 些解释中任意的或所有的都可被使用。每个解释可对训练样例形成不同的泛化，但所有解释都 将被给定的领域理论论证。在 <span class="s6">Prolog-EBG </span>中，解释的生成使用了如 <span class="s6">Prolog </span>中的后向链式搜 索。<span class="s6">Prolog-EBG </span>如 <span class="s6">Prolog </span>一样，在它找到第一个有效证明时终止。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s37" style="padding-left: 11pt;text-indent: 0pt;text-align: left;">11.2.1.2 <span class="s20">分析解释</span></p><p class="s21" style="padding-top: 8pt;padding-left: 11pt;text-indent: 21pt;line-height: 110%;text-align: justify;"><span class="p">在泛化训练样例时面临的关键问题是“在当前样例中许多正好为真的特征中，哪一个是在 一般情况下与目标概念相关的？”由学习器构造的解释对此问题作出了直接的回答：正好是那 些在解释中提及的特征。例如，图 </span><span class="s6">11-2 </span><span class="p">的解释包含了 </span>Obj<span class="s6">1 </span><span class="p">的 </span>Density<span class="p">，但没有它的 </span>Owner <span class="p">属 性。因此，</span>SafeToStack<span class="s6">(</span>x<span class="s6">,</span>y<span class="s6">)</span><span class="p">的假设应包含 </span>Density<span class="s6">(</span>x<span class="s6">,0.3)</span><span class="p">，而不包含 </span>Owner<span class="s6">(</span>x<span class="s6">,</span>Fred<span class="s6">)</span><span class="p">。通过收集图 </span><span class="s6">11-2 </span><span class="p">中解释的叶结点中提及的特征，并将 </span>Obj<span class="s6">1 </span><span class="p">和 </span>Obj<span class="s6">2 </span><span class="p">替换为 </span>x <span class="p">和 </span>y<span class="p">，可形成一个由领域理论 论证的一般规则。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s107" style="padding-top: 3pt;padding-left: 21pt;text-indent: 45pt;text-align: left;">SafeToStack <span class="s108">(</span>x<span class="s108">, </span>y<span class="s108">) </span><span class="s109"> </span>Volume<span class="s108">(</span>x<span class="s108">,2) </span><span class="s109"> </span>Density <span class="s108">(</span>x<span class="s108">,0.3) </span><span class="s109"> </span>Type<span class="s108">( </span>y<span class="s108">, </span>Endtable<span class="s108">)</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 19pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="569" height="1" alt="image" src="机器学习/Image_407.png"/></span></p><p class="s48" style="padding-left: 21pt;text-indent: 0pt;text-align: left;">插图——原书页码： <span class="s21">315</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-top: 1pt;padding-left: 33pt;text-indent: 0pt;text-align: left;">Explanation: <span class="p">解释</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 33pt;text-indent: 0pt;text-align: left;">Training Example: <span class="p">训练样例</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 20pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="553" height="1" alt="image" src="机器学习/Image_408.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 150pt;text-indent: 0pt;text-align: center;">图 <span class="h4">11-2 </span>训练样例的解释</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s16" style="padding-left: 43pt;text-indent: 21pt;line-height: 125%;text-align: justify;"><span class="s14">下部的网络以图形绘出了表 </span>11-1 <span class="s14">中的训练样例 </span><i>SafeToStack</i>(<i>Obj</i>1,<i>Obj</i>2)<span class="s14">。图上面部分绘出了此样 例怎样满足目标概念 </span><i>SafeToStack </i><span class="s14">的解释。训练样例中的阴影部分表示在解释中用到的样例属性。其他 不相关的样例属性将从形成的泛化假设中去掉。</span></p><p class="s21" style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;"><span class="p">上面的规 则体包含 了证明树 中每个叶 结点，除 了“ </span>Equal<span class="s6">(0.6, </span>times<span class="s6">(2,0.3)) </span><span class="p">”和 “</span>LessThan<span class="s6">(0.6, 5)</span><span class="p">”之外。去掉这两个是因为根据定义它们总是被满足的，与 </span>x <span class="p">和 </span>y <span class="p">无关。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 113%;text-align: justify;">连同此学到的规则一起，程序还可以提供其论证：对训练样例的解释形成了对此规则正确 性的证明。虽然此解释是为了覆盖观察到的训练样例而形成，同样的解释将适用于任何与此一 般规则匹配的实例。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 109%;text-align: justify;">上面的规则构成了此训练样例的一个很有意义的泛化，因为它去除了样例的许多与目标概 念无关属性（如两个对象的 <span class="s21">Color</span>），然而通过对解释更仔细地分析可以得到更一般的规则。 <span class="s6">Prolog-EBG </span>可计算能由解释论证的最一般的规则，方法通过计算解释的最弱前像（<span class="s6">weakest preimage</span>），定义如下：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 48pt;text-indent: -21pt;line-height: 107%;text-align: left;">定义： 结论 <span class="s21">C </span>对应于证明 <span class="s21">P </span>的最弱前像（<span class="s6">weakest preimage</span>）为最一般的初始断言集 合 <span class="s21">A</span>，使得 <span class="s21">A </span>按照 <span class="s21">P </span>涵蕴 <span class="s21">C</span>。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;"><span class="p">例如，目标概念 </span><i>SafeToStack</i>(<i>x</i>,<i>y</i>)<span class="p">对应表 </span>11-1 <span class="p">解释的最弱前像由下面规则的体给出。这是能 由图 </span>11-2 <span class="p">的解释论证的最一般规则：</span></p><p class="s21" style="padding-top: 6pt;padding-left: 76pt;text-indent: 0pt;text-align: left;">SafeToStack<span class="s6">(</span>x<span class="s6">, </span>y<span class="s6">)</span><span class="p">←</span>Volume<span class="s6">(</span>x<span class="s6">, </span>vx<span class="s6">)</span><span class="p">∧</span>Density<span class="s6">(</span>x<span class="s6">,</span>dx<span class="s6">) </span><span class="p">∧</span></p><p class="s21" style="padding-top: 1pt;padding-left: 163pt;text-indent: 0pt;text-align: left;">Equal<span class="s6">(</span>wx<span class="s6">, </span>times<span class="s6">(</span>vx<span class="s6">, </span>dx<span class="s6">)) </span><span class="p">∧</span>LessThan<span class="s6">(</span>wx<span class="s6">,5) </span><span class="p">∧</span></p><p class="s21" style="padding-top: 4pt;text-indent: 0pt;text-align: center;">Type<span class="s6">(</span>y<span class="s6">, </span>Endtable<span class="s6">)</span></p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">注意这个更一般的规则不要求给出 <span class="s21">Volume </span>和 <span class="s21">Density </span>的特定值，而前一个规则需要。它只 是对这此这些属性的值进行更一般的约束。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 5pt;text-indent: 21pt;line-height: 110%;text-align: left;">Prolog-EBG <span class="p">计算目标概念的关于解释的最弱前像的过程，使用的是一称为回归 </span>(regression) <span class="p">的过程（</span>Waldinger 1977<span class="p">）。回归过程针对的是由任意 </span>Horn <span class="p">子句集表示的领域理论。它的工作 方式是在解释中反复地后退，首先对应于解释中最末证明步计算目标概念的最弱前像，然后对 应于其前一步骤计算结果表达式的最弱前像，依此类推。该过程在遍历过解释中所有步骤后终 止，得到对应于解释的叶节点上的文字的目标概念的最弱前件。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 26pt;text-indent: 0pt;text-align: left;">此回归过程的运行步骤见图 <span class="s6">11-3 </span>所示。在此图中，图 <span class="s6">11-2 </span>中出现过的解释以标准字体</p><p class="s21" style="padding-top: 1pt;padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: justify;"><span class="p">（非斜体）重画出。而在每一步由回归过程创建的边缘回归表达式以带下划线的斜体字显示。 此过程开始于树的根部，其边缘被初始化为一般目标概念 </span>SafeToStack<span class="s6">(</span>x<span class="s6">,</span>y<span class="s6">)</span><span class="p">。第一步是计算此边 缘表达式对 应于解释中 最末（最上 面的）推理 规则的最弱 前像。在此 情形下规 则 为 </span>SafeToStack<span class="s6">(</span>x<span class="s6">, </span>y<span class="s6">) </span><span class="p">←</span>Lighter<span class="s6">(</span>x<span class="s6">, </span>y<span class="s6">)</span><span class="p">，因此得到的最弱前像为 </span>Lighter<span class="s6">(</span>x<span class="s6">,</span>y<span class="s6">)</span><span class="p">。然后，通过此解释中下一 </span><span class="s6">Horn </span><span class="p">子句，该过程继续对此新边缘</span><span class="s6">{</span>Lighter<span class="s6">(</span>x<span class="s6">, </span>y<span class="s6">)}</span><span class="p">进行回归，得到回归表达式</span><span class="s6">{</span>Weight<span class="s6">(</span>x<span class="s6">, </span>wx<span class="s6">), </span>LessThan<span class="s6">(</span>wx<span class="s6">, </span>wy<span class="s6">), </span>Weight<span class="s6">(</span>y<span class="s6">, </span>wy<span class="s6">)}</span><span class="p">。此式意味着，对于任意的 </span>x <span class="p">和 </span>y<span class="p">，若 </span>x <span class="p">的重量 </span>wx <span class="p">大于 </span>y <span class="p">的重 量 </span>wy <span class="p">，解释成立。此边缘的回归以此一步步的方式退回到解释的叶结点，最终得到树的叶结 点上的一组泛化文字。此最终的泛化文字集合，如图 </span><span class="s6">11-3 </span><span class="p">底部所示，形成了最终规则的规则 体。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 13pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="569" height="1" alt="image" src="机器学习/Image_409.png"/></span></p><p class="s48" style="padding-left: 15pt;text-indent: 0pt;text-align: left;">插图——原书页码： <span class="s21">317</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 20pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="553" height="1" alt="image" src="机器学习/Image_410.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><h4 style="padding-top: 1pt;padding-left: 64pt;text-indent: 45pt;text-align: left;"><span class="p">图 </span>11-3 <span class="p">计算 </span><i>SafeToStack</i>(<i>Obj</i>1,<i>Obj</i>2)<span class="p">关于解释的最弱前像</span></h4><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-left: 43pt;text-indent: 21pt;line-height: 132%;text-align: justify;">目标概念从解释的根部（结论）开始回归，下降到叶结点。在每一步（由虚线表示），当前文字 集合边缘（带下划线的斜体）在解释的一个规则上被后向回归。当此过程完成时，结果文字合取构成 了对应于解释的目标概念的最弱前像。此最弱前像在图的底部以斜体的文字显示。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 11pt;text-indent: 21pt;line-height: 107%;text-align: justify;">回归过程的核心是，在每一步通过领域理论的一条 <span class="s6">Horn </span>子句回归当前边缘表达式的算 法。此算法在表 <span class="s6">11-3 </span>中描述并例示。表中的范例对应于图 <span class="s6">11-3 </span>中最底部的回归步。如表中显 示的，<span class="s6">Regress </span>算法的操作过程是，寻找一个置换使 <span class="s6">Horn </span>子句的头与边缘中的相应文字合一， 用规则体替换边缘中的此表达式，再应用一个合一置换到整个边缘。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 11pt;text-indent: 21pt;text-align: justify;">由<span class="s6">Prolog-EBG</span>输出的最终<span class="s6">Horn</span>子句形式如下：子句体被定义为上述过程计算出的最弱前 件。子句头为目标概念本身，以及应用到它上的每一回归步中的每个置换（如表 <span class="s6">11-3 </span>中的置 换<span class="s47">θ</span><span class="s36">hl</span>）。应用此置换是为了在创建出的子句头和子句体中保持一致变量名，以及当此解释只 应用于目标概念的特殊情况时特化子句头。如前指出的，对于当前的例子，最终规则为：</p><p class="s21" style="padding-top: 7pt;padding-left: 82pt;text-indent: 0pt;text-align: left;">SafeToStack<span class="s6">(</span>x<span class="s6">, </span>y<span class="s6">)</span><span class="p">←</span>Volume<span class="s6">(</span>x<span class="s6">, </span>vx<span class="s6">)</span><span class="p">∧</span>Density<span class="s6">(</span>x<span class="s6">,</span>dx<span class="s6">) </span><span class="p">∧</span></p><p class="s21" style="padding-top: 1pt;padding-left: 169pt;text-indent: 0pt;text-align: left;">Equal<span class="s6">(</span>wx<span class="s6">, </span>times<span class="s6">(</span>vx<span class="s6">, </span>dx<span class="s6">)) </span><span class="p">∧</span>LessThan<span class="s6">(</span>wx<span class="s6">,5) </span><span class="p">∧</span></p><p class="s21" style="padding-top: 4pt;padding-left: 27pt;text-indent: 0pt;text-align: center;">Type<span class="s6">(</span>y<span class="s6">, </span>Endtable<span class="s6">)</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 128pt;text-indent: 0pt;text-align: left;">表 <span class="h4">11-3 </span>通过一个 <span class="h4">Horn </span>子句回归一组文字的算法</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-left: 43pt;text-indent: 21pt;line-height: 119%;text-align: justify;">由边缘（<span class="s56">Frontier</span>）给出的文字集合通过<span class="s56">Rule</span>被回归。<span class="s56">Literal</span>为此解释中由<span class="s56">Rule</span>推理的<span class="s56">Frontier</span>成 员。置换<span class="s177">θ</span><span class="s65">hi</span>给出了从<span class="s56">Rule</span>的头到解释中对应文字的变量约束。此算法首先计算一个能使<span class="s56">Rule</span>的头与 <span class="s56">Literal </span>合一的置换<span class="s177">θ</span><span class="s65">hl</span><span class="s67"> </span>，其方法是使其与置换<span class="s177">θ</span><span class="s65">hi</span><span class="s67"> </span>一致。然后此置换<span class="s177">θ</span><span class="s65">hl</span><span class="s67"> </span>被应用于建立关于<span class="s56">Rule</span>的 <span class="s56">Frontier</span>的前像。算法中符号“＋”和“－”表示集合并和集合差。记号<span class="s16">{</span><span class="s56">z</span><span class="s16">/</span><span class="s56">y</span><span class="s16">}</span>表示用<span class="s56">y</span>置换<span class="s56">z</span>。表中还给 出了分步运行的例子。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 2pt;text-align: left;"><span><img width="570" height="2" alt="image" src="机器学习/Image_411.png"/></span></p><p class="s56" style="padding-left: 11pt;text-indent: 0pt;line-height: 122%;text-align: left;"><span class="s16">Regress(</span>Frontier<span class="s16">, </span>Rule<span class="s16">, </span>Literal<span class="s16">, </span><span class="s177">θ</span><span class="s65">hi</span><span class="s16">) </span>Frontier<span class="s14">：通过规则被回归的文字集合 </span>Rule<span class="s14">：一个 </span>Horn <span class="s14">子句</span></p><p class="s56" style="padding-top: 1pt;padding-left: 11pt;text-indent: 0pt;text-align: left;">Literal<span class="s14">：在 </span>Frontier <span class="s14">中的一个文字，它由解释中的 </span>Rule <span class="s14">推得</span></p><p class="s14" style="padding-top: 2pt;padding-left: 11pt;text-indent: 0pt;line-height: 122%;text-align: left;"><span class="s177">θ</span><span class="s65">hi</span>：使<span class="s56">Rule</span>的头与解释中的相应文字合一的置换 返回构成 <span class="s56">Frontier </span>的关于 <span class="s56">Rule </span>的最弱前像的文字集合 <span class="s55">n </span><span class="s56">head</span>←<span class="s56">Rule </span>的头</p><p class="s56" style="padding-top: 1pt;padding-left: 12pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span>body<span class="s14">←</span>Rule <span class="s14">的体</span></p><p class="s14" style="padding-top: 2pt;padding-left: 12pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span><span class="s177">θ</span><span class="s65">hl</span>←<span class="s56">head</span>与<span class="s56">Literal</span>的最一般合一，使得存在置换<span class="s177">θ</span><span class="s65">li</span>满足：</p><p class="s16" style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: center;"><span class="s177">θ</span><span class="s65">li </span>(<span class="s177">θ</span><span class="s65">hl </span>(<i>head</i>))= <span class="s177">θ</span><span class="s65">hi</span><span class="s67"> </span>(<i>head</i>)</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="560" height="1" alt="image" src="机器学习/Image_412.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><table style="border-collapse:collapse;margin-left:5.60001pt" cellspacing="0"><tr style="height:17pt"><td style="width:426pt;border-top-style:solid;border-top-width:2pt;border-top-color:#808080;border-bottom-style:solid;border-bottom-width:1pt"><p class="s53" style="padding-left: 5pt;text-indent: 0pt;line-height: 14pt;text-align: left;"><span class="s287">n </span><span class="s174">返回</span><span class="s288">θ</span><span class="s175">hl</span>(<i>Frontier</i>-<i>head</i>+<i>body</i>)</p></td></tr><tr style="height:156pt"><td style="width:426pt;border-top-style:solid;border-top-width:1pt;border-bottom-style:solid;border-bottom-width:2pt;border-bottom-color:#808080"><p class="s53" style="padding-left: 5pt;padding-right: 260pt;text-indent: 0pt;line-height: 121%;text-align: left;"><span class="s174">示例（图 </span>11-3 <span class="s174">中最下面的回归步）： </span>Regress(<i>Frontier</i>, <i>Rule</i>, <i>Literal</i>, <span class="s288">θ</span><span class="s175">hi</span>)<span class="s174">，其中</span></p><p class="s54" style="padding-top: 1pt;padding-left: 5pt;padding-right: 50pt;text-indent: 0pt;line-height: 126%;text-align: left;">Frontier <span class="s53">= {</span>Volume<span class="s53">(</span>x<span class="s53">, </span>vx<span class="s53">), </span>Density<span class="s53">(</span>x<span class="s53">, </span>dx<span class="s53">), </span>Equal<span class="s53">(</span>wx<span class="s53">, </span>times<span class="s53">(</span>vx<span class="s53">, </span>dx<span class="s53">)), </span>LessThan<span class="s53">(</span>wx<span class="s53">, </span>wy<span class="s53">), </span>Weight<span class="s53">(</span>y<span class="s53">, </span>wy<span class="s53">)} </span>Rule <span class="s53">= </span>Weight<span class="s53">(</span>z<span class="s53">, 5) </span><span class="s174">←</span>Type<span class="s53">(</span>z<span class="s53">, </span>Endtable<span class="s53">)</span></p><p class="s54" style="padding-top: 1pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Literal <span class="s53">= </span>Weight<span class="s53">(</span>y<span class="s53">, </span>wy<span class="s53">)</span></p><p class="s53" style="padding-top: 2pt;padding-left: 5pt;text-indent: 0pt;text-align: left;"><span class="s288">θ</span><span class="s175">hi </span>= {<i>z</i>/<i>Obj</i>2}</p><p class="s54" style="padding-top: 2pt;padding-left: 26pt;text-indent: 0pt;text-align: left;"><span class="s287">n </span>head<span class="s174">←</span>Weight<span class="s53">(</span>z<span class="s53">, 5)</span></p><p class="s54" style="padding-top: 3pt;padding-left: 26pt;text-indent: 0pt;text-align: left;"><span class="s287">n </span>body<span class="s174">←</span>Type<span class="s53">(</span>z<span class="s53">, </span>Endtable<span class="s53">)</span></p><p class="s53" style="padding-top: 2pt;padding-left: 26pt;text-indent: 0pt;text-align: left;"><span class="s287">n </span><span class="s288">θ</span><span class="s175">hl</span><span class="s174">←</span>{<i>z</i>/<i>y</i>, <i>wy</i>/5}<span class="s174">，其中</span><span class="s288">θ</span><span class="s175">li</span>={<i>y</i>/<i>Obj</i>2}</p><p class="s53" style="padding-top: 2pt;padding-left: 26pt;text-indent: 0pt;text-align: left;"><span class="s287">n </span><span class="s174">返回</span>{<i>Volume</i>(<i>x</i>, <i>vx</i>), <i>Density</i>(<i>x</i>, <i>dx</i>), <i>Equal</i>(<i>wx</i>, <i>times</i>(<i>vx</i>, <i>dx</i>)), <i>lessThan</i>(<i>wx</i>, 5), <i>Type</i>(<i>y</i>, <i>Endtable</i>)}</p></td></tr></table><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s37" style="padding-top: 1pt;padding-left: 11pt;text-indent: 0pt;text-align: left;">11.2.1.3 <span class="s20">改进当前假设</span></p><p style="padding-top: 8pt;padding-left: 10pt;text-indent: 21pt;line-height: 107%;text-align: justify;">在每一阶段的当前假设由当时学习到的 <span class="s6">Horn </span>子句集组成。在每一阶段，序列覆盖算法选 取一个还未被当前 <span class="s6">Horn </span>子句覆盖的新正例，解释该正例，并按照上面的过程形成新规则。注 意我们已定义的算法中只有正例被覆盖，而且学习到的 <span class="s6">Horn </span>子句集只预测正例。对于一个新 实例，如果当前规则预测其正例失败，则它被分类为反例。这是与 <span class="s6">Prolog </span>这样的 <span class="s6">Horn </span>子句推 理系统中标准的失败否定方法相吻合的。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 11pt;text-indent: 0pt;text-align: left;">11.3 <span class="s17">对基于解释的学习的说明</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 11pt;text-indent: 21pt;line-height: 107%;text-align: justify;">如我们在上例中看到的 <span class="s6">Prolog-EBG </span>对单个训练样例进行详细分析，以确定如何最好地从 特殊样例泛化到一般 <span class="s6">Horn </span>子句假设。下面为此算法的要点：</p><p class="s10" style="padding-top: 4pt;padding-left: 33pt;text-indent: 0pt;line-height: 14pt;text-align: left;"> <span class="s6">Prolog-EBG </span><span class="p">不像归纳的方法，它通过运用先验知识分析单个样例以产生合理的</span></p><p style="text-indent: 0pt;line-height: 14pt;text-align: center;">（<span class="s6">justified</span>）一般假设。</p><p class="s10" style="padding-left: 54pt;text-indent: -21pt;line-height: 14pt;text-align: left;"> <span class="p">对样例如何满足目标概念的解释，确定了样例的哪些属性是相关的：即在解释中 提及的属性。</span></p><p class="s10" style="padding-left: 54pt;text-indent: -21pt;line-height: 94%;text-align: left;"> <span class="p">对解释的进一步分析，即回归目标概念以确定其对应解释的最弱前像，可推导出 相关特征值的一般约束。</span></p><p style="padding-top: 1pt;padding-left: 54pt;text-indent: -21pt;line-height: 14pt;text-align: left;"><span class="s10"> </span>每个学习到的 <span class="s6">Horn </span>子句对应于满足目标概念的一个充分条件。学习到的 <span class="s6">Horn </span>子 句集覆盖了学习器遇到的正例，以及其他与此共享同样解释的实例。</p><p style="padding-left: 33pt;text-indent: 0pt;line-height: 13pt;text-align: left;"><span class="s10"> </span>学习到的 <span class="s6">Horn </span>子句的泛性将依赖于领域理论的形式以及训练样例被考虑的序列。</p><p class="s10" style="padding-left: 54pt;text-indent: -21pt;line-height: 14pt;text-align: left;"> <span class="s6">Prolog-EBG </span><span class="p">隐含假定了领域理论是正确且完整的，如果领域理论不正确或不完 整，学到的概念也将不正确。</span></p><p style="padding-top: 6pt;padding-left: 31pt;text-indent: 0pt;text-align: left;">在基于解释的学习中有一些相关的观点，可有助于理解其能力和限制：</p><ul id="l32"><li style="padding-top: 6pt;padding-left: 54pt;text-indent: -21pt;text-align: left;"><p class="s6" style="display: inline;">EBL <span class="p">作为理论引导的样例泛化（</span>theory-guided generalization of examples<span class="p">）。</span>EBL <span class="p">使 用给定的领域理论以从样例中合理地泛化，区分出相关和不相关的样例属性，因 此可以避免用于纯归纳推理中的样本复杂度界限。这是一个隐含在上面描述的 </span>Prolog-BEG <span class="p">算法中的观点。</span></p></li><li style="padding-left: 54pt;text-indent: -21pt;line-height: 94%;text-align: left;"><p class="s6" style="display: inline;">EBL <span class="p">作为样例引导的理论重建（</span>example-guided reformulation of theories<span class="p">）。</span>Prolog- EBG <span class="p">算法被看作是一种重建领域理论到一种可操作形式的方法。确切地讲，重建 领域理论是通过创建这样的规则：（</span>a<span class="p">）能从领域理论中演绎派生，以及（</span>b<span class="p">）在一</span></p></li></ul><p style="padding-top: 1pt;padding-left: 49pt;text-indent: 0pt;line-height: 14pt;text-align: justify;">个推理步内分类观察到的训练样例。这样，学习到的规则可被看作将领域理论重 建为一组特殊情况下的规则，它能在一个推理步内对目标概念的实例分类。</p><ul id="l33"><li style="padding-left: 49pt;text-indent: -21pt;line-height: 94%;text-align: left;"><p style="display: inline;"><span class="s6">EBL </span>作为“仅仅”重述学习器已经“知道”的（<span class="s6">“just” restating what the learner already “knows”</span>）。在某种程度上，在 <span class="s21">SafeToStack </span>例子中的学习器开始于其目标 概念的全部知识。也就是说，如果它的初始领域理论充分解释了任何训练样例，</p></li></ul><p style="padding-left: 49pt;text-indent: 0pt;text-align: justify;">那么它也能充分预测其分类。那么学习的意义在哪儿呢？一种回答是，在许多任 务中，原则上已知的和实践上可有效计算的之间的区别很大，因此这种“知识重 建”为学习的重要形式。例如在下棋的例子中，对弈的规则构成了一个完美的领 域理论，原则上足以进行完美的对弈。即使如此，人们仍然需要大量的经验来学 习如何很好地下棋。这正是这样一种情形，（人类的）学习器已经知道了完美的 领域理论，而进一步学习只是“简单地”将此知识重建为另一种形式，以用于更 有效的指导适当的行为。有同样属性的另一个例子是学习牛顿力学课程：基本的 物理定律已被简单地陈述，但学生仍旧需要在学期中花一大部分时间学习这一课 程，以拥有更可操作形式的知识，然后就不需要在最后的考试中用最基本的定律 来推导每个问题的解。<span class="s6">Prolog-EBG </span>执行的就是这种形式的知识重建，它学习到的 规则可从可观察的实例特征映射到关于目标概念的分类，方法是使其与基本领域 理论一致。使用原始的领域理论可能需要许多推理步和很可观的搜索才能对任意 实例分类，而学习到的规则可在一个推理步内分类观察到的实例。</p><p style="padding-top: 7pt;padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">因此，纯粹的 <span class="s6">EBL </span>致力于重建领域理论以产生可单步推理出样例分类的一般规则。这种 知识重建的过程有时被称为知识汇编（<span class="s6">knowledge compilation</span>），表示这种转换是为了增加效 率，而不改变系统知识的正确性。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">11.3.1 <span class="s25">发现新特征</span></h3><p style="padding-top: 10pt;padding-left: 6pt;text-indent: 21pt;line-height: 109%;text-align: justify;"><span class="s6">Prolog-EBG </span>一个有趣的能力是形成在训练样例的描述中没有显式出现的新特征，但这些 特征是在描述训练样例中的一般规则时必需的。这种能力在前一节的分步算法和学到的规则中 例示。确切地说，学到的规则断言对 <span class="s21">x </span>的 <span class="s21">Volume </span>和 <span class="s21">Density </span>的必要约束为其乘积小于 <span class="s6">5</span>。实际 上，训练样例并不包含此乘积以及它应取的值的描述。此约束是由学习器自动形成的。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 109%;text-align: justify;">注意此学习到的“特征”类似于由神经网络的隐藏单元表示的特征类型。也就是说，这个 特征是可由已有实例属性计算出的、大量潜在的特征之一。和后向传播算法一样，<span class="s6">Prolog-EBG </span>在其尝试拟合训练数据的过程中，自动形成这样的特征。然而，不像神经网络中使用统计过程 从多个训练样例中推导出隐藏单元特征，<span class="s6">Prolog-EBG </span>应用了一个分析过程基于单个训练样例 的分析 推 导新的 特 征。上 面 的例子中 <span class="s6">Prolog-EBG </span>用 分 析的方 法 推导出 特 征 <span class="s21">Volume </span><span class="s6">· </span><span class="s21">Density</span><span class="s6">&gt;5 </span>， 它来自于用于解释单个训练样例的领域理论的特定实例化。 例如， “<span class="s21">Volumn </span>和 <span class="s21">Density </span>的乘积很重要”这一概念是来自于定义 <span class="s21">Weight </span>的领域理论规则。该乘积必 须小于 <span class="s6">5 </span>的概念来自于另外两条领域理论规则，它们断言 <span class="s21">Obj</span><span class="s6">1 </span>必须比茶几（<span class="s21">EndTable</span>）更轻</p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 107%;text-align: left;">（<span class="s21">Lighter</span>），以及茶几（<span class="s21">Endtable</span>）的重量（<span class="s21">Weight</span>）等于 <span class="s6">5</span>。因此，正是这些领域理论中的原 子项的特定合成和实例化才导致了此新特征的定义。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 113%;text-align: justify;">自动学习有用特征以扩大实例表示的问题是机器学习的一个重要问题。在基于解释的学习 中分析推导新特征，和在神经网络的隐藏单元中归纳推导新特征提供了两种不同的途径。因 此，它们依赖的信息来源不同（一个是在许多样例上的统计规则，另一个是使用领域理论的单 个样例分析），有可能结合两种来源探索出新的方法。</p><h3 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">11.3.2 <span class="s25">演绎学习</span></h3><p style="padding-top: 10pt;padding-left: 6pt;text-indent: 21pt;line-height: 107%;text-align: justify;">纯粹的 <span class="s6">Prolog-EBG </span>是一个演绎的而不是归纳的学习过程。也就是说，通过计算解释的最 弱前像，它产生一个可从领域理论 <span class="s21">B </span>中演绎派生的假设 <span class="s21">h</span>，而且覆盖训练数据 <span class="s21">D</span>。更精确地 讲，<span class="s6">Prolog-EBG </span>输出一个假设 <span class="s21">h </span>满足下面的约束：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="padding-top: 2pt;padding-left: 26pt;text-indent: 0pt;text-align: center;"><span class="s33">(</span><span class="s38"></span>x<span class="s52">i </span><span class="s33">, </span>f <span class="s33">(</span>x<span class="s52">i </span><span class="s33">)</span><span class="s38"> </span><span class="s38"> </span>D<span class="s33">)(</span>h <span class="s38"> </span>x<span class="s52">i </span><span class="s33">) </span><span class="p">├</span><span class="s21">f</span><span class="s6">(</span><span class="s21">x</span><span class="s36">i</span><span class="s6">) </span><span class="p">（</span><span class="s6">11</span><span class="p">．</span><span class="s6">1</span><span class="p">）</span></p><p style="padding-top: 3pt;padding-left: 27pt;text-indent: 0pt;line-height: 28pt;text-align: center;"><span class="s21">D</span>∧<span class="s21">B</span>├<span class="s21">h </span>（<span class="s6">11</span>．<span class="s6">2</span>） 其中训练数据<span class="s21">D</span>由一组训练样例组成，<span class="s21">x</span><span class="s36">i</span>为第<span class="s21">i</span>个训练实例，<span class="s21">f</span><span class="s6">(</span><span class="s21">x</span><span class="s36">i</span><span class="s6">)</span>为它的目标值（<span class="s21">f</span>为目标函</p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 12pt;text-align: justify;">数）。注意第一个约束只是简单地将机器学习的通常的需求形式化，即假设<span class="s21">h</span>能对训练数据中</p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: justify;">每个实例<span class="s21">x</span><span class="s36">i</span>正确预测目标值<span class="s21">f</span><span class="s6">(</span><span class="s21">x</span><span class="s36">i</span><span class="s6">)</span><span class="s46">*</span>。当然一般情况下有多种假设满足这一约束。第二个约束描述 了<span class="s6">Prolog-EBL</span>中领域理论的作用：输出假设被进一步约束以使其派生于领域理论和数据。这第 二个约束减少了学习器在必须选择假设时面临的歧义性。因此，领域理论的作用是减少假设空 间的有效规模并降低学习的样本复杂度。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 26pt;text-indent: 0pt;text-align: center;">使用相似的记号，我们可描述出 <span class="s6">Prolog-EBG </span>所需的领域理论的知识类型。确切地讲，</p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 0pt;text-align: justify;"><span class="s6">Prolog-EBG </span>假定领域理论 <span class="s21">B </span>涵蕴训练数据中实例的分类。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="padding-top: 2pt;padding-left: 27pt;text-indent: 68pt;line-height: 182%;text-align: left;"><span class="s33">(</span><span class="s38"></span>x<span class="s52">i</span><span class="s41"> </span><span class="s33">, </span>f <span class="s33">(</span>x<span class="s52">i</span><span class="s41"> </span><span class="s33">)</span><span class="s38"> </span><span class="s38"> </span>D<span class="s33">)(</span>B <span class="s38"> </span>x<span class="s52">i</span><span class="s41"> </span><span class="s33">) </span><span class="p">├</span><span class="s21">f</span><span class="s6">(</span><span class="s21">x</span><span class="s36">i</span><span class="s6">) </span><span class="p">（</span><span class="s6">11</span><span class="p">．</span><span class="s6">3</span><span class="p">） 这个对领域理论 </span><span class="s21">B </span><span class="p">的约束保证了对每个正例可构造出解释。</span></p><p style="padding-top: 3pt;padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">将 <span class="s6">Prolog-EBG </span>学习问题和归纳逻辑编程（第 <span class="s6">10 </span>章）的学习问题作一比较很有意义。在第 <span class="s6">10 </span>章我们讨论了一般化的归纳学习任务，其中对学习器提供了背景知识 <span class="s21">B</span><span class="s6">´</span>。我们使用 <span class="s21">B</span><span class="s6">´</span>而不 是 <span class="s21">B </span>来代表 <span class="s6">ILP </span>所使用的背景知识，因为它一般不满足式 <span class="s6">11.3 </span>的约束。<span class="s6">ILP </span>是一个归纳学习系 统，而 <span class="s6">Prolog-EBG </span>是演绎学习系统。<span class="s6">ILP </span>使用其背景知识 <span class="s21">B</span><span class="s6">´</span>来扩大待考虑的假设集合，而 <span class="s6">Prolog-EBG </span>使用其领域理论 <span class="s21">B </span>来减小可接受假设的集合。如式 <span class="s6">10.2 </span>表示的，<span class="s6">ILP </span>系统输出的 <span class="s21">h </span>满足下面的约束：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="padding-top: 2pt;padding-left: 147pt;text-indent: 0pt;text-align: left;"><span class="s33">(</span><span class="s38"></span>x<span class="s52">i</span><span class="s41"> </span><span class="s33">, </span>f <span class="s33">(</span>x<span class="s52">i</span><span class="s41"> </span><span class="s33">)</span><span class="s38"> </span><span class="s38"> </span>D<span class="s33">)(</span>B<span class="s33">&#39;</span><span class="s38"></span>h <span class="s38"> </span>x<span class="s52">i</span><span class="s41"> </span><span class="s33">) </span><span class="p">├</span><span class="s21">f</span><span class="s6">(</span><span class="s21">x</span><span class="s36">i</span><span class="s6">)</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;text-align: justify;">注意此表达式与<span class="s6">Prolog-EBG</span>对<span class="s21">h</span>产生的约束（由式 <span class="s6">11.2 </span>和 <span class="s6">11.3 </span>给出）之间的联系。这个在 <span class="s21">h</span>上的<span class="s6">ILP</span>约束是式 <span class="s6">11.1 </span>中约束的弱化形式。<span class="s6">ILP</span>约束只要求 <span class="s33">(</span><span class="s30">B</span><span class="s33">&#39;</span><span class="s38"></span><span class="s30">h </span><span class="s38"> </span><span class="s30">x</span><span class="s52">i</span><span class="s41"> </span><span class="s33">) </span>├<span class="s21">f</span><span class="s6">(</span><span class="s21">x</span><span class="s36">i</span><span class="s6">)</span>，而<span class="s6">Prolog-EBG </span>要求更严格的 <span class="s33">(</span><span class="s30">h </span><span class="s38"> </span><span class="s30">x</span><span class="s52">i</span><span class="s41"> </span><span class="s33">) </span>├<span class="s21">f</span><span class="s6">(</span><span class="s21">x</span><span class="s36">i</span><span class="s6">)</span>。还要注意<span class="s6">ILP</span>中没有对应式 <span class="s6">11.2 </span>中<span class="s6">Prolog-EBG</span>约束。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 26pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="193" height="1" alt="image" src="机器学习/Image_413.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-top: 3pt;padding-left: 5pt;text-indent: 21pt;line-height: 125%;text-align: left;"><span class="s70">* </span>这里在涵蕴（├）的定义中包含了<span class="s16">Prolog</span>样式的失败否定，因此如果样例不能被证明为正例，则它们被 涵蕴为反例。</p><h3 style="padding-left: 6pt;text-indent: 0pt;text-align: justify;">11.3.3 <span class="s25">基于解释的学习的归纳偏置</span></h3><p style="padding-top: 10pt;padding-left: 5pt;text-indent: 21pt;line-height: 110%;text-align: justify;">回忆第 <span class="s6">2 </span>章的叙述，一个学习算法的归纳偏置为一组断言，它们与训练样例一起演绎涵蕴 学习器的后续预测。归纳偏置的重要性在于它刻画出学习器是怎样从观察到的训练样例泛化 的。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;"><span class="s6">Prolog-EBG </span>的归纳偏置是什么？在 <span class="s6">Prolog-EBG </span>中，如式 <span class="s6">11.2 </span>所描述的，输出的假设 <span class="s21">h </span>从 <span class="s21">D</span>∧<span class="s21">B </span>中演绎派生。因此领域理论 <span class="s21">B </span>为一组断言，它们与训练样例一起涵蕴输出假设。由于学 习器的预测从此假设 <span class="s21">h </span>中派生，似乎 <span class="s6">Prolog-EBG </span>的归纳偏置就是输入学习器中的领域理论 <span class="s21">B</span>。实际上可以这样认定，除了还需考虑另外一个细节：领域理论可涵蕴多个可选的 <span class="s6">Horn </span>子句 集。因此，归纳偏置还需包含 <span class="s6">Prolog-EBG </span>在这些可选的 <span class="s6">Horn </span>子句集中作出选择这部分内容。 如上面所见到的，<span class="s6">Prolog-EBG </span>使用序列覆盖算法不断形成附加的 <span class="s6">Horn </span>子句直到所有的正例被 覆盖。更进一步，每个单独的 <span class="s6">Horn </span>子句是当前训练样例的解释所许可的最一般子句（即最弱 前像）。因此在领域理论涵蕴的各 <span class="s6">Horn </span>子句集之中，我们可以将 <span class="s6">Prolog-EBG </span>的偏置刻画为对 极大一般化 <span class="s6">Horn </span>子句的小集合的偏好。实际上 <span class="s6">Prolog-EBG </span>的贪婪算法只是为寻找极大一般化 <span class="s6">Horn </span>子句的真正最短集合所需的彻底搜索算法的一个启发式的近似。无论怎样，<span class="s6">Prolog-EBG </span>归纳偏置仍可用这种方式近似刻画。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-left: 18pt;text-indent: 0pt;text-align: center;">近似的 <span class="s187">Prolog-EBG </span>归纳偏置：领域理论 <span class="s56">B</span>，加上对极大一般化 <span class="s16">Horn </span>子句的小集合的偏好。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 107%;text-align: justify;">这里最重要的要点在于，<span class="s6">Prolog-EBG </span>的归纳偏置（即它从训练数据中泛化的策略）在很 大程度上由输入的领域理论确定。它与我们所讨论过的多数学习算法完全不同。多数学习算法</p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 0pt;line-height: 111%;text-align: justify;">（如神经网络，决策树学习）中归纳偏置是学习算法的一个固定属性，一般是由其假设表示的 语法所确定的。为什么把归纳偏置作为一个输入参数而不是学习器的固定属性十分重要？这是 因为，如我们在第 <span class="s6">2 </span>章及其他地方讨论过的，不存在一个全局有效的归纳偏置，而且无偏学习 是无用的。因此任何开发通用学习方法的尝试，都至少会允许归纳偏置能够针对待解决的学习 问题有所不同。在一个更实践性的层次上，许多学习任务更希望输入领域特定的知识（如 <span class="s21">SafeToStack </span>例子中的有关 <span class="s21">Weight </span>的知识）以影响学习器从训练数据中泛化的方法。相反，通 过限制假设的语法形式（如偏好短决策树）来“实现”某适当的偏置性则不太自然。最后，如 果考虑一个更大的问题，一个自治 <span class="s6">agent </span>如何随着时间改进它的学习能力，那么最好是有一个 学习算法，它的泛化能力可在其获得到更多的领域知识后增强。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 6pt;text-indent: 0pt;text-align: justify;">11.3.4 <span class="s25">知识层次的学习</span></h3><p style="padding-top: 10pt;padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">如式 <span class="s6">11.2 </span>指出的，由 <span class="s6">Prolog-EBG </span>输出的假设 <span class="s21">h </span>从领域理论 <span class="s21">B </span>和训练数据 <span class="s21">D </span>中演绎派生。 实际上，通过考查 <span class="s6">Prolog-EBG </span>算法，很容易看出 <span class="s21">h </span>直接从单独的 <span class="s21">B </span>中派生，而与 <span class="s21">D </span>无关。为 了理解这一点，我们可以假想有一个称为条目枚举器（<span class="s6">Lemma-enumerator</span>）的算法。这个算法 基于领域理论 <span class="s21">B </span>中的断言简单地枚举能得到目标概念的所有证明树。对每个证明树，<span class="s6">Lemma- enumerator </span>用与 <span class="s6">Prolog-EBG </span>相似的方法计算最弱前像并构造一个 <span class="s6">Horn </span>子句。在 <span class="s6">Lemma- enumerator </span>和 <span class="s6">Prolog-EBG </span>之间惟一的不同是，<span class="s6">Lemma-enumerator </span>忽略训练数据并枚举出所有 的证明树。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 26pt;text-indent: 0pt;text-align: left;">注意 <span class="s6">Lemma-enumerator </span>输出的是 <span class="s6">Prolog-EBG </span>输出 <span class="s6">Horn </span>子句的超集。由于这一点，产生</p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 110%;text-align: justify;">了几个问题。首先，如果它的假设单独从领域理论中派生，那么 <span class="s6">Prolog-EBG </span>中训练数据有什 么作用？答案在于，训练样例使 <span class="s6">Prolog-EBG </span>关注于生成规则以覆盖实际出现的样例的分布。 例如，在原来的下棋例子中，所有可能的条目数很大，而在通常对弈中出现的棋盘状态只是语 法上可能出现的棋盘状态的一小部分。因此，通过只关注实际上会遇到的训练样例，比尝试枚 举棋盘的所有可能条目，程序更可能得到更小的、更相关的规则集。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 20pt;line-height: 109%;text-align: justify;">产生的第二个问题是，<span class="s6">Prolog-EBG </span>是否能学习到一个超出隐含在领域理论中的知识的假 设？换言之，它是否能学习到一个实例的分类，这个实例不能用原始的领域理论进行分类（假 定定理证明器有无限的计算资源）？不幸的是，它不能做到。如果 <span class="s21">B</span>├<span class="s21">h</span>，那么任何由 <span class="s21">h </span>涵蕴 的分类也将由 <span class="s21">B </span>涵蕴。这是否是分析学习或演绎学习的固有缺陷？并非如此，如下例所示。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 107%;text-align: justify;">为了举一个演绎学习的例子，其中学习到的假设 <span class="s21">h </span>可涵蕴出 <span class="s21">B </span>不能涵蕴的结论，我们必须 创建一个 <span class="s21">B</span>├<span class="s6">/ </span><span class="s21">h </span>但 <span class="s21">D</span>∧<span class="s21">B</span>├<span class="s21">h </span>的例子（回忆式 <span class="s6">11.2 </span>给出的约束）。可以考虑 <span class="s21">B </span>包含这样的断 言：“若 <span class="s21">x </span>满足目标概念，那么 <span class="s21">g</span><span class="s6">(</span><span class="s21">x</span><span class="s6">)</span>也满足。”单独这个断言不能涵蕴出任何实例的分类。然 而，一但我们观察到一正例，它允许演绎泛化到其他未见实例。例如，考虑学习 <span class="s21">PlayTennis </span>的 目标概念，它描述了 <span class="s6">Ross </span>希望打网球的日子。假如每个日子只被描述为单个属性 <span class="s21">Humidity</span>， 并且领域理论包含单个断言“如果 <span class="s6">Ross </span>喜欢在湿度（<span class="s21">Humidity</span>）为 <span class="s21">x </span>的日子打网球，那么他也 喜欢在湿度小于 <span class="s21">x </span>的日子打网球”，可被形式化地描述为：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s108" style="padding-top: 3pt;padding-left: 28pt;text-indent: 0pt;text-align: left;">(<span class="s109"></span><i>x</i>)</p><p class="s6" style="padding-top: 2pt;padding-left: 25pt;text-indent: 0pt;line-height: 202%;text-align: left;">IF((<i>PlayTennis</i>=<i>Yes</i>)<span class="p">←</span>(<i>Humidity</i>=<i>x</i>)) THEN ((<i>PlayTennis</i>=<i>Yes</i>) <span class="p">←</span>(<i>Humidity</i><span class="p">≤</span><i>x</i>))</p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">注意此领域理论不会对 <span class="s21">PlayTennis </span>的实例中哪些是正例，哪些是负例涵蕴出任何结论。然 而，一但学习器观察到一个正例中 <span class="s21">Humidity</span><span class="s6">=0.3</span>，领域理论连同此正例一起涵蕴到下面的一般 假设 <span class="s21">h</span>：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 151pt;text-indent: 0pt;text-align: left;">(<i>PlayTennis</i>=<i>Yes</i>) <span class="p">←</span>(<i>Humidity</i><span class="p">≤</span>0.30)</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 109%;text-align: justify;">概括起来，此例子描述了一种情形其中 <span class="s21">B</span>├<span class="s6">/ </span><span class="s21">h</span>，但 <span class="s21">B</span>∧<span class="s21">D</span>├<span class="s21">h</span>。这里学到的假设涵蕴的预测 不能被单独的领域理论涵蕴。术语“知识层次的学习”（<span class="s6">knowledge-level learning</span>）有时被用 于称这种类型的学习，其中学习到的假设涵蕴的预测超出了能被领域理论涵蕴的范围。由断言 集合 <span class="s6">Y </span>涵蕴的所有预测的集合常称为 <span class="s6">Y </span>的演绎闭包（<span class="s6">deductive closure</span>）。这里的关键区别在 于，知识层次的学习中 <span class="s6">B </span>的演绎闭包是 <span class="s6">B</span>＋<span class="s6">h </span>演绎闭包的真子集。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 109%;text-align: justify;">知识层次的分析学习的另一个例子是，考虑一种类型的断言，通常称为 <span class="s6">determination</span>，它 的细节研究见 <span class="s6">Russel</span>（<span class="s6">1989</span>）以及其他一些工作。<span class="s6">Determination </span>断言，实例的某属性完全取决 于某些特定属性，但不必指明这种依赖性的确切性质。例如，考虑学习一个目标概念“说葡萄 牙语的人”，并且假定领域理论为单个 <span class="s6">determination </span>断言“某人说的语言由他的国籍决定。” 只有这条领域理论，不能够用来分类正例和反例。然而，如果我们观察到“<span class="s6">Joe</span>，<span class="s6">23 </span>岁，左撇 子，巴西人，说葡萄牙语”，那么我们就可以此正例和领域理论中得到：“所有的巴西人都说 葡萄牙语”。</p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 107%;text-align: justify;">这些例子都演示了分析学习如何产生不能由领域理论单独涵蕴的假设。其中的输出假设 <span class="s21">h </span>都满足 <span class="s21">D</span>∧<span class="s21">B</span>├<span class="s21">h</span>，但不满足 <span class="s21">B</span>├<span class="s21">h</span>。在两种情况下，学习器都演绎（<span class="s6">deduce</span>）出一个合理的假 设，它既不能从领域理论中单独派生，也不能从训练数据中单独派生。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">11.4 <span class="s17">搜索控制知识的基于解释的学习</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 110%;text-align: justify;">如上述指出的，<span class="s6">Prolog-EBG </span>算法的实际能力受领域理论必须正确且完整这一要求所限 制。能够满足这一要求的学习问题的一个重要类别为通过学习使复杂的搜索程序速度加快。实 际上，应用基于解释的学习的最大规模的尝试已经开始解决学习控制搜索的问题，它有时又被 称为“加速”（<span class="s6">speedup</span>）学习。例如，像棋类这样的对弈中，对合法搜索操作的定义以及搜 索目标的定义提供了学习搜索控制知识的一个完整且正确的领域理论。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 108%;text-align: justify;">如何确切地定义学习搜索控制问题的形式以使用基于解释的学习？考虑一个一般搜索问 题，其中<span class="s21">S</span>为可能搜索状态的集合，<span class="s21">O</span>为合法搜索算子的集合，它将一种搜索状态转换成另一 种搜索状态，而且<span class="s21">G</span>为在<span class="s21">S</span>上定义的谓词，它表示哪种状态为目的状态。问题一般是寻找一系 列的算子，它将任意初始状态<span class="s21">s</span><span class="s36">i</span>转化为某最终状态<span class="s21">s</span><span class="s36">f</span>，使目的谓词<span class="s21">G</span>得到满足。定义学习问题形 式的一种办法是让系统对<span class="s21">O</span>中每个算子学习一个分立的目标概念。确切地讲，对<span class="s21">O</span>中每个算子 <span class="s21">o</span>，它可尝试学习目标概念“能用<span class="s21">O</span>导致目的状态的状态集合”。当然究竟选择哪一个作为待 学习的目标状态，依赖于必须使用此学习到的知识的问题求解器的内部结构，例如，如果问题 求解器是一个<span class="s6">means-ends</span>规划系统，它的工作过程是通过建立和解决子目的，那么我们希望学 习的目标概念可以是“<span class="s21">A</span>类型的子目的必须在<span class="s21">B</span>类型的子目的之前解决的规划状态集合。”</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">使用基于解释的学习以改进其搜索的一个系统是<span class="s6">Prodigy</span>（<span class="s6">Carbonell et al. 1990</span>）。 <span class="s6">Prodigy </span>是一个领域无关的规划系统，它接受以状态空间<span class="s21">S</span>和算子集合<span class="s21">O</span>定义的问题领域。然后它解决 这样形式的问题：“寻找一个算子序列使初始状态<span class="s21">s</span><span class="s36">i</span>转换到满足目的谓词<span class="s21">G</span>的状态。” <span class="s6">Prodigy </span>使用一个<span class="s6">means-ends</span>规划器将问题分解为子目的，解决这些子目的，然后合并起来成为整个问 题的解。这样，在其搜索问题解的过程中 <span class="s6">Prodigy </span>重复面临这样的问题：“下一步要解决的是 哪个子目的？”以及“为解决此子目的要用哪个操作？。” <span class="s6">Minton</span>（<span class="s6">1988</span>）描述了将基于解 释的学习集成到 <span class="s6">Prodigy</span>的过程，方法是定义一组适合于这种不断遇到的控制决策的目标概 念。例如，一个目标概念是“子目标<span class="s21">A</span>必须在子目标<span class="s21">B</span>之前解决的状态集合。”对这个目标概 念，由<span class="s6">Prodigy</span>学到的规则在简单的物体堆叠问题中的一个例子为：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 77pt;text-indent: -51pt;line-height: 190%;text-align: left;">IF <span class="p">待解决的子目标之一为 </span><i>On</i>(<i>x</i>,<i>y</i>)<span class="p">，并且 待解决的子目标之一为 </span><i>On</i>(<i>y</i>,<i>z</i>)</p><p class="s6" style="padding-top: 2pt;padding-left: 26pt;text-indent: 0pt;text-align: left;">THEN <span class="p">在 </span><i>On</i>(<i>x</i>,<i>y</i>)<span class="p">之前解决 </span><i>On</i>(<i>y</i>,<i>z</i>)</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;"><span class="p">为理解此规则，再次考虑图 </span>9-3 <span class="p">中示例的简单的块状物体堆叠问题。在图示的问题中，目 的是将物块堆叠成为单词 </span>universal<span class="p">。</span>Prodigy <span class="p">将把此问题分解为几个要达到的子目的，包括 </span><i>ON</i>(<i>U</i>, <i>N</i>)<span class="p">，</span><i>ON</i>(<i>N</i>, <i>I</i>)<span class="p">等。注意上面的规则匹配子目的 </span><i>ON</i>(<i>U</i>, <i>N</i>)<span class="p">和 </span><i>ON</i>(<i>N</i>, <i>I</i>)<span class="p">，并且建议在解决子 问题 </span><i>ON</i>(<i>U</i>,<i>N</i>)<span class="p">之前解决 </span><i>ON</i>(<i>N</i>, <i>I</i>)<span class="p">。此规则的理由（以及 </span>Prodigy <span class="p">用于学习此规则的解释）在于</span></p><p class="s6" style="padding-left: 6pt;text-indent: 0pt;line-height: 109%;text-align: justify;"><span class="p">如果我们以逆序解决这两个子目的，将会遇到冲突，从而必须撤消 </span><i>ON</i>(<i>U</i>, <i>N</i>)<span class="p">的解以达到另一 子目的 </span><i>ON</i>(<i>N</i>, <i>I</i>)<span class="p">。</span>Prodigy <span class="p">学习过程首先遇到这样一个冲突，然后自我解释冲突的原因，并创 建一个类似于以上的规则。其效果在于 </span>Prodigy <span class="p">使用关于可能的子目的冲突的领域无关的知 识，以及关于特定操作的领域特定的知识（如机器人只能一次举起一个物块），以学习到有用 的领域特定的规划规则，如上面例示的那个规则。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 109%;text-align: justify;">使用基于解释的学习以获取 <span class="s6">Prodigy </span>的控制知识，已经在不同的问题领域中例示。包括上 面简单的物块堆叠问题，以及其他更复杂的调度和规划问题 。<span class="s6">Minton</span>（<span class="s6">1988</span>）报告了 <span class="s6">3 </span>个领 域中的实验，其中学习到的控制规则把问题求解的效率提高了 <span class="s6">2 </span>到 <span class="s6">4 </span>倍。更进一步，这些学到 的规则的性能在这 <span class="s6">3 </span>个问题中与手写规则有可比性。<span class="s6">Minton </span>也描述了对基本的基于解释学习的 若干扩展，它们提高了学习控制知识的效率。方法包括简化学习到的规则以及去除那些收益小 于开销的规则。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 108%;text-align: justify;">另一个结合了某种形式的基于解释学习的一般问题求解框架为 <span class="s6">Soar </span>系统（<span class="s6">Laird et al. 1986</span>；<span class="s6">Newell 1990</span>）。<span class="s6">Soar </span>支持范围较宽的问题求解策略，包含了 <span class="s6">Prodigy </span>的 <span class="s6">means-ends </span>规划 策略在内。然而，像 <span class="s6">Prodigy </span>一样，<span class="s6">Soar </span>中的学习是通过解释当前的控制策略为什么导致低 效。当它遇到一个搜索选择，其中没有一个确定无疑的答案时（如下一步该应用哪一个操作 符），<span class="s6">Soar </span>思考这个搜索僵局，使用如生成再测试这种弱化的方法来决定正确的行动方向。用 来解决这种僵局的推理可被理解为对将来怎样解决类似僵局的解释。<span class="s6">Soar </span>使用另一种不同的基 于解释学习称为 <span class="s6">chunking</span>，以抽取出可应用相同的解释的一般条件。<span class="s6">Soar </span>已被应用于多数的问 题领域，并被提议为人类学习过程中一种心理学上可行的模型（见 <span class="s6">Newell 1990 </span>）。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 5pt;text-indent: 21pt;line-height: 110%;text-align: justify;">Prodigy <span class="p">和 </span>Soar <span class="p">演示了基于解释的学习方法可被成功应用于在不同问题领域中获取搜索控 制知识。然而，大多数启发式搜索程序仍然使用类似于第 </span>1 <span class="p">章描述的数值评估函数，而不是由 基于解释的学习获取的规则。原因是什么？实际上有一些重要的实践问题应用了 </span>EBL <span class="p">学习搜 索控制。首先，在许多情况下必须学习的控制规则的数目非常大（如数千个规则）。当系统学 习到越来越多的控制规则以改进搜索，要花去越来越大的开销在每步中匹配这组规则到当前搜 索状态中。注意这个问题并不只局限于基于解释的学习，它在用增长的规则集表示其学到知识 的任意系统中都会出现。有效的匹配规则算法可缓和这一问题，但不能完全消除它。</span>Minton</p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 107%;text-align: justify;">（<span class="s6">1988</span>）讨论了经验地估计每个规则的计算开销和收益的策略，只在估计的收益超过估计的开 销时才学习这些规则，并在某些规则有负效用时删除它们。他描述了如何使用这种效用分析</p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 0pt;line-height: 107%;text-align: justify;">（<span class="s6">utility analysis</span>）来确定哪些应被学习哪些该忘记，很大地增强了 <span class="s6">Prodigy </span>中基于解释学习的 有效性。例如，在一系列机器人的物块堆叠问题中，<span class="s6">Prodigy </span>遇到了 <span class="s6">328 </span>个机会可学习一个新 规则，但只利用了其中 <span class="s6">69 </span>个，并且最终去除了低效用的规则后剩余 <span class="s6">19 </span>个规则。 <span class="s6">Tambe et al.</span></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 107%;text-align: justify;">（<span class="s6">1990</span>）和 <span class="s6">Doorenbos</span>（<span class="s6">1993</span>）讨论了怎样确定规则中匹配开销特别大的类型，并讨论了将这 些规则重新表示为更有效的形式和优化规则匹配的算法。 <span class="s6">Doorenbos</span>（<span class="s6">1993</span>）描述了这些方法 怎样使 <span class="s6">Soar </span>在一个问题领域中有效匹配 <span class="s6">100,000 </span>条规则，而不会对每状态匹配规则的开销有大 的增长。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 110%;text-align: justify;">应用 <span class="s6">EBL </span>以学习搜索控制另一个实践上的问题在于，多数情况下即使对希望的目标概念 建立解释也有相当大的计算量。例如，在棋类问题中我们可能希望学习一个目标概念：“操作 <span class="s21">A </span>导致最优解的状态。”不幸的是，为证明或解释为什么 <span class="s21">A </span>导致最优解需要解释其他的操作会</p><p style="padding-left: 6pt;text-indent: 0pt;text-align: justify;">导致不如 <span class="s21">A </span>的解。这一般需要搜索深度的指数级的计算量。 <span class="s6">Chien</span>（ <span class="s6">1993 </span>）和 <span class="s6">Tadepalli</span></p><p style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;line-height: 112%;text-align: justify;">（<span class="s6">1990</span>）探索了“消极”学习和“增量”学习的方法，其中启发式规则被用于产生部分的、近 似的、但易计算的解释。与解释是完美的情况一样，一些规则被从这些不完美的解释中抽取出 来。当然这些学到的规则会由于解释的不完整性而不正确。系统通过监视在后续情况下规则的 性能来处理此问题。如果规则后来出错，那么原始的解释被增量地完善以覆盖新的情况，并且 从此解释中抽取出更好的规则。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 27pt;text-indent: 0pt;text-align: left;">其他有许多研究工作探索了基于解释的学习的应用以改进基于搜索的问题求解器的效率</p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 0pt;line-height: 107%;text-align: justify;">（例如 <span class="s6">Mitchell 1981; Silver 1983; Shavlik 1990; Mahadevan et al.1993; Gervasio &amp; Dejong 1994; Dejong 1994</span>）。<span class="s6">Bennett &amp; Dejong </span>（<span class="s6">1996</span>）研究了基于解释学习在机器人规划系统的应用，其 系统中描述其世界和行为的领域理论是不完美的。<span class="s6">Dietterich &amp; Flann </span>（<span class="s6">1995</span>）探索了基于解释 学习和增强学习（见第 <span class="s6">13 </span>章）的集成。<span class="s6">Mitchell &amp; Thrun</span>（<span class="s6">1993</span>）描述了将一个基于解释的神 经网络学习方法（见第 <span class="s6">12 </span>章讨论的 <span class="s6">EBNN </span>算法）应用到增强学习问题中。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 6pt;text-indent: 0pt;text-align: justify;">11.5 <span class="s17">小结和补充读物</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 27pt;text-indent: 0pt;text-align: left;">本章的要点包括</p><p style="padding-top: 6pt;padding-left: 49pt;text-indent: -21pt;text-align: justify;"><span class="s10"> </span>纯粹的归纳学习方法寻找一个假设以拟合训练数据，与此不同，纯粹的分析学习 方法搜寻一个假设拟合学习器的先验知识并覆盖训练样例。人类经常使用先验知 识指导新假设的形成。本章考查了纯粹的分析学习方法。下一章介绍归纳<span class="s6">-</span>分析学 习的结合。</p><p style="padding-left: 49pt;text-indent: -21pt;line-height: 94%;text-align: justify;"><span class="s10"> </span>基于解释的学习是分析学习的一种形式，其中学习器处理每个新训练样例的方法 是（<span class="s6">1</span>）按照领域理论解释该样例中观察到的目标值，（<span class="s6">2</span>）分析此解释以确定解 释成立的一般条件；（<span class="s6">3</span>）改进其假设以合并这些一般条件。</p><p class="s6" style="padding-left: 49pt;text-indent: -21pt;line-height: 94%;text-align: justify;"><span class="s10"> </span>Prolog-EBG <span class="p">是一个基于解释的学习算法，它使用一阶 </span>Horn <span class="p">子句来表示其领域理论 和学到的假设。在 </span>Prolog-EBG <span class="p">中，解释即为 </span>Prolog <span class="p">证明，而从解释中抽取的假设 是此证明的最弱前像。作为结果，由 </span>Prolog-EBG <span class="p">输出的假设从其领域理论中演绎 派生。</span></p><p style="padding-left: 49pt;text-indent: -21pt;text-align: left;"><span class="s10"> </span>如 <span class="s6">Prolog-EBG </span>这样的分析学习方法建立有用的中间特征作为分析单独训练样例的 一个副效用。这种生成特征的分析途径补充了如后向传播这样的归纳方法中基于 统计方法的中间特征生成（如隐藏单元特征）。</p><p style="padding-left: 49pt;text-indent: -21pt;line-height: 94%;text-align: left;"><span class="s10"> </span>虽然 <span class="s6">Prolog-EBG </span>不会产生能扩展其领域理论的演绎闭包的假设，其他演绎学习过 程有这个能力。例如，一个包含 <span class="s6">determination </span>断言（如“国籍确定语言”）的领 域理论可被用于与训练数据一起演绎推理超出领域理论的演绎闭包的假设。</p><p style="padding-left: 49pt;text-indent: -21pt;line-height: 94%;text-align: left;"><span class="s10"> </span>可应用正确且完整的领域理论的一类重要问题为大状态空间搜索的问题。如 <span class="s6">Prodigy </span>和 <span class="s6">Soar </span>这样的系统已例示了基于解释的学习方法的效用，它们自动获取有 效的搜索规则以加速后续的问题求解。</p><p style="padding-left: 49pt;text-indent: -21pt;text-align: left;"><span class="s10"> </span>虽然基于解释的学习方法对人类来说很有用，但纯粹的演绎实现（如 <span class="s6">Prolog- EBG</span>）有一缺点在于它输出的假设的正确性只在领域理论正确时才能保证。在下 一章，我们考查了结合归纳和分析学习方法的途径以从不完美的领域理论和有限 训练数据中有效学习。</p><p style="padding-top: 7pt;padding-left: 6pt;text-indent: 21pt;line-height: 107%;text-align: left;">分析学习方法的根源可追溯到 <span class="s6">Fikes et al.</span>（<span class="s6">1972</span>）早期的工作，它可通过对 <span class="s6">ABSTRIPS </span>中 的操作符的分析学习宏操作符 <span class="s6">(macro-operator)</span>。较迟一些的是 <span class="s6">Soloway(1977)</span>的研究，他在学</p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: justify;">习中使用明确的先验知识。类似于本章讨论的基于解释的学习方法首先出现于几个 <span class="s6">80 </span>年代早 期开发的系统，包括 <span class="s6">DeJong(1981); Mitchell(1981); Winston et al.(1983); </span>和 <span class="s6">Silver(1983)</span>。 <span class="s6">DeJong &amp; Mooney(1986)</span>和 <span class="s6">Mitchell et al.(1986)</span>提供了对基于有解释学习方法的一般描述，这些 引发了 <span class="s6">80 </span>年代晚期对这个主题的研究热潮。由依里诺斯大学所做的一系列基于解释的学习的 研究由 <span class="s6">DeJong(1993)</span>描述，其中包括修改解释的结构从循环的和临时的解释中正确泛化。更多 最近的研究着重于扩展基于解释的方法以使用不完美的领域理论，以及结合归纳学习和分析学 习（见第 <span class="s6">12 </span>章）。关于目的和先验知识在人类和机器学习中的作用，<span class="s6">Ram &amp; Leake(1995)</span>提供 了一个综合的叙述，而近期基于解释的学习的概览见 <span class="s6">DeJong(1997)</span>。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 109%;text-align: justify;">应用带有完美领域理论的最严肃的尝试是在学习搜索控制的领域，或“加速”学习。由 <span class="s6">Laird et al.(1986)</span>提出的 <span class="s6">Soar </span>系统和 <span class="s6">Carbonell et al.</span>（<span class="s6">1990</span>）描述的 <span class="s6">Prodigy </span>系统是使用基于解 释的学习以学习问题求解的两个最成熟的系统。 <span class="s6">Rosenbloom &amp; Laird(1986)</span>讨论了 <span class="s6">Soar </span>的学习 方法（称为 <span class="s6">chunking</span>）和其他基于解释学习方法之间的紧密联系。最近 <span class="s6">Dietterich &amp; Flann</span></p><p style="padding-left: 26pt;text-indent: -21pt;text-align: left;">（<span class="s6">1995</span>）探索了结合基于解释的学习和增强学习以学习搜索控制的方法。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 110%;text-align: justify;">虽然我们这里的主要目的是研究机器学习算法，仍需注意到对人类学习的实验性研究为人 类学习是基于解释这一猜想提供了支持。例如，<span class="s6">Ahn et al.</span>（<span class="s6">1987</span>）和 <span class="s6">Qin et al.</span>（<span class="s6">1992</span>）概述了 支持人类应用基于解释学习过程这一推想的证据。<span class="s6">Wisniewski &amp; Medin</span>（<span class="s6">1995</span>）描述了对人类 学习的实验性研究，它建议在先验知识和观察数据之间进行丰富的相互作用以影响学习过程。 <span class="s6">Kotovsky &amp; Baillargeon</span>（<span class="s6">1994</span>）描述的实验说明即使 <span class="s6">11 </span>个月大的婴儿在其学习时也是基于其 先验知识的。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">基于解释的学习中执行的分析类似于 <span class="s6">Prolog </span>程序中使用的几类程序优化方法，比如部分评 估（<span class="s6">partial evaluation</span>）。<span class="s6">van Harmelen &amp; Bundy </span>（<span class="s6">1988</span>）提供了对此关系的讨论。</p><p style="padding-top: 3pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">习题</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 27pt;text-indent: 0pt;text-align: left;">11.1 <span class="p">考虑学习问题为 学 习目标概 念 “居住在 同 一房屋内 的 两个人， ” 表示为谓词 </span></p><p class="s21" style="padding-top: 1pt;padding-left: 26pt;text-indent: -21pt;line-height: 212%;text-align: left;">HouseMates<span class="s6">(</span>x<span class="s6">,</span>y<span class="s6">)</span><span class="p">。下面为此概念的一个正例： </span>HouseMates<span class="s6">(</span>Joe<span class="s6">, </span>Sue<span class="s6">)</span></p><p class="s21" style="padding-top: 2pt;padding-left: 26pt;text-indent: 0pt;text-align: left;">Person<span class="s6">(</span>Joe<span class="s6">) </span>Person<span class="s6">(</span>Sue<span class="s6">)</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 26pt;text-indent: 0pt;line-height: 229%;text-align: left;">Sex<span class="s6">(</span>Joe<span class="s6">, </span>Male<span class="s6">) </span>Sex<span class="s6">(</span>Sue<span class="s6">, </span>Female<span class="s6">) </span>HairColor<span class="s6">(</span>Joe<span class="s6">, </span>Black<span class="s6">) </span>HairColor<span class="s6">(</span>Sue<span class="s6">, </span>Brown<span class="s6">) </span>Height<span class="s6">(</span>Joe<span class="s6">, </span>Short<span class="s6">) </span>Height<span class="s6">(</span>Sue<span class="s6">, </span>Short<span class="s6">) </span>Nationality<span class="s6">(</span>Joe<span class="s6">, </span>US<span class="s6">) </span>Nationality<span class="s6">(</span>Sue<span class="s6">, </span>US<span class="s6">) </span>Mother<span class="s6">(</span>Joe<span class="s6">, </span>Mary<span class="s6">) </span>Mother<span class="s6">(</span>Sue<span class="s6">, </span>Mary<span class="s6">)</span></p><p class="s21" style="padding-left: 26pt;text-indent: 0pt;line-height: 193%;text-align: left;">Age<span class="s6">(</span>Joe<span class="s6">, 8) </span>Age<span class="s6">(</span>Sue<span class="s6">, 6) </span><span class="p">下面的领域理论有助于获取 </span>HouseMates <span class="p">概念： </span>HouseMates<span class="s6">(</span>x<span class="s6">, </span>y<span class="s6">)</span><span class="p">←</span>InSameFamily<span class="s6">(</span>x<span class="s6">, </span>y<span class="s6">) </span>HouseMates<span class="s6">(</span>x<span class="s6">, </span>y<span class="s6">) </span><span class="p">←</span>FraternityBrothers<span class="s6">(</span>x<span class="s6">, </span>y<span class="s6">) </span>InSameFamily<span class="s6">(</span>x<span class="s6">, </span>y<span class="s6">) </span><span class="p">←</span>Married<span class="s6">(</span>x<span class="s6">, </span>y<span class="s6">)</span></p><p class="s21" style="padding-top: 2pt;padding-left: 26pt;text-indent: 0pt;line-height: 190%;text-align: left;">InSameFamily<span class="s6">(</span>x<span class="s6">, </span>y<span class="s6">) </span><span class="p">←</span>Youngster<span class="s6">(</span>x<span class="s6">) </span><span class="p">∧</span>Youngster<span class="s6">(</span>y<span class="s6">) </span><span class="p">∧</span>SameMother<span class="s6">(</span>x<span class="s6">,</span>y<span class="s6">) </span>SameMother<span class="s6">(</span>x<span class="s6">,</span>y<span class="s6">) </span><span class="p">←</span>Mother<span class="s6">(</span>x<span class="s6">,</span>z<span class="s6">) </span><span class="p">∧</span>Mother<span class="s6">(</span>y<span class="s6">,</span>z<span class="s6">)</span></p><p class="s21" style="padding-top: 2pt;padding-left: 26pt;text-indent: 0pt;text-align: left;">Youngster<span class="s6">(</span>x<span class="s6">) </span><span class="p">←</span>Aget<span class="s6">(</span>x<span class="s6">,</span>a<span class="s6">)</span><span class="p">∧</span>LessThan<span class="s6">(</span>a<span class="s6">,10)</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 26pt;text-indent: 0pt;text-align: left;">应用 <span class="s6">Prolog-EBG </span>算法到泛化上述实例的任务中，使用上面的领域理论。确切地讲：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 20pt;line-height: 107%;text-align: left;">（<span class="s6">a</span>）手动执行 <span class="s6">Prolog-EBG </span>算法应用于此问题，也就是说，写出对此实例生成的解释，写 出此解释中回归目标概念的结果，以及得到的 <span class="s6">Horn </span>子句规则。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">（<span class="s6">b</span>）假定目标概念为“与 <span class="s21">Joe </span>住在一起的人”而不是“住在一起的两个人。”用上面的 相同的形式化的方法写出目标概念。假定训练实例和领域理论与以前相同，<span class="s6">Prolog-EBG </span>对此 新目标概念产生的 <span class="s6">Horn </span>子句是什么？</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 26pt;text-indent: 0pt;text-align: left;">11.2 <span class="p">如 </span>11.3.1 <span class="p">节指出的</span>, Prolog-EBG <span class="p">可构造出并非实例的显式特征的有用的新特征，但它</span></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 113%;text-align: justify;">们是用显式特征定义的，并且有助于描述合适的泛化。这些特征的推导是分析训练样例解释的 一个副效应。推导有用特征的另一方法是对多层神经网络使用反向传播算法，其中新特征是基 于大量样例的统计属性由隐藏单元学习到的。能否推荐一种方法，可以结合这些分析的和归纳 的途径来生成新特征？（注意：这是一个待解决的研究问题。）</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s8" style="padding-left: 100pt;text-indent: 0pt;line-height: 24pt;text-align: left;">第<span class="h1">12</span>章 归纳和分析学习的结合</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 12pt;text-indent: 21pt;line-height: 112%;text-align: justify;">纯粹的归纳学习方法通过在训练样例中寻找经验化的规律来形成一般假设。纯粹的分析方 法使用先验知识演绎推导一般假设。本章考虑将归纳和分析的机制结合起来的方法，以获得两 者的优点：有先验知识时更高的泛化精度，和依赖训练数据克服先验知识的不足。所得到的结 合的方法比纯粹的归纳学习方法和纯粹的分析学习方法性能都要高。本章考虑的归纳<span class="s6">-</span>分析学 习方法同时基于符号表示和人工神经网络表示。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 12pt;text-indent: 0pt;text-align: left;">12.1 <span class="s17">动机</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 12pt;text-indent: 21pt;line-height: 112%;text-align: justify;">在前几章我们已经见到了两种类型的机器学习：归纳学习和分析学习。归纳方法如决策树 归纳和神经网络反向传播等，它寻找拟合训练数据的一般假设。分析的方法如 <span class="s6">Prolog-EBG</span>， 它寻找拟合先验知识的一般假设，同时使它覆盖训练数据。这两种学习范型所基于的对学习到 的假设的论证方法有根本的不同，因此，优缺点互为补充。将它们结合起来有可能得到更强有 力的学习方法。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 12pt;text-indent: 21pt;line-height: 112%;text-align: justify;">纯粹的分析学习方法优点在于，可用先验知识从较少的数据中更精确地泛化以引导学习， 然而当先验知识不正确或不足时，这一方法可能会进入歧途。纯粹的归纳方法具有的优点是不 需要显式的先验知识，并且主要基于训练数据学习到规律。然而，若训练数据不足时它能会失 败，并且会被其中隐式的归纳偏置所误导，而归纳偏置是从观察数据中泛化所必需的。表 <span class="s6">12-1 </span>概述了两者的互补的优点和缺陷。本章考虑的问题是怎样将二者结合成一个单独的算法，以获 得它们各自的优点。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 12pt;text-indent: 21pt;line-height: 110%;text-align: justify;">归纳和分析学习方法之间的不同可从它们对学习到的假设进行的论证（<span class="s6">justification</span>）的性 质中看出。由纯粹的分析学习（如 <span class="s6">Prolog-EBG</span>）输出的假设执行的是逻辑（<span class="s6">logical</span>）论证：输 出的假设从领域理论和训练数据中演绎派生。对纯粹的归纳学习方法（如反向传播）输出的假 设执行的是统计论证：输出的假设从统计论据中派生，它说明训练样本足够大从而可能代表样 例的基准分布。归纳的统计论证在第 <span class="s6">7 </span>章讨论的 <span class="s6">PAC </span>学习中已被清晰地阐明。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 12pt;text-indent: 21pt;line-height: 113%;text-align: justify;">既然分析的方法提出逻辑论证的假设，而归纳方法提供统计论证的假设，很容易看出为什 么可以将两者结合起来。逻辑的论证的强度只相当于它们所基于的假定或先验知识。如果先验 知识不正确或不可得，逻辑论证是不可信的且无力的。统计论证的强度依赖于它们基于的数据 和统计假定。当基准分布不可信或数据稀缺时，统计论证也是不可信且无力的。简而言之，两 种方法针对不同的类型的问题时才有效。通过两者的结合，有望开发出更通用的学习方法，可 以覆盖较广的学习任务。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="570" height="2" alt="image" src="机器学习/Image_414.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="570" height="2" alt="image" src="机器学习/Image_415.png"/></span></p><p style="padding-left: 131pt;text-indent: 0pt;text-align: left;">表 <span class="h4">12-1 </span>纯粹的分析学习和纯粹归纳学习的比较</p><p style="text-indent: 0pt;text-align: left;"><br/></p><table style="border-collapse:collapse;margin-left:142.52pt" cellspacing="0"><tr style="height:27pt"><td style="width:101pt;border-top-style:solid;border-top-width:2pt;border-top-color:#808080;border-bottom-style:solid;border-bottom-width:2pt;border-bottom-color:#808080"><p class="s174" style="padding-top: 5pt;padding-left: 11pt;text-indent: 0pt;text-align: left;">归纳学习</p></td><td style="width:100pt;border-top-style:solid;border-top-width:2pt;border-top-color:#808080;border-bottom-style:solid;border-bottom-width:1pt"><p class="s174" style="padding-top: 5pt;padding-left: 53pt;text-indent: 0pt;text-align: left;">分析学习</p></td></tr></table><p style="text-indent: 0pt;text-align: left;"><br/></p><table style="border-collapse:collapse;margin-left:6.60001pt" cellspacing="0"><tr style="height:17pt"><td style="width:85pt;border-top-style:solid;border-top-width:2pt;border-top-color:#808080"><p class="s174" style="padding-top: 1pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">目标</p></td><td style="width:187pt;border-top-style:solid;border-top-width:2pt;border-top-color:#808080"><p class="s174" style="padding-top: 1pt;padding-left: 62pt;text-indent: 0pt;text-align: left;">拟合数据的假设</p></td><td style="width:110pt;border-top-style:solid;border-top-width:1pt"><p class="s174" style="padding-top: 1pt;padding-left: 17pt;text-indent: 0pt;text-align: left;">拟合领域理论的假设</p></td></tr><tr style="height:16pt"><td style="width:85pt"><p class="s174" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">论证</p></td><td style="width:187pt"><p class="s174" style="padding-left: 62pt;text-indent: 0pt;text-align: left;">统计推理</p></td><td style="width:110pt"><p class="s174" style="padding-left: 17pt;text-indent: 0pt;text-align: left;">演绎推理</p></td></tr><tr style="height:16pt"><td style="width:85pt"><p class="s174" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">优点</p></td><td style="width:187pt"><p class="s174" style="padding-left: 62pt;text-indent: 0pt;text-align: left;">需要很少先验知识</p></td><td style="width:110pt"><p class="s174" style="padding-left: 17pt;text-indent: 0pt;text-align: left;">从稀缺的数据中学习</p></td></tr><tr style="height:17pt"><td style="width:85pt;border-bottom-style:solid;border-bottom-width:2pt;border-bottom-color:#808080"><p class="s174" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">缺陷</p></td><td style="width:187pt;border-bottom-style:solid;border-bottom-width:2pt;border-bottom-color:#808080"><p class="s174" style="padding-left: 62pt;text-indent: 0pt;text-align: left;">稀缺的数据，不正确的偏置</p></td><td style="width:110pt;border-bottom-style:solid;border-bottom-width:2pt;border-bottom-color:#808080"><p class="s174" style="padding-left: 17pt;text-indent: 0pt;text-align: left;">不完美的领域理论</p></td></tr></table><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 19pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="569" height="1" alt="image" src="机器学习/Image_416.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="380" height="1" alt="image" src="机器学习/Image_417.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="570" height="2" alt="image" src="机器学习/Image_418.png"/></span></p><p class="s48" style="padding-left: 21pt;text-indent: 0pt;text-align: left;">插图——原书页码： <span class="s21">336</span></p><p class="s6" style="padding-top: 6pt;padding-left: 32pt;text-indent: 0pt;line-height: 107%;text-align: left;">Inductive learning: <span class="p">归纳学习 </span>Plentiful data: <span class="p">丰富的数据 </span>No prior knowledge:<span class="p">无先验知识 </span>Analytical learning: <span class="p">分析学习</span></p><p class="s6" style="padding-left: 32pt;text-indent: 0pt;line-height: 107%;text-align: left;">Perfect prior knowledge:<span class="p">完美的先验知识 </span>Scarce data: <span class="p">稀缺的数据</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 20pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="553" height="1" alt="image" src="机器学习/Image_419.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 64pt;text-indent: 104pt;text-align: left;">图 <span class="h4">12-1 </span>学习任务的分布范围。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-left: 43pt;text-indent: 21pt;line-height: 129%;text-align: justify;">在最左端，没有可用的先验知识，因此需要纯粹的归纳学习方法以及较高的样本复杂度。在最右 端，有完美的领域理论，可以使用如 <span class="s16">Prolog-EBG </span>这样的纯粹分析方法。更多的实际问题位于这两个极 端之间。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 12pt;text-indent: 21pt;line-height: 111%;text-align: justify;">图 <span class="s6">12-1 </span>概述了学习问题的分布范围，它随着可获得的先验知识和训练数据不同而变化。 在一个极端，有大量的训练数据，但没有先验知识。在另一极端，有很强的先验知识，但训练 数据很少。多数实际学习问题位于这两个极端之间。例如，分析医疗记录的数据库以学习“用 治疗手段 <span class="s21">x </span>比治疗手段 <span class="s21">y </span>更有效的病症”，通常可以开始于近似的先验知识（如疾病中内在的 因果机制的定性模型），比如认定患者的体温比他的姓名更相关。类似地，在分析一个股票市 场数据库以学习目标概念“股票值在后 <span class="s6">10 </span>个月会翻番的公司”中，如果已有了经济学的大概 知识，可以提出公司的总利润比公司标志的颜色更相关。在这两种问题中，我们的先验知识是 不完整的，但显然，它有助于区分相关和不相关的特征。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 12pt;text-indent: 21pt;line-height: 113%;text-align: justify;">本章考虑的问题是：“我们可以设计出怎样的算法，使用近似的先验知识结合可用数据来 形成一般假设？”注意，即使在使用纯粹的归纳学习算法时，仍有机会基于特定学习任务的先 验知识来选择设计方案。例如，当应用反向传播来解决语音识别这样的问题时，设计者必须选 择输入和输出数据的编码方式、在梯度下降中被最小化的误差函数、隐藏单元的数量、网络的 拓扑结构、学习速率和冲量等。在做这些选择时，设计者可以将领域特定的知识嵌入到学习算 法中。然而结果仍然是纯粹的归纳算法反向传播的一个实现，由设计者特殊化后针对语音识别 任务。我们的感兴趣的不在于此，而在于一个系统能将先验知识作为显式的输入给学习器，训 练数据也同样作为显式输入。这样它们仍为通用的算法，但利用了领域特定的知识。简要地概 括一下，我们感兴趣的是使用显式输入的领域相关知识的领域无关算法。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 12pt;text-indent: 21pt;line-height: 110%;text-align: justify;">对于结合了归纳和分析学习的不同方法，应使用什么样的准则来比较它们呢？由于学习器 一般不能预先知道领域理论和训练数据的质量。我们感兴趣的是能对图 <span class="s6">12-1 </span>整个问题系列都 可操作的一般方法。这样的学习方法应具有以下的特殊属性：</p><p class="s10" style="padding-left: 28pt;text-indent: 0pt;line-height: 14pt;text-align: left;"> <span class="p">如果没有领域理论，它至少能像纯粹的归纳方法一样有效学习。</span></p><p class="s10" style="padding-left: 28pt;text-indent: 0pt;line-height: 14pt;text-align: left;"> <span class="p">如果有完美的领域理论，它至少能像纯粹的分析方法样有效学习。</span></p><p class="s10" style="padding-left: 49pt;text-indent: -21pt;line-height: 14pt;text-align: left;"> <span class="p">如果领域理论和训练数据都不完美，它应能结合两者的长处，比单纯的归纳或分 析方法的性能都要好。</span></p><p class="s10" style="padding-left: 28pt;text-indent: 0pt;line-height: 13pt;text-align: left;"> <span class="p">它应能处理训练数据中未知程度的差错。</span></p><p class="s10" style="padding-left: 26pt;text-indent: 1pt;line-height: 149%;text-align: left;"> <span class="p">它应能处理领域理论中未知程度的差错。 注意这里列出的期望目标很难达到。例如，处理训练数据中的差错，即使在基于统计的归</span></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 10pt;text-align: justify;">纳方法中，如果没有某些先验知识和对差错分布的假定，这仍是值得研究的问题。结合归纳和</p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 0pt;line-height: 113%;text-align: justify;">分析学习的方法是当前活跃的研究领域。虽然上面列出的是我们希望算法能达到的美好性质， 目前没有算法能以完全一般化的方式满足所有这些约束。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 110%;text-align: justify;">下一节对结合归纳<span class="s6">-</span>分析学习的问题作出了更详细的讨论。后面几节描述了 <span class="s6">3 </span>种不同的途 径，结合近似的先验知识和可用数据来指导学习器搜索合适的假设。每种途径都已在多个问题 领域中显示出有超出纯归纳方法的性能。为方便比较，我们使用同一例子来说明 <span class="s6">3 </span>种途径。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 6pt;text-indent: 0pt;text-align: justify;">12.2 <span class="s17">学习的归纳</span>-<span class="s17">分析途径</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 6pt;text-indent: 0pt;text-align: justify;">12.2.1 <span class="s25">学习问题</span></h3><p style="padding-left: 27pt;text-indent: 0pt;line-height: 28pt;text-align: left;">概而言之，本章考虑的学习问题为： 已知：</p><p style="padding-top: 1pt;padding-left: 28pt;text-indent: 0pt;line-height: 14pt;text-align: left;"><span class="s10"> </span>一个训练样例集合 <span class="s21">D</span>，可能包含差错</p><p style="padding-left: 28pt;text-indent: 0pt;line-height: 14pt;text-align: left;"><span class="s10"> </span>一个领域理论 <span class="s21">B</span>，可能包含差错</p><p class="s10" style="padding-left: 28pt;text-indent: 0pt;line-height: 14pt;text-align: left;"> <span class="p">候选假设的空间 </span><span class="s21">H</span></p><p style="padding-top: 7pt;padding-left: 26pt;text-indent: 0pt;text-align: left;">求解：</p><p class="s10" style="padding-top: 5pt;padding-left: 26pt;text-indent: 1pt;line-height: 148%;text-align: left;"> <span class="p">一个最好地拟合训练样例和领域理论的假设 “最好地拟合训练样例和领域理论”这句话确切含义是什么？或者说，是否会选择一个拟</span></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 11pt;text-align: justify;">合数据程度较好而拟合理论较差的假设，或反之？为了更精确起见，需要定义对应数据和对应</p><p class="s21" style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;line-height: 106%;text-align: justify;"><span class="p">于领域理论的假设错误率度量，然后用这些错误率来表示这个问题。回忆第 </span><span class="s6">5 </span><span class="p">章中</span>error<span class="s36">D</span><span class="s6">(</span>h<span class="s6">)</span><span class="p">定 义为</span>D<span class="p">中被</span>h<span class="p">误分类的样例所占比例。可定义</span>h<span class="p">关于领域理论</span>B<span class="p">的错误率</span>error<span class="s36">B</span><span class="s6">(</span>h<span class="s6">)</span><span class="p">为，</span>h<span class="p">与</span>B<span class="p">在分类 一个随机抽取实例时不一致的概率。接下来就可尝试用这些错误率的形式刻画所希望的输出假 设。例如，我们可以要求假设使上述错误率的某种综合度量最小化，如：</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="padding-top: 2pt;padding-left: 149pt;text-indent: 0pt;line-height: 16pt;text-align: left;"><span class="s33">arg min </span>k<span class="s52">D</span>error<span class="s52">D </span><span class="s33">(</span>h<span class="s33">) </span><span class="s38"> </span>k<span class="s52">B</span>error<span class="s52">B </span><span class="s33">(</span>h<span class="s33">)</span></p><p class="s41" style="padding-left: 26pt;text-indent: 0pt;line-height: 8pt;text-align: center;">h<span class="s40"></span>H</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;text-align: justify;"><span class="p">虽然粗看起来这很合理，但还不清楚怎样确定</span>k<span class="s36">D</span><span class="p">和</span>k<span class="s36">B</span><span class="p">的值，以指定拟合数据和拟合理论两 者的相对重要程度。如果有非常差的理论，却有大量可靠数据，最好使</span>error<span class="s36">D</span><span class="s6">(</span>h<span class="s6">)</span><span class="p">的权值更大。 如果有很强的理论，而数据样本很小且存在大量噪声，把</span>error<span class="s36">B</span><span class="s6">(</span>h<span class="s6">)</span><span class="p">的权值增大会得到最好的结 果。当然如果学习器预先不知道领域理论和训练数据的质量，它就不清楚该怎样为这两部分错</span></p><p style="padding-left: 6pt;text-indent: 0pt;text-align: left;">误率加权。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 5pt;text-indent: 21pt;line-height: 109%;text-align: justify;"><span class="p">怎样确定先验知识和数据权值这一问题，另一种解决方法是使用贝叶斯的观点来考虑。回 忆一下第 </span><span class="s6">6 </span><span class="p">章，贝叶斯定律描述了怎样计算给定训练数据 </span>D <span class="p">时假设 </span>h <span class="p">的后验概率 </span>P<span class="s6">(</span>h<span class="s6">|</span>D<span class="s6">)</span><span class="p">。确切 地讲，贝叶斯定律计算此后验概率是基于观察到的数据 </span>D <span class="p">以及先验知识的，以 </span>P<span class="s6">(</span>h<span class="s6">)</span><span class="p">、</span>P<span class="s6">(</span>D<span class="s6">)</span><span class="p">和 </span>P<span class="s6">(</span>D<span class="s6">|</span>h<span class="s6">)</span><span class="p">的形式表示。因此我们可把 </span>P<span class="s6">(</span>h<span class="s6">)</span><span class="p">、</span>P<span class="s6">(</span>D<span class="s6">)</span><span class="p">和 </span>P<span class="s6">(</span>D<span class="s6">|</span>h<span class="s6">)</span><span class="p">看作是某种形式的背景知识或领域理 论，而且可把贝叶斯理论看成一种为领域理论加权的方法，它与观察到的数据 </span>D <span class="p">一起，赋予 </span>h <span class="p">的后验概率为 </span>P<span class="s6">(</span>h<span class="s6">|</span>D<span class="s6">)</span><span class="p">。按照贝叶斯的观点，所选择的假设应为后验概率中最大的一个，并且贝 叶斯公式提供了为此先验知识和观察到数据的贡献加权的良好方法。不幸的是，贝叶斯公式隐 含假定了拥有关于 </span>P<span class="s6">(</span>h<span class="s6">)</span><span class="p">、</span>P<span class="s6">(</span>D<span class="s6">)</span><span class="p">和 </span>P<span class="s6">(</span>D<span class="s6">|</span>h<span class="s6">)</span><span class="p">概率分布的完美的知识。当这些量只是近似已知时，单 独贝叶斯公式没有规定如何将其与观察数据结合起来。（在此情况下一种方法是假定有 </span>P<span class="s6">(</span>h<span class="s6">)</span><span class="p">， </span>P<span class="s6">(</span>D<span class="s6">)</span><span class="p">和 </span>P<span class="s6">(</span>D<span class="s6">|</span>h<span class="s6">)</span><span class="p">之上的先验概率分布，然而后计算后验概率 </span>P<span class="s6">(</span>h<span class="s6">|</span>D<span class="s6">)</span><span class="p">的期望值。然而这要求有 </span>P<span class="s6">(</span>h<span class="s6">)</span><span class="p">，</span>P<span class="s6">(</span>D<span class="s6">)</span><span class="p">和 </span>P<span class="s6">(</span>D<span class="s6">|</span>h<span class="s6">)</span><span class="p">之上的先验分布方面的附加知识，因此并没有真正解决此问题。）</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 113%;text-align: justify;">当考虑特定算法时，我们会再次考虑“最佳”拟合假设和数据是什么含义。现在，我们只 是简单地称学习问题是为了使假设在数据和领域理论上错误率的某种综合度量最小化。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">12.2.2 <span class="s25">假设空间搜索</span></h3><p style="padding-top: 10pt;padding-left: 6pt;text-indent: 21pt;line-height: 113%;text-align: justify;">如何将领域理论和训练数据最好地结合起来，以限制可接受假设的搜索？这在机器学习中 仍是待研究的问题。本章考察了几种已提出的方法，其中许多要对已讨论过的归纳方法（如反 向传播，<span class="s6">FOIL</span>）进行扩展。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 110%;text-align: justify;">为了解可能途径的范围，一种办法是回到前面对学习的看法，即将其看作是一种搜索多个 可选假设空间的任务。为了将大多数学习任务刻画为搜索算法，需要定义待搜索的假设空间 <span class="s21">H</span>，搜索的开始点初始假设<span class="s21">h</span><span class="s35">0</span>，定义单个搜索步的搜索算子集合<span class="s21">O</span>，以及指定搜索目标的目的 判据<span class="s21">G</span>。本间中探索了 <span class="s6">3 </span>种方法使用先验知识来改变纯归纳方法中执行的搜索。</p><p style="padding-top: 4pt;padding-left: 49pt;text-indent: -21pt;text-align: left;"><span class="s10"> </span>使用先验知识推导出搜索起步的初始假设。用这种方法，领域理论<span class="s21">B</span>被用于建立一 个与<span class="s21">B</span>一致的初始假设<span class="s21">h</span><span class="s35">0</span>。然后以这个初始假设<span class="s21">h</span><span class="s35">0</span>为起点应用标准归纳方法。例 如，下面描述的<span class="s6">KBNN</span>系统是按这种方法学习人工神经网络的。它使用先验知识来 设计初始网络的互联结构和权值，这样，此初始网络与给定的领域理论完全一 致。然后此初始网络假设使用反向传播算法和训练数据被归纳地精化。从一个与 领域理论一致的假设开始搜索，使得最终输出假设更有可能拟合此理论。</p><p style="padding-left: 49pt;text-indent: -21pt;text-align: justify;"><span class="s10"> </span>使用先验知识来改变假设空间搜索的目标。在这种方法中，目的判据 <span class="s21">G </span>被修改， 以要求输出假设拟合训练样例的同时也拟合领域理论。例如，下面描述的 <span class="s6">EBNN </span>系统以这种方法学习神经网络。神经网络的归纳学习执行梯度下降来使网络在训 练数据上的误差平方最小化，而 <span class="s6">EBNN </span>中执行梯度下降来优化另一个判据。这个 修改的判据包含一个附加项，它衡量了学习到的网络相对于领域理论的误差。</p><p style="padding-left: 49pt;text-indent: -21pt;text-align: left;"><span class="s10"> </span>使用先验知识改变可用的搜索步。在此方法中，领域理论修改了搜索算子集合 <span class="s21">O</span>。例如，下面描述的 <span class="s6">FOCL </span>系统以这种方法学习 <span class="s6">Horn </span>子句集。它基于归纳系统 <span class="s6">FOIL</span>。<span class="s6">FOIL </span>在可能的 <span class="s6">Horn </span>子句空间上执行贪婪搜索，每步通过加入一个新文字 来修正当前假设。<span class="s6">FOCL </span>在修正假设中使用领域理论来扩展可用的文字集合。它允 许在单个搜索步中加入多个文字，只要它们能由领域理论保证其正确性。以这种 方式，<span class="s6">FOCL </span>在假设空间中移动一步相当于使用原来的算法移动多步。这些“宏移</p><p style="padding-top: 1pt;padding-left: 55pt;text-indent: 0pt;line-height: 14pt;text-align: left;">动”（<span class="s6">macro-moves</span>）可极大地改变搜索的方向，这样最终的与数据一致的假设与 只使用归纳搜索步时找到的假设不同。</p><p style="padding-top: 6pt;padding-left: 33pt;text-indent: 0pt;text-align: left;">下面几节依次介绍了这几种方法。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 12pt;text-indent: 0pt;text-align: left;">12.3 <span class="s17">使用先验知识得到初始假设</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 11pt;text-indent: 21pt;line-height: 110%;text-align: justify;">一种使用先验知识的方法是，将假设初始化为完美拟合领域理论，然后按照需要归纳地精 化此初始假设以拟合训练数据。这种方法被用于 <span class="s6">KBANN</span>（<span class="s6">Knowledge-Based Artificial Neural Network</span>，基于知识的人工神经网络）算法中。在 <span class="s6">KBANN </span>中，首先建立了一个初始的网络。 对每个可能实例，网络赋予它的分类等于领域理论赋予的分类。然后应用了反向传播算法来调 整初始网络，使其拟合训练样例。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 12pt;text-indent: 21pt;line-height: 112%;text-align: justify;">很容易看出，该技术的动机在于：如果领域理论是正确的，初始假设将正确分类所有训练 样例，而无需再对其修正。然而，如果初始假设不能完美地分类训练样例，那么它需要被归纳 精化，以改进其在训练样例上的拟合度。回忆在纯粹归纳的反向传播算法中，权值一般被初始 化为小的随机值。<span class="s6">KBANN </span>背后的直观含义在于，即使领域理论是近似正确的，将网络初始化 为拟合领域理论，比初始化为随机权值有更好的近似开端。这应该会得到有更好的泛化精度的 最终假设。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 12pt;text-indent: 21pt;line-height: 107%;text-align: justify;">这种使用领域理论来初始化假设的途径已经被许多研究者探索过。 包括 <span class="s6">Shavlik &amp; Towell(1989)</span>， <span class="s6">Towell &amp; Shavlik(1994), Fu (1989, 1993) </span>和 <span class="s6">Pratt(1993a, 1993b)</span>。我们将使用 <span class="s6">Shavlik &amp; Towell</span>（<span class="s6">1989</span>）描述的 <span class="s6">KBANN </span>算法来例示这一途径。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 12pt;text-indent: 0pt;text-align: left;">12.3.1 KBANN <span class="s25">算法</span></h3><p class="s6" style="padding-top: 10pt;padding-left: 33pt;text-indent: 0pt;text-align: left;">KBANN <span class="p">运用领域理论来初始化假设。其中假定领域理论用一组命题形式的非递归的 </span>Horn</p><p style="padding-top: 1pt;padding-left: 32pt;text-indent: -21pt;text-align: left;">子句来表示。命题形式 <span class="s6">Horn </span>子句表示它不包含变量。<span class="s6">KBANN </span>的输入和输出如下：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 32pt;text-indent: 0pt;text-align: left;">已知：</p><p class="s10" style="padding-top: 5pt;padding-left: 34pt;text-indent: 0pt;line-height: 14pt;text-align: left;"> <span class="p">一组训练样例</span></p><p style="padding-left: 32pt;text-indent: 1pt;line-height: 148%;text-align: left;"><span class="s10"> </span>由非递归命题型 <span class="s6">Horn </span>子句组成的领域理论 求解：</p><p class="s10" style="padding-left: 34pt;text-indent: 0pt;text-align: left;"> <span class="p">一个拟合训练样例的，被领域理论偏置的人工神经网络</span></p><p style="padding-top: 7pt;padding-left: 25pt;text-indent: 0pt;text-align: center;">表 <span class="h4">12-2KBANN </span>算法</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-left: 64pt;text-indent: 0pt;text-align: left;">领域理论被转换为等效的神经网络（步骤 <span class="s16">1</span>－<span class="s16">3</span>），然后用反向传播算法归纳精化（第 <span class="s16">4 </span>步）。<span class="s16">W</span></p><p class="s14" style="padding-top: 3pt;padding-left: 11pt;text-indent: 31pt;text-align: left;">常量的值可取为 <span class="s16">0.4</span>。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 2pt;text-align: left;"><span><img width="570" height="2" alt="image" src="机器学习/Image_420.png"/></span></p><p class="s16" style="padding-top: 1pt;padding-left: 11pt;text-indent: 0pt;line-height: 126%;text-align: left;">KBANN(<i>Domain</i>_<i>Theory</i>, <i>Training</i>_<i>Examples</i>) <i>Domain</i>_<i>Theory</i>: <span class="s14">非递归命题型 </span>Horn <span class="s14">子句集合 </span><i>Training</i>_<i>Examples</i>:<span class="s14">目标函数的</span>&lt;<i>input</i>, <i>output</i>&gt;<span class="s14">对的集合</span></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 2pt;text-align: left;"><span><img width="570" height="2" alt="image" src="机器学习/Image_421.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 2pt;text-align: left;"><span><img width="570" height="2" alt="image" src="机器学习/Image_422.png"/></span></p><p class="s14" style="padding-left: 26pt;text-indent: 0pt;text-align: left;">分析步：创建一个等价于领域理论的初始网络</p><p class="s16" style="padding-top: 3pt;padding-left: 33pt;text-indent: 0pt;text-align: left;">1. <span class="s14">对每个实例属性创建一个网络输入</span></p><p class="s16" style="padding-top: 3pt;padding-left: 33pt;text-indent: 0pt;text-align: left;">2. <span class="s14">对 </span><i>Domain</i>_<i>Theory </i><span class="s14">的每个 </span>Horn <span class="s14">子句，如下创建一个网络单元</span></p><p class="s55" style="padding-top: 3pt;padding-left: 54pt;text-indent: 0pt;text-align: left;">n <span class="s14">连接此单元的输入到此子句的先行词测试的属性</span></p><p class="s14" style="padding-top: 3pt;padding-left: 54pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span>对子句的每个非负先行词，赋予权值 <span class="s56">W </span>给对应的 <span class="s16">sigmoid </span>单元输入</p><p class="s14" style="padding-top: 3pt;padding-left: 54pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span>对子句的每个负先行词，赋予权值<span class="s16">-</span><span class="s56">W </span>给对应的 <span class="s16">sigmoid </span>单元输入</p><p class="s56" style="padding-top: 3pt;padding-left: 54pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span><span class="s14">设置此单元的阈值</span>w<span class="s64">0</span><span class="s14">为</span><span class="s16">-(</span>n<span class="s16">-0.5)</span>W<span class="s14">，其中</span>n<span class="s14">为子句的非负先行词的数目</span></p><p class="s14" style="padding-top: 3pt;padding-left: 33pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><span class="s16">3. </span>在网络单元之间增加附加的连接，连接深度为 <span class="s56">i </span>的每个网络单元到深度为 <span class="s56">i</span><span class="s16">+1 </span>的所有网络单元的 输入层上。赋予这些附加的连接为接近 <span class="s16">0 </span>的随机权值。</p><p class="s14" style="padding-top: 2pt;padding-left: 11pt;text-indent: 0pt;text-align: left;">归纳步：精化此初始网络</p><p class="s16" style="padding-top: 3pt;padding-left: 33pt;text-indent: 0pt;text-align: left;">4. <span class="s14">应用反向传播算法来调整初始网络权值以拟合 </span><i>Training</i>_<i>Examples</i></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 2pt;text-align: left;"><span><img width="570" height="2" alt="image" src="机器学习/Image_423.png"/></span></p><p class="s6" style="padding-top: 6pt;padding-left: 12pt;text-indent: 21pt;line-height: 110%;text-align: justify;">KBANN <span class="p">算法包含两个阶段，首先它创建一个完美拟合领域理论的人工神经网络，然后使 用反向传播算法来精化初始网络以拟合训练样例。算法的细节，包括创建初始网络的算法在表 </span>12-2 <span class="p">中列出，并将在 </span>12.3.2 <span class="p">节说明。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 27pt;text-indent: 0pt;text-align: center;">表 <span class="h4">12-3</span><span class="s7">Cup </span>学习任务</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="570" height="2" alt="image" src="机器学习/Image_424.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="1" height="275" alt="image" src="机器学习/Image_425.png"/></span></p><p class="s14" style="padding-left: 27pt;text-indent: 0pt;text-align: center;">表中列出了目标概念 <span class="s56">Cup </span>的一组近似领域理论和一组训练样例。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><table style="border-collapse:collapse;margin-left:6.60001pt" cellspacing="0"><tr style="height:126pt"><td style="width:388pt;border-top-style:solid;border-top-width:2pt;border-top-color:#808080" colspan="11"><p class="s174" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">领域理论：</p><p class="s54" style="padding-top: 3pt;padding-left: 150pt;padding-right: 112pt;text-indent: 0pt;line-height: 126%;text-align: center;">Cup<span class="s174">←</span>Stable<span class="s53">, </span>Liftable<span class="s53">, </span>OpenVessel Stable<span class="s174">←</span>BottomIsFlat Liftable<span class="s174">←</span>Graspable<span class="s53">, </span>Light Graspable<span class="s174">←</span>HasHandle</p><p class="s54" style="padding-left: 5pt;text-indent: 118pt;text-align: left;">OpenVessel<span class="s174">←</span>HasConcavity<span class="s53">, </span>ConcavityPointsUp</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s174" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">训练样例：</p></td></tr><tr style="height:16pt"><td style="width:122pt"/><td style="width:30pt;border-top-style:solid;border-top-width:1pt"/><td style="width:35pt;border-top-style:solid;border-top-width:1pt"><p class="s54" style="padding-top: 1pt;padding-left: 17pt;text-indent: 0pt;text-align: left;">Cups</p></td><td style="width:18pt;border-top-style:solid;border-top-width:1pt"/><td style="width:26pt;border-top-style:solid;border-top-width:1pt;border-right-style:solid;border-right-width:1pt"/><td style="width:26pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt"/><td style="width:26pt;border-top-style:solid;border-top-width:1pt"/><td style="width:53pt;border-top-style:solid;border-top-width:1pt" colspan="2"><p class="s54" style="padding-top: 1pt;padding-left: 8pt;text-indent: 0pt;text-align: left;">Non<span class="s53">-</span>Cups</p></td><td style="width:52pt;border-top-style:solid;border-top-width:1pt;border-right-style:solid;border-right-width:1pt" colspan="2"/></tr><tr style="height:16pt"><td style="width:122pt"><p class="s54" style="padding-top: 2pt;padding-left: 38pt;text-indent: 0pt;text-align: left;">BottomIsFlat</p></td><td style="width:30pt"><p class="s174" style="padding-left: 12pt;text-indent: 0pt;text-align: left;">√</p></td><td style="width:35pt"><p class="s174" style="padding-left: 8pt;text-indent: 0pt;text-align: left;">√</p></td><td style="width:18pt"><p class="s174" style="text-indent: 0pt;text-align: left;">√</p></td><td style="width:26pt;border-right-style:solid;border-right-width:1pt"><p class="s174" style="padding-left: 8pt;text-indent: 0pt;text-align: left;">√</p></td><td style="width:26pt;border-left-style:solid;border-left-width:1pt"><p class="s174" style="padding-left: 8pt;text-indent: 0pt;text-align: left;">√</p></td><td style="width:26pt"><p class="s174" style="padding-left: 8pt;text-indent: 0pt;text-align: left;">√</p></td><td style="width:26pt"><p class="s174" style="padding-left: 8pt;text-indent: 0pt;text-align: left;">√</p></td><td style="width:27pt"/><td style="width:26pt"/><td style="width:26pt;border-right-style:solid;border-right-width:1pt"><p class="s174" style="padding-left: 8pt;text-indent: 0pt;text-align: left;">√</p></td></tr><tr style="height:16pt"><td style="width:122pt"><p class="s54" style="padding-top: 2pt;padding-left: 38pt;text-indent: 0pt;text-align: left;">ConcavityPointsUp</p></td><td style="width:30pt"><p class="s174" style="padding-left: 12pt;text-indent: 0pt;text-align: left;">√</p></td><td style="width:35pt"><p class="s174" style="padding-left: 8pt;text-indent: 0pt;text-align: left;">√</p></td><td style="width:18pt"><p class="s174" style="text-indent: 0pt;text-align: left;">√</p></td><td style="width:26pt;border-right-style:solid;border-right-width:1pt"><p class="s174" style="padding-left: 8pt;text-indent: 0pt;text-align: left;">√</p></td><td style="width:26pt;border-left-style:solid;border-left-width:1pt"><p class="s174" style="padding-left: 8pt;text-indent: 0pt;text-align: left;">√</p></td><td style="width:26pt"/><td style="width:26pt"><p class="s174" style="padding-left: 8pt;text-indent: 0pt;text-align: left;">√</p></td><td style="width:27pt"><p class="s174" style="padding-left: 8pt;text-indent: 0pt;text-align: left;">√</p></td><td style="width:26pt"/><td style="width:26pt;border-right-style:solid;border-right-width:1pt"/></tr><tr style="height:16pt"><td style="width:122pt"><p class="s54" style="padding-top: 2pt;padding-left: 38pt;text-indent: 0pt;text-align: left;">Expensive</p></td><td style="width:30pt"><p class="s174" style="padding-left: 12pt;text-indent: 0pt;text-align: left;">√</p></td><td style="width:35pt"/><td style="width:18pt"><p class="s174" style="text-indent: 0pt;text-align: left;">√</p></td><td style="width:26pt;border-right-style:solid;border-right-width:1pt"/><td style="width:26pt;border-left-style:solid;border-left-width:1pt"/><td style="width:26pt"/><td style="width:26pt"><p class="s174" style="padding-left: 8pt;text-indent: 0pt;text-align: left;">√</p></td><td style="width:27pt"/><td style="width:26pt"><p class="s174" style="padding-left: 8pt;text-indent: 0pt;text-align: left;">√</p></td><td style="width:26pt;border-right-style:solid;border-right-width:1pt"/></tr><tr style="height:16pt"><td style="width:122pt"><p class="s54" style="padding-top: 2pt;padding-left: 38pt;text-indent: 0pt;text-align: left;">Fragile</p></td><td style="width:30pt"><p class="s174" style="padding-left: 12pt;text-indent: 0pt;text-align: left;">√</p></td><td style="width:35pt"><p class="s174" style="padding-left: 8pt;text-indent: 0pt;text-align: left;">√</p></td><td style="width:18pt"/><td style="width:26pt;border-right-style:solid;border-right-width:1pt"/><td style="width:26pt;border-left-style:solid;border-left-width:1pt"><p class="s174" style="padding-left: 8pt;text-indent: 0pt;text-align: left;">√</p></td><td style="width:26pt"><p class="s174" style="padding-left: 8pt;text-indent: 0pt;text-align: left;">√</p></td><td style="width:26pt"/><td style="width:27pt"><p class="s174" style="padding-left: 8pt;text-indent: 0pt;text-align: left;">√</p></td><td style="width:26pt"/><td style="width:26pt;border-right-style:solid;border-right-width:1pt"><p class="s174" style="padding-left: 8pt;text-indent: 0pt;text-align: left;">√</p></td></tr><tr style="height:16pt"><td style="width:122pt"><p class="s54" style="padding-top: 2pt;padding-left: 38pt;text-indent: 0pt;text-align: left;">HandleOnTop</p></td><td style="width:30pt"/><td style="width:35pt"/><td style="width:18pt"/><td style="width:26pt;border-right-style:solid;border-right-width:1pt"/><td style="width:26pt;border-left-style:solid;border-left-width:1pt"><p class="s174" style="padding-left: 8pt;text-indent: 0pt;text-align: left;">√</p></td><td style="width:26pt"/><td style="width:26pt"><p class="s174" style="padding-left: 8pt;text-indent: 0pt;text-align: left;">√</p></td><td style="width:27pt"/><td style="width:26pt"/><td style="width:26pt;border-right-style:solid;border-right-width:1pt"/></tr><tr style="height:16pt"><td style="width:122pt"><p class="s54" style="padding-top: 2pt;padding-left: 38pt;text-indent: 0pt;text-align: left;">HandleOnSide</p></td><td style="width:30pt"><p class="s174" style="padding-left: 12pt;text-indent: 0pt;text-align: left;">√</p></td><td style="width:35pt"/><td style="width:18pt"/><td style="width:26pt;border-right-style:solid;border-right-width:1pt"><p class="s174" style="padding-left: 8pt;text-indent: 0pt;text-align: left;">√</p></td><td style="width:26pt;border-left-style:solid;border-left-width:1pt"/><td style="width:26pt"/><td style="width:26pt"/><td style="width:27pt"/><td style="width:26pt"><p class="s174" style="padding-left: 8pt;text-indent: 0pt;text-align: left;">√</p></td><td style="width:26pt;border-right-style:solid;border-right-width:1pt"/></tr><tr style="height:16pt"><td style="width:122pt"><p class="s54" style="padding-top: 2pt;padding-left: 38pt;text-indent: 0pt;text-align: left;">HasConcavity</p></td><td style="width:30pt"><p class="s174" style="padding-left: 12pt;text-indent: 0pt;text-align: left;">√</p></td><td style="width:35pt"><p class="s174" style="padding-left: 8pt;text-indent: 0pt;text-align: left;">√</p></td><td style="width:18pt"><p class="s174" style="text-indent: 0pt;text-align: left;">√</p></td><td style="width:26pt;border-right-style:solid;border-right-width:1pt"><p class="s174" style="padding-left: 8pt;text-indent: 0pt;text-align: left;">√</p></td><td style="width:26pt;border-left-style:solid;border-left-width:1pt"><p class="s174" style="padding-left: 8pt;text-indent: 0pt;text-align: left;">√</p></td><td style="width:26pt"/><td style="width:26pt"><p class="s174" style="padding-left: 8pt;text-indent: 0pt;text-align: left;">√</p></td><td style="width:27pt"><p class="s174" style="padding-left: 8pt;text-indent: 0pt;text-align: left;">√</p></td><td style="width:26pt"><p class="s174" style="padding-left: 8pt;text-indent: 0pt;text-align: left;">√</p></td><td style="width:26pt;border-right-style:solid;border-right-width:1pt"><p class="s174" style="padding-left: 8pt;text-indent: 0pt;text-align: left;">√</p></td></tr><tr style="height:16pt"><td style="width:122pt"><p class="s54" style="padding-top: 2pt;padding-left: 38pt;text-indent: 0pt;text-align: left;">HasHandle</p></td><td style="width:30pt"><p class="s174" style="padding-left: 12pt;text-indent: 0pt;text-align: left;">√</p></td><td style="width:35pt"/><td style="width:18pt"/><td style="width:26pt;border-right-style:solid;border-right-width:1pt"><p class="s174" style="padding-left: 8pt;text-indent: 0pt;text-align: left;">√</p></td><td style="width:26pt;border-left-style:solid;border-left-width:1pt"><p class="s174" style="padding-left: 8pt;text-indent: 0pt;text-align: left;">√</p></td><td style="width:26pt"/><td style="width:26pt"><p class="s174" style="padding-left: 8pt;text-indent: 0pt;text-align: left;">√</p></td><td style="width:27pt"/><td style="width:26pt"><p class="s174" style="padding-left: 8pt;text-indent: 0pt;text-align: left;">√</p></td><td style="width:26pt;border-right-style:solid;border-right-width:1pt"/></tr><tr style="height:16pt"><td style="width:122pt"><p class="s54" style="padding-top: 2pt;padding-left: 38pt;text-indent: 0pt;text-align: left;">Light</p></td><td style="width:30pt"><p class="s174" style="padding-left: 12pt;text-indent: 0pt;text-align: left;">√</p></td><td style="width:35pt"><p class="s174" style="padding-left: 8pt;text-indent: 0pt;text-align: left;">√</p></td><td style="width:18pt"><p class="s174" style="text-indent: 0pt;text-align: left;">√</p></td><td style="width:26pt;border-right-style:solid;border-right-width:1pt"><p class="s174" style="padding-left: 8pt;text-indent: 0pt;text-align: left;">√</p></td><td style="width:26pt;border-left-style:solid;border-left-width:1pt"><p class="s174" style="padding-left: 8pt;text-indent: 0pt;text-align: left;">√</p></td><td style="width:26pt"><p class="s174" style="padding-left: 8pt;text-indent: 0pt;text-align: left;">√</p></td><td style="width:26pt"><p class="s174" style="padding-left: 8pt;text-indent: 0pt;text-align: left;">√</p></td><td style="width:27pt"/><td style="width:26pt"><p class="s174" style="padding-left: 8pt;text-indent: 0pt;text-align: left;">√</p></td><td style="width:26pt;border-right-style:solid;border-right-width:1pt"/></tr><tr style="height:16pt"><td style="width:122pt"><p class="s54" style="padding-top: 2pt;padding-left: 38pt;text-indent: 0pt;text-align: left;">MadeOfCeramic</p></td><td style="width:30pt"><p class="s174" style="padding-left: 12pt;text-indent: 0pt;text-align: left;">√</p></td><td style="width:35pt"/><td style="width:18pt"/><td style="width:26pt;border-right-style:solid;border-right-width:1pt"/><td style="width:26pt;border-left-style:solid;border-left-width:1pt"><p class="s174" style="padding-left: 8pt;text-indent: 0pt;text-align: left;">√</p></td><td style="width:26pt"/><td style="width:26pt"><p class="s174" style="padding-left: 8pt;text-indent: 0pt;text-align: left;">√</p></td><td style="width:27pt"><p class="s174" style="padding-left: 8pt;text-indent: 0pt;text-align: left;">√</p></td><td style="width:26pt"/><td style="width:26pt;border-right-style:solid;border-right-width:1pt"/></tr><tr style="height:16pt"><td style="width:122pt"><p class="s54" style="padding-top: 2pt;padding-left: 38pt;text-indent: 0pt;text-align: left;">MadeOfPaper</p></td><td style="width:30pt"/><td style="width:35pt"/><td style="width:18pt"/><td style="width:26pt;border-right-style:solid;border-right-width:1pt"><p class="s174" style="padding-left: 8pt;text-indent: 0pt;text-align: left;">√</p></td><td style="width:26pt;border-left-style:solid;border-left-width:1pt"/><td style="width:26pt"/><td style="width:26pt"/><td style="width:27pt"/><td style="width:26pt"><p class="s174" style="padding-left: 8pt;text-indent: 0pt;text-align: left;">√</p></td><td style="width:26pt;border-right-style:solid;border-right-width:1pt"/></tr><tr style="height:17pt"><td style="width:122pt"><p class="s54" style="padding-top: 2pt;padding-left: 38pt;text-indent: 0pt;text-align: left;">MadeOfStyrofoam</p></td><td style="width:30pt;border-bottom-style:solid;border-bottom-width:1pt"/><td style="width:35pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s174" style="padding-left: 8pt;text-indent: 0pt;text-align: left;">√</p></td><td style="width:18pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s174" style="text-indent: 0pt;text-align: left;">√</p></td><td style="width:26pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"/><td style="width:26pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt"/><td style="width:26pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s174" style="padding-left: 8pt;text-indent: 0pt;text-align: left;">√</p></td><td style="width:26pt;border-bottom-style:solid;border-bottom-width:1pt"/><td style="width:27pt;border-bottom-style:solid;border-bottom-width:1pt"/><td style="width:26pt;border-bottom-style:solid;border-bottom-width:1pt"/><td style="width:26pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s174" style="padding-left: 8pt;text-indent: 0pt;text-align: left;">√</p></td></tr></table><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 2pt;text-align: left;"><span><img width="570" height="2" alt="image" src="机器学习/Image_426.png"/></span></p><h3 style="padding-left: 6pt;text-indent: 0pt;text-align: justify;">12.3.2 <span class="s25">一个示例</span></h3><p style="padding-top: 10pt;padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">为例示 <span class="s6">KBANN </span>的操作，考虑表 <span class="s6">12-3 </span>列出的一个简单的学习问题，它取自于 <span class="s6">Towell &amp; Shavlik</span>（<span class="s6">1989</span>）并略作改动。这里每个实例代表一物理对象。描述了它的物理材料、它的轻重 等等。任务是学习定义在这物理对象上的目标概念 <span class="s21">Cup</span>。表 <span class="s6">12-3 </span>描述了 <span class="s21">Cup </span>目标概念的训练 样例和领域理论。注意领域理论中定义 <span class="s21">Cup </span>为一个 <span class="s21">Stable</span>、<span class="s21">Liftable </span>以及 <span class="s21">OpenVessel </span>的对象。 领域理论还把这 <span class="s6">3 </span>个属性定义为更基本的属性，即描述了此实例的原子的、可操作的属性。注 意领域理论并不是与训练样例完全一致的。例如，领域理论错误地分类第 <span class="s6">2 </span>和第 <span class="s6">3 </span>个训练样例 为反例。不过，领域理论形成了目标概念的有效近似。<span class="s6">KBANN </span>使用领域理论和训练样例一起 学习目标概念，可以比单独使用其中一种更精确。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 26pt;text-indent: 0pt;text-align: left;">在<span class="s6">KBANN</span>算法的第一阶段（算法中的 <span class="s6">1-3 </span>步），构建了一个与领域理论一致的初始网</p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 0pt;text-align: justify;">络。例如，从<span class="s21">Cup</span>的领域理论中构建的网络描绘于图 <span class="s6">12-2 </span>中。一般说来，网络的构建是通过对</p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 0pt;text-align: justify;">领域理论中每一<span class="s6">Horn</span>子句建立一个<span class="s6">sigmoid</span>单元。<span class="s6">KBANN</span>遵从惯例，<span class="s6">sigmoid</span>输出值大于 <span class="s6">0.5 </span>时</p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 0pt;line-height: 106%;text-align: justify;">被解释为真，小于 <span class="s6">0.5 </span>则为假。因此每个单元的构建方法为：当对应的<span class="s6">Horn</span>子句存在时，单元 的输出就大于 <span class="s6">0.5</span>。对此<span class="s6">Horn</span>子句的每个先行词，就建立其对应的<span class="s6">sigmoid</span>单元作为输入。然后 设置<span class="s6">sigmoid</span>单元的权值，使其计算得出其输入的逻辑与。确切地讲，对于每个对应于非负先 行词的输入，权值被设置为某正常量<span class="s21">W</span>。对每个对应于负先行词的输入，权值设为<span class="s6">-</span><span class="s21">W</span>。单元的 阈值权<span class="s21">w</span><span class="s35">0</span>设为<span class="s6">-(</span><span class="s21">n</span><span class="s6">-0.5)</span><span class="s21">W</span>，其中<span class="s21">n</span>为非负先行词的数目。当单元输入值为 <span class="s6">1 </span>或 <span class="s6">0 </span>时，这保证了当 且仅当所有的子句先行词满足时，输入的加权和加上<span class="s21">w</span><span class="s35">0 </span>为正（而且此<span class="s6">sigmoid</span>的输出大于 <span class="s6">0.5</span>）。注意对于<span class="s6">sigmoid</span>单元，第二层及以后的层中单元输入不一定为 <span class="s6">1 </span>或 <span class="s6">0</span>，上面的命题无 法应用于此。然而如果为<span class="s21">W</span>选择足够大的值，此<span class="s6">KBANN</span>算法可以对任意深度的网络进行领域 理论编码。<span class="s6">Towell &amp; Shavlik</span>（<span class="s6">1994</span>）在其多数实验中使用<span class="s21">W</span>＝<span class="s6">4.0</span>。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 109%;text-align: justify;">每个 <span class="s6">sigmoid </span>单元输入被连接到适当的网络输入或另一 <span class="s6">sigmoid </span>单元的输出，以反映领域 理论中对应属性的依赖关系图。最后一步，又附加了许多输入到每个阈值单元，它们的权值设 置近似为 <span class="s6">0</span>。这些附加连接的作用是允许网络能归纳学习到的内容可超出领域理论中提出的依 赖关系。图 <span class="s6">12-2 </span>中的粗实线表明权值为 <span class="s21">W </span>的单元输入，而细线表明初始权值约为 <span class="s6">0 </span>的连接。 很容易验证对于足够大的 <span class="s21">W </span>值，此网络输出值等于领域理论的预测。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 13pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="569" height="1" alt="image" src="机器学习/Image_427.png"/></span></p><p class="s48" style="padding-left: 15pt;text-indent: 0pt;text-align: left;">插图——原书页码： <span class="s21">343</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 14pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="553" height="1" alt="image" src="机器学习/Image_428.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 141pt;text-indent: 0pt;text-align: left;">图 <span class="h4">12-2 </span>一个等价于领域理论的神经网络</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-left: 37pt;text-indent: 21pt;line-height: 125%;text-align: justify;">这个网络在 <span class="s16">KBANN </span>算法的第一阶段创建出来，它产生的输出分类等于给定的领域理论中的子句 做的分类。粗线表示权值为 <span class="s56">W </span>的连接，对应领域理论中的子句先行词。细线表示权值近似为 <span class="s16">0 </span>的连 接。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: left;">KBANN <span class="p">的第二阶段（表 </span>12-2 <span class="p">中算法的第 </span>4 <span class="p">步）使用训练样例和反向传播算法来精化初始 网络权值。当然，如果领域理论和训练样例不包含差错，初始的网络就已经拟合训练数据了。</span></p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 107%;text-align: left;">然而在 <span class="s21">Cup </span>例子中，领域理论与训练数据不一致，所以此步骤会改变初始网络的权值。得到的 训练过的网络显示在图 <span class="s6">12-3 </span>中，粗实线表明最大的正权值，粗虚线表明最大负权值，细线表</p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 107%;text-align: left;">明可忽略的权值。虽然初始网络误分类了表 <span class="s6">12-3 </span>中几个训练样例，但图 <span class="s6">12-3 </span>中精化了的网络 能完美地分类所有训练例。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">有必要比较一下最终归纳精化的网络权值和领域理论导出的初始权值。如图 <span class="s6">12-3 </span>所见， 在归纳步中发现了全新的依赖关系，包括 <span class="s21">Liftable </span>单元对 <span class="s21">MadeofStyrofoam </span>的依赖关系。必须牢 记，虽然标有 <span class="s21">Liftable </span>的单元最初由它的 <span class="s6">Horn </span>子句定义，但后来由反向传播修改的权值已经完 全改变了此隐藏单元的意义。在网络被训练过后，该单元可能有了与初始的 <span class="s21">Liftable </span>记号无关 的非常不同的意义。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 13pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="569" height="1" alt="image" src="机器学习/Image_429.png"/></span></p><p class="s48" style="padding-left: 15pt;text-indent: 0pt;text-align: left;">插图——原书页码： <span class="s21">344</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 14pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="553" height="1" alt="image" src="机器学习/Image_430.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 146pt;text-indent: 0pt;text-align: left;">图 <span class="h4">12-3 </span>对初始网络归纳精化后的结果</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-left: 58pt;text-indent: 0pt;text-align: left;"><span class="s16">KBANN </span>使用训练样例来修改从领域理论中导出的网络权值。注意其中新产生的 <span class="s56">Liftable </span>对</p><p class="s56" style="padding-top: 3pt;padding-left: 37pt;text-indent: 0pt;text-align: left;">MadeOfStyrofoam <span class="s14">和 </span>HandleOnTop <span class="s14">的依赖性。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 6pt;text-indent: 0pt;text-align: justify;">12.3.3 <span class="s25">说明</span></h3><p style="padding-top: 10pt;padding-left: 5pt;text-indent: 21pt;line-height: 110%;text-align: justify;">概括地讲，<span class="s6">KBANN </span>用分析的方式创建了等价于给定领域理论的网络，然后归纳地精化此 初始假设以更好地拟合训练数据。在此过程中，它为了改变领域理论和训练数据不一致的情况 而修改网络权值。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 110%;text-align: justify;">与纯归纳的反向传播（它开始于随机的权值）相比，<span class="s6">KBANN </span>的好处在于，它在给定近似 正确领域理论时，能够比反向传播有更高的泛化精度，特别是在训练数据稀缺时。在几种实际 系统中，<span class="s6">KBANN </span>和其他初始化假设的途径已显示出优于纯归纳的系统。例如，<span class="s6">Towell et al.</span></p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 14pt;text-align: justify;">（<span class="s6">1990</span>）描述了将 <span class="s6">KBANN </span>应用于分子遗传问题。其中的任务是学习识别称为激发区域</p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 0pt;line-height: 107%;text-align: justify;">（<span class="s6">promoter region</span>）的 <span class="s6">DNA </span>片断，它影响基因的活性。在此实验中，<span class="s6">KBANN </span>的领域理论从一 个分析遗传学家那里获取，而激发区域的训练样例中包含 <span class="s6">53 </span>个正例和 <span class="s6">53 </span>个反例。性能评估使 用了“留一法”（<span class="s6">leave-one-out</span>），系统运行 <span class="s6">106 </span>次。每次循环中 <span class="s6">KBANN </span>用 <span class="s6">105 </span>个样例训 练，并在剩余的 <span class="s6">1 </span>个上测试。这 <span class="s6">106 </span>次实验的结果被积聚起来提供对真实错误率的估计。 <span class="s6">KBANN </span>错误率为 <span class="s6">4</span>／<span class="s6">106</span>，而标准的反向传播错误率为 <span class="s6">8</span>／<span class="s6">106</span>。<span class="s6">KBANN </span>的一个变种由 <span class="s6">Fu</span></p><p class="s6" style="padding-left: 6pt;text-indent: 0pt;line-height: 110%;text-align: justify;"><span class="p">（</span>1993<span class="p">）实现，它报告在同样数据上的错误率为 </span>2<span class="p">／</span>106<a href="http://www.ics.uci.edu/%7Emlearn/MLReository.html" class="s223" target="_blank">。因此，先验知识在这些实验中很大 程 度 地 减 小 了 错 误 率 。 此 实 验 的 训 练 数 据 可 以 从 万 维 网 址 </a>http://www.ics.uci.edu/~mlearn/MLReository.html <span class="p">上得到。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 6pt;text-indent: 21pt;line-height: 110%;text-align: justify;">Fu<span class="p">（</span>1993<span class="p">）和 </span>Towell et al.<span class="p">（</span>1990<span class="p">）都报告：从最终训练过的网络中抽取的 </span>Horn <span class="p">子句，可 提供一个能更好拟合训练数据的领域理论。虽然有时可能从学习到的网络权值映射回一个精化 的 </span>Horn <span class="p">子句集，但在一般情形下这种作法是有问题的。因为某些权值设置没有直接对应的</span></p><p class="s6" style="padding-left: 5pt;text-indent: 0pt;line-height: 107%;text-align: left;">Horn <span class="p">子句。</span>Craven &amp; Shavlik<span class="p">（</span>1994<span class="p">）和 </span>Craven<span class="p">（</span>1996<span class="p">）描述了另外的方法以从学习过的网络 中抽取符号规则。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 110%;text-align: justify;">为理解 <span class="s6">KBANN </span>的定义，有必要考虑其中的假设搜索与纯归纳的反向传播算法中有什么区 别。这两种算法中执行的假设空间搜索在图 <span class="s6">12-4 </span>中示意。如其中显示的，关键区别在于执行 权值调节所基于的初始假设。在有多个假设（权值向量）能拟合数据的情况下（这种情况在训 练数据稀缺时更可能出现），<span class="s6">KBANN </span>更有可能收敛到这样的假设，它从训练数据中的泛化与 领域理论的预测更相似。另一方面，反向传播收敛到的特定假设更可能是小权值的假设，它大 致对应于在训练样例间平滑插值的泛化偏置。简要地说，<span class="s6">KBANN </span>使用一个领域特定的理论来 偏置泛化，而反向传播算法使用一个领域无关的语法偏置（偏向于小的权值）。注意在此概述 中我们忽略了搜索中局部极小值的影响。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 13pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="569" height="1" alt="image" src="机器学习/Image_431.png"/></span></p><p class="s48" style="padding-left: 15pt;text-indent: 0pt;text-align: left;">插图——原书页码： <span class="s21">346</span></p><p class="s6" style="padding-top: 6pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">Hypothesis Space<span class="p">： 假设空间</span></p><p class="s6" style="padding-top: 1pt;padding-left: 26pt;text-indent: 0pt;line-height: 107%;text-align: left;">Hypotheses that fit training data equally well<span class="p">：以同样程度拟合训练数据的假设 </span>Initial hypothesis for KBANN<span class="p">： </span>KBANN <span class="p">的初始假设</span></p><p class="s6" style="padding-left: 26pt;text-indent: 0pt;text-align: left;">Initial hypothesis for Backpropagation<span class="p">： 反向传播的初始假设</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 14pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="553" height="1" alt="image" src="机器学习/Image_432.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 25pt;text-indent: 0pt;text-align: center;">图 <span class="h4">12-4KBANN </span>中的假设空间搜索</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s16" style="padding-left: 37pt;text-indent: 21pt;line-height: 129%;text-align: justify;">KBANN <span class="s14">初始化网络使其拟合领域理论，而反向传播将网络初始化为随机小权值。然后它们使用 相同的梯度下降规则反复精化权值。当找到多个能拟合训练数据的假设时（如阴影区域所示）， </span>KBANN <span class="s14">和反向传播可能找到不一样的假设，因为它们的起点不同。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 6pt;text-indent: 20pt;line-height: 107%;text-align: justify;">KBANN <span class="p">的局限性之一为，它只能使用命题领域理论，即无变量的 </span>Horn <span class="p">子句集。如果给 予很不精确的领域理论，</span>KBANN <span class="p">也可能被误导，从而其泛化精度变得低于反向传播。不过， </span>KBANN <span class="p">和相关算法确实在若干实际问题中显示出有助于学习。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 26pt;text-indent: 0pt;text-align: center;">KBANN <span class="p">是结合分析和归纳学习的初始化假设途径中的一种。这一途径的其他例子包括 </span>Fu</p><p style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: justify;">（<span class="s6">1993 </span>）；<span class="s6">Gallant(1988)</span>；<span class="s6">Bradshaw et al.</span>（<span class="s6">1989</span>）；<span class="s6">Yang &amp; Bhargava(1990)</span>；<span class="s6">Lacher et al.</span></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: justify;">（<span class="s6">1991</span>）。这些途径不同之处在于建立初始假设的实际使用的技术、权值调整的反向传播的应 用、以及从精化了的网络中抽取符号描述的方法。<span class="s6">Pratt</span>（<span class="s6">1993a</span>，<span class="s6">1993b</span>）描述的一个初始化假 设途径中，先验知识是通过先前对相关任务学习到的神经网络来提供的。训练贝叶斯置信网的 值的方法（如 <span class="s6">6.11 </span>节中讨论的）也可被看作是用先验知识来初始化假设。这里先验知识对应 于一组条件独立性假定，它确定了贝叶斯网的图结构，然后其条件概率表从训练数据中归纳得 到。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 6pt;text-indent: 0pt;text-align: justify;">12.4 <span class="s17">使用先验知识改变搜索目标</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 26pt;text-indent: 0pt;text-align: center;">上面的途径由一个完美拟合领域理论的假设开始梯度下降搜索，然后在需要时改变此假设</p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 113%;text-align: justify;">以最大程度地拟合训练数据。使用先验知识的另一方法是将它合并到梯度下降中需最小化的误 差判据，这样网络须拟合的是训练数据和领域理论的组合函数。确切地讲，我们考虑的先验知 识的形式是目标函数的某种已知的导出式。一些类型的先验知识可以很自然地用此形式表示。 例如，在训练一个神经网络以识别手写字符时，我们可以指定目标函数的某种导数，以表示这 种的先验知识：“字符的确认独立于图像的微小平移和旋转。”</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">下面描述的 <span class="s6">TangentProp </span>算法训练神经网络，使其同时拟合训练值和训练导数。<span class="s6">12.4.4 </span>节 说明了怎样用类似于 <span class="s6">12.3 </span>节使用的 <span class="s21">Cup </span>例子中的方法从领域理论中获得这些训练导数。确切 地讲，它讨论了 <span class="s6">EBNN </span>算法怎样构造单独样例的解释，以抽取出训练导数来供 <span class="s6">TangentProp </span>使 用。<span class="s6">TangentProp </span>和 <span class="s6">EBNN </span>已在多个领域中被示范出有优于纯归纳方法的性能，包括字符和物 体识别，以及机器人感知和控制任务中。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 6pt;text-indent: 0pt;text-align: justify;">12.4.1 TangentProp <span class="s25">算法</span></h3><p class="s6" style="padding-top: 10pt;padding-left: 5pt;text-indent: 21pt;line-height: 106%;text-align: justify;">TangentProp <span class="p">（</span>Simard et al. 1992<span class="p">）接受的领域知识被表示为对应于其输入变换的目标函数 的导数。考虑一个学习任务，包含一个实例空间</span><i>X</i><span class="p">和目标函数</span><i>f</i><span class="p">。至此我们所作的假定中每个训 练样例形式为</span>&lt;<i>x</i><span class="s36">i</span>,<i>f</i>(<i>x</i><span class="s36">i</span>)&gt;<span class="p">，它描述了某实例</span><i>x</i><span class="s36">i</span><span class="p">和其训练值</span><i>f</i>(<i>x</i><span class="s36">i</span>)<span class="p">。</span>TangentProp<span class="p">算法还假定提供了目标 函数的不同的训练导数（</span>training derivative<span class="p">）。例如，如果每个实例</span><i>x</i><span class="s36">i</span><span class="p">描述为一个实数，那么每</span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="1" height="40" alt="image" src="机器学习/Image_433.png"/></span></p><p class="s30" style="padding-left: 6pt;text-indent: 0pt;line-height: 15pt;text-align: left;"><span class="p">个训练样例形式可能为 </span><span class="s38"> </span>x <span class="s33">, </span>f <span class="s33">(</span>x <span class="s33">), </span><span class="s117"></span><u>f </u><u>( </u><u>x</u><u>)</u></p><p style="text-indent: 0pt;text-align: left;"><span><img width="1" height="40" alt="image" src="机器学习/Image_434.png"/></span></p><p class="s91" style="padding-left: 6pt;text-indent: 0pt;line-height: 15pt;text-align: left;"><span class="s114"></span><span class="s38"> </span><span class="p">。这里 </span><span class="s117"></span>f <span class="s92">( </span>x<span class="s92">)</span></p><p class="s21" style="padding-top: 6pt;padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;"><span class="p">表示目标函数在点</span>x<span class="s6">=</span>x <span class="p">上对</span>x<span class="p">的导</span></p><p class="s41" style="text-indent: 0pt;line-height: 7pt;text-align: left;">x</p><p style="text-indent: 0pt;text-align: left;"/><p class="s41" style="padding-left: 126pt;text-indent: 0pt;line-height: 14pt;text-align: left;">i i <span class="s191"></span><span class="s30">x</span></p><p class="s44" style="text-indent: 0pt;line-height: 4pt;text-align: right;">i</p><p style="padding-top: 2pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">数。</p><p class="s41" style="text-indent: 0pt;line-height: 4pt;text-align: right;">i</p><p class="s38" style="padding-left: 5pt;text-indent: 0pt;line-height: 15pt;text-align: left;"><span class="s30">x </span><span class="s52">x</span><span class="s289">i</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;line-height: 108%;text-align: justify;"><span class="p">为了从直觉上理解在学习中不仅提供训练值也提供训练导数的好处，考虑一个简单的任 务，在图 </span>12-5 <span class="p">表示。其中待学习的目标函数</span><i>f</i><span class="p">显示于其中最左边的图形，它基于所显示的 </span>3 <span class="p">个 训练样例</span>&lt;<i>x</i><span class="s35">1</span>, <i>f</i>(<i>x</i><span class="s35">1</span>)&gt;<span class="p">，</span>&lt;<i>x</i><span class="s35">2</span>, <i>f</i>(<i>x</i><span class="s35">2</span>)&gt;<span class="p">和</span>&lt;<i>x</i><span class="s35">3</span>, <i>f</i>(<i>x</i><span class="s35">3</span>)&gt;<span class="p">。有了这 </span>3 <span class="p">个样例，反向传播算法可望得到一个平 滑函数假设，如中间图显示的函数</span><i>g</i><span class="p">。最右边的图显示了提供训练导数（或斜率）作为每个训</span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="1" height="40" alt="image" src="机器学习/Image_435.png"/></span></p><p class="s30" style="padding-left: 5pt;text-indent: 0pt;line-height: 15pt;text-align: left;"><span class="p">练样例的附加信息（如 </span><span class="s38"> </span>x <span class="s33">, </span>f <span class="s33">(</span>x <span class="s33">), </span><span class="s117"></span><u>f </u><u>( </u><u>x</u><u>)</u></p><p class="s21" style="padding-top: 7pt;padding-left: 5pt;text-indent: 0pt;line-height: 8pt;text-align: left;"><span class="s38"> </span><span class="p">）的效果。通过拟合训练值</span>f<span class="s6">(</span>x <span class="s6">)</span><span class="p">同时拟合这些导数</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="39" height="40" alt="image" src="机器学习/Image_436.png"/></span></p><p class="s30" style="padding-left: 8pt;text-indent: 0pt;line-height: 10pt;text-align: left;"><span class="s38"></span>f <span class="s33">(</span>x<span class="s33">)</span></p><p class="s41" style="text-indent: 0pt;line-height: 7pt;text-align: left;">x</p><p style="text-indent: 0pt;text-align: left;"/><p class="s35" style="padding-left: 8pt;text-indent: 0pt;line-height: 15pt;text-align: left;">1 1 <span class="s152"></span><span class="s30">x </span><i>i</i></p><p class="s189" style="padding-left: 82pt;text-indent: 0pt;line-height: 4pt;text-align: left;">1</p><p class="s38" style="padding-top: 6pt;padding-left: 16pt;text-indent: 0pt;text-align: left;"><span class="s30">x </span><span class="s52">x</span><span class="s289">i</span></p><p style="padding-left: 1pt;text-indent: 0pt;line-height: 11pt;text-align: left;">，学习器可以更好地从稀疏训练数据中正确泛化。概括地说，包含训练导数的效果是</p><p style="padding-top: 2pt;padding-left: 6pt;text-indent: 0pt;line-height: 113%;text-align: left;">为了克服反向传播中的语法归纳偏置（它偏好各点间的平滑插值），将其替换为所希望的导数 的显式输入信息。结果假设<span class="s21">h</span>显示在最右边的图中，它提供了对真实目标函数<span class="s21">f</span>的更精确估计。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 13pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="569" height="1" alt="image" src="机器学习/Image_437.png"/></span></p><p class="s48" style="padding-left: 15pt;text-indent: 0pt;text-align: left;">插图——原书页码： <span class="s21">347</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 14pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="553" height="1" alt="image" src="机器学习/Image_438.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 58pt;text-indent: 88pt;text-align: left;">图 <span class="h4">12-5 </span>用 <span class="h4">TangentProp </span>拟合值和导数</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s16" style="padding-left: 37pt;text-indent: 21pt;line-height: 117%;text-align: left;"><span class="s14">令</span><i>f</i><span class="s14">为目标函数，它的三个样例</span>&lt;<i>x</i><span class="s64">1</span>, <i>f</i>(<i>x</i><span class="s64">1</span>)&gt;<span class="s14">，</span>&lt;<i>x</i><span class="s64">2</span>, <i>f</i>(<i>x</i><span class="s64">2</span>)&gt;<span class="s14">和</span>&lt;<i>x</i><span class="s64">3</span>, <i>f</i>(<i>x</i><span class="s64">3</span>)&gt;<span class="s14">已知。基于这些点，学习器可能 生成假设</span><i>g</i><span class="s14">。如果导数也已知，学习器可以泛化到更精确的</span><i>h</i><span class="s14">。</span></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 108%;text-align: justify;">在上述例子中，我们只考虑了简单类型的目标函数导数。实际上，<span class="s6">TangentProp</span>可接受对应 于输入<span class="s21">x</span>的各种变换的训练导数。例如，考虑学习识别手写字符的任务。确切地讲，假定输入<span class="s21">x </span>对应于包含单个手写字符的图像，而任务是正确分类此字符。在此任务中，我们可能希望告诉 学习器“目标函数对于图像中字符的微小旋转不受影响”。为输入此先验知识给学习器，我们 首先定义一个变换<span class="s21">s</span><span class="s6">(</span><span class="s47">α</span><span class="s6">,</span><span class="s21">x</span><span class="s6">)</span>，它把图像<span class="s21">x</span>旋转<span class="s47">α</span>度。现在我们可把旋转不变性的断言如下表示： 对每个训练实例<span class="s21">x</span><span class="s36">i </span>，目标函数对应此变换的导数为 <span class="s6">0</span>（即旋转输入图像不改变目标函数的 值）。换言之，我们可对每个训练实例<span class="s21">x</span><span class="s36">i</span>断言下面的训练导数：</p><p style="text-indent: 0pt;text-align: left;"><span><img width="77" height="1" alt="image" src="机器学习/Image_439.png"/></span></p><p class="s33" style="padding-top: 10pt;padding-left: 26pt;text-indent: 0pt;line-height: 20pt;text-align: center;"><span class="s38"></span><i>f </i>(<i>s</i>(<span class="s119"></span>, <i>x</i><span class="s52">i </span>)) <span class="s152"></span><span class="s38"> </span>0</p><p class="s38" style="padding-left: 6pt;text-indent: 0pt;line-height: 12pt;text-align: center;"><span class="s119"></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-top: 1pt;padding-left: 26pt;text-indent: 0pt;text-align: left;"><span class="p">其中</span>f<span class="p">为目标函数，而</span>s<span class="s6">(</span><span class="s47">α</span><span class="s6">,</span>x<span class="s36">i</span><span class="s6">)</span><span class="p">为应用此变换</span>s<span class="p">到图像</span>x<span class="s36">i</span><span class="p">得到的图像。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">这样的训练导数在 <span class="s6">TangentProp </span>中怎样被用于约束神经网络的权值？在 <span class="s6">TangentProp </span>中这些 训练导数被合并到梯度下降中须最小化的误差函数中，回忆第 <span class="s6">4 </span>章中反向传播算法执行梯度下 降试图使误差平方和最小化：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s42" style="text-indent: 0pt;line-height: 7pt;text-align: left;">2</p><p style="text-indent: 0pt;text-align: left;"/><p class="s107" style="padding-top: 3pt;padding-left: 20pt;text-indent: 0pt;line-height: 20pt;text-align: center;">E <span class="s109"> </span><span class="s124"></span><span class="s108">( </span>f <span class="s108">(</span>x<span class="s52">i </span><span class="s108">) </span><span class="s109"> </span>f<span class="s290">ˆ </span><span class="s108">(</span>x<span class="s52">i</span><span class="s41"> </span><span class="s108">))</span></p><p class="s41" style="padding-left: 26pt;text-indent: 0pt;line-height: 7pt;text-align: center;">i</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">其中<span class="s21">x</span><span class="s36">i</span>代表第<span class="s21">i</span>个训练实例，<span class="s21">f </span>代表真实目标值，而 <span class="s107">f</span><span class="s290">ˆ</span><span class="s108"> </span>代表学习到的神经网络表示的函数。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;text-align: justify;"><span class="p">在</span>TangentProp<span class="p">中，误差函数中新增了一项以惩罚训练导数和学习到的神经网络函数的实际 导数 </span><span class="s107">f</span><span class="s290">ˆ </span><span class="p">之间的分歧。一般地，</span>TangentProp<span class="p">可接受多个变换（例如，我们希望断言旋转不变 性，同时断言字符识别中的平移不变性），每个变换形式必须为</span><i>s</i><span class="s36">j</span>(<span class="s47">α</span>,<i>x</i>)<span class="p">，其中</span><span class="s47">α</span><span class="p">为连续参数， 而</span><i>s</i><span class="s36">j</span><span class="p">可微，而且</span><i>s</i><span class="s36">j</span>(0,<i>x</i>)=<i>x</i><span class="p">（例如对于 </span>0 <span class="p">度的旋转，函数即为恒等函数）。对每个这样的变换 </span><i>s</i><span class="s36">j</span>(<span class="s47">α</span>,<i>x</i>)<span class="p">，</span>TangentProp<span class="p">考虑指定的训练导数和学习到的神经网络的实际导数间的误差平方。修改 后的误差函数为：</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="padding-top: 3pt;padding-left: 64pt;text-indent: 0pt;line-height: 14pt;text-align: left;"><span class="s165">⎡ </span><span class="s162">⎛ </span><span class="s38"></span>f <span class="s33">(</span>s</p><p class="s33" style="padding-top: 8pt;padding-left: 3pt;text-indent: 0pt;line-height: 9pt;text-align: left;">(<span class="s119"></span>, <i>x </i>))</p><p class="s30" style="padding-top: 6pt;padding-left: 11pt;text-indent: 0pt;line-height: 11pt;text-align: left;"><span class="s38"></span>f<span class="s31">ˆ</span><span class="s33"> (</span>s</p><p class="s42" style="text-indent: 0pt;line-height: 7pt;text-align: left;">2</p><p style="text-indent: 0pt;text-align: left;"/><p class="s33" style="padding-top: 3pt;padding-left: 3pt;text-indent: 0pt;line-height: 14pt;text-align: left;">(<span class="s119"></span>, <i>x </i>)) <span class="s162">⎞</span><span class="s38"> </span><span class="s165">⎤</span></p><p class="s38" style="padding-left: 64pt;text-indent: 0pt;line-height: 1pt;text-align: left;">⎢ <span class="s33">ˆ </span><span class="s291">2</span></p><p class="s103" style="padding-left: 33pt;text-indent: 0pt;line-height: 1pt;text-align: left;">⎜ <span class="s143">j i      </span></p><p class="s38" style="padding-left: 10pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span class="s143">              j i </span><span class="s103">⎟</span> ⎥</p><p class="s33" style="padding-left: 29pt;text-indent: 0pt;line-height: 11pt;text-align: left;"><i>E </i><span class="s38"></span> <span class="s39"></span><span class="s152">⎢</span>( <i>f </i>(<i>x</i><span class="s52">i</span><span class="s41"> </span>) <span class="s38"></span>  <i>f </i>(<i>x</i><span class="s52">i</span><span class="s41"> </span>))</p><p class="s33" style="padding-left: 6pt;text-indent: 0pt;line-height: 11pt;text-align: left;"><span class="s38"></span> <span class="s119"></span><span class="s39"></span><span class="s152">⎜</span>         <span class="s123"></span></p><p class="s38" style="padding-left: 29pt;text-indent: 0pt;line-height: 11pt;text-align: left;"> <span class="s123"></span> <span class="s152">⎟</span></p><p style="padding-left: 32pt;text-indent: 0pt;line-height: 11pt;text-align: left;">（<span class="s6">12</span>．<span class="s6">1</span>）</p><p class="s38" style="padding-left: 19pt;text-indent: 0pt;line-height: 0pt;text-align: left;">⎥</p><p class="s41" style="text-indent: 0pt;line-height: 7pt;text-align: left;">i</p><p style="text-indent: 0pt;text-align: left;"/><p class="s41" style="text-indent: 0pt;line-height: 7pt;text-align: left;">j</p><p style="text-indent: 0pt;text-align: left;"/><p class="s119" style="padding-left: 64pt;text-indent: 0pt;line-height: 22pt;text-align: left;"><span class="s123">⎣ </span><span class="s191">⎝ </span>  <span class="s191">⎠</span></p><p class="s200" style="padding-top: 7pt;padding-left: 4pt;text-indent: 0pt;text-align: left;"> <span class="s40"></span><span class="s42">0 </span><span class="s102">⎦</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 6pt;text-indent: 21pt;line-height: 110%;text-align: justify;">其中<span class="s47">μ</span>为用户提供的常量，以确定拟合训练数据和拟合训练导数之间的相对重要性。注意 <span class="s21">E </span>定义中第一项为原来的训练数据同网络之间的误差平方，而第二项为训练导数同网络之间的 误差平方。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">Simard et al. <span class="p">（</span>1992<span class="p">）给出了使此扩展的误差函数最小化的梯度下降规则。它可由类似于 第 </span>4 <span class="p">章中反向传播规则中的方法进行推导。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">12.4.2 <span class="s25">示例</span></h3><p class="s6" style="padding-top: 10pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">Simard <span class="p">等提供了 </span>TangentProp <span class="p">的泛化精度同纯归纳反向传播之间的比较结果，针对的问题</span></p><p style="padding-left: 11pt;text-indent: 0pt;line-height: 107%;text-align: justify;">为手写字符识别。更确切地讲，这里的任务是为单个数字 <span class="s6">0 </span>到 <span class="s6">9 </span>的图像作标记。在一个实验 中，<span class="s6">TangentProp </span>和反向传播都用不同大小的训练集进行训练，然后基于它们在独立的 <span class="s6">160 </span>个 样例的测试集上评估性能。给予 <span class="s6">TangentProp </span>的先验知识为：数字的分类不因图像的水平和垂 直平移而改变（即此目标函数对应于这些变换的导数为 <span class="s6">0</span>）。结果显示在表 <span class="s6">12-4 </span>中，证明了 <span class="s6">TangentProp </span>使用先验知识的泛化精度确实高于纯反向传播算法。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 80pt;text-indent: 0pt;text-align: left;">表 <span class="h4">12-4TangentProp </span>和反向传播的泛化精度，针对手写数字识别问题</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s16" style="padding-left: 63pt;text-indent: 0pt;text-align: left;">TangentProp <span class="s14">泛化精度更高，因为它有先验知识：数字的确定有平移不变性。这些结果来自于</span></p><p class="s16" style="padding-top: 3pt;padding-left: 42pt;text-indent: 0pt;text-align: left;">Simard et al.<span class="s14">（</span>1992<span class="s14">）。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><table style="border-collapse:collapse;margin-left:5.36pt" cellspacing="0"><tr style="height:24pt"><td style="width:83pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt" rowspan="2"><p class="s95" style="padding-top: 3pt;padding-left: 30pt;padding-right: 25pt;text-indent: -5pt;line-height: 113%;text-align: left;">训练集 大小</p></td><td style="width:227pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt" colspan="2"><p class="s95" style="padding-top: 3pt;padding-left: 50pt;text-indent: 0pt;text-align: left;">在测试集上的错误率百分比</p></td></tr><tr style="height:17pt"><td style="width:114pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s98" style="padding-top: 3pt;padding-left: 29pt;text-indent: 0pt;text-align: left;">TangentProp</p></td><td style="width:113pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s95" style="padding-left: 35pt;text-indent: 0pt;text-align: left;">反向传播</p></td></tr><tr style="height:13pt"><td style="width:83pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s98" style="text-indent: 0pt;line-height: 12pt;text-align: center;">10</p></td><td style="width:114pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s98" style="text-indent: 0pt;line-height: 12pt;text-align: center;">34</p></td><td style="width:113pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s98" style="text-indent: 0pt;line-height: 12pt;text-align: center;">48</p></td></tr><tr style="height:13pt"><td style="width:83pt;border-left-style:solid;border-left-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s98" style="text-indent: 0pt;line-height: 11pt;text-align: center;">20</p></td><td style="width:114pt;border-left-style:solid;border-left-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s98" style="text-indent: 0pt;line-height: 11pt;text-align: center;">17</p></td><td style="width:113pt;border-left-style:solid;border-left-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s98" style="text-indent: 0pt;line-height: 11pt;text-align: center;">33</p></td></tr><tr style="height:12pt"><td style="width:83pt;border-left-style:solid;border-left-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s98" style="text-indent: 0pt;line-height: 11pt;text-align: center;">40</p></td><td style="width:114pt;border-left-style:solid;border-left-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s98" style="text-indent: 0pt;line-height: 11pt;text-align: center;">7</p></td><td style="width:113pt;border-left-style:solid;border-left-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s98" style="text-indent: 0pt;line-height: 11pt;text-align: center;">18</p></td></tr><tr style="height:12pt"><td style="width:83pt;border-left-style:solid;border-left-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s98" style="text-indent: 0pt;line-height: 11pt;text-align: center;">80</p></td><td style="width:114pt;border-left-style:solid;border-left-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s98" style="text-indent: 0pt;line-height: 11pt;text-align: center;">4</p></td><td style="width:113pt;border-left-style:solid;border-left-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s98" style="text-indent: 0pt;line-height: 11pt;text-align: center;">10</p></td></tr><tr style="height:12pt"><td style="width:83pt;border-left-style:solid;border-left-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s98" style="text-indent: 0pt;line-height: 11pt;text-align: center;">160</p></td><td style="width:114pt;border-left-style:solid;border-left-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s98" style="text-indent: 0pt;line-height: 11pt;text-align: center;">0</p></td><td style="width:113pt;border-left-style:solid;border-left-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s98" style="text-indent: 0pt;line-height: 11pt;text-align: center;">3</p></td></tr><tr style="height:12pt"><td style="width:83pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s98" style="text-indent: 0pt;line-height: 11pt;text-align: center;">320</p></td><td style="width:114pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s98" style="text-indent: 0pt;line-height: 11pt;text-align: center;">0</p></td><td style="width:113pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s98" style="text-indent: 0pt;line-height: 11pt;text-align: center;">0</p></td></tr></table><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-top: 1pt;padding-left: 11pt;text-indent: 0pt;text-align: left;">12.4.3 <span class="s25">说明</span></h3><p style="padding-top: 10pt;padding-left: 10pt;text-indent: 21pt;line-height: 109%;text-align: justify;">概括地说，<span class="s6">TangentProp </span>使用的先验知识形式为目标函数对应其输入变换的所希望的导 数。它通过使一个目标函数最小化来结合先验知识和观察到的训练数据，目标函数同时度量了 网络对应训练样例值的误差（拟合数据），和网络对应于导数的误差（拟合先验知识）。<span class="s47">μ</span>的 值决定了网络在整个误差中拟合这两部分的程度。算法的行为对<span class="s47">μ</span>值敏感，它是由设计者选择 的。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;line-height: 110%;text-align: justify;">虽然 <span class="s6">TangentProp </span>成功地结合了先验知识和训练数数据以指导神经网络学习，但它对于先 验知识中的错误鲁棒性不强。当先验知识不正确时，即输入到学习器的训练导数不能正确反映 真实目标函数的导数时，算法将试图拟合不正确的导数，从而导致泛化精度不如完全忽略先验 知识使用纯反向传播算法的精度。如果我们预先知道训练导数中错误出现程度，我们可用这一 信息选择常量<span class="s47">μ</span>，以确定拟合训练值和拟合训练导数的相对重要程度。然而，这一信息不太可 能预先知道。在下一节我们讨论了 <span class="s6">EBNN </span>算法，它可自动根据 <span class="s6">example-by-example </span>的基础选择 <span class="s47">μ</span>的值，以解决不正确的先验知识的问题。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;line-height: 108%;text-align: justify;">有必要比较一下 <span class="s6">TangentProp</span>、<span class="s6">KBANN </span>和反向传播执行的假设空间（权值空间）的搜索方 法。<span class="s6">TangentProp </span>结合先验知识，通过改变由梯度下降最小化的目的<span class="s6">(objective)</span>函数来影响假设 搜索。它相当于改变了假设空间搜索的目标，如图 <span class="s6">12-6 </span>所示。如反向传播算法一样（但与 <span class="s6">KBANN </span>不同），<span class="s6">TangentProp </span>开始于随机小权值的初始网络。然而，它的梯度训练法则产生的 权值更新与反向传播的不同，从而得到不同的最终假设。如图中所示，使 <span class="s6">TangentProp </span>的目的 函数最小化的假设集合不同于使反向传播的目的函数最小化的假设集合，重要的是，如果训练 样例和先验知识都正确，并且目标函数可用 <span class="s6">ANN </span>精确表示，那么满足 <span class="s6">TangentProp </span>目标的权 向量集合将为满足反向传播目标的权向量集合的子集。这两个最终假设的集合的差别为一些不</p><p style="padding-left: 15pt;text-indent: -9pt;text-align: left;">正确的假设，它们会被反向传播考虑，但会因为先验知识而被 <span class="s6">TangentProp </span>剔除掉。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 13pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="569" height="1" alt="image" src="机器学习/Image_440.png"/></span></p><p class="s48" style="padding-left: 15pt;text-indent: 0pt;text-align: left;">插图——原书页码： <span class="s21">351</span></p><p class="s6" style="padding-top: 6pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">Hypothesis Space<span class="p">： 假设空间</span></p><p class="s6" style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: left;">Hypotheses that maximize fit to data and prior knowledge: <span class="p">对数据和先验知识都有最大拟 合度的假设</span></p><p class="s6" style="padding-top: 1pt;padding-left: 26pt;text-indent: 0pt;text-align: left;">Hypotheses that maximize fit to data <span class="p">对数据拟合度最大的假设</span></p><p class="s6" style="padding-top: 1pt;padding-left: 26pt;text-indent: 0pt;text-align: left;">TangentProp Search TangentProp <span class="p">搜索</span></p><p class="s6" style="padding-top: 1pt;padding-left: 26pt;text-indent: 0pt;text-align: left;">Backpropagation Search <span class="p">反向传播搜索</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 14pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="553" height="1" alt="image" src="机器学习/Image_441.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 143pt;text-indent: 0pt;text-align: left;">图 <span class="h4">12-6TangentProp </span>中的假设空间搜索</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s16" style="padding-left: 37pt;text-indent: 21pt;line-height: 125%;text-align: justify;">TangentProp <span class="s14">将网络初始化为随机小权值，如反向传播中一样。然而，它使用不同的误差函数来 引导梯度下降搜索。</span>TangentProp <span class="s14">中使用的误差包括了预测训练值的误差，也包括预测由先验知识提供 的训练导数的误差。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 110%;text-align: justify;">注意，对目标函数的训练导数拟合的另一种方法是，简单地将观察到的训练样例附近的附 加训练样例综合起来，使用已知的训练导数来估计这些附近的实例的训练值。例如，在上面的 字符识别任务中，可以取一个训练图像，对其少量的平移，然后断言平移后的图像与原来的样 例属于同一类。可以期望使用反向传播和这些综合的样例，能得到相似于 <span class="s6">TangentProp </span>中使用 原始样例和导数所得到的结果。<span class="s6">Simard et al.</span>（<span class="s6">1992</span>）作的实验显示两种情况下有近似相等的泛 化错误率，但 <span class="s6">TangentProp </span>能更为有效地收敛。有意思的是第 <span class="s6">4 </span>章提到的学习驾驶汽车的 <span class="s6">ALVINN </span>系统，使用了很相似的途径以综合附加训练样例。它使用有关如何根据镜头图像的水 平平移来改变驾驶方向的先验知识，来创建多个综合的训练样例以扩充每个观察到的训练样 例。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">12.4.4 EBNN <span class="s25">算法</span></h3><p style="padding-top: 10pt;padding-left: 6pt;text-indent: 21pt;line-height: 109%;text-align: justify;"><span class="s6">EBNN(Explanation-Based neural network) </span>即基于解释的神经网络（见 <span class="s6">Mitchell &amp; Thrun 1993a; Thrun 1996</span>），这种算法以两种方式改进了 <span class="s6">TangentProp </span>算法。首先，它不依靠用户提 供训练导数，而是对每个训练样例自行计算此训练导数。计算方法是通过用一套给定的领域理 论来解释每个训练样例。其次，<span class="s6">EBANN </span>涉及了如何确定学习过程中归纳和分析部分相对重要 程度的问题（即如何选择式 <span class="s6">12.1 </span>中参数<span class="s47">μ</span>的值）。<span class="s47">μ</span>的值是对每个训练样例独立选择的，它 基于一个启发式规则，考虑领域理论能否精确预测特定样例的训练值。因此对于那些能由领域 理论正确解释的训练样例，学习的分析成分被强化；而对不能正确解释的样例，分析成分被弱 化。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 6pt;text-indent: 21pt;text-align: justify;">EBNN<span class="p">的输入包括（</span>1<span class="p">）形式为</span>&lt;<i>x</i><span class="s36">i</span>,<i>f</i>(<i>x</i><span class="s36">i</span>)&gt;<span class="p">的一组训练样例，不包含训练导数；（</span>2<span class="p">）一组领 域理论，类似于基于解释的学习（第 </span>11 <span class="p">章）和</span>KBANN<span class="p">中使用的，但它表示为一组预先训练过</span></p><p class="s6" style="padding-left: 6pt;text-indent: 0pt;line-height: 107%;text-align: left;"><span class="p">的神经网络，而不是</span>Horn<span class="p">子句。</span>EBNN<span class="p">的输出是一个能逼近目标函数</span><i>f</i><span class="p">的新的神经网络。此学习 到的网络能够拟合训练样例</span>&lt;<i>x</i><span class="s36">i</span>,<i>f</i>(<i>x</i><span class="s36">i</span>)&gt;<span class="p">，以及从领域理论中抽取的</span><i>f</i><span class="p">的训练导数。对训练样例</span></p><p class="s6" style="padding-left: 6pt;text-indent: 0pt;text-align: left;">&lt;<i>x</i><span class="s36">i</span>,<i>f</i>(<i>x</i><span class="s36">i</span>)&gt;<span class="p">的拟合构成了学习的归纳成分，而对领域理论中抽取的训练导数的拟合构成了学习的 分析成分。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 108%;text-align: justify;">为说明 <span class="s6">EBNN </span>中使用的领域理论，考虑图 <span class="s6">12-7</span>。图的上面部分显示的是目标函数 <span class="s21">Cup </span>的 <span class="s6">EBNN </span>领域理论，每一方块表示领域理论中一个神经网络。注意在此例中，表 <span class="s6">12-3 </span>的符号领 域理论中每个 <span class="s6">Horn </span>子句有一对应的网络。例如，标为 <span class="s21">Graspable </span>的网络输入为一实例描述， 输出为反映对象是否 <span class="s21">Graspable </span>的值（<span class="s6">EBNN </span>典型情况下用 <span class="s6">0.8 </span>表示真命题，用 <span class="s6">0.2 </span>表示假命 题）。此网络类似于表 <span class="s6">12-3 </span>中给出的 <span class="s21">Graspable </span>的 <span class="s6">Horn </span>子句。某些网络以其他网络的输出作 为输入（例如，最右边标为 <span class="s21">Cup </span>的网的输入为 <span class="s21">Stable</span>、<span class="s21">Liftable </span>和 <span class="s21">OpenVessel </span>网络的输出。） 因此，组成领域理论的这些网络可以链接起来，对每个输入案例推理出目标函数，如 <span class="s6">Horn </span>子 句之间的链接一样。一般地，这些领域理论网络可由某外部源提供给学习器，或者也可是同一 系统以前学习的结果。<span class="s6">EBNN </span>使用这些领域理论来学习新的目标函数。它在此过程中不改变领 域理论。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 27pt;text-indent: 0pt;text-align: left;">EBNN<span class="p">的目的是学习一个描述目标函数的新神经网络。我们将此新网络称为目标网络</span></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">（<span class="s6">target network</span>）。在图 <span class="s6">12-7 </span>的例子中，目标网络<span class="s21">Cup</span><span class="s36">target</span>显示在图的底部，它的输入为任意 的实例描述，输出为表示此对象是否为<span class="s21">Cup</span>的值。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 5pt;text-indent: 21pt;text-align: justify;">EBNN<span class="p">通过执行前一节描述的</span>TangentProp<span class="p">算法来学习目标网络，回忆一下，</span>TangentProp<span class="p">训 练网络以拟合训练值和训练导数。 </span>EBNN <span class="p">把它接收 到的输入训练值 </span>&lt;<i>x</i><span class="s36">i</span>,<i>f</i>(<i>x</i><span class="s36">i</span>)&gt; <span class="p">传递给 </span>TangentProp<span class="p">。此外，</span>EBNN<span class="p">还把它从领域理论中计算出的导数提供给</span>TangentProp<span class="p">。为理解 </span>EBNN<span class="p">是如何计算这些训练导数的，再次考虑图 </span>12-7<span class="p">。图上方显示了对一特定训练实例</span><i>x</i><span class="s36">i</span><span class="p">，领 域理论作出的目标函数值预测。</span>EBNN<span class="p">对应于输入实例的每一个特征计算此预测的导数。例 如，在图中，实例</span><i>x</i><span class="s36">i</span><span class="p">描述为几个特征如</span><i>MadeOfStyrofoam</i>=0.2<span class="p">（即为假），而领域理论预测为 </span><i>Cup</i><span class="p">＝</span>0.8<span class="p">（即真）。</span>EBNN<span class="p">对应于每个实例特征计算此预测的偏导，得到下面的偏导集合：</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s117" style="padding-left: 28pt;text-indent: 0pt;line-height: 14pt;text-align: left;"><span class="s38">⎡ </span><span class="s91">Cup </span><span class="s115">, </span><span class="s91">Cup </span><span class="s115">,..., </span><span class="s91">Cup </span><span class="s38">⎤</span></p><p class="s38" style="text-indent: 0pt;line-height: 12pt;text-align: left;">⎣</p><p style="text-indent: 0pt;text-align: left;"/><p class="s41" style="text-indent: 0pt;line-height: 13pt;text-align: left;"><span class="s116">⎦</span><span class="s33"> </span>x<span class="s40"></span><span class="s42"> </span>x</p><p style="text-indent: 0pt;text-align: left;"/><p class="s263" style="padding-left: 28pt;text-indent: 0pt;line-height: 18pt;text-align: left;">⎢<span class="s38"></span><span class="s30">BottomIsFlat</span></p><p class="s38" style="padding-top: 3pt;padding-left: 6pt;text-indent: 0pt;text-align: left;"><span class="s30">ConcavityPointsUp</span></p><p class="s38" style="padding-left: 17pt;text-indent: 0pt;line-height: 18pt;text-align: left;"><span class="s30">MadeOfStyrofoam </span><span class="s263">⎥</span></p><p class="s44" style="padding-left: 31pt;text-indent: 0pt;line-height: 5pt;text-align: center;">i</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 13pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="569" height="1" alt="image" src="机器学习/Image_442.png"/></span></p><p class="s48" style="padding-left: 15pt;text-indent: 0pt;text-align: left;">插图——原书页码： <span class="s21">353</span></p><p class="s6" style="padding-top: 6pt;padding-left: 6pt;text-indent: 21pt;line-height: 107%;text-align: left;">Explanation of training example in terms of domain theory: <span class="p">根据领域理论得到的训练样例 的解释</span></p><p class="s6" style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">Target network: <span class="p">目标网络</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 14pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="553" height="1" alt="image" src="机器学习/Image_443.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 58pt;text-indent: 87pt;text-align: left;">图 <span class="h4">12-7 </span>在 <span class="h4">EBNN </span>中一训练样例的解释</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-left: 37pt;text-indent: 21pt;line-height: 132%;text-align: left;">此解释由领域理论网络（上部）作出的目标函数值预测构成。训练导数从此解释中抽取出来，以 训练分离的目标网络。每个矩形块表示一个单独的多层神经网络。</p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 108%;text-align: justify;">这组导数是领域理论预测函数对输入实例的梯度。下标表示这些导数在<span class="s21">x</span><span class="s6">=</span><span class="s21">x</span><span class="s36">i</span>上计算。在更 一般的情况下，目标函数有多个输出单元，梯度对每个输出进行计算。这个梯度矩阵被称为目 标函数的雅可比行列式（<span class="s6">Jacobian</span>）。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 27pt;text-indent: 0pt;text-align: left;">为理解这些训练导数在帮助学习目标网络的重要性，考虑导数</p><p class="s38" style="padding-top: 2pt;text-indent: 0pt;text-align: center;"><span class="s30">Cup</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="75" height="1" alt="image" src="机器学习/Image_444.png"/></span></p><p class="s38" style="text-indent: 0pt;text-align: center;"><span class="s30">Expensive</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: center;">。如果领域理</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s38" style="text-indent: 0pt;line-height: 11pt;text-align: center;"><span class="s30">Cup</span></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 11pt;text-align: left;">论编码的知识中<span class="s21">Expensive</span>特征与目标函数<span class="s21">Cup</span>无关，那么从此解释中抽取的导数</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="75" height="1" alt="image" src="机器学习/Image_445.png"/></span></p><p class="s38" style="text-indent: 0pt;text-align: left;"><span class="s30">Expensive</span></p><p style="padding-top: 2pt;padding-left: 6pt;text-indent: 0pt;line-height: 111%;text-align: justify;">的值为 <span class="s6">0</span>。为 <span class="s6">0 </span>的导数表示这样的断言，特征<span class="s21">Expensive</span>上的改变对<span class="s21">Cup</span>值的预测没有影响。另 一方面，很大的正导数或负导数表示断言：此特征与目标值非常相关。因此，从领域理论解释 中抽取的导数提供了区分相关和不相关特征的重要信息。当这些抽取出的导数被提供为 <span class="s6">TangentProp </span>的训练导数以学习目标网络 <span class="s21">Cup</span><span class="s36">target</span><span class="s41"> </span>，它们提供了指导泛化过程的有用的偏置 </p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 14pt;text-align: justify;">（<span class="s6">bias</span>）。通常神经网络中的语法归纳偏置在这里被替换为从领域理论中得到的导数所产生的</p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 0pt;text-align: justify;">偏置。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 107%;text-align: justify;">上面我们描述了领域理论预测如何被用于生成一组训练导数。精确地讲，完整的<span class="s6">EBNN</span>算 法如下：给定训练样例和领域理论，<span class="s6">EBNN</span>首先创建一个新的全连接前馈网络以表示此目标函 数。该目标网络被初始化为随机小权值，如在反向传播中那样。然后，<span class="s6">EBNN</span>对每个训练样例</p><p class="s21" style="padding-left: 6pt;text-indent: 0pt;text-align: justify;"><span class="s6">&lt;</span>x<span class="s36">i</span><span class="s6">,</span>f<span class="s6">(</span>x<span class="s36">i</span><span class="s6">)&gt;</span><span class="p">确定相应的训练导数，以两步骤实现。第一步用领域理论来预测实例</span>x<span class="s36">i</span><span class="p">的目标函数 值。令</span>A<span class="s6">(</span>x<span class="s36">i</span><span class="s6">)</span><span class="p">代表此领域理论对实例</span>x<span class="s36">i</span><span class="p">预测。换言之，</span>A<span class="s6">(</span>x<span class="s36">i</span><span class="s6">)</span><span class="p">为形成</span>x<span class="s36">i</span><span class="p">的解释的领域理论组合网络定 义的函数。第二步，分析领域理论的权值和激活状态以抽取出对应</span>x<span class="s36">i</span><span class="p">每个分量的</span>A<span class="s6">(</span>x<span class="s36">i</span><span class="s6">)</span><span class="p">的导数。</span></p><p class="s21" style="padding-left: 5pt;text-indent: 0pt;line-height: 15pt;text-align: justify;"><span class="p">（即在</span>x<span class="s6">=</span>x<span class="s36">i</span><span class="p">计算的</span>A<span class="s6">(</span>x<span class="s6">)</span><span class="p">的雅可比行列式）。抽取导数的过程类似于反向传播算法中计算</span><span class="s47">δ</span><span class="p">项</span></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 107%;text-align: justify;">（见习题 <span class="s6">12.5</span>）。最后，<span class="s6">EBNN</span>使用了<span class="s6">TangentProp</span>的微小变型来训练目标网络以拟合下面的误 差函数。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s38" style="padding-top: 3pt;padding-left: 98pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><span class="s165">⎡ </span><span class="s162">⎛</span> <span class="s30">A</span><span class="s33">(</span><span class="s30">x</span><span class="s33">)</span></p><p class="s42" style="text-indent: 0pt;line-height: 7pt;text-align: left;">2</p><p style="text-indent: 0pt;text-align: left;"/><p class="s30" style="padding-top: 3pt;padding-left: 11pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><span class="s38"></span>f<span class="s31">ˆ </span><span class="s33">(</span>x<span class="s33">) </span><span class="s162">⎞</span><span class="s38"> </span><span class="s165">⎤</span></p><p class="s38" style="text-indent: 0pt;line-height: 12pt;text-align: left;">⎜</p><p style="text-indent: 0pt;text-align: left;"/><p class="s42" style="text-indent: 0pt;line-height: 7pt;text-align: left;">2</p><p style="text-indent: 0pt;text-align: left;"/><p class="s33" style="padding-left: 63pt;text-indent: 0pt;line-height: 16pt;text-align: left;"><i>E </i><span class="s38"></span> <span class="s124"></span><span class="s116">⎢</span>( <i>f </i>(<i>x</i><span class="s52">i</span><span class="s41"> </span>) <span class="s38"></span>  <i>f</i><span class="s31">ˆ</span> (<i>x</i><span class="s52">i</span><span class="s41"> </span>))</p><p class="s38" style="padding-left: 20pt;text-indent: 0pt;line-height: 1pt;text-align: center;">⎢</p><p class="s38" style="padding-left: 1pt;text-indent: 0pt;line-height: 17pt;text-align: left;"><span class="s33"> </span><span class="s119"></span><span class="s52">i</span><span class="s41"> </span><span class="s135"></span><span class="s191">⎜</span></p><p class="s38" style="padding-top: 10pt;padding-left: 5pt;text-indent: 0pt;line-height: 6pt;text-align: left;"><span class="s30">x </span><span class="s83">j</span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="39" height="1" alt="image" src="机器学习/Image_446.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="38" height="1" alt="image" src="机器学习/Image_447.png"/></span></p><p class="s38" style="text-indent: 0pt;line-height: 12pt;text-align: left;"></p><p style="text-indent: 0pt;text-align: left;"/><p class="s38" style="padding-left: 46pt;text-indent: 0pt;line-height: 11pt;text-align: left;">⎟ ⎥</p><p class="s38" style="padding-left: 22pt;text-indent: 0pt;line-height: 6pt;text-align: left;"><span class="s30">x </span><span class="s244">j </span><span class="s159">⎟</span> ⎥</p><p style="padding-left: 28pt;text-indent: 0pt;text-align: left;">（<span class="s6">12.2</span>）</p><p class="s41" style="padding-left: 89pt;text-indent: 0pt;line-height: 16pt;text-align: left;">i <span class="s94">⎣ </span>j <span class="s102">⎝</span></p><p class="s41" style="padding-left: 69pt;text-indent: 0pt;line-height: 16pt;text-align: left;"><span class="s116">⎠</span><span class="s38"> </span><span class="s42">( </span>x<span class="s40"> </span>x<span class="s180">i</span><span class="s44"> </span><span class="s42">) </span><span class="s102">⎦</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">其中</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s38" style="text-indent: 0pt;text-align: right;"><span class="s119"></span><span class="s52">i </span> <span class="s33">1 </span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="94" height="22" alt="image" src="机器学习/Image_448.png"/></span></p><p class="s30" style="padding-left: 4pt;text-indent: 0pt;text-align: center;">A<span class="s33">(</span>x<span class="s52">i </span><span class="s33">) </span><span class="s38"> </span>f <span class="s33">(</span>x<span class="s52">i</span><span class="s41"> </span><span class="s33">)</span></p><p class="s30" style="padding-top: 2pt;padding-left: 2pt;text-indent: 0pt;text-align: center;">c</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 27pt;text-indent: 0pt;text-align: left;">（<span class="s6">12</span>．<span class="s6">3</span>）</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 3pt;padding-left: 6pt;text-indent: 21pt;text-align: justify;">这里<span class="s21">x</span><span class="s36">i</span>代表第<span class="s21">i</span>个训练实例，<span class="s21">A</span><span class="s6">(</span><span class="s21">x</span><span class="s6">)</span>代表输入<span class="s21">x</span>的领域理论预测。上标符号<span class="s21">x</span><span class="s83">j</span>代表向量<span class="s21">x</span>的第<span class="s21">j</span>个 分量（即神经网络的第<span class="s21">j</span>个输入结点）。系数<span class="s21">c</span>为一个归一化常量，它的值是为了保证对所有<span class="s21">i</span>， <span class="s33">0 </span><span class="s38"> </span><span class="s119"></span><span class="s52">i </span><span class="s38"> </span><span class="s33">1</span>。</p><p style="padding-top: 13pt;padding-left: 26pt;text-indent: 0pt;text-align: left;">虽然公式看起来很复杂，其中的思想很简单。由式 <span class="s6">12.2 </span>给出的误差函数与式 <span class="s6">12.1 </span>中由</p><p class="s6" style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;line-height: 15pt;text-align: left;">TangentProp<span class="p">最小化的误差函数有相同的一般形式。最左边的项如通常那样，是训练值</span><i>f</i>(<i>x</i><span class="s36">i</span>)<span class="p">和目</span></p><p class="s30" style="padding-left: 6pt;text-indent: 0pt;line-height: 16pt;text-align: left;"><span class="p">标网络预测值 </span>f<span class="s31">ˆ</span><span class="s33"> (</span>x <span class="s33">) </span><span class="p">之间的误差平方。最右边的项衡量了从领域理论中抽取的训练导数 </span><span class="s117"></span><u>A</u><u>( </u><u>x</u><u>)</u></p><p class="s244" style="padding-left: 89pt;text-indent: 0pt;line-height: 15pt;text-align: left;">i <span class="s38"></span><span class="s30">x </span><span class="s83">j</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 0pt;text-align: left;">和目标网络的实际导数</p><p class="s30" style="padding-top: 2pt;text-indent: 0pt;text-align: left;"><span class="s38"></span>f<span class="s31">ˆ</span><span class="s33"> (</span>x<span class="s33">)</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="38" height="1" alt="image" src="机器学习/Image_449.png"/></span></p><p class="s38" style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><span class="s30">x </span><span class="s83">j</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;">之间的误差平方。因此，最左边的项提供是归纳约束，假设必须</p><p style="padding-left: 6pt;text-indent: 0pt;text-align: left;">拟合训练数据；而最右边的项提供的是分析约束，即假设必须拟合从领域理论中抽取的训练导</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 0pt;text-align: left;">数。注意在式 <span class="s6">12.2 </span>中的导数</p><p class="s30" style="padding-top: 3pt;text-indent: 0pt;text-align: left;"><span class="s38"></span>f<span class="s31">ˆ</span><span class="s33"> (</span>x<span class="s33">)</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="38" height="1" alt="image" src="机器学习/Image_450.png"/></span></p><p class="s38" style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><span class="s30">x </span><span class="s83">j</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;">只是式 <span class="s6">12.1 </span>中表达式</p><p class="s41" style="text-indent: 0pt;line-height: 7pt;text-align: left;">j              i</p><p style="text-indent: 0pt;text-align: left;"/><p class="s33" style="padding-top: 1pt;padding-left: 1pt;text-indent: 0pt;text-align: center;"><span class="s38"></span><i>f</i><span class="s31">ˆ </span>(<i>s </i>(<span class="s119"></span>, <i>x </i>))</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="84" height="1" alt="image" src="机器学习/Image_451.png"/></span></p><p class="s38" style="text-indent: 0pt;text-align: center;"><span class="s119"></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;">的一种特殊形式，其中</p><p class="s41" style="padding-left: 89pt;text-indent: 0pt;line-height: 1pt;text-align: left;">j j</p><p style="padding-left: 27pt;text-indent: -21pt;line-height: 15pt;text-align: left;">将 <span class="s107">s </span><span class="s52">j</span><span class="s41"> </span><span class="s108">(</span><span class="s119"> </span><span class="s108">, </span><span class="s107">x</span><span class="s52">i</span><span class="s41"> </span><span class="s108">) </span>中的<span class="s21">x</span><span class="s36">i</span><span class="s41"> </span>替为了<span class="s21">x</span><span class="s36">i</span><span class="s41"> </span><span class="s6">+</span><span class="s47">α</span>，<span class="s6">EBNN</span>使用的精确的权值训练法则由<span class="s6">Thrun</span>（<span class="s6">1996</span>）描述。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 6pt;text-indent: 21pt;line-height: 109%;text-align: justify;">EBNN<span class="p">中归纳和分析学习部分的相对重要性由常量</span><span class="s47">μ</span><span class="s36">i</span><span class="p">确定，它由式 </span>12-3 <span class="p">定义。</span><span class="s47">μ</span><span class="s36">i</span><span class="p">的值是 由领域理论的预测</span><i>A</i>(<i>x</i><span class="s36">i</span>) <span class="p">和训练值</span><i>f</i>(<i>x</i><span class="s36">i</span>)<span class="p">的差异确定的。学习的分析成分对于能被领域理论正确预 测的训练样例其权值被加重，而对于不能正确预测的样例权值减轻。这一加权启发式规则假定 在训练值能够被领域理论正确预测时，从领域理论中抽取的训练导数更有可能是正确的。虽然 可能构造出此启发式规则失败的情况，在实践中几个领域中都已证明是有效的（例如，见 </span>Mitchell &amp; Thrun 1993a; Thrun 1996<span class="p">）。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 6pt;text-indent: 0pt;text-align: justify;">12.4.5 <span class="s25">说明</span></h3><p style="padding-top: 10pt;padding-left: 5pt;text-indent: 21pt;line-height: 109%;text-align: justify;">概括地说，<span class="s6">EBNN</span>算法使用的领域理论被表示为一组预先学习到的神经网络，然后领域理 论与训练样例一起训练其输出假设（目标网络）。对每个训练样例，<span class="s6">EBNN</span>使用其领域理论来 解释它，然后从此解释中抽取训练导数。对实例的每个属性计算出一个训练导数，以描述：按 照领域理论，目标函数值是怎样由其属性值的微小变化影响的。这个训练导数被提供给 <span class="s6">TangentProp</span>的一个变体，其中使目标网络拟合这些导数和训练样例值。拟合导数限制了学习到 网络必须拟合领域理论给出的依赖关系，而拟合训练值限制了网络必须拟合观察到的数据本 身。拟合导数的权值<span class="s47">μ</span><span class="s36">i</span>是由每个训练样例独立确定的，它基于领域理论预测此样例训练值的 精确程度。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 27pt;text-indent: 0pt;text-align: left;">在多个领域内， <span class="s6">EBNN </span>已被证明是从近似领域理论中学习的一种有效方法。 <span class="s6">Thrum</span></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: justify;">（<span class="s6">1996</span>）描述了它在上述讨论的 <span class="s21">Cup </span>学习任务的变体上的应用，并且报告说它比标准反向传播 算法泛化更为精确，特别是在训练数据缺少的情况下。例如，在经过 <span class="s6">30 </span>个样例训练后， <span class="s6">EBANN </span>在另一测试数据集上得到的均方根误差为 <span class="s6">5.5</span>，而反向传播的误差为 <span class="s6">12.0</span>。<span class="s6">Mitchell &amp; Thrun</span>（<span class="s6">1993a</span>）描述了应用 <span class="s6">EBNN </span>以学习控制模拟的移动机器人，其中领域理论由神经网络构 成，它们预测了不同机器人对外界状态的动作的效果。其中 <span class="s6">EBNN </span>也使用了近似的预先学习 的领域理论，并获得了比反向传播更好的性能。这里反向传播需要约 <span class="s6">90 </span>个训练事件才能达到 <span class="s6">EBNN </span>中 <span class="s6">25 </span>个训练事件后的性能。<span class="s6">O&#39;Sullivan et al.</span>（<span class="s6">1997</span>）和 <span class="s6">Thrun</span>（<span class="s6">1996</span>）描述了 <span class="s6">EBNN </span>应 用到其他几种真实世界感知和控制任务，其中领域理论由网络组成，它使用声纳、视觉和激光 范围传感器预测了室内移动机器人的动作效果。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">EBNN <span class="p">与其他基于解释的学习方法之间存在内在的联系，如第 </span>11 <span class="p">章描述的 </span>Prolog-EBG<span class="p">。 回忆该章中 </span>Prolog-EBG <span class="p">也基于领域理论构造解释（对样例目标值的预测）。在 </span>Prolog-EBG <span class="p">中，解释的构造来自于由 </span>Horn <span class="p">子句组成的领域理论，而目标假设的精化是通过计算此解释成 立的最弱条件。因此解释中的相关依赖性在学习到的 </span>Horn <span class="p">子句假设中反映。</span>EBNN <span class="p">构造了一 个相似的解释，但它是基于神经网络形式的领域理论，而不是 </span>Horn <span class="p">子句。如在 </span>Prolog-EBG</p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 110%;text-align: justify;">中，相关的依赖性是从解释中抽取的，而且被用于精化目标假设。在 <span class="s6">EBNN </span>中，这些依赖性 形式为导数，因为在神经网络这样的连续函数中，导数是表示依赖性的很自然的方法。相反， 在符号解释或逻辑证明中，表示依赖性的自然方法是描述此证明所应用的样例集。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 109%;text-align: justify;">第 <span class="s6">11 </span>章描述的符号的基于解释方法与 <span class="s6">EBNN </span>在其学习能力方面有几个不同。主要不同在 于 <span class="s6">EBNN </span>能处理不完美的领域知识，而 <span class="s6">Prolog-EBG </span>不能。这一不同是由于 <span class="s6">EBNN </span>是建立在拟 合观察训练值的归纳机制之上的，而且领域理论只被作为学习到的假设的附加约束。第二个重 要不同在于 <span class="s6">Prolog-EBG </span>学习到逐渐增长的 <span class="s6">Horn </span>子句集。而 <span class="s6">EBNN </span>学习到固定大小的神经网 络。如第 <span class="s6">11 </span>章讨论的，学习 <span class="s6">Horn </span>子句集的一个难题是，随着学习过程的进行和新 <span class="s6">Horn </span>子句 被加入，分类新实例的开销不断增长。然而固定大小的神经网络也有相应的不足，它可能无法 表示足够复杂的函数，而增长的 <span class="s6">Horn </span>子句集可以表示越来越复杂的函数。<span class="s6">Mitchell &amp; Thrun</span></p><p style="padding-left: 6pt;text-indent: 0pt;text-align: justify;">（<span class="s6">1993b</span>）更详细地讨论了关于 <span class="s6">EBNN </span>和符号表示的基于解释学习方法之间联系。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 6pt;text-indent: 0pt;text-align: justify;">12.5 <span class="s17">使用先验知识来扩展搜索算子</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 110%;text-align: justify;">前面两节考查了先验知识在学习中的两种不同角色。初始化学习器的假设、和改变目的函 数以引导假设空间上的搜索。本节我们考虑使用先验知识来改变假设空间搜索的第三种方法： 即改变搜索中定义合法搜索步的算子集合。这一途径被用于 <span class="s6">FOCL</span>（<span class="s6">Pazzani et al. 1991</span>， <span class="s6">Pazzani &amp; Kibler 1992</span>）以及 <span class="s6">ML-SMART</span>（<span class="s6">Bergadano &amp; Giordanna 1990</span>）等系统。这里我们用 <span class="s6">FOCL </span>来说明这一途径。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><ol id="l34"><ol id="l35"><ol id="l36"><li style="padding-left: 41pt;text-indent: -35pt;text-align: justify;"><h3 style="display: inline;">FOCL <span class="s25">算法</span></h3><p class="s6" style="padding-top: 10pt;padding-left: 6pt;text-indent: 21pt;line-height: 108%;text-align: justify;">FOCL <span class="p">是第 </span>10 <span class="p">章描述的纯归纳的 </span>FOIL <span class="p">系统的一个扩展。</span>FOIL <span class="p">和 </span>FOCL <span class="p">都学习一组一阶 </span>Horn <span class="p">子句以覆盖观察到的训练例。两个系统都应用了序列覆盖算法来学习单个 </span>Horn <span class="p">子句，移 去那些被新 </span>Horn <span class="p">子句覆盖的正例，然后在剩余的训练样例上重复这一过程。在两个系统中， 每个新 </span>Horn <span class="p">子句都是通过一般到特殊搜索创建的，开始于最一般的 </span>Horn <span class="p">子句（即不含前件的 子句）。然后生成当前子句的几个候选特化式，并选择其中关于训练样例有最大信息增益的一 个。重复该过程，生成更多的候选特化式并选择最佳的，直到获得一个满足指定性能的 </span>Horn <span class="p">子句。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 6pt;text-indent: 21pt;line-height: 107%;text-align: justify;">FOIL <span class="p">和 </span>FOCL <span class="p">之间的区别在于搜索单个 </span>Horn <span class="p">子句的一般到特殊过程中候选假设生成的方 法。第 </span>10 <span class="p">章描述的 </span>FOIL <span class="p">生成每个候选特化式是通过加入一个新文字到子句前件中得到的。 </span>FOCL <span class="p">使用同样的方法产生候选特化式，但还基于领域理论生成了附加的特化式。图 </span>12-8 <span class="p">的搜 索树的实线边显示了在 </span>FOIL <span class="p">典型的搜索中考虑的一般到特殊搜索步。图 </span>12-8 <span class="p">搜索树的虚线边 表示 </span>FOCL <span class="p">中基于领域理论考虑的附加候选特化式。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 107%;text-align: justify;">虽然 <span class="s6">FOCL </span>和 <span class="s6">FOIL </span>都学习一阶 <span class="s6">Horn </span>子句，我们这时演示的操作都只有简单的命题 <span class="s6">Horn </span>子句（无变量的）。特别地，再次考虑图 <span class="s6">12-3 </span>中的 <span class="s21">Cup </span>目标概念、训练样例和领域理论。为 描述 <span class="s6">FOIL </span>的操作，我们必须首先在出现于领域理论和假设表示中的两种文字之间作一区分。 当一个文字可被用于描述一个输出假设时，我们称它是操作型（<span class="s6">operational</span>）。例如，在图 <span class="s6">12-</span></p><p style="padding-left: 6pt;text-indent: 0pt;text-align: justify;"><span class="s6">3 </span>的 <span class="s21">Cup </span>例子中，我们允许输出假设中只能引用描述训练样例的 <span class="s6">12 </span>个属性（如：<span class="s21">HasHandle</span><span class="s6">,</span></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: justify;"><span class="s21">HandleOnTop</span>）。基于这 <span class="s6">12 </span>个属性的文字被认为是操作型的。相反，那些只出现在领域理论中 作为中间特征但不是实例的原子属性的文字，被认为是非操作型。在此情况下非操作型属性的 一个例子是属性 <span class="s21">Stable</span>。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 13pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="569" height="1" alt="image" src="机器学习/Image_452.png"/></span></p><p class="s48" style="padding-left: 15pt;text-indent: 0pt;text-align: left;">插图——原书页码： <span class="s21">358</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">Generated by the domain theory<span class="p">：由领域理论生成</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 14pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="553" height="1" alt="image" src="机器学习/Image_453.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 25pt;text-indent: 0pt;text-align: center;">图 <span class="h4">12-8FOCL </span>中的假设空间搜索</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-left: 37pt;text-indent: 21pt;line-height: 129%;text-align: justify;">为学习一个规则，<span class="s16">FOCL </span>从一般的假设开始，搜索逐渐特殊的假设。有两种算子用于生成当前假 设的特化式。一种是增加一个新的文字（图中的实线）。另一种算子是通过增加一组文字特化此规 则。这组文字按照领域理论构成了目标概念的逻辑充分条件（图中虚线）。<span class="s16">FOCL </span>在所有这些候选化 式中基于它们在数据上的性能进行选择。因此，不完美的领域理论只会在有证据支持理论时才会影响 假设。该例基于前面 <span class="s16">KBANN </span>例子相同的训练数据和领域理论。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 27pt;text-indent: 0pt;text-align: left;">在其一般到特殊搜索的每一点，<span class="s6">FOCL </span>使用下面两种算子扩展其当前假设 <span class="s21">h</span>：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;"><span class="s6">1</span>．对不是 <span class="s21">h </span>一部分的每个操作型文字，创建 <span class="s21">h </span>的一个特化式，方法是加入文字到前件 中。这也是 <span class="s6">FOIL </span>中生成候选后继的方法。图 <span class="s6">12-8 </span>实线箭头表示了此种类型的特化。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;"><span class="s6">2</span>．按照领域理论，创建一个操作型的，并且是目标概念的逻辑充分条件。将这组文字加 入到 <span class="s21">h </span>的当前前件中去。最后修剪 <span class="s21">h </span>的前件，移去对于训练数据不需要的文字。图 <span class="s6">12-8 </span>中虚 箭头表示了此种类型的特化。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 110%;text-align: justify;">上面第 <span class="s6">2 </span>种算子的详细过程如下。<span class="s6">FOCL </span>首先选择一条领域理论子句，它的头部（前件） 匹配目标概念。如果有多个这样的子句，选择其中体部（后件）关于训练样例有最高信息增益 的。例如，在领域理论的训练数据中（图 <span class="s6">12-3</span>），只有一个样的子句：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 26pt;text-indent: 0pt;text-align: center;">Cup<span class="p">←</span>Stable<span class="s6">, </span>Liftable<span class="s6">, </span>OpenVessel</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 113%;text-align: justify;">所选子句的前件形成了目标概念的一个逻辑充分条件。在这些充分条件中，再次使用领域 理论，每个非操作型文字被替换掉，并且将子句前件代入到子句后件中。例如，领域理论子句 <span class="s21">Stable</span>←<span class="s21">BottomIsFlat </span>被用于将操作型的 <span class="s21">BottomIsFlat </span>代换非操作型的 <span class="s21">Stable</span>。这个“展开”</p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: justify;">（ <span class="s6">unfolding</span>）领域理论的过程持续直到充分条件已被表述为操作型文字。如果有多个可选的领 域理论产生不同的结果，那么在此展开过程的每一步用贪婪的方法选择有最大信息增益一个。 读者可以验证在这个例子中，给定数据和领域理论，最终的操作型充分条件为：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 25pt;text-indent: 0pt;text-align: center;">BottomIsFlat<span class="s6">, </span>HasHandle<span class="s6">, </span>Light<span class="s6">, </span>HasConcavity<span class="s6">, </span>ConcavityPointsUp</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 113%;text-align: justify;">作为生成候选特化式的最后一步，此充分条件被修剪。对表达式中的每个文字，除非文字 的移除会降 低训练例上 的分类精度 ，否则它被 移去。包含 这一步骤是 为了从过 特 化</p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 107%;text-align: justify;"><span class="s6">(overspecialization)</span>的情况下恢复，这时不完美的领域理论中包含不相关的文字。在我们的例子 中，上述的文字集合匹配两个正例和两个反例。修剪（移去）文字 <span class="s21">HasHandle </span>会使性能改进。 因此，最终的修剪过的操作型充分条件为：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 114pt;text-indent: 0pt;text-align: left;">BottomIsFlat<span class="s6">, </span>Light<span class="s6">, </span>HasConcavity<span class="s6">, </span>ConcavityPointsUp</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 107%;text-align: justify;">这组文字现在被加入到当前假设的前件中。注意此假设是图 <span class="s6">12-8 </span>中虚线箭头显示的搜索 步的结果。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 112%;text-align: justify;">使用了上面两种操作后，一但当前假设的候选特化式已经生成了，有最大信息增益的候选 者被选择。在图 <span class="s6">12-8 </span>中显示的例子中，在搜索树的第一层选择的候选者为领域理论生成的那 一个。搜索过程继续考虑这个领域理论推举的前件的更进一步的特化式，这样学习的归纳成分 可以精化领域理论中导出的前件。在此例中，领域理论先影响搜索的第一层。然而，情况并非 总是如此。如果在第一层对其他候选有更强的经验化的支持，领域理论推举的文字仍可能在搜 索的后续步骤中被加入。概括地说，<span class="s6">FOCL </span>学习以下形式的 <span class="s6">Horn </span>子句：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s107" style="padding-top: 3pt;padding-left: 24pt;text-indent: 0pt;text-align: center;">c <span class="s109"> </span>o<span class="s292">i </span><span class="s109"> </span>o<span class="s292">b </span><span class="s109"> </span>o <span class="s292">f</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;text-align: justify;">其中<span class="s21">c</span>为目标概念，<span class="s21">o</span><span class="s36">i</span>为初始的操作型文字的合取，它由第一个语法算子每次加入一个文 字，<span class="s21">o</span><span class="s36">b</span>是基于领域理论单步加入的操作型文字合取，而<span class="s21">o</span><span class="s36">f</span>为第一个语法算子每次加入一个的操 作型文字的合取。这三个文字集合都可能为空。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 109%;text-align: justify;">上述的讨论演示了使用命题型领域理论在单个 <span class="s6">Horn </span>子句的一般到特殊搜索中创建假设的 候选特化式的过程。该算法很容易被扩展到一阶表示中（即含有变量的表示）。第 <span class="s6">10 </span>章详细 讨论了 <span class="s6">FOIL </span>中生成一阶 <span class="s6">Horn </span>子句的算法，包括上述第一个算子扩展到一阶表示的情况。为 扩展第二个算子以处理一阶领域理论，必须在展开领域理论时考虑变量代换。这可以通过涉及 到表 <span class="s6">11-3 </span>回归过程的一种方法完成。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">12.5.2 <span class="s25">说明</span></h3><p class="s6" style="padding-top: 10pt;padding-left: 5pt;text-indent: 21pt;line-height: 110%;text-align: justify;">FOCL <span class="p">使用领域理论来增加每步搜索单个 </span>Horn <span class="p">子句中考虑的候选特化式数量。图 </span>12-9 <span class="p">比 较了 </span>FOCL <span class="p">执行的假设空间搜索以及纯归纳的 </span>FOIL <span class="p">算法执行的搜索。</span>FOCL <span class="p">中领域理论推举 的特化式对应 </span>FOIL <span class="p">搜索中的一个“宏“（</span>marcro<span class="p">）步，其中多个文字在一步中被加入。此过 程可被看成是将一个可能以后被考虑的假设提升为立即被考虑的假设。如果领域理论是正确 的，训练数据会显示出此假设比其他假设的优越性，因此它被选择。如果领域理论不正确，对 所有候选的经验化评估会将搜索导向另外一条路径。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 13pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="569" height="1" alt="image" src="机器学习/Image_454.png"/></span></p><p class="s48" style="padding-left: 15pt;text-indent: 0pt;text-align: left;">插图——原书页码： <span class="s21">361</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;line-height: 190%;text-align: left;">Hypotheses that fit training data equally well: <span class="p">对训练数据有同等拟合度的假设 </span>FOCL search: FOCL <span class="p">搜索</span></p><p class="s6" style="padding-left: 27pt;text-indent: 0pt;text-align: left;">FOIL search: FOIL <span class="p">搜索</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 14pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="553" height="1" alt="image" src="机器学习/Image_455.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 150pt;text-indent: 0pt;text-align: left;">图 <span class="h4">12-9 </span>在 <span class="h4">FOCL </span>中搜索的假设空间</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s16" style="padding-left: 37pt;text-indent: 21pt;line-height: 125%;text-align: left;">FOCL <span class="s14">扩大了 </span>FOIL <span class="s14">中使用的搜索算子集合。</span>FOIL <span class="s14">在每步只考虑加入单个新文字，而 </span>FOCL <span class="s14">还考 虑加入由领域理论导出的多个文字。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 110%;text-align: justify;">概括地说，<span class="s6">FOCL </span>使用语法生成的候选特化式的同时，还使用了领域理论驱动的在搜索中 每步的候选特化生成。该算法选择这些候选主要是基于它们在训练数据上的经验化支持。因 此，领域理论使用方式是使学习器偏置，但让它基于其在训练数据上的性能进行最终的选择。 由领域理论引入的这种偏置表现形式为：优先选择这样的 <span class="s6">Horn </span>子句，它最相似于领域理论涵 蕴（<span class="s6">entail</span>）的操作型的逻辑充分条件。此偏置与纯归纳的 <span class="s6">FOIL </span>程序的偏置结合在一起。后面 一个偏置优先选择短的假设。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">在许多不完美领域理论的应用中，<span class="s6">FOCL </span>已显示出比纯归纳的 <span class="s6">FOIL </span>算法有更高的泛化精 度。例如 <span class="s6">Pazzanzi &amp; Kibler</span>（<span class="s6">1992</span>）研究了学习“合法棋盘状态”概念的问题。给定 <span class="s6">60 </span>个训 练样例，<span class="s6">30 </span>个合法的终盘棋盘状态，<span class="s6">30 </span>个为不合法的。<span class="s6">FOIL </span>在一独立测试样例集上得以了 <span class="s6">86%</span>的精度。<span class="s6">FOCL </span>使用相同的 <span class="s6">60 </span>个训练样例，以及一个精度为 <span class="s6">76%</span>的近似领域理论。结果得 到的假设泛化精度为 <span class="s6">94</span>％——误差率比 <span class="s6">FOIL </span>的一半还小。在其他领域也得到了类似的结果。 例如，给定 <span class="s6">500 </span>个电话网问题的训练样例，以及电话公司 <span class="s6">NYNEX </span>对它们的诊断，<span class="s6">FOIL </span>精度 为 <span class="s6">90%</span>，而 <span class="s6">FOCL </span>在给定相同训练数据以及 <span class="s6">95</span>％精度的领域理论时，最终达到精度为 <span class="s6">98</span>％。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">12.6 <span class="s17">研究现状</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 113%;text-align: justify;">本章展示的方法只是结合分析和归纳学习的可能途径中的几个例子。其中每个方法都被证 明在所选领域中性能超出纯归纳的学习方法，但没有一个在大范围的问题领域中被彻底测试或 证明。结合归纳和分析学习的主题仍是一个非常活跃的研究领域。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">12.7 <span class="s17">小结和补充读物</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 27pt;text-indent: 0pt;text-align: left;">本章的要点包括：</p><p style="padding-top: 6pt;padding-left: 49pt;text-indent: -21pt;text-align: justify;"><span class="s10"> </span>近似的先验知识（或领域理论）在许多实际学习问题中是可利用的。决策树和神 经网络反向传播这样的纯归纳方法不能利用这样的领域理论，因此在数据稀缺时 性能较差。<span class="s6">Prolog-EBG </span>这样的纯分析学习方法能够利用这样的领域理论，但在给 定不完美先验知识时会产生不正确的假设。结合归纳和分析学习的方法可以获得 两者的优点，减小样本复杂度，并且否决不正确的先验知识。</p><p style="padding-left: 49pt;text-indent: -21pt;line-height: 94%;text-align: left;"><span class="s10"> </span>看待结合归纳和分析学习算法的一种方法是，考虑领域理论是如何影响假设空间 搜索的。本章我们考查了几种方法，它们使用不完美的领域理论。（<span class="s6">1</span>）创建搜索 中的初始假设，（<span class="s6">2</span>）扩充当前假设的搜索算子集合，（<span class="s6">3</span>）改变搜索目的。</p><p style="padding-left: 49pt;text-indent: -21pt;text-align: left;"><span class="s10"> </span>使用领域理论来初始化假设的一个系统是 <span class="s6">KBANN</span>。此算法使用一套编码为命题规 则的领域理论来分析地创建等价于领域理论的神经网络。然后此网络被反向传播 算法归纳地精化，以改进其在训练数据上的性能。结果是一个被原始领域理论偏 置的网络，其权值被基于训练数据归纳精化。</p><p class="s6" style="padding-left: 49pt;text-indent: -21pt;line-height: 94%;text-align: justify;"><span class="s10"> </span>TangentProp <span class="p">使用的先验知识被表示为目标函数的所希望的导数。在某些领域时， 如图像处理，这样表示先验知识的一个很自然的方法。</span>TangentProp <span class="p">通过改变目的 函数使用这一知识，此函数在搜索假设空间的梯度下降中被最小化。</span></p><p class="s6" style="padding-left: 49pt;text-indent: -21pt;text-align: left;"><span class="s10"> </span>EBNN <span class="p">使用领域理论改变人工神经网络搜索的假设空间的目标。它使用的领域理论 由预先学习的神经网络组成，其作用是实现一个神经网络，以模拟符号的基于解 释学习。如在符号的基于解释的学习中一样，领域理论被用于解释单个样例，获 得不同样例特征的相关程度的信息。然而在神经网络表示中，有关相关性的信息 被表示为目标函数对应于实例特征的导数。网络假设的训练使用了 </span>TangentProp <span class="p">算 法的一个变种，其中被最小化的误差不仅包含了网络输出值的误差，还包含了从 解释中获得的网络导数的误差。</span></p><p class="s6" style="padding-left: 49pt;text-indent: -21pt;text-align: left;"><span class="s10"> </span>FOCL <span class="p">使用领域理论来扩展每步搜索中考虑的的候选集。它使用表示为一阶 </span>Horn <span class="p">子句的近似领域理论来学习一组逼近目标函数的 </span>Horn <span class="p">子句。</span>FOCL <span class="p">应用了序列覆 盖算法，通过一般到特殊搜索过程来学习每个 </span>Horn <span class="p">子句。领域理论被用于扩大此 搜索中每步考虑的下一个更特殊候选假设集。然后候选假设基于其在训练数据上 的性能被评估。以这种方法，</span>FOCL <span class="p">结合了 </span>FOIL <span class="p">的贪婪的、一般到特殊搜索策 略，以及分析方法中的规则链分析推理。</span></p><p class="s10" style="padding-top: 1pt;padding-left: 49pt;text-indent: -21pt;line-height: 14pt;text-align: left;"> <span class="p">如何最好地融合先验知识到新观察事物中的问题，仍是机器学习中主要的待解决 问题之一。</span></p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: left;">还有许多种算法试图结合归纳和分析学习。例如，第 <span class="s6">6 </span>章讨论的学习贝叶斯置信网的方法 提供了另一种途径。本章末尾的参考文献提供了进一步阅读的例子来源。</p><p style="padding-top: 3pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">习题</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 6pt;text-indent: 21pt;line-height: 107%;text-align: justify;">12.1 <span class="p">考虑学习一个目标概念 </span><i>GoodCreditRisk</i><span class="p">，它定义在某实例描述之上，实例描述包含 </span>4 <span class="p">个属性 </span><i>HasStudentLoan</i>, <i>HasSavingsAccount</i>, <i>IsStudent</i>, <i>OwnsCar</i><span class="p">。对于下面的领域理论，给出 </span>KBANN <span class="p">创建的初始网络，包括所有的网络连接和权值。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 172pt;text-indent: -22pt;line-height: 107%;text-align: left;">GoodCreditRisk<span class="p">←</span>Empolyed<span class="s6">, </span>LowDebt Employed<span class="p">←</span><span class="s10"></span>IsStudent</p><p class="s21" style="padding-left: 114pt;text-indent: 0pt;text-align: left;">LowDebt<span class="p">←</span><span class="s10"></span>HasStudentLoan<span class="s6">, </span>HasSavingsAccount</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 107%;text-align: justify;"><span class="s6">12.2 KBANN </span>将一组命题 <span class="s6">Horn </span>子句变换为一个初始神经网络。考虑一类 <span class="s21">n</span><span class="s6">-of-</span><span class="s21">m </span>子句，这 种 <span class="s6">Horn </span>子句前件（先行词）中包含 <span class="s21">m </span>个文字，并且包含一关联的参数 <span class="s21">n</span>，<span class="s21">n</span>≤<span class="s21">m</span>。当 <span class="s21">m </span>个前件 中至少 <span class="s21">n </span>个满足时，此 <span class="s21">n</span><span class="s6">-of-</span><span class="s21">m </span><span class="s6">Horn </span>子句被认为满足。例如，子句：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 26pt;text-indent: 0pt;text-align: center;">Student<span class="p">←</span>LivesInDorm<span class="s6">, </span>Young<span class="s6">, </span>Studies<span class="s6">; </span>n<span class="s6">=2</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 27pt;text-indent: 0pt;text-align: left;">断言如果 <span class="s6">3 </span>个前件中至少两个满足时，此人为 <span class="s21">Student</span>。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 107%;text-align: justify;">给出与 <span class="s6">KBANN </span>相似的一个算法，它接受一组命题型 <span class="s21">n</span><span class="s6">-of-</span><span class="s21">m </span>子句并且能构造出与领域理 论一致的神经网络。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">12.3 <span class="p">试将 </span>KBANN <span class="p">扩展，以接受包含一阶 </span>Horn <span class="p">子句的领域理论，而不只是命题 </span>Horn <span class="p">子 句。（即允许 </span>Horn <span class="p">子句包含变量，如第 </span>10 <span class="p">章中那样）。给出一个算法以构造等价于一个 </span>Horn <span class="p">子句集的神经网络，如果不能则讨论其中的困难所在。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;"><span class="s6">12.4 </span>此习题要求推导出类似于 <span class="s6">TangentProp </span>使用的梯度下降法则。考虑实例空间 <span class="s21">X </span>由实数 构成，而假设空间 <span class="s21">H </span>由 <span class="s21">x </span>的二次函数构成。即每个假设形式为：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 26pt;text-indent: 0pt;text-align: center;">h<span class="s6">(</span>x<span class="s6">)=</span>w<span class="s35">0</span><span class="s6">+</span>w<span class="s35">1</span>x<span class="s6">+</span>w<span class="s35">2</span>x<span class="s46">2</span></p><p style="padding-top: 11pt;padding-left: 6pt;text-indent: 21pt;line-height: 107%;text-align: justify;">（<span class="s6">a</span>）推导一个梯度下降法则，它最小化反向传播中相同的判据：即在假设和训练数据目 标值之间的误差平方和。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 27pt;text-indent: 0pt;text-align: left;">（<span class="s6">b</span>）推导一个梯度下降法则，它最小化 <span class="s6">TangentProp </span>中相同的判据。只考虑一个变换</p><p class="s6" style="padding-left: 4pt;text-indent: 0pt;text-align: center;"><i>s</i>(<span class="s47">α</span>,<i>x</i>)=<i>x</i>+<span class="s47">α</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;"><span class="s6">12.5 EBNN</span>从解释中抽取训练导数的方法是，考虑构成解释的神经网络的权值和激活状 态。考虑一个简单的例子，其中解释的形式为有<span class="s21">n</span>个输入的单个<span class="s6">sigmoid</span>单元。推导一个过程以</p><p style="text-indent: 0pt;text-align: left;"><span><img width="39" height="48" alt="image" src="机器学习/Image_456.png"/></span></p><p class="s30" style="padding-left: 50pt;text-indent: 0pt;line-height: 9pt;text-align: left;"><span class="s38"></span>f<span class="s31">ˆ</span><span class="s33"> (</span>x<span class="s33">)</span></p><p style="padding-left: 6pt;text-indent: 0pt;text-align: left;">抽取导数</p><p class="s38" style="padding-top: 10pt;padding-left: 5pt;text-indent: 0pt;text-align: left;"><span class="s30">x </span><span class="s83">j</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s41" style="padding-left: 6pt;text-indent: 0pt;text-align: left;">x<span class="s40"> </span>x<span class="s43">i</span></p><p style="padding-left: 1pt;text-indent: 0pt;line-height: 16pt;text-align: left;">，其中<span class="s21">x</span><span class="s36">i</span>为输入到此单元的特定训练实例， <span class="s107">f</span><span class="s290">ˆ </span><span class="s108">(</span><span class="s107">x</span><span class="s108">) </span>为<span class="s6">sigmoid</span>单元输出，并且</p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 0pt;text-align: left;"><span class="s21">x</span><span class="s83">j</span>代表<span class="s6">sigmoid</span>单元第<span class="s21">j</span>个输入。也可以使用记号<span class="s21">x</span><span class="s36">i</span><span class="s83">j</span>代表<span class="s21">x</span><span class="s36">i</span>的第<span class="s21">j</span>个分量。提示：该导数与反向传播 训练法则中的导数相似。</p><p class="s6" style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">12.6 <span class="p">再次考虑图 </span>12-8 <span class="p">中显示的 </span>FOCL <span class="p">的搜索步骤。假如在搜索的第一层选择的假设改 为：</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 19pt;text-indent: 0pt;text-align: center;">Cup<span class="p">←</span><span class="s10"></span>HasHandle</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 110%;text-align: justify;">描述 <span class="s6">FOCL </span>生成的作为此假设后继的第二层候选假设。只需要包括那些由 <span class="s6">FOCL </span>的第二个 搜索算子生成的假设，即使用领域理论生成的假设。不要忘记对充分条件进行后修剪。使用表 <span class="s6">12-3 </span>中的训练数据。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 5pt;text-indent: 21pt;line-height: 110%;text-align: justify;">12.7 <span class="p">本章讨论了 </span>3 <span class="p">种途径来使用先验知识以影响假设空间的搜索。你认为如何集成这三种 方法？能否提出一个特殊算法，它集成了至少两种算法以针对某种特殊的假设表示。在此集成 中有什么样的优缺点？</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">12.8 <span class="p">再次考虑 </span>12.2.1 <span class="p">节中的问题，即当数据和先验知识都存在时，应使用什么样的准则在 假设中进行选择。给出你在这个问题上的见解。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s8" style="padding-left: 5pt;text-indent: 0pt;line-height: 24pt;text-align: center;">第<span class="h1">13</span>章 增强学习</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 109%;text-align: justify;">增强学习要解决的是这样的问题：一个能够感知环境的自治 <span class="s6">agent</span>，怎样学习选择能达到 其目标的最优动作。这个很具有普遍性的问题应用于学习控制移动机器人、在工厂中学习进行 最优操作工序、以及学习棋类对弈等。当 <span class="s6">agent </span>在其环境中作出每个动作时，施教者会提供奖 赏或惩罚信息，以表示结果状态的正确与否。例如，在训练 <span class="s6">agent </span>进行棋类对弈时，施教者可 在游戏胜利时给出正回报，而在游戏失败时给出负回报，其他时候为零回报。<span class="s6">Agent </span>的任务就 是从这个非直接的、有延迟的回报中学习，以便后续的动作产生最大的累积回报。本章着重介 绍一个称为 <span class="s6">Q </span>学习的算法，它可从有延迟的回报中获取最优控制策略，即使 <span class="s6">agent </span>没有有关其 动作会对环境产生怎样的效果的先验知识。增强学习与动态规划（<span class="s6">dynamic programming</span>）算法 有关，后者常被用于解决最优化问题。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">13.1 <span class="s17">介绍</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 27pt;text-indent: 0pt;text-align: left;">考虑建造一个可学习机器人。该机器人（或 <span class="s6">agent</span>）有一些传感器可以观察其环境的状态</p><p style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;line-height: 107%;text-align: left;">（<span class="s6">state</span>）并能做出一组动作（<span class="s6">action</span>）已改变这些状态。例如，移动机器人具有镜头和声纳等 传感器，并 可以做出“ 直走”和“ 转弯”等动 作。学习的 任务是获得 一个控制 策 略</p><p style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;line-height: 107%;text-align: left;">（<span class="s6">policy</span>），以选择能达到目的的行为。例如，此机器人的任务是在其电池电量转低时找到充 电器进行充电。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 108%;text-align: justify;">本章关心的就是：这样的 <span class="s6">agent </span>怎样在其环境中做实验并成功地学习到控制策略。这里假 定 <span class="s6">agent </span>的目标可被定义为一个回报（<span class="s6">reward</span>）函数，它对 <span class="s6">agent </span>从不同的状态中选取不同的动 作赋予一个数字值，即立即清算（<span class="s6">immediate payoff</span>）。例如：寻找电池充电器的目标可用这样 的回报函数指定：对那些能够连接到充电器的状态<span class="s6">-</span>动作转换赋予正回报（如<span class="s6">+100</span>），对其他 的状态动作转换赋予 <span class="s6">0 </span>回报。这个回报函数可内嵌在机器人中；或者只有一个外部施教者知 道，由它对机器人的每个动作给出回报值。机器人的任务是执行一系列动作，观察其后果，再 学习控制策略。我们希望的控制策略是能够从任何初始状态选择恰当的动作，使 <span class="s6">agent </span>随时间 的累积的回报达到最大。这个机器人学习问题的一般框架在图 <span class="s6">13-1 </span>中概要列出。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 13pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="569" height="1" alt="image" src="机器学习/Image_457.png"/></span></p><p class="s48" style="padding-left: 15pt;text-indent: 0pt;text-align: left;">插图——原书页码： <span class="s21">368</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-top: 3pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">Agent: Agent</p><p class="s6" style="padding-left: 27pt;text-indent: 0pt;text-align: left;">State: <span class="p">状态</span></p><p class="s6" style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">Reward: <span class="p">回报</span></p><p class="s6" style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">Action: <span class="p">动作</span></p><p class="s6" style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">Environment: <span class="p">环境</span></p><p class="s6" style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">Goal:Learn to choose actions that maximize<span class="p">： 目标：学习选择动作使下式最大化</span></p><p class="s6" style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">where: <span class="p">其中</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 14pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="553" height="1" alt="image" src="机器学习/Image_458.png"/></span></p><p style="padding-left: 58pt;text-indent: 101pt;text-align: left;">图 <span class="h4">13-1 </span>一个与环境交互的 <span class="h4">agent</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-left: 37pt;text-indent: 21pt;line-height: 118%;text-align: justify;">此<span class="s16">agent</span>生存的环境被描述为某可能的状态集合<span class="s56">S</span>。它可执行任意的可能动作集合<span class="s56">A</span>。每次在某状 态<span class="s56">s</span><span class="s65">t</span>下执行一动作<span class="s56">a</span><span class="s65">t</span>，此<span class="s16">agent</span>会收到一个实值回报<span class="s56">r</span><span class="s65">t</span>，它表示此状态<span class="s16">-</span>动作转换的立即值。如此产生了一 系列的状态<span class="s56">s</span><span class="s65">i</span>，动作<span class="s56">a</span><span class="s65">i</span>和立即回报<span class="s56">r</span><span class="s65">i</span>的集合，如图所示。<span class="s16">Agent</span>的任务是学习一个控制策略<span class="s177">π</span><span class="s16">:</span><span class="s56">S</span>→<span class="s56">A</span>，它 使这些回报的和的期望值最大化，其中后面的汇报值随着他们的延迟指数减小。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 111%;text-align: justify;">图 <span class="s6">13-1 </span>中可清楚地看到，学习控制策略以使累积回报最大化这个问题非常普遍，它覆盖 了机器人学习任务以外的许多问题。一般地，此问题是一个通过学习来控制序列过程的问题。 例如生产优化问题，其中要选择一系列的生产动作，而使生产出的货物减去其成本达到最大 化。再如一些序列调度问题，像在一个大城市中选择出租车运载乘客，其中回报函数为乘客等 待的时间和出租车队的整体油耗。一般来说，我们感兴趣的问题类型是：一个 <span class="s6">agent </span>需要通过 学习和选择动作来改变环境状态，而其中使用了一个累积回报函数来定义任意动作序列的质 量。在此类问题中。我们考虑几种特殊的框架：包括动作是否具有确定性的输出；<span class="s6">agent </span>是否 有其动作对环境的效果的先验知识。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">在本书前面，我们已经接触到了通过学习来控制序列过程的问题。在第 <span class="s6">11.4 </span>节中。我们 讨论了用基于解释的方法学习规则，以控制问题解决中的搜索。在其中 <span class="s6">agent </span>的目的是在搜索 其目标状态时的每一步从可选动作中做出抉择。本章讨论的技术不同于 <span class="s6">11.4 </span>节，因为这里考</p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 110%;text-align: justify;">虑的问题中行为可能有非确定性的输出，而且学习器缺少描述其行为输出的领域理论。在第 <span class="s6">1 </span>章，我们讨论了在西洋双陆棋对弈中的学习问题。其中概述的学习方法非常类似于本章的学习 方法。 实际上本章的增强学习算法的一个最成功的应用就是类似的博弈问题。 <span class="s6">Tesauro</span></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 107%;text-align: justify;">（<span class="s6">1995</span>）描述的 <span class="s6">TD-Gammon </span>程序，它使用增强学习成为了世界级的西洋双陆棋选手。这个程 序经过了 <span class="s6">150 </span>万个自生成的对弈训练后，已近似达到了人类最好选手的水平，并且在国际西洋 双陆棋联赛中与顶尖棋手对弈取得了良好的成绩。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 108%;text-align: justify;">学习控制策略以选择动作的问题在某种程度上类似于其他章讨论过的函数逼近问题。这里 待学习的目标函数为控制策略<span class="s47">π</span><span class="s6">:</span><span class="s21">S</span>→<span class="s21">A</span>。它在给定当前状态 <span class="s21">S </span>集合中的 <span class="s21">s </span>时，从集合 <span class="s21">A </span>中输出 一个合适的动作 <span class="s21">a</span>。然而，增强学习问题与其他的函数逼近问题有几个重要不同：</p><p class="s6" style="padding-top: 4pt;padding-left: 49pt;text-indent: -21pt;line-height: 93%;text-align: left;"><span class="s10"> </span><span class="p">延迟回报（</span>delayed reward<span class="p">）。 </span>Agent <span class="p">的任务是学习一个目标函数</span><span class="s47">π</span><span class="p">。它把当前状 态 </span><i>s </i><span class="p">映射到最优动作 </span><i>a</i>=<span class="s47">π</span>(<i>s</i>)<span class="p">。在前面章节中，我们总是假定在学习</span><span class="s47">π</span><span class="p">这样的目标 函数时，每个训练样例是序偶的形式</span>&lt;<i>s</i>, <span class="s47">π</span>(<i>s</i>)&gt;<span class="p">。然而在增强学习中，训练信息不 能以这种形式得到。相反，施教者只在 </span>agent <span class="p">执行其序列动作时提供一个序列立即 回报值，因此 </span>agent <span class="p">面临一个时间信用分配（</span>temporal credit assignment <span class="p">）的问题： 确定最终回报的生成应归功于其序列中哪一个动作。</span></p><p style="padding-left: 49pt;text-indent: -21pt;text-align: justify;"><span class="s10"> </span>探索（<span class="s6">exploration </span>）。在增强学习中，<span class="s6">agent </span>通过其选择的动作序列影响训练样例 的分布。这产生了一个问题：哪种实验策略可产生最有效的学习。学习器面临的 是一个折中的问题：是选择探索未知的状态和动作（以收集新信息），还是选择 它已经学习过、会产生高回报的状态和动作（以使累积回报最大化）。</p><ul id="l37"><li style="padding-left: 49pt;text-indent: -21pt;text-align: left;"><p style="display: inline;">部分可观察状态（<span class="s6">partially observable states</span>）。虽然为了方便起见，可以假定 <span class="s6">agent </span>传感器在每一步可感知到环境的全部状态，但在实际的情况下传感器只能提供部 分信息。例如：带有前向镜头的机器人不能看到它后面的情况。在此情况下可能</p></li></ul></li></ol></ol></ol><p style="padding-top: 1pt;padding-left: 49pt;text-indent: 0pt;line-height: 14pt;text-align: left;">需要结合考虑其以前的观察以及当前的传感器数据以选择动作，而最佳的策略有 可能是选择特定的动作以改进环境可观察性。</p><p style="padding-left: 49pt;text-indent: -21pt;line-height: 14pt;text-align: left;"><span class="s10"> </span>长期学习（<span class="s6">life-long learning</span>）。不象分离的函数逼近任务，机器人学习问题经常要 求此机器人在相同的环境下使用相同的传感器学习多个相关任务。怎样在窄小的</p><p style="padding-left: 49pt;text-indent: 0pt;line-height: 14pt;text-align: left;">走廊中行走，以及怎样从激光打印机中取得打印纸等。这使得有可能使用先前获 得的经验或知识在学习新任务时减小样本复杂度。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">13.2 <span class="s17">学习任务</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 110%;text-align: justify;">在本节中，我们把学习序列控制策略的问题更精确地形式化。有许多种方法可以做到。例 如：可假定 <span class="s6">agent </span>的行为是确定性或非确定性的；假定 <span class="s6">agent </span>可以预测每一个行为所产生的状 态，或不能预测；假定 <span class="s6">agent </span>是由外部专家通过示例最优动作序列来训练，或必须通过执行自 己选择的动作来训练。这里我们基于马尔可夫决策过程定义该问题的一般形式。这种问题形式 遵循图 <span class="s6">13-1 </span>示例的问题。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;text-align: justify;">在马尔可夫决策过程（<span class="s6">Markov decision process</span>，<span class="s6">MDP</span>）中，<span class="s6">agent </span>可感知到其环境的不同 状态集合<span class="s21">S</span>，并且有它可执行的动作集合<span class="s21">A</span>。在每个离散时间步<span class="s21">t</span>，<span class="s6">agent </span>感知到当前状态<span class="s21">s</span><span class="s36">t </span>，选 择当前动作<span class="s21">a</span><span class="s36">t </span>并执行它。环境响应此<span class="s6">agent</span>，给出回报 <span class="s21">r</span><span class="s36">t</span><span class="s6">=</span><span class="s21">r</span><span class="s6">(</span><span class="s21">s</span><span class="s36">t</span><span class="s6">, </span><span class="s21">a</span><span class="s36">t</span><span class="s6">)</span>，并产生一个后继状态<span class="s21">S</span><span class="s36">t</span><span class="s42">+1</span><span class="s6">=</span><span class="s47">δ </span><span class="s6">(</span><span class="s21">s</span><span class="s36">t</span><span class="s6">, </span><span class="s21">a</span><span class="s36">t</span><span class="s6">)</span>。这里函数<span class="s47">δ</span>和<span class="s21">r</span>是环境的一部分，<span class="s6">agent </span>不必知道。在<span class="s6">MDP</span>中，函数<span class="s47">δ</span><span class="s6">(</span><span class="s21">s</span><span class="s36">t</span><span class="s6">, </span><span class="s21">a</span><span class="s36">t</span><span class="s6">)</span>和<span class="s21">r</span><span class="s6">(</span><span class="s21">s</span><span class="s36">t</span><span class="s6">, </span><span class="s21">a</span><span class="s36">t</span><span class="s6">)</span>只 依赖于当前状态和动作，而不依赖于以前的状态和动作。本章中我们只考虑<span class="s21">S</span>和<span class="s21">A</span>为有限的情 形。一般来说，<span class="s47">δ</span>和<span class="s21">r</span>可为非确定性函数，但我们首先从确定性的情形开始。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 16pt;text-align: justify;"><span class="s6">Agent</span>的任务是学习一个策略<span class="s47">π</span><span class="s6">:</span><span class="s21">S</span>→<span class="s21">A</span>，以基于当前观察到的状态<span class="s21">s</span><span class="s36">t</span>选择下的一步动作<span class="s21">a</span><span class="s36">t</span>；即 <span class="s47">π</span><span class="s6">(</span><span class="s21">s</span><span class="s36">t</span><span class="s6">)=</span><span class="s21">a</span><span class="s36">t</span>。如何精确指定此<span class="s6">agent</span>要学习的策略<span class="s47">π</span>呢？一个明显的方法是要求此策略对机器人产 生最大的积累回报。为精确地表述这个要求，我们定义：通过遵循一个任意策略<span class="s47">π</span>从任意初始</p><p class="s260" style="padding-left: 102pt;text-indent: 0pt;line-height: 3pt;text-align: left;">π</p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 12pt;text-align: left;">状态<span class="s21">s</span><span class="s36">t</span>获得的累积值<span class="s21">V</span></p><p class="s6" style="padding-left: 3pt;text-indent: 0pt;line-height: 12pt;text-align: left;">(<i>s</i><span class="s36">t</span>)<span class="p">为：</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s200" style="text-indent: 0pt;line-height: 7pt;text-align: left;"></p><p style="text-indent: 0pt;text-align: left;"/><p class="s30" style="padding-top: 3pt;padding-left: 160pt;text-indent: 0pt;text-align: left;">V <span class="s33">(</span>s<span class="s52">t </span><span class="s33">) </span><span class="s38"> </span>r<span class="s52">t </span><span class="s38"> </span><span class="s119"></span>r<span class="s52">t </span><span class="s40"></span><span class="s42">1 </span><span class="s38"> </span><span class="s119"></span></p><p class="s42" style="text-indent: 0pt;line-height: 7pt;text-align: left;">2</p><p style="text-indent: 0pt;text-align: left;"/><p class="s30" style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">r<span class="s52">t </span><span class="s40"></span><span class="s42">2 </span><span class="s38"> </span><span class="s33">...</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s40" style="padding-top: 3pt;text-indent: 0pt;line-height: 6pt;text-align: right;"></p><p class="s38" style="text-indent: 0pt;line-height: 19pt;text-align: right;"> <span class="s39"></span></p><p class="s41" style="text-indent: 0pt;line-height: 7pt;text-align: right;">i<span class="s40"></span><span class="s42">0</span></p><p class="s41" style="text-indent: 0pt;line-height: 7pt;text-align: left;">i</p><p style="text-indent: 0pt;text-align: left;"/><p class="s41" style="padding-top: 10pt;text-indent: 0pt;text-align: left;"><span class="s154"> </span><span class="s30">r</span>t <span class="s40"></span>i</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 2pt;text-indent: 0pt;text-align: left;">（<span class="s6">13.1</span>）</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 2pt;padding-left: 6pt;text-indent: 21pt;line-height: 16pt;text-align: right;">其中回报序列<span class="s21">r</span><span class="s36">t</span><span class="s42">+</span><span class="s41">i</span>的生成是通过由状态<span class="s21">s</span><span class="s36">t</span>开始并重复使用策略<span class="s47">π</span>来选择上述的动作（如<span class="s21">a</span><span class="s36">t</span><span class="s6">=</span><span class="s47">π </span><span class="s6">(</span><span class="s21">s</span><span class="s36">t</span><span class="s6">)</span>，<span class="s21">a</span><span class="s36">t</span><span class="s42">+1</span><span class="s6">=</span><span class="s47">π</span><span class="s6">(</span><span class="s21">s</span><span class="s36">t</span><span class="s42">+1</span><span class="s6">)</span>等）。这里 <span class="s6">0</span>≤<span class="s47">γ</span><span class="s6">&lt;1 </span>为一常量，它确定了延迟回报与立即回报的相对值。确 切地讲，在未来的第<span class="s21">i</span>时间步收到的回报被因子<span class="s47">γ</span><span class="s83">i</span>以指数级折算。注意如果设置<span class="s47">γ</span><span class="s6">=0</span>，那么只 考虑立即回报。当<span class="s47">γ</span>被设置为接近 <span class="s6">1 </span>的值时，未来的回报相对于立即回报有更大的重要程度。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s41" style="text-indent: 0pt;line-height: 7pt;text-align: left;">h</p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-left: 5pt;text-indent: 21pt;line-height: 108%;text-align: justify;">由式 <span class="s6">13.1  </span>定义的量<span class="s21">V</span><span class="s259">π</span><span class="s6">(</span><span class="s21">s</span><span class="s6">)</span>常被称为由策略<span class="s47">π</span>从初始状态<span class="s21">s</span>获得的折算累积回报（<span class="s6">discounted cumulative  reward</span>）。把未来的回报相对于立即回报进行折算是合理的，因为在许多的情况 下，我们要希望获得更快的回报。不过，其他的整体回报定义也被研究过。例如：有限水平回 报（<span class="s6">finite  horizon  reward  </span>）定义为 <span class="s39"></span><span class="s176">i</span><span class="s40"></span><span class="s42">0 </span><span class="s30">r</span><span class="s52">t</span><span class="s41"> </span><span class="s40"></span><span class="s41">i  </span>，它计算有限的<span class="s21">h</span>步内回报的非折算和。另一种定</p><p class="s33" style="padding-top: 2pt;padding-left: 218pt;text-indent: 0pt;line-height: 7pt;text-align: left;">1 <span class="s41">h</span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="11" height="1" alt="image" src="机器学习/Image_459.png"/></span></p><p class="s249" style="text-indent: 0pt;line-height: 13pt;text-align: left;">h<span class="s30">     </span><span class="s41">i</span><span class="s40"></span><span class="s42">0</span></p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-left: 5pt;text-indent: 0pt;line-height: 19pt;text-align: left;">义方式是平均回报（<span class="s6">average raward </span>） <span class="s33">lim</span><span class="s52">h</span><span class="s40"> </span><span class="s121"> </span><span class="s30">r</span><span class="s52">t </span><span class="s40"></span><span class="s41">i </span>。它考虑的是<span class="s6">agent</span>整个生命期内每时</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 107%;text-align: left;">间步的平均回报。本章只限制于考虑式 <span class="s6">13.1 </span>定义的折算回报。<span class="s6">Mahadevan</span>（<span class="s6">1996</span>）讨论了当优 化准则为平均回报时的增强学习。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 20pt;text-align: left;">现在可以精确陈述<span class="s6">agent</span>的学习任务。我们要求<span class="s6">agent</span>学习到一个策略<span class="s47">π</span>，使得对于所有状 态<span class="s21">s</span>，<span class="s21">V</span><span class="s259">π</span><span class="s6">(</span><span class="s21">s</span><span class="s6">)</span>为最大。此策略被称为最优策略（<span class="s6">optimal policy </span>），并用<span class="s47">π</span><span class="s46">*</span>来表示。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s33" style="padding-top: 3pt;padding-left: 134pt;text-indent: 0pt;line-height: 15pt;text-align: left;"><span class="s119"> </span><span class="s46">*</span><span class="s42"> </span><span class="s38"> </span>arg max<i>V </i><span class="s293"></span><span class="s200"> </span>(<i>s</i>),(<span class="s38"></span><i>s</i>)</p><p class="s200" style="text-indent: 0pt;line-height: 9pt;text-align: right;"></p><p style="padding-top: 4pt;padding-left: 35pt;text-indent: 0pt;text-align: left;">（<span class="s6">13.2</span>）</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s189" style="text-indent: 0pt;line-height: 5pt;text-align: left;">*</p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-top: 4pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">为简化表示，我们将此最优策略的值函数<span class="s30">V </span><span class="s184"></span></p><p class="s6" style="padding-top: 5pt;text-indent: 0pt;text-align: left;"><span class="s33">(</span><span class="s30">s</span><span class="s33">) </span><span class="p">记作</span><i>V</i><span class="s46">*</span>(<i>s</i>)<span class="p">。</span><i>V</i><span class="s46">*</span>(<i>s</i>)<span class="p">给出了当</span>agent<span class="p">从状态</span><i>s</i><span class="p">开</span></p><p style="padding-top: 2pt;padding-left: 26pt;text-indent: -21pt;text-align: left;">始时可获得的最大折算累计回报，即从状态<span class="s21">s</span>开始遵循最优策略时获得的折算累积回报。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">为了说明这些概念，图 <span class="s6">13-2 </span>的上方显示了一个简单的格状世界环境。此图中的 <span class="s6">6 </span>个方格 代表 <span class="s6">agent </span>的 <span class="s6">6 </span>种可能的状态或位置。图中每个箭头代表 <span class="s6">agent </span>可采取的可能动作，从一个状 态移动到另一个。与每个箭头相关联的数值表示如果 <span class="s6">agent </span>执行相应的状态动作转换可收到的 立即回报 <span class="s21">r</span><span class="s6">(</span><span class="s21">s</span><span class="s6">,</span><span class="s21">a</span><span class="s6">)</span>。注意在这个特定环境下，所有的状态动作转换，除了导向状态 <span class="s21">G </span>的以外，都 被定义为 <span class="s6">0</span>。为便于讨论，可将状态 <span class="s21">G </span>看作是目标状态，因为 <span class="s6">agent </span>可接受到回报的惟一方法 是进入此状态。还要注意在此环境下，<span class="s6">agent </span>一旦进入状态 <span class="s21">G</span>，它可选的动作只能是留在该状 态中。因此，我们称 <span class="s21">G </span>为吸收状态（<span class="s6">absorbing state</span>）。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 108%;text-align: justify;">我们已经定义了状态、动作和立即回报，只要再选择折算因子<span class="s47">γ</span>的值，就可以确定最优策 略<span class="s47">π</span><span class="s46">*</span>和它的值函数<span class="s21">V</span><span class="s46">*</span><span class="s6">(</span><span class="s21">s</span><span class="s6">)</span>了。在这里我们选择<span class="s47">γ</span><span class="s6">=0.9</span>。图 <span class="s6">13-2 </span>的下方显示了在此设定下的一种 最优策略（还有其他的最优策略）。与任意策略一样，该策略确切地指定了<span class="s6">agent</span>在任意给定 状态下应选择的一个动作。如所想象的那样，该最优策略把<span class="s6">agent</span>以最短路径导向状态<span class="s21">G</span>。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 13pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="569" height="1" alt="image" src="机器学习/Image_460.png"/></span></p><p class="s48" style="padding-left: 11pt;text-indent: 0pt;text-align: center;">插图——原书页码： <span class="s21">372</span></p><p class="s6" style="padding-top: 6pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">(immediate reward)values<span class="p">： 立即回报值</span></p><p class="s6" style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">values: <span class="p">值</span></p><p class="s6" style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">values: <span class="p">值</span></p><p class="s6" style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">One optimal policy<span class="p">：一个最优策略</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 14pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="553" height="1" alt="image" src="机器学习/Image_461.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 58pt;text-indent: 44pt;text-align: left;">图 <span class="h4">13-2 </span>说明 <span class="h4">Q-</span>学习的基本概念的一个简单的确定性世界</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s16" style="padding-left: 37pt;text-indent: 21pt;line-height: 122%;text-align: justify;"><span class="s14">每个方格代表一个不同的状态，每个箭头代表一个不同的动作。立即回报函数把进入目标状态</span><i>G </i><span class="s14">的回报赋予 </span>100<span class="s14">，其他的赋予 </span>0<span class="s14">。</span><i>V</i><span class="s70">*</span>(<i>s</i>)<span class="s14">和</span><i>Q</i>(<i>s</i>, <i>a</i>)<span class="s14">的值来自于</span><i>r</i>(<i>s</i>, <i>a</i>)<span class="s14">以及折算因子</span><span class="s177">γ</span>=0.9<span class="s14">。对应于最大</span><i>Q</i><span class="s14">值 的动作的一个最优策略也显示在图中。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: left;">图 <span class="s6">13-2 </span>的右边的图显示每状态的<span class="s21">V</span><span class="s46">*</span>值。例如：考虑此图的右下角的状态。此状态的<span class="s21">V</span><span class="s46">*</span>值 为 <span class="s6">100</span>，因为在此状态下最优策略会选择“向上”的动作，从而得到立即回报 <span class="s6">100</span>。然后，</p><p style="padding-top: 2pt;padding-left: 5pt;text-indent: 0pt;line-height: 107%;text-align: justify;"><span class="s6">agent</span>会留在吸收状态中，不再接到更多的回报。类似的，中下方的状态的<span class="s21">V</span><span class="s46">*</span>值为 <span class="s6">90</span>。这是因 为最优策略会使<span class="s6">agent</span>从这里向右移动（得到为 <span class="s6">0 </span>的立即回报），然后向上（生成为 <span class="s6">100 </span>的立即 回报）。这样，此状态的折算过的回报为：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 26pt;text-indent: 0pt;text-align: center;">0+<span class="s47">γ</span>100+<span class="s47">γ</span><span class="s46">2</span>0+<span class="s47">γ</span><span class="s46">3</span>0+...=90</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 107%;text-align: justify;">回忆 <span class="s21">V</span><span class="s6">*</span>的定义中，它是在无限未来上的折算回报和。在这个特定的环境下，一但 <span class="s6">agent </span>到 达了吸收状态 <span class="s21">G</span>，其无限未来将留在此状态中并获得 <span class="s6">0 </span>回报。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 6pt;text-indent: 0pt;text-align: justify;">13.3 <i>Q </i><span class="s17">学习</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 6pt;text-indent: 21pt;text-align: justify;"><span class="p">一个</span>agent<span class="p">在任意的环境中如何能学到最优的策略</span><span class="s47">π</span><span class="s46">*</span><span class="p">？直接学习函数</span><span class="s47">π</span><span class="s46">*</span>: <i>S</i><span class="p">→</span><i>A</i><span class="p">很困难，因 为训练数据中没有提供</span>&lt;<i>s</i>, <i>a</i>&gt;<span class="p">形式的训练样例。作为替代，惟一可用的训练信息是立即回报程 序列</span><i>r</i>(<i>s</i><span class="s36">i</span>,<i>a</i><span class="s36">i</span>)<span class="p">，</span><i>i</i>=0,1,2...<span class="p">。如我们将看到的，给定了这种类型的训练信息，更容易的是学习一个 定义在状态和动作上的数值评估函数，然后以此评估函数的形式实现最优策略。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 6pt;text-indent: 21pt;text-align: justify;"><span class="s6">Agent</span><span class="p">应尝试学习什么样的评估函数？很明显的一个选择是</span>V<span class="s46">*</span><span class="p">。只要当</span>V<span class="s46">*</span><span class="s6">(</span>s<span class="s35">1</span><span class="s6">)&gt;</span>V<span class="s46">*</span><span class="s6">(</span>s<span class="s35">2</span><span class="s6">)</span><span class="p">时， </span><span class="s6">agent</span><span class="p">认为状态</span>s<span class="s35">1</span><span class="p">优于</span>s<span class="s35">2</span><span class="p">，因为从</span>s<span class="s35">1</span><span class="p">中可得到较大的立即回报。当然</span><span class="s6">agent</span><span class="p">的策略要选择的是动作 而非状态。然而在合适的设定中使用</span>V<span class="s46">*</span><span class="p">也可选择动作。在状态</span>s<span class="p">下的最优动作是使立即回报 </span>r<span class="s6">(</span>s<span class="s6">,</span>a<span class="s6">)</span><span class="p">加上立即后继状态的</span>V<span class="s46">*</span><span class="p">值（被</span><span class="s47">γ</span><span class="p">折算）最大化的动作</span>a<span class="p">。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s33" style="padding-top: 3pt;padding-left: 98pt;text-indent: 0pt;text-align: left;"><span class="s119"> </span><span class="s46">*</span><span class="s42"> </span>(<i>s</i>) <span class="s38"> </span>arg max[<i>r</i>(<i>s</i>, <i>a</i>) <span class="s38"> </span><span class="s119"></span><i>V </i><span class="s46">*</span><span class="s42"> </span>(<span class="s119"> </span>(<i>s</i>, <i>a</i>))]</p><p class="s41" style="padding-left: 30pt;text-indent: 0pt;text-align: center;">a</p><p style="padding-top: 3pt;padding-left: 42pt;text-indent: 0pt;text-align: left;">（<span class="s6">13.3</span>）</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 2pt;padding-left: 5pt;text-indent: 21pt;text-align: justify;">（回忆<span class="s47">δ</span><span class="s6">(</span><span class="s21">s</span><span class="s6">,</span><span class="s21">a</span><span class="s6">)</span>代表应用动作<span class="s21">a</span>到状态<span class="s21">s</span>的结果状态）。因此，<span class="s6">agent</span>可通过学习<span class="s21">V</span><span class="s46">*</span>获得最优策 略的条件是：它具有立即回报函数<span class="s21">r</span>和状态转换函数<span class="s47">δ</span>的完美知识。当<span class="s6">agent</span>得知了外界环境用 来响应动作的函数<span class="s21">r</span>和<span class="s47">δ</span>的完美知识，它就可用式 <span class="s6">13.3 </span>来计算任意状态下的最优动作。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 108%;text-align: justify;">不幸的是，只在<span class="s6">agent</span>具有<span class="s21">r</span>和<span class="s47">δ</span>完美知识时，学习<span class="s21">V</span><span class="s46">*</span>才是学习最优策略的有效方法。这要 求它能完美预测任意状态转换的立即结果（即立即回报和立即后续）。在许多实际的问题中， 比如机器人控制，<span class="s6">agent</span>以及它的程序设计者都不可能预先知道应用任意动作到任意状态的确 切输出。例如，对于一个用手臂铲土的机器人，当结果状态包含土块的状态时，如何描述<span class="s47">δ</span>函 数？因此当<span class="s47">δ</span>或<span class="s21">r</span>都未知时，学习<span class="s21">V</span><span class="s6">*</span>是无助于选择最优动作的，因为<span class="s6">agent</span>不能用式 <span class="s6">13-3 </span>进行评 估。在更一般的选择中，<span class="s6">agent</span>应使用什么样的评估函数呢？下一节定义的评估函数<span class="s21">Q</span>提供了答 案。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">13.3.1 <i>Q </i><span class="s25">函数</span></h3><p class="s21" style="padding-top: 10pt;padding-left: 6pt;text-indent: 20pt;line-height: 107%;text-align: justify;"><span class="p">评估函数 </span>Q<span class="s6">(</span>s<span class="s6">,</span>a<span class="s6">)</span><span class="p">定义为：它的值是从状态 </span>s <span class="p">开始并使用动作 </span>a <span class="p">作为第一个动作时的最大折 算累积回报。换言之，</span>Q <span class="p">的值为从状态 </span>s <span class="p">执行动作 </span>a <span class="p">的立即回报加上以后遵循最优策略的值</span></p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 14pt;text-align: left;">（用<span class="s47">γ</span>折算）。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s33" style="padding-top: 3pt;padding-left: 123pt;text-indent: 0pt;text-align: left;"><i>Q</i>(<i>s</i>, <i>a</i>) <span class="s38"> </span><i>r</i>(<i>s</i>, <i>a</i>) <span class="s38"> </span><span class="s119"></span><i>V </i><span class="s46">*</span><span class="s42"> </span>(<span class="s119"> </span>(<i>s</i>, <i>a</i>))</p><p class="s6" style="padding-top: 6pt;padding-left: 45pt;text-indent: 0pt;text-align: left;">(13.4)</p><p class="s21" style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: left;"><span class="p">注意 </span>Q<span class="s6">(</span>s<span class="s6">,</span>a<span class="s6">)</span><span class="p">正是式 </span><span class="s6">13.3 </span><span class="p">中为选择状态 </span>s <span class="p">上的最优动作 </span>a <span class="p">应最大化的量，因此可将式 </span><span class="s6">13.3 </span><span class="p">重 写为 </span>Q<span class="s6">(</span>s<span class="s6">,</span>a<span class="s6">)</span><span class="p">的形式：</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s33" style="padding-top: 3pt;padding-left: 156pt;text-indent: 0pt;text-align: left;"><span class="s119"> </span><span class="s46">*</span><span class="s42"> </span>(<i>s</i>) <span class="s38"> </span>arg max <i>Q</i>(<i>s</i>, <i>a</i>) <span class="p">（</span><span class="s6">13.5</span><span class="p">）</span></p><p class="s41" style="padding-left: 26pt;text-indent: 0pt;text-align: center;">a</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 3pt;padding-left: 5pt;text-indent: 21pt;text-align: justify;">重写该式为什么很重要？因为它显示了如果<span class="s6">agent</span>学习<span class="s21">Q</span>函数而不是<span class="s21">V</span><span class="s46">*</span>函数，即使在缺少函 数<span class="s21">r</span>和<span class="s47">δ</span>的知识时，<span class="s6">agent</span>也可选择最优动作。式 <span class="s6">13.5 </span>清楚地显示出，<span class="s6">agent</span>只须考虑其当前的状 态<span class="s21">s</span>下每个可用的动作<span class="s21">a</span>，并选择其中使<span class="s21">Q</span><span class="s6">(</span><span class="s21">s</span><span class="s6">,</span><span class="s21">a</span><span class="s6">)</span>最大化的动作。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">这一点开始看起来令人惊奇，只须对当前的状态的 <span class="s21">Q </span>的局部值重复做出反应，就可选择 到全局最优化的动作序列，这意味着 <span class="s6">agent </span>不须进行前瞻性搜索，不须明确地考虑从此动作得 到的状态，就可选择最优动作。<span class="s21">Q </span>学习的美妙之处一部分在于其评估函数的定义精确地拥有此 属性：当前状态和动作的 <span class="s21">Q </span>值在单个的数值中概括了所有需要的信息，以确定在状态 <span class="s21">s </span>下选择 动作 <span class="s21">a </span>时在将来会获得的折算累计回报。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;text-align: justify;">为说明这一点，见图 <span class="s6">13-2</span>。其中在简单的格子世界中显示了每个状态和动作的<span class="s21">Q</span>值。注意 每个状态动作的转换的<span class="s21">Q</span>值等于此转换的<span class="s21">r</span>值加上结果状态的<span class="s21">V</span><span class="s46">*</span>值（用<span class="s47">γ</span>折算）。还要注意图中 显示的最优策略对应于选择有最大的<span class="s21">Q</span>值的动作。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s25" style="padding-left: 6pt;text-indent: 0pt;text-align: left;"><span class="h3">13.3.2 </span>学习 <span class="s203">Q </span>的一个算法</p><p style="padding-left: 27pt;text-indent: 0pt;line-height: 28pt;text-align: left;">学习 <span class="s21">Q </span>函数对应于学习最优策略。<span class="s21">Q </span>怎样能被学习到？ 关键在于要找到一个可靠的方法，在只有时间上展开的立即回报序列的情况下估计训练</p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 12pt;text-align: left;">值。这可通过迭代逼近的方法完成。为理解怎样完成这一过程，注意<span class="s21">Q</span>和<span class="s21">V</span><span class="s46">*</span>之间的密切联系：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s33" style="padding-top: 3pt;padding-left: 24pt;text-indent: 0pt;line-height: 14pt;text-align: center;"><i>V </i>*(<i>s</i>) <span class="s38"> </span>max <i>Q</i>(<i>s</i>, <i>a</i><span class="s38"></span>)</p><p class="s41" style="padding-left: 26pt;text-indent: 0pt;line-height: 8pt;text-align: center;">a<span class="s40"></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 26pt;text-indent: 0pt;text-align: left;">它可被用于重写式 <span class="s6">13.4 </span>为</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s33" style="padding-top: 3pt;padding-left: 122pt;text-indent: 0pt;line-height: 14pt;text-align: left;"><i>Q</i>(<i>s</i>, <i>a</i>) <span class="s38"> </span><i>r</i>(<i>s</i>, <i>a</i>) <span class="s38"> </span><span class="s119"> </span>max <i>Q</i>(<span class="s119"> </span>(<i>s</i>, <i>a</i>), <i>a</i><span class="s38"></span>) <span class="p">（</span><span class="s6">13.6</span><span class="p">）</span></p><p class="s41" style="padding-left: 17pt;text-indent: 0pt;line-height: 8pt;text-align: center;">a<span class="s40"></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;"><span class="p">这个 </span><i>Q </i><span class="p">函数的递归定义提供了循环逼近 </span><i>Q </i><span class="p">算法的基础（</span>Watkins 1989<span class="p">）。为描述此算法， 我们将使用符号 </span><span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span><span class="p">来指代实际 </span><i>Q </i><span class="p">函数的学习器的估计，或者说假设。在此算法中学习器表示 其假设 </span><span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span><span class="p">是通过一个大表，其中对每个状态</span>-<span class="p">动作对有一表项。状态</span>-<span class="p">动作对</span>&lt;<i>s</i>, <i>a</i>&gt;<span class="p">的表项中存 储了 </span><span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span>(<i>s</i>,<i>a</i>)<span class="p">的值，即学习器对实际的但未知的 </span><i>Q</i>(<i>s</i>,<i>a</i>)<span class="p">值的当前假设。此表可被初始填充为随机 值（当然，如果认为是全 </span>0 <span class="p">的初始值更易于理解）。</span>Agent <span class="p">重复地观察其当前的状态 </span><i>s</i><span class="p">，选择 某动作 </span><i>a</i><span class="p">，执行此动作，然后观察结果回报 </span><i>r</i>=<i>r</i>(<i>s</i>,<i>a</i>)<span class="p">以及新状态 </span><i>s</i>´=<span class="s47">δ</span>(<i>s</i>,<i>a</i>)<span class="p">。然后 </span>agent <span class="p">遵循每个 这样的转换更新 </span><span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span>(<i>s</i>,<i>a</i>)<span class="p">的表项，按照以下的规则：</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="padding-top: 3pt;padding-left: 116pt;text-indent: 0pt;line-height: 16pt;text-align: left;">Q<span class="s31">ˆ</span><span class="s33"> (</span>s<span class="s33">, </span>a<span class="s33">) </span><span class="s38"> </span>r <span class="s38"> </span><span class="s119"> </span><span class="s33">max </span>Q<span class="s31">ˆ </span><span class="s33">(</span>s<span class="s38"></span><span class="s33">, </span>a<span class="s38"></span><span class="s33">)</span></p><p class="s41" style="text-indent: 0pt;line-height: 8pt;text-align: right;">a<span class="s40"></span></p><p style="padding-top: 5pt;padding-left: 54pt;text-indent: 0pt;text-align: left;">（<span class="s6">13.7</span>）</p><p style="padding-top: 2pt;padding-left: 11pt;text-indent: 21pt;line-height: 109%;text-align: justify;">注意此训练值使用 <span class="s6">agent </span>对新状态 <span class="s21">s</span><span class="s6">´</span>的当前 <span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span>值来精化其对前一状态 <span class="s21">s </span>的 <span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span><span class="s6">(</span><span class="s21">s</span><span class="s6">,</span><span class="s21">a</span><span class="s6">)</span>估计。此 训练规则是从式 <span class="s6">13.6 </span>中得到的，不过此训练值考虑 <span class="s6">agent </span>的近似 <span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span>，而式 <span class="s6">13.6 </span>应用到实际的 <span class="s21">Q </span>函数。注意虽然式 <span class="s6">13.6 </span>以函数<span class="s47">δ</span><span class="s6">(</span><span class="s21">s</span><span class="s6">,</span><span class="s21">a</span><span class="s6">)</span>和 <span class="s21">r</span><span class="s6">(</span><span class="s21">s</span><span class="s6">,</span><span class="s21">a</span><span class="s6">)</span>的形式描述 <span class="s21">Q</span>，<span class="s6">agent </span>不需知道这些一般函数来应 用式 <span class="s6">13.7 </span>的训练规则。相反，它在其环境中执行动作，并观察结果状态 <span class="s21">s</span><span class="s6">´</span>和回报 <span class="s21">r</span>。这样，它 可被看作是在 <span class="s21">s </span>和 <span class="s21">a </span>的当前值上采样。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 12pt;text-indent: 21pt;line-height: 109%;text-align: justify;">上述对于确定性马尔可夫决策过程的 <span class="s21">Q </span>学习算法在表 <span class="s6">13-1 </span>中被更精确地描述。使用此算 法，<span class="s6">agent </span>估计的 <span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span>在极限时收敛到实际 <span class="s21">Q </span>函数，只要系统可被建模为一个确定性马尔可夫决 策过程，回报函数 <span class="s21">r </span>有界，并且动作的选择可使每个状态<span class="s6">-</span>动作对被无限频率的访问。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: center;">表 <span class="h4">13-1 </span>在确定性回报和动作假定下的 <span class="s7">Q </span>学习算法</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-left: 64pt;text-indent: 0pt;text-align: left;">折算因子<span class="s127"></span>为任意常量满足 <span class="s16">0</span><span class="s57"></span><span class="s127"></span><span class="s16">&lt;1</span>。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 2pt;text-align: left;"><span><img width="570" height="2" alt="image" src="机器学习/Image_462.png"/></span></p><p class="s56" style="padding-left: 12pt;text-indent: 0pt;text-align: left;">Q <span class="s14">学习算法</span></p><p class="s16" style="padding-top: 4pt;padding-left: 12pt;text-indent: 0pt;text-align: left;"><span class="s14">对每个 </span><i>s</i>,<i>a</i><span class="s14">，初始化表项 </span><span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span>(<i>s</i>,<i>a</i>)<span class="s14">为 </span>0</p><p class="s14" style="padding-top: 4pt;padding-left: 11pt;text-indent: 0pt;text-align: left;">观察当前状态 <span class="s56">s</span></p><p class="s14" style="padding-top: 3pt;padding-left: 11pt;text-indent: 0pt;text-align: left;">一直重复做：</p><p class="s14" style="padding-top: 3pt;padding-left: 26pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span>选择一个动作 <span class="s56">a </span>并执行它</p><p class="s55" style="padding-top: 3pt;padding-left: 26pt;text-indent: 0pt;text-align: left;">n <span class="s14">接收到立即回报 </span><span class="s56">r</span></p><p class="s55" style="padding-top: 3pt;padding-left: 26pt;text-indent: 0pt;text-align: left;">n <span class="s14">观察新状态 </span><span class="s56">s</span><span class="s16">´</span></p><p class="s16" style="padding-top: 4pt;padding-left: 26pt;text-indent: 0pt;text-align: left;"><span class="s55">n </span><span class="s14">对 </span><span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span>(<i>s</i>,<i>a</i>)<span class="s14">按照下式更新表项：</span></p><p class="s30" style="padding-top: 5pt;padding-left: 27pt;text-indent: 0pt;line-height: 16pt;text-align: center;">Q<span class="s31">ˆ</span><span class="s33"> (</span>s<span class="s33">, </span>a<span class="s33">) </span><span class="s38"> </span>r <span class="s38"> </span><span class="s119"> </span><span class="s33">max </span>Q<span class="s31">ˆ </span><span class="s33">(</span>s<span class="s38"></span><span class="s33">, </span>a<span class="s38"></span><span class="s33">)</span></p><p class="s41" style="padding-left: 27pt;text-indent: 0pt;line-height: 8pt;text-align: center;">a<span class="s40"></span></p><p class="s56" style="padding-top: 3pt;padding-left: 27pt;text-indent: 0pt;text-align: center;"><span class="s55">n </span>s<span class="s14">←</span>s<span class="s16">´</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 2pt;text-align: left;"><span><img width="570" height="2" alt="image" src="机器学习/Image_463.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 12pt;text-indent: 0pt;text-align: left;">13.3.3 <span class="s25">示例</span></h3><p style="padding-top: 10pt;padding-left: 12pt;text-indent: 21pt;line-height: 108%;text-align: justify;">为说明 <span class="s21">Q </span>学习算法的操作过程，考虑图 <span class="s6">13-3 </span>显示的某个 <span class="s6">agent </span>采取的一个动作和对应的对 <span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span>的精化。在此例中，<span class="s6">agent </span>在其格子世界中向右移动一个单元格，并收到此转换的立即回报 为 <span class="s6">0</span>。然后它应用训练规则式 <span class="s6">13.7 </span>来对刚执行的状态<span class="s6">-</span>动作转换精化其 <span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span>的估计。按照训练规 则，此转换的新 <span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span>估计为收到的回报（<span class="s6">0</span>）与用<span class="s72"></span>（<span class="s6">0.9</span>）折算的与结果状态相关联的最高 <span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span>值</p><p style="padding-top: 1pt;padding-left: 12pt;text-indent: 0pt;text-align: left;">（<span class="s6">100</span>）的和。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 11pt;text-indent: 21pt;line-height: 111%;text-align: justify;">每次 <span class="s6">agent </span>从一旧状态前进到一新状态，<span class="s21">Q </span>学习会从新状态到旧状态向后传播其 <span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span>估计。 同时，<span class="s6">agent </span>收到的此转换的立即回报被用于扩大这些传播的 <span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span>值。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 11pt;text-indent: 21pt;line-height: 107%;text-align: justify;">考虑将此算法应用到格子世界中，其回报函数显示在图 <span class="s6">13-2 </span>中，其中的回报值除了进入 目标状态的以外都为 <span class="s6">0</span>。因为此世界包含一个吸收目标状态。我们可假定训练过程包含一系列 的情节（<span class="s6">episode</span>）。在每个情节的过程中，<span class="s6">agent </span>从某随机选择的状态开始。执行动作直到其 到达吸收目标状态。这时情节结束，然后 <span class="s6">agent </span>被运输到一个随机选择的新初始状态开始下一</p><p style="padding-left: 15pt;text-indent: -9pt;text-align: left;">个情节。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 13pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="569" height="1" alt="image" src="机器学习/Image_464.png"/></span></p><p class="s48" style="padding-left: 15pt;text-indent: 0pt;text-align: left;">插图——原书页码： <span class="s21">376</span></p><p class="s6" style="padding-top: 6pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">Initial state: <span class="p">初始状态</span></p><p class="s6" style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">Next state: <span class="p">下一状态</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 14pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="553" height="1" alt="image" src="机器学习/Image_465.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 144pt;text-indent: 0pt;text-align: left;">图 <span class="h4">13-3 </span>在执行单个动作后对 <span class="s7">Q </span>的更新</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-left: 58pt;text-indent: 0pt;text-align: left;">左边的图显 示了机器人 <span class="s56">R </span>的初始状态 <span class="s56">s</span><span class="s64">1</span><span class="s66"> </span>，以及初始 假设中几个 相关的 <span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span>值。 例如， </p><p class="s30" style="padding-top: 1pt;padding-left: 38pt;text-indent: 0pt;line-height: 11pt;text-align: left;">Q<span class="s31">ˆ </span><span class="s33">(</span>s <span class="s33">, </span>a</p><p class="s33" style="padding-top: 4pt;padding-left: 14pt;text-indent: 0pt;line-height: 8pt;text-align: left;">) <span class="s16">=72.9</span><span class="s14">，其中</span><span class="s56">a</span></p><p class="s14" style="padding-top: 5pt;padding-left: 9pt;text-indent: 0pt;line-height: 7pt;text-align: left;">指代<span class="s56">R</span>向右移动的动作。当机器人执行动作<span class="s56">a</span></p><p class="s14" style="padding-top: 5pt;padding-left: 9pt;text-indent: 0pt;line-height: 7pt;text-align: left;">后，它收到立即回报<span class="s56">r</span><span class="s16">=</span></p><p class="s42" style="padding-left: 56pt;text-indent: 0pt;line-height: 8pt;text-align: left;">1 <i>right </i><span class="s295">right</span></p><p class="s67" style="text-indent: 0pt;line-height: 6pt;text-align: center;">right</p><p class="s14" style="padding-top: 1pt;padding-left: 37pt;text-indent: 0pt;text-align: left;"><span class="s16">0</span>，并转换到状态<span class="s56">s</span><span class="s64">2</span>。然后它基于其对新状态<span class="s56">s</span><span class="s64">2</span>的 <span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span>估计更新其 <span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> (</span><span class="s30">s</span><span class="s79">1</span><span class="s42"> </span><span class="s33">, </span><span class="s30">a</span><span class="s52">right</span><span class="s41"> </span><span class="s33">) </span>估计。这里<span class="s177">γ</span><span class="s16">=0.9</span>。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 3pt;padding-left: 5pt;text-indent: 21pt;line-height: 110%;text-align: justify;">在此例中，当应用 <span class="s21">Q </span>学习算法时， <span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span>的值是如何演化的？因为初始的 <span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span>值都为 <span class="s6">0</span>，<span class="s6">agent </span>对任意 <span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span>表项都不会改变，直到它恰好到达目标状态并且收到非零的回报。在下一个情节中， 如果经过这些与目标状态相临的状态，其非 <span class="s6">0 </span>的 <span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span>值会导致与目的相差两步的状态中值的变 化，依此类推。给定足够数量的训练情节，信息会从有非零回报的转换向后传播到整个状态<span class="s6">- </span>动作空间，最终得到一个 <span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span>表。其中的 <span class="s21">Q </span>值如图 <span class="s6">13-2 </span>所示。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;line-height: 109%;text-align: justify;">在下一节，我们证明了在一定条件下表 <span class="s6">13-1 </span>的<span class="s21">Q</span>学习算法会收敛到正确的<span class="s21">Q</span>函数。首先考 虑此<span class="s21">Q</span>学习算法的两个特点，这两个特点是对回报非负且所有 <span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span>值初始化为 <span class="s6">0 </span>的任意确定性的 <span class="s6">MDP</span>都普遍存在的。第一个属性是，在上述条件下 <span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span>值在训练中永远不会下降。更形式化地 讲，令 <span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span><span class="s36">n</span><span class="s6">(</span><span class="s21">s</span><span class="s6">,</span><span class="s21">a</span><span class="s6">)</span>表示训练过程的第<span class="s21">n</span>次循环后学习到的 <span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span><span class="s6">(</span><span class="s21">s</span><span class="s6">,</span><span class="s21">a</span><span class="s6">)</span>值（即<span class="s6">agent</span>所采取的第<span class="s21">n</span>个状态<span class="s6">-</span>动 作转换之后）。则有：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s33" style="padding-top: 3pt;text-indent: 0pt;text-align: right;">(<span class="s38"></span><i>s</i>, <i>a</i>, <i>n</i>)<i>Q</i><span class="s31">ˆ</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s41" style="padding-top: 5pt;text-indent: 0pt;text-align: left;">n<span class="s40"></span><span class="s42">1</span></p><p class="s41" style="text-indent: 0pt;line-height: 7pt;text-align: left;">n</p><p style="text-indent: 0pt;text-align: left;"/><p class="s33" style="padding-top: 3pt;text-indent: 0pt;text-align: left;">(<i>s</i>, <i>a</i>) <span class="s38"> </span><i>Q</i><span class="s31">ˆ</span></p><p class="s33" style="padding-top: 6pt;text-indent: 0pt;text-align: left;">(<i>s</i>, <i>a</i>)</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 3pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">第二个普遍特点是在整个训练过程中，每个 <span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span>值将保持在零和真实 <span class="s21">Q </span>值的区间内：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s41" style="text-indent: 0pt;line-height: 7pt;text-align: left;">n</p><p style="text-indent: 0pt;text-align: left;"/><p class="s33" style="padding-top: 3pt;text-indent: 0pt;text-align: right;">(<span class="s38"></span><i>s</i>, <i>a</i>, <i>n</i>)0 <span class="s38"> </span><i>Q</i><span class="s31">ˆ</span></p><p class="s33" style="padding-top: 5pt;text-indent: 0pt;text-align: left;">(<i>s</i>, <i>a</i>) <span class="s38"> </span><i>Q</i>(<i>s</i>, <i>a</i>)</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-top: 8pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">13.3.4 <span class="s25">收敛性</span></h3><p style="padding-top: 9pt;padding-left: 5pt;text-indent: 21pt;line-height: 109%;text-align: justify;">表 <span class="s6">13-1 </span>的算法是否会收敛到一个等于真实 <span class="s21">Q </span>函数的 <span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span>值？在特定条件下，回答是肯定 的。首先需要假定系统为一确定性的 <span class="s6">MDP</span>。其次，必须假定立即回报值都是有界的，即存在 某正常数 <span class="s21">c</span>，对所有状态 <span class="s21">s </span>和动作 <span class="s21">a</span>，<span class="s6">|</span><span class="s21">r</span><span class="s6">(</span><span class="s21">s</span><span class="s6">, </span><span class="s21">a</span><span class="s6">)|&lt;</span><span class="s21">c</span>。第三，<span class="s6">agent </span>选择动作的方式为它无限频繁地 访问所有可能的状态<span class="s6">-</span>动作对。这个条件意味着如果动作 <span class="s21">a </span>是从状态 <span class="s21">s </span>出发的一个合法的动作， 那么随时间的累计，<span class="s6">agent </span>的动作序列逐渐达到无限长。<span class="s6">agent </span>必须以非 <span class="s6">0 </span>的频率重复地从状态 <span class="s21">s </span>执行动作 <span class="s21">a</span>。注意这些条件在某种程度上十分一般，但有时又相当严格。它们描述了比前一</p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: justify;">节所举的例子中更一般的设定，因为它们允许环境有任意的正或负回报，并且环境中可有任意 数量的状态<span class="s6">-</span>动作转换可产生非零回报。这些条件的严格性在于它要求 <span class="s6">agent </span>无限频繁的访问每 个不同的状态<span class="s6">-</span>动作转换。这在非常大的（或者甚至是连续的）领域中是非常强的假定。我们 将在后面讨论更强的收敛结果。然而本节描述的结果将为理解 <span class="s21">Q </span>学习的运行机制提供直观的 理解。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 112%;text-align: justify;">对收敛性证明的关键思路在于，有最大误差的表项 <span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span><span class="s6">(</span><span class="s21">s</span><span class="s6">,</span><span class="s21">a</span><span class="s6">)</span>必须在其更新时将误差按因子<span class="s47">γ </span>减小。原因在于它的新值的一部分依赖于有误差倾向的 <span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span>估计，其余的部分依赖于无误差的观 察到的立即回报 <span class="s21">r</span>。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s16" style="padding-left: 26pt;text-indent: 21pt;line-height: 107%;text-align: justify;"><span class="s14">定理 </span>13.1<span class="s14">。确定性马尔可夫决策过程中的</span><i>Q</i><span class="s14">学习的收敛性。考虑一个</span><i>Q</i><span class="s14">学习</span>agent<span class="s14">，在一个确定性 </span>MDP<span class="s14">中，并且有有界回报 </span><span class="s33">(</span><span class="s38"></span><span class="s30">s</span><span class="s33">, </span><span class="s30">a</span><span class="s33">)</span><span><img width="1" height="20" alt="image" src="机器学习/Image_466.png"/></span><span class="s30">r</span><span class="s33">(</span><span class="s30">s</span><span class="s33">, </span><span class="s30">a</span><span class="s33">)</span><span><img width="1" height="20" alt="image" src="机器学习/Image_467.png"/></span><span class="s38"> </span><span class="s30">c </span><span class="s14">。</span><i>Q</i><span class="s14">学习</span>agent<span class="s14">使用式 </span>13.7 <span class="s14">的训练规则，将表 </span><span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span>(<i>s</i>,<i>a</i>)<span class="s14">初始 化为任意有限值，并且使用折算因子</span><span class="s177">γ</span><span class="s14">，</span>0<span class="s14">≤</span><span class="s177">γ</span>&lt;1<span class="s14">。令 </span><span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span><span class="s65">n</span>(<i>s</i>,<i>a</i>)<span class="s14">代表在第</span><i>n</i><span class="s14">次更新后</span>agent<span class="s14">的假设 </span><span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span>(<i>s</i>,<i>a</i>)<span class="s14">。 如果每个状态</span>-<span class="s14">动作对都被无限频繁的访问，那么对所有</span><i>s</i><span class="s14">，</span><i>a</i><span class="s14">，当</span><i>n</i><span class="s14">→∞时 </span><span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span><span class="s64">n</span>(<i>s</i>,<i>a</i>)<span class="s14">收敛到</span><i>Q</i>(<i>s</i>,<i>a</i>)<span class="s14">。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-top: 2pt;padding-left: 26pt;text-indent: 21pt;line-height: 106%;text-align: justify;">证明：因为每个状态<span class="s16">-</span>动作转换无限频繁发生，考虑连续的区间，其中每个状态<span class="s16">-</span>动作转换至少发生 过一次。所需要证明的是，在 <span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span>表中所有表项上的最大误差在每个这样的连续区间内至少按因子<span class="s177">γ</span>减 少。 <span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span><span class="s65">n</span>为<span class="s56">n</span>次更新后<span class="s16">agent</span>估计的<span class="s56">Q</span>值表。令Δ<span class="s65">n</span>为 <span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span><span class="s65">n</span>中最大误差，即：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="1" height="27" alt="image" src="机器学习/Image_468.png"/></span></p><p class="s38" style="padding-top: 3pt;padding-left: 49pt;text-indent: 0pt;line-height: 14pt;text-align: left;">  <span class="s33">max </span><span class="s30">Q</span><span class="s31">ˆ</span></p><p class="s41" style="padding-left: 58pt;text-indent: 0pt;line-height: 9pt;text-align: left;"><span class="s90">n </span>s<span class="s42">,</span>a <span class="s90">n</span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="1" height="27" alt="image" src="机器学习/Image_469.png"/></span></p><p class="s33" style="padding-top: 5pt;text-indent: 0pt;text-align: left;">(<i>s</i>, <i>a</i>) <span class="s38"> </span><i>Q</i>(<i>s</i>, <i>a</i>)</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s16" style="padding-top: 3pt;padding-left: 47pt;text-indent: 0pt;text-align: left;"><span class="s14">下面我们使用</span><i>s</i>´<span class="s14">来代表</span><span class="s177">δ</span>(<i>s</i>,<i>a</i>)<span class="s14">，现在对在第</span><i>n</i>+1 <span class="s14">次迭代中更新的任意表项 </span><span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span><span class="s65">n</span>(<i>s</i>,<i>a</i>)<span class="s14">，在修正后的估计</span></p><p class="s16" style="padding-top: 1pt;padding-left: 28pt;text-indent: 0pt;text-align: left;"><span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span><span class="s65">n</span><span class="s66">+1</span>(<i>s</i>,<i>a</i>)<span class="s14">中的误差量为：</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="1" height="27" alt="image" src="机器学习/Image_470.png"/></span></p><p class="s49" style="padding-top: 3pt;text-indent: 0pt;text-align: right;">Q<span class="s50">ˆ</span><span class="s33"> </span><span class="s41">n</span><span class="s40"></span><span class="s42">1</span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="1" height="27" alt="image" src="机器学习/Image_471.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="1" height="31" alt="image" src="机器学习/Image_472.png"/></span></p><p class="s33" style="padding-top: 3pt;text-indent: 0pt;line-height: 14pt;text-align: right;">(<i>s</i>, <i>a</i>) <span class="s38"> </span><i>Q</i>(<i>s</i>, <i>a</i>) <span class="s38"> </span>(<i>r </i><span class="s38"> </span><span class="s119"> </span>max <i>Q</i><span class="s31">ˆ</span></p><p class="s41" style="text-indent: 0pt;line-height: 9pt;text-align: right;">a<span class="s40"> </span><span class="s90">n</span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="1" height="31" alt="image" src="机器学习/Image_473.png"/></span></p><p class="s33" style="padding-top: 5pt;text-indent: 0pt;line-height: 14pt;text-align: left;">(<i>s</i><span class="s38"></span>, <i>a</i><span class="s38"></span>)) <span class="s38"> </span>(<i>r </i><span class="s38"> </span><span class="s119"> </span>max <i>Q</i>(<i>s</i><span class="s38"></span>, <i>a</i><span class="s38"></span>))</p><p class="s41" style="text-indent: 0pt;line-height: 8pt;text-align: center;">a<span class="s40"></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="1" height="31" alt="image" src="机器学习/Image_474.png"/></span></p><p class="s38" style="padding-top: 3pt;text-indent: 0pt;line-height: 14pt;text-align: right;"> <span class="s119"> </span><span class="s33">max </span><span class="s30">Q</span><span class="s31">ˆ</span></p><p class="s41" style="text-indent: 0pt;line-height: 9pt;text-align: right;">a<span class="s40"> </span><span class="s90">n</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="1" height="27" alt="image" src="机器学习/Image_475.png"/></span></p><p class="s38" style="text-indent: 0pt;line-height: 14pt;text-align: right;"> <span class="s119"> </span><span class="s33">max </span><span class="s30">Q</span><span class="s31">ˆ</span></p><p class="s41" style="text-indent: 0pt;line-height: 9pt;text-align: right;">a<span class="s40"> </span><span class="s90">n</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="1" height="27" alt="image" src="机器学习/Image_476.png"/></span></p><p class="s38" style="text-indent: 0pt;line-height: 14pt;text-align: right;"> <span class="s119"> </span><span class="s33">max </span><span class="s30">Q</span><span class="s31">ˆ</span></p><p class="s41" style="text-indent: 0pt;line-height: 9pt;text-align: right;">s<span class="s40"></span><span class="s42">,</span>a<span class="s40"> </span><span class="s90">n</span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="1" height="31" alt="image" src="机器学习/Image_477.png"/></span></p><p class="s33" style="padding-top: 5pt;text-indent: 0pt;line-height: 14pt;text-align: left;">(<i>s</i><span class="s38"></span>, <i>a</i><span class="s38"></span>) <span class="s38"> </span>max <i>Q</i>(<i>s</i><span class="s38"></span>, <i>a</i><span class="s38"></span>)</p><p class="s41" style="text-indent: 0pt;line-height: 8pt;text-align: center;">a<span class="s40"></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s33" style="text-indent: 0pt;text-align: left;">(<i>s</i><span class="s38"></span>, <i>a</i><span class="s38"></span>) <span class="s38"> </span><i>Q</i>(<i>s</i><span class="s38"></span>, <i>a</i><span class="s38"></span>)<span><img width="1" height="27" alt="image" src="机器学习/Image_478.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="1" height="27" alt="image" src="机器学习/Image_479.png"/></span></p><p class="s33" style="padding-top: 17pt;text-indent: 0pt;text-align: left;">(<i>s</i><span class="s38"></span>, <i>a</i><span class="s38"></span>) <span class="s38"> </span><i>Q</i>(<i>s</i><span class="s38"></span>, <i>a</i><span class="s38"></span>)</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="1" height="27" alt="image" src="机器学习/Image_480.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="1" height="27" alt="image" src="机器学习/Image_481.png"/></span></p><p class="s41" style="text-indent: 0pt;line-height: 7pt;text-align: left;">n<span class="s40"></span><span class="s42">1                                                       </span>n</p><p style="text-indent: 0pt;text-align: left;"/><p class="s30" style="padding-top: 3pt;padding-left: 51pt;text-indent: 0pt;text-align: left;">Q<span class="s31">ˆ</span><span class="s33"> (</span>s<span class="s33">, </span>a<span class="s33">) </span><span class="s38"> </span>Q<span class="s33">(</span>s<span class="s33">, </span>a<span class="s33">) </span><span class="s38"> </span><span class="s119"></span><span class="s38"></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-top: 8pt;padding-left: 48pt;text-indent: 0pt;text-align: left;">上面的第三行从第二行中导出，原因是对任意两个函数<span class="s56">f</span><span class="s64">1</span>和<span class="s56">f</span><span class="s64">2</span>有下列不等式成立：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="1" height="31" alt="image" src="机器学习/Image_482.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="1" height="31" alt="image" src="机器学习/Image_483.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="1" height="20" alt="image" src="机器学习/Image_484.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="1" height="20" alt="image" src="机器学习/Image_485.png"/></span></p><p class="s33" style="padding-left: 51pt;text-indent: 0pt;line-height: 14pt;text-align: left;">max <i>f</i><span class="s79">1</span><span class="s42"> </span>(<i>a</i>) <span class="s38"> </span>max <i>f </i><span class="s79">2</span><span class="s42"> </span>(<i>a</i>) <span class="s38"> </span>max <i>f</i><span class="s79">1</span><span class="s42"> </span>(<i>a</i>) <span class="s38"> </span><i>f </i><span class="s79">2</span><span class="s42"> </span>(<i>a</i>)</p><p class="s41" style="padding-left: 60pt;text-indent: 0pt;line-height: 7pt;text-align: left;">a a a</p><p class="s14" style="padding-top: 1pt;padding-left: 27pt;text-indent: 21pt;line-height: 121%;text-align: justify;">从第三行到第四行的推导，我们引入了一个新变量<span class="s56">s</span><span class="s16">´´</span>在其上执行最大化。其合理性在于当我们允许 附加的变量变化时，此最大值只可能更大或至少是相等。注意，通过引入此变量，我们获得了一个与Δ<span class="s65">n</span><span class="s67"> </span>的定义匹配的表达式。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-left: 26pt;text-indent: 21pt;line-height: 115%;text-align: justify;">因此，对任意<span class="s56">s</span><span class="s16">, </span><span class="s56">a</span>，更新后的 <span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span><span class="s65">n</span><span class="s66">+1</span><span class="s16">(</span><span class="s56">s</span><span class="s16">,</span><span class="s56">a</span><span class="s16">)</span>的误差最多为 <span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span><span class="s65">n</span>表中最大误差Δ<span class="s65">n</span>的<span class="s177">γ</span>倍。在初始表中的最 大误差Δ<span class="s64">0</span>是有界的，因为 <span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span><span class="s64">0</span><span class="s16">(</span><span class="s56">s</span><span class="s16">,</span><span class="s56">a</span><span class="s16">)</span>和<span class="s56">Q</span><span class="s16">(</span><span class="s56">s</span><span class="s16">,</span><span class="s56">a</span><span class="s16">)</span>的值对所有<span class="s56">s</span><span class="s16">, </span><span class="s56">a</span>都有界。现在，在每个<span class="s56">s</span><span class="s16">,</span><span class="s56">a</span>都被访问过的第一个 区间内，此表中最大的误差至多为<span class="s177">γ</span>Δ<span class="s64">0</span>。在<span class="s56">k</span>个区间后，误差最多为<span class="s177">γ</span><span class="s256">k</span>Δ<span class="s64">0</span>。因为每个状态都被无限频繁 地访问，这样的区间的数目是无限的，因此当<span class="s56">n</span>→∞时Δ<span class="s65">n</span>→<span class="s16">0</span>。定理得证。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">13.3.5 <span class="s25">实验策略</span></h3><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;line-height: 109%;text-align: justify;">注意表 <span class="s6">13-1 </span>的算法没有指定 <span class="s6">agent </span>如何选择动作。一个明显的策略是，对于在状态 <span class="s21">s </span>的 <span class="s6">agent</span>，选择使 <span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span><span class="s6">(</span><span class="s21">s</span><span class="s6">,</span><span class="s21">a</span><span class="s6">)</span>最大化的动作，从而利用其当前逼近的 <span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span>。然而，使用此策略存在风 险，<span class="s6">agent </span>可能过度束缚到在早期训练中有高 <span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span>值的动作，而不能够探索到其他可能有更高值 得动作。实际上，上面的收敛性定理要求每个状态<span class="s6">-</span>动作转换无限频繁地发生。显然，如果 <span class="s6">agent </span>总选择使当前 <span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span><span class="s6">(</span><span class="s21">s</span><span class="s6">,</span><span class="s21">a</span><span class="s6">)</span>最大的动作，将不能保证此无限频繁性。因此，在 <span class="s21">Q </span>学习中通常使 用概率的途径来选择动作。有较高 <span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span>值的动作被赋予较高的概率，但所有动作的概率都非 <span class="s6">0</span>。 赋予这种概率的一种方法是</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="text-indent: 0pt;text-align: right;">P<span class="s33">(</span>a<span class="s52">i </span><span class="s33">| </span>s<span class="s33">) </span><span class="s38"></span></p><p class="s41" style="padding-top: 4pt;padding-left: 11pt;text-indent: 0pt;text-align: left;"><span class="s255">k</span><span class="s30"> </span>Q<span class="s291">ˆ</span><span class="s42"> ( </span>s<span class="s42">,</span>a<span class="s43">i </span><span class="s42">)</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 1pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="71" height="1" alt="image" src="机器学习/Image_486.png"/></span></p><p class="s121" style="text-indent: 0pt;line-height: 18pt;text-align: left;"></p><p style="text-indent: 0pt;text-align: left;"/><p class="s41" style="padding-left: 20pt;text-indent: 0pt;line-height: 15pt;text-align: left;"><span class="s168">k</span><span class="s30"> </span>Q<span class="s291">ˆ</span><span class="s42"> ( </span>s<span class="s42">,</span>a <span class="s180">j</span><span class="s44"> </span><span class="s42">)</span></p><p class="s41" style="padding-left: 16pt;text-indent: 0pt;line-height: 6pt;text-align: left;">j</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;line-height: 106%;text-align: justify;">其中<span class="s21">P</span><span class="s6">(</span><span class="s21">a</span><span class="s36">i</span><span class="s6">|</span><span class="s21">s</span><span class="s6">)</span>为<span class="s6">agent</span>在状态<span class="s21">s</span>时选择动作<span class="s21">a</span><span class="s36">i</span>的概率，<span class="s21">k</span><span class="s6">&gt;0 </span>为一常量，它确定此选择优先考虑高 <span class="s30">Q</span><span class="s31">ˆ </span>值的程度。较大的<span class="s21">k</span>值会将较高的概率赋予超出平均 <span class="s30">Q</span><span class="s31">ˆ </span>的动作，致使<span class="s6">agent</span>利用它所学习到的 知识来选择它认为会使回报最大的动作。相反，较小的<span class="s21">k</span>值会使其他动作有较高的概率，导致</p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 114%;text-align: left;"><span class="s6">agent</span>探索那些当前 <span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span>值还不高的动作。在某些情况下，<span class="s21">k</span>是随着迭代次数而变化的。以使<span class="s6">agent </span>在学习的早期可用探索型策略，然后逐步转换到利用型的策略。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">13.3.6 <span class="s25">更新序列</span></h3><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;line-height: 109%;text-align: justify;">上面收敛性定理一个重要性暗示在于，<span class="s21">Q </span>学习不需要用最优动作进行训练，就可以收敛到 最优策略。实际上，只要每步的训练动作完全随机选择，使得结果训练序列无限频繁的访问每 个状态<span class="s6">-</span>动作转换，就可以学习到 <span class="s21">Q </span>函数（以及最优策略）。这一事实建议改变训练转换样例 的序列，以改进训练效率而不危及最终的收敛性。为说明这一点，再次考虑在一个 <span class="s6">MDP </span>中有 单个吸收目标状态的学习过程，如同 <span class="s6">13-1 </span>中所示。如以前那样，假定使用序列化的情节</p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 108%;text-align: justify;">（<span class="s6">episode</span>）来训练 <span class="s6">agent</span>。对每个情节，<span class="s6">agent </span>被放置在一个随机初始状态，然后执行动作以更 新其 <span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span>表，直到它到达吸收状态。然后开始一个新的训练情节，通过将 <span class="s6">agent </span>从目标状态转换 到一个新的随机初始状态。如前面指出的，如果开始所有 <span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span>值的初始化为 <span class="s6">0</span>，则在第一个情节 后，<span class="s6">agent </span>的 <span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span>表中只有一个表项改变：即对应于最后转换到目标状态的表项。如果在第二个</p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 108%;text-align: justify;">情节中，<span class="s6">agent </span>恰好从相同的随机初始状态沿着相同动作序列移动，则另一表项变为非 <span class="s6">0</span>，依此 类推。如果重复地以相同的方式运行情节，非 <span class="s6">0 </span><span class="s30">Q</span><span class="s31">ˆ </span>值的边缘逐渐向右移动，从目标状态开始， 每个情节移动到一个新的状态<span class="s6">-</span>动作转换。现在考虑在这些相同的状态<span class="s6">-</span>动作转换上的训练，但 对每个情节以反向的时序。即对每个考虑的转换应用式 <span class="s6">13-7 </span>中相同的更新规则，但以逆序执 行这些更新。这样，在第一个情节后，<span class="s6">agent </span>会更新达到目标路径上每个转换的 <span class="s30">Q</span><span class="s31">ˆ </span>估计。此训 练过程显然会在更少的循环次数内收敛，虽然它要求 <span class="s6">agent </span>在开始此情节训练前使用更多的内 存来存储整个情节。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 5pt;text-indent: 21pt;line-height: 110%;text-align: justify;"><span class="p">改进收敛速率的第二个策略是存储过去的状态</span>-<span class="p">动作转换，以及相应收到的立即回报，然 后周期性地在其上重新训练。开始可能会认为用相同的转换重新训练是做无用功。但注意到更 新的 </span><span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span>(<i>s</i>,<i>a</i>)<span class="p">值是由后继状态 </span><i>s</i>´=<span class="s47">δ</span>(<i>s</i>,<i>a</i>)<span class="p">的 </span><span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span>(<i>s´</i>,<i>a</i>)<span class="p">值确定的。因此，如果后续的训练改变了 </span><span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span>(<i>s</i>,<i>a</i>)<span class="p">值其中一个，在转换</span>&lt;<i>s</i>,<i>a</i>&gt;<span class="p">上重训练会得到 </span><span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span>(<i>s</i>,<i>a</i>)<span class="p">的不同值。一般地，我们希望重放旧 的转换相比于从环境中获得新转换的程度取决于这两种操作在特定问题领域中相对开销。例如 在机器人导航动作的领域，其动作执行需要数秒的时间，从外部世界收集新的状态</span>-<span class="p">动作转换 的延迟会比在内部重放以前观察过的转换的开销要大若干数量级。由于 </span><i>Q </i><span class="p">学习通常要求成千 上万的训练循环才收敛，这种差别显得十分重要的。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 5pt;text-indent: 21pt;line-height: 106%;text-align: justify;"><span class="p">注意贯穿在上述讨论中的两个假定是，</span>agent <span class="p">不知道环境用来生成后继状态 </span><i>s</i>´<span class="p">的状态转换 函数</span><span class="s47">δ</span>(<i>s</i>,<i>a</i>)<span class="p">，也不知道生成回报的函数 </span><i>r</i>(<i>s</i>,<i>a</i>)<span class="p">。如果它知道了这两个函数，就可能有更多有效 的方法。例如，如果执行外部动作开销很大，</span>agent <span class="p">可以简单地忽略环境，在其内部模拟环 境，有效生成模拟动作并赋予适当的模拟回报，</span>Sutton<span class="p">（</span>1991<span class="p">）描述了 </span>Dyna <span class="p">体系结构，它在 外部世界中执行的每步动作后执行一定数量的模拟动作。</span>Moore &amp; Atkeson<span class="p">（</span>1993<span class="p">）描述了一 种称为优先级扫除（</span>prioritized sweeping<span class="p">）的途径，选择最可能的状态来更新下一个，着重于 当前状态有较大更新时的前驱状态。</span>Peng &amp; Williams<span class="p">（</span>1994<span class="p">）描述了一个相似的途径。从动态 规划领域来的大量有效算法可被应用于函数</span><span class="s47">δ</span><span class="p">和 </span><i>r </i><span class="p">未知的情况。</span>Kaelbling et al.<span class="p">（</span>1996<span class="p">）调查了 其中的几种算法。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 6pt;text-indent: 0pt;text-align: justify;">13.4 <span class="s17">非确定性回报和动作</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">上面我们考虑了确定性环境下的</p><p class="s21" style="padding-top: 1pt;padding-left: 3pt;text-indent: 0pt;text-align: left;">Q <span class="p">学习。这里我们考虑非确定性情况，其中回报函数</span></p><p class="s6" style="padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: justify;"><i>r</i>(<i>s</i>,<i>a</i>)<span class="p">和动作转换函数</span><span class="s47">δ</span>(<i>s</i>,<i>a</i>)<span class="p">可能有概率的输出。例如，在 </span>Tesauro<span class="p">（</span>1995<span class="p">）的西洋双陆棋对弈 程序中，输出的动作是具有固有的概率性的，因为每次移动需要掷骰子决定。类似的，在有噪 声的传感器和效应器的机器人中，将动作和回报建摸为非确定性过程较为合适。在这样的情况 下，函数</span><span class="s47">δ</span>(<i>s</i>,<i>a</i>)<span class="p">和 </span><i>r</i>(<i>s</i>,<i>a</i>)<span class="p">可被看作是首先基于 </span><i>s </i><span class="p">和 </span><i>a </i><span class="p">产生输出的概率分布，然后按此分布抽取随 机的输出。当这些概率分布主要依赖于 </span><i>s </i><span class="p">和 </span><i>a </i><span class="p">时（例如，它们不依赖以前的状态和动作），我 们可称这个系统为非确定性马尔可夫决策过程。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: left;">本节中我们把处理确定问题的 <span class="s21">Q </span>学习算法扩展到非确定性的 <span class="s6">MDP</span>。为达到这个目的，我 们回顾在确定性情况下的算法推导步骤，在需要时对其做出修正。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 26pt;text-indent: 0pt;text-align: left;">在非确定性情况下，我们必须先重新叙述学习器的目标，以考虑动作的输出不再是确定性</p><p style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;line-height: 107%;text-align: left;">的情况。很明显，一种一般化的方法是把一个策略<span class="s47">π</span>的值<span class="s21">V</span><span class="s259">π</span>重定义为应用此策略时收到折算累 积回报的期望值（在这些非确定性输出上）。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s40" style="text-indent: 0pt;line-height: 7pt;text-align: left;"></p><p style="text-indent: 0pt;text-align: left;"/><p class="s30" style="padding-top: 3pt;text-indent: 0pt;line-height: 8pt;text-align: right;">V <span class="s184"></span><span class="s181"> </span><span class="s33">(</span>s <span class="s33">) </span><span class="s38"> </span>E <span class="s150">⎡</span></p><p class="s119" style="padding-top: 3pt;padding-left: 2pt;text-indent: 0pt;line-height: 8pt;text-align: left;"> <span class="s83">i </span><span class="s30">r </span><span class="s150">⎤</span></p><p class="s41" style="text-indent: 0pt;line-height: 15pt;text-align: right;">t                <span class="s134">⎢</span><span class="s121"></span></p><p class="s38" style="text-indent: 0pt;line-height: 11pt;text-align: right;">⎣ <span class="s41">i</span><span class="s40"></span><span class="s42">0</span></p><p class="s41" style="padding-top: 3pt;padding-left: 13pt;text-indent: 0pt;line-height: 11pt;text-align: left;">t <span class="s40"></span>i <span class="s134">⎥</span></p><p class="s38" style="padding-left: 24pt;text-indent: 0pt;line-height: 11pt;text-align: left;">⎦</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;text-align: left;">如以前那样，其中回报序列<span class="s21">r</span><span class="s36">t</span><span class="s42">+</span><span class="s41">i</span>是从状态<span class="s21">s</span>开始遵循策略<span class="s47">π</span>生成。注意此式是式 <span class="s6">13.1 </span>的一般 化形式，后者覆盖了确定性的情形。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 2pt;padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: left;">如以前那样，我们定义最优策略<span class="s47">π</span><span class="s46">*</span>为所有状态<span class="s21">s</span>中使<span class="s21">V</span><span class="s259">π</span><span class="s6">(</span><span class="s21">s</span><span class="s6">)</span>最大化的策略<span class="s47">π</span>。下一步我们把 先前式 <span class="s6">13.4 </span>中对<span class="s21">Q</span>的定义一般化，再一次运用其期望值。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s33" style="padding-top: 3pt;padding-left: 113pt;text-indent: 0pt;text-align: left;"><i>Q</i>(<i>s</i>, <i>a</i>) <span class="s38"> </span><i>E</i>[<i>r</i>(<i>s</i>, <i>a</i>) <span class="s38"> </span><span class="s119"></span><i>V </i><span class="s46">*</span><span class="s42"> </span>(<span class="s119"> </span>(<i>s</i>, <i>a</i>))]</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s33" style="padding-top: 3pt;padding-left: 26pt;text-indent: 0pt;text-align: center;"><span class="s38"> </span><i>E</i>[<i>r</i>(<i>s</i>, <i>a</i>)] <span class="s38"> </span><span class="s119"></span><i>E</i>[<i>V </i><span class="s46">*</span><span class="s42"> </span>(<span class="s119"> </span>(<i>s</i>, <i>a</i>))]</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="padding-left: 149pt;text-indent: 0pt;line-height: 21pt;text-align: left;"><span class="s38"> </span>E<span class="s33">[</span>r<span class="s33">(</span>s<span class="s33">, </span>a<span class="s33">)] </span><span class="s38"> </span><span class="s119"> </span><span class="s39"></span><span class="s121"> </span>P<span class="s33">(</span>s<span class="s38"> </span><span class="s33">| </span>s<span class="s33">, </span>a<span class="s33">)</span>V <span class="s46">*</span><span class="s42"> </span><span class="s33">(</span>s<span class="s38"></span><span class="s33">) </span><span class="p">（</span><span class="s6">13.8</span><span class="p">）</span></p><p class="s41" style="padding-left: 19pt;text-indent: 0pt;line-height: 8pt;text-align: center;">s<span class="s40"></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-top: 1pt;padding-left: 6pt;text-indent: 21pt;text-align: left;"><span class="p">其中</span>P<span class="s6">(</span>s<span class="s6">´|</span>s<span class="s6">,</span>a<span class="s6">)</span><span class="p">为在状态</span>s<span class="p">采取动作</span>a<span class="p">会产生下一个状态为</span>s<span class="s6">´</span><span class="p">的概率。注意我们在这里已经使用 了</span>P<span class="s6">(</span>s<span class="s6">´|</span>s<span class="s6">,</span>a<span class="s6">)</span><span class="p">来改写</span>V<span class="s46">*</span><span class="s6">(</span><span class="s47">δ</span><span class="s6">(</span>s<span class="s6">,</span>a<span class="s6">))</span><span class="p">的期望值，形式为与概率性的</span><span class="s47">δ</span><span class="p">的可能输出相关联的概率。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 26pt;text-indent: 0pt;text-align: left;">如以前，可将 <span class="s21">Q </span>重新表达为递归的形式：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="padding-left: 95pt;text-indent: 0pt;line-height: 17pt;text-align: left;">Q<span class="s33">(</span>s<span class="s33">, </span>a<span class="s33">) </span><span class="s38"> </span>E<span class="s33">[</span>r<span class="s33">(</span>s<span class="s33">, </span>a<span class="s33">)] </span><span class="s38"> </span><span class="s119"> </span><span class="s39"></span><span class="s121"> </span>P<span class="s33">(</span>s<span class="s38"> </span><span class="s33">| </span>s<span class="s33">, </span>a<span class="s33">) max </span>Q<span class="s33">(</span>s<span class="s38"></span><span class="s33">, </span>a<span class="s38"></span><span class="s33">) </span><span class="p">（</span><span class="s6">13.9</span><span class="p">）</span></p><p class="s69" style="padding-left: 51pt;text-indent: 0pt;line-height: 12pt;text-align: center;">s<span class="s252"></span><span class="s40"> </span><span class="s41">a</span><span class="s42">&#39;</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-top: 1pt;padding-left: 6pt;text-indent: 21pt;line-height: 107%;text-align: left;"><span class="p">它是前面式 </span>13.6 <span class="p">的一般化形式。概括地说，我们把非确定性情况下的 </span><i>Q</i>(<i>s</i>,<i>a</i>)<span class="p">简单地重定义 为确定性情况下定义的量的期望值。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;line-height: 108%;text-align: justify;">我们已经把<span class="s21">Q</span>的定义一般化以适应非确定性环境下的函数<span class="s21">r</span>和<span class="s47">δ</span>，现在所需要的是一个新训 练法则。前面对确定性情形推导的训练法则（式 <span class="s6">13.7</span>）不能够在非确定性条件下收敛。例如， 考虑一个非确定性回报函数<span class="s21">r</span><span class="s6">(</span><span class="s21">s</span><span class="s6">,</span><span class="s21">a</span><span class="s6">)</span>，每次重复<span class="s6">&lt;</span><span class="s21">s</span><span class="s6">,</span><span class="s21">a</span><span class="s6">&gt;</span>转换时产生不同的回报。这样，即使 <span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span>表值 被初始化为正确的<span class="s21">Q</span>函数，训练规则仍会不断的改变 <span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span><span class="s6">(</span><span class="s21">s</span><span class="s6">,</span><span class="s21">a</span><span class="s6">)</span>的值。简要的说，此训练规则不收 敛。此难题的解决可通过修改训练规则，令其使用当前 <span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span>值和修正的估计的一个衰减的加权平 均。用 <span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span><span class="s36">n</span>来代表第<span class="s21">n</span>次循环中<span class="s6">agent</span>的估计，下面修改后的训练规则足以保证 <span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span>收敛到<span class="s21">Q</span>。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s33" style="padding-top: 3pt;padding-left: 60pt;text-indent: 0pt;line-height: 14pt;text-align: left;"><i>Q</i><span class="s31">ˆ</span> (<i>s</i>, <i>a</i>) <span class="s38"> </span>(1 <span class="s38"> </span><span class="s119"> </span>)<i>Q</i><span class="s31">ˆ</span> (<i>s</i>, <i>a</i>) <span class="s38"> </span><span class="s119"> </span>[<i>r </i><span class="s38"> </span><span class="s119"> </span>max <i>Q</i><span class="s31">ˆ</span> (<i>s</i><span class="s38"></span>, <i>a</i><span class="s38"></span>)]</p><p class="s41" style="padding-left: 68pt;text-indent: 0pt;line-height: 9pt;text-align: left;">n n n<span class="s40"></span><span class="s42">1 </span>n <span class="s69">a</span><span class="s40"> </span>n<span class="s40"></span><span class="s42">1</span></p><p style="padding-top: 5pt;padding-left: 31pt;text-indent: 0pt;text-align: left;">（<span class="s6">13.10</span>）</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">其中</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s119" style="text-indent: 0pt;text-align: right;"> <span class="s52">n</span><span class="s41"> </span><span class="s38"></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s33" style="padding-top: 8pt;padding-left: 1pt;text-indent: 0pt;text-align: center;">1</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 1pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="97" height="1" alt="image" src="机器学习/Image_487.png"/></span></p><p class="s33" style="text-indent: 0pt;text-align: center;">1 <span class="s38"> </span><i>visits</i><span class="s52">n</span><span class="s41"> </span>(<i>s</i>, <i>a</i>)</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 27pt;text-indent: 0pt;text-align: left;">（<span class="s6">13.11</span>）</p><p class="s21" style="padding-left: 6pt;text-indent: 21pt;text-align: justify;"><span class="p">其中</span>s<span class="p">和</span>a<span class="p">为第</span>n<span class="p">次循环中更新的状态和动作，而且</span>visits<span class="s36">n</span><span class="s6">(</span>s<span class="s6">,</span>a<span class="s6">)</span><span class="p">为此状态</span><span class="s6">-</span><span class="p">动作对在这</span>n<span class="p">次循环 内（包括第</span>n<span class="p">次循环）被访问的总次数。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;text-align: justify;">在此修正了的规则中关键思想在于对 <span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span>的更新比确定性情况下更为平缓。注意，如果在式 <span class="s6">13.10 </span>中把<span class="s47">α</span><span class="s36">n</span>设置为 <span class="s6">1</span>，可得到确定性情形下的训练规则。使用较小的<span class="s47">α</span>值，该项可以被当前 的 <span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span><span class="s6">(</span><span class="s21">s</span><span class="s6">,</span><span class="s21">a</span><span class="s6">)</span>均化以产生新的更新值。在式 <span class="s6">13.11 </span>中<span class="s47">α</span><span class="s36">n</span>的值随<span class="s21">n</span>的增长而减小，因此当训练进行时 更新程度逐渐变小。在训练中以一定速率减小<span class="s47">α</span>，可以达到收敛到正确<span class="s21">Q</span>函数的目的。上面给 出的<span class="s47">α</span><span class="s36">n</span>的选择是满足收敛性条件的选择之一，它按照下面的定理（见<span class="s6">Watkn &amp; Danyan 1992</span>）</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s14" style="padding-left: 26pt;text-indent: 21pt;text-align: left;">定理 <span class="s187">13.2 </span>对非确定性马尔可夫决策过程的<span class="s296">Q</span>学习收敛性。考虑一个<span class="s56">Q</span>学习<span class="s16">agent</span>在一非确定性<span class="s16">MDP </span>中，并且有有界的回报 <span class="s33">(</span><span class="s38"></span><span class="s30">s</span><span class="s33">, </span><span class="s30">a</span><span class="s33">) | </span><span class="s30">r</span><span class="s33">(</span><span class="s30">s</span><span class="s33">, </span><span class="s30">a</span><span class="s33">) |</span><span class="s38"> </span><span class="s30">c </span>。此<span class="s56">Q</span>学习<span class="s16">agent</span>使用式 <span class="s16">13.10 </span>的训练规则，初始化表 <span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span><span class="s16">(</span><span class="s56">s</span><span class="s16">,</span><span class="s56">a</span><span class="s16">)</span></p><p class="s14" style="padding-top: 4pt;padding-left: 26pt;text-indent: 0pt;line-height: 120%;text-align: left;">为任意有限值，并且使用折算因子 <span class="s16">0</span>≤<span class="s177">γ</span><span class="s16">&lt;1</span>，令<span class="s56">n</span><span class="s16">(</span><span class="s56">i</span><span class="s16">,</span><span class="s56">s</span><span class="s16">,</span><span class="s56">a</span><span class="s16">)</span>为对应动作<span class="s56">a</span>第<span class="s56">i</span>次应用于状态<span class="s56">s</span>的迭代。如果每个 状态<span class="s16">-</span>动作对被无限频繁访问，<span class="s16">0</span>≤<span class="s177">α</span><span class="s65">n</span><span class="s16">&lt;1</span>，并且</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s40" style="padding-top: 3pt;text-indent: 0pt;line-height: 7pt;text-align: center;"> </p><p class="s42" style="text-indent: 0pt;line-height: 7pt;text-align: left;">2</p><p style="text-indent: 0pt;text-align: left;"/><p class="s41" style="padding-left: 163pt;text-indent: 0pt;line-height: 18pt;text-align: left;"><span class="s121"></span><span class="s154"> </span>n<span class="s42">(</span>i<span class="s42">,</span>s<span class="s42">,</span>a<span class="s42">) </span><span class="s118"> </span><span class="s38"> </span><span class="s16">, </span><span class="s121"></span><span class="s31">[</span><span class="s119"> </span>n<span class="s42">(</span>i<span class="s42">,</span>s<span class="s42">,</span>a<span class="s42">) </span><span class="s31">] </span><span class="s38"> </span><span class="s38"></span></p><p class="s41" style="text-indent: 0pt;line-height: 7pt;text-align: right;">i<span class="s40"></span><span class="s42">1</span></p><p class="s41" style="padding-left: 65pt;text-indent: 0pt;line-height: 7pt;text-align: left;">i<span class="s40"></span><span class="s42">1</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s56" style="padding-top: 3pt;padding-left: 47pt;text-indent: 0pt;text-align: left;"><span class="s14">那么对所有</span>s<span class="s14">和</span>a<span class="s14">，当</span>n<span class="s14">→∞时， </span><span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span><span class="s65">n</span><span class="s16">(</span>s<span class="s16">,</span>a<span class="s16">) </span><span class="s14">→</span>Q<span class="s16">(</span>s<span class="s16">,</span>a<span class="s16">)</span><span class="s14">，概率为 </span><span class="s16">1</span><span class="s14">。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 20pt;line-height: 107%;text-align: justify;">虽然 <span class="s21">Q </span>学习和有关的增强算法可被证明在一定条件下收敛，在使用 <span class="s21">Q </span>学习的实际系统 中，通常需要数以千计的训练循环以收敛。例如，<span class="s6">Tesauro </span>的西洋双陆棋对弈使用 <span class="s6">150 </span>万个对 弈棋局进行训练，每次包括数十个状态<span class="s6">-</span>动作转换。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">13.5 <span class="s17">时间差别学习</span>(<span style=" color: #00F;">temporal difference learning </span><span class="s298">瞬时差分学习</span>)</h2><p style="padding-top: 7pt;padding-left: 5pt;text-indent: 21pt;line-height: 108%;text-align: justify;"><span class="s21">Q </span>学习算法的学习过程是循环地减小对相邻状态的 <span class="s21">Q </span>值的估计之间的差异。在这个意义 上，<span class="s21">Q </span>学习是更广泛的时间差别（<span class="s6">temporal difference</span>）算法中的特例。时间差别学习算法学习 过程是减小 <span class="s6">agent </span>在不同的时间做出估计之间的差异。因为式 <span class="s6">13.10 </span>的规则减小了对某状态的 <span class="s30">Q</span><span class="s31">ˆ </span>值估计以及其立即后继的 <span class="s30">Q</span><span class="s31">ˆ </span>估计之间的差，我们也可以设计算法来减小此状态与更远的后 继或前趋状态之间的差异。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 5pt;text-indent: 21pt;line-height: 111%;text-align: justify;"><span class="p">为进一步探讨这一问题，回忆一下</span>Q<span class="p">学习，它的训练规则计算出的 </span><span class="s30">Q</span><span class="s31">ˆ </span><span class="s6">(</span>s<span class="s36">t</span><span class="s6">,</span>a<span class="s36">t</span><span class="s6">)</span><span class="p">的训练值是以 </span><span class="s30">Q</span><span class="s31">ˆ </span><span class="s6">(</span>s<span class="s36">t</span><span class="s42">+1</span><span class="s6">,</span>a<span class="s36">t</span><span class="s42">+1</span><span class="s6">)</span><span class="p">表示的，其中</span>s<span class="s36">t</span><span class="s42">+1</span><span class="p">是应用动作</span>a<span class="s36">t</span><span class="p">到状态</span>s<span class="s36">t</span><span class="p">的结果。令</span>Q<span class="s46">(1)</span><span class="s6">(</span>s<span class="s36">t</span><span class="s6">,</span>a<span class="s36">t</span><span class="s6">)</span><span class="p">为此单步前瞻计算的训练 值：</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="padding-top: 6pt;text-indent: 0pt;line-height: 9pt;text-align: right;">Q<span class="s46">(1) </span><span class="s33">(</span>s <span class="s33">, </span>a <span class="s33">) </span><span class="s38"> </span>r</p><ul id="l38"><li style="padding-top: 3pt;padding-left: 11pt;text-indent: -8pt;line-height: 12pt;text-align: left;"><p class="s33" style="display: inline;"><span class="s119"> </span>max <i>Q</i><span class="s31">ˆ</span> (<i>s</i></p><p class="s33" style="padding-top: 6pt;padding-left: 9pt;text-indent: 0pt;line-height: 9pt;text-align: left;">, <i>a</i>)</p><p class="s41" style="text-indent: 0pt;line-height: 7pt;text-align: right;">t t t</p><p class="s69" style="padding-left: 28pt;text-indent: 0pt;line-height: 11pt;text-align: left;">a <span class="s41">t </span><span class="s40"></span><span class="s42">1</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;"><span class="p">计算</span>Q<span class="s6">(</span>s<span class="s36">t</span><span class="s6">,</span>a<span class="s36">t</span><span class="s6">)</span><span class="p">训练值的另一种方法是基于两步的观察到的回报：</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="padding-top: 6pt;padding-left: 133pt;text-indent: 0pt;line-height: 9pt;text-align: left;">Q<span class="s46">(2) </span><span class="s33">(</span>s <span class="s33">, </span>a <span class="s33">) </span><span class="s38"> </span>r</p></li><li style="padding-top: 5pt;padding-left: 11pt;text-indent: -8pt;line-height: 10pt;text-align: left;"><p class="s119" style="display: inline;"><span class="s30">r</span></p><ul id="l39"><li style="padding-top: 3pt;padding-left: 18pt;text-indent: -8pt;line-height: 12pt;text-align: left;"><p class="s33" style="display: inline;"><span class="s119"> </span><span class="s46">2 </span>max <i>Q</i><span class="s31">ˆ </span> (<i>s</i></p></li></ul></li></ul></li></ol><p class="s33" style="padding-top: 6pt;padding-left: 10pt;text-indent: 0pt;line-height: 9pt;text-align: left;">, <i>a</i>)</p><p class="s41" style="text-indent: 0pt;line-height: 7pt;text-align: right;">t t t</p><p class="s41" style="text-indent: 0pt;line-height: 7pt;text-align: right;">t <span class="s40"></span><span class="s42">1</span></p><p class="s69" style="padding-left: 33pt;text-indent: 0pt;line-height: 11pt;text-align: left;">a <span class="s41">t </span><span class="s40"></span><span class="s42">2</span></p><p style="padding-left: 27pt;text-indent: 0pt;text-align: left;">以及在一般的情况下 <span class="s21">n </span>步的回报：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="padding-top: 6pt;padding-left: 92pt;text-indent: 0pt;line-height: 2pt;text-align: left;">Q<span class="s46">(</span><span class="s41">n</span><span class="s42">) </span><span class="s33">(</span>s <span class="s33">, </span>a <span class="s33">) </span>r r</p><p class="s42" style="padding-top: 5pt;text-indent: 0pt;line-height: 2pt;text-align: right;">(<i>n</i><span class="s40"></span>1) <span class="s255">r</span></p><p class="s33" style="padding-top: 3pt;padding-left: 35pt;text-indent: 0pt;line-height: 4pt;text-align: left;"><span class="s83">n </span>max <i>Q</i><span class="s31">ˆ</span> <i>s a</i></p><p class="s41" style="text-indent: 0pt;line-height: 15pt;text-align: right;">t t <span class="s118"></span></p><p class="s38" style="padding-left: 5pt;text-indent: 0pt;line-height: 15pt;text-align: left;"><span class="s52">t</span><span class="s41"> </span> <span class="s119"> </span><span class="s52">t</span><span class="s41"> </span><span class="s40"></span><span class="s42">1 </span><span class="s101">L </span> <span class="s119"></span></p><p class="s41" style="padding-left: 21pt;text-indent: 0pt;line-height: 13pt;text-align: left;">t <span class="s40"></span>n<span class="s40"></span><span class="s42">1 </span><span class="s118"></span><span class="s38"> </span><span class="s119"></span></p><p class="s41" style="text-indent: 0pt;line-height: 6pt;text-align: right;">a</p><p class="s33" style="padding-left: 17pt;text-indent: 0pt;line-height: 15pt;text-align: left;">( <span class="s52">t </span><span class="s40"></span><span class="s41">n </span>, )</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">Sutton <span class="p">介绍了混合这些不同训练估计的一般方法，称为 </span>TD(<span class="s47">λ</span>)<span class="p">。这一想法是使用常量 </span>0<span class="p">≤</span></p><p style="padding-left: 6pt;text-indent: 0pt;text-align: left;"><span class="s47">λ</span>≤<span class="s6">1 </span>来合并从不同前瞻距离中获得的估计，见下式：</p><p class="s33" style="padding-top: 5pt;padding-left: 28pt;text-indent: 0pt;line-height: 18pt;text-align: left;"><i>Q</i><span class="s293"></span><span class="s299"> </span>(<i>s </i>, <i>a </i>) <span class="s38"></span> (1<span class="s38"></span> <span class="s119"></span>)<span class="s300"></span><i>Q</i><span class="s46">(</span><span class="s42">1) </span>(<i>s </i>, <i>a </i>) <span class="s38"></span> <span class="s119"></span><i>Q</i><span class="s46">(</span><span class="s42">2) </span>(<i>s </i>, <i>a </i>) <span class="s38"></span> <span class="s119"></span><span class="s46">2</span><i>Q</i><span class="s46">(</span><span class="s42">3) </span>(<i>s </i>, <i>a </i>) <span class="s38"></span><span class="s101">L</span><span class="s300"></span></p><p class="s41" style="padding-left: 53pt;text-indent: 0pt;line-height: 7pt;text-align: left;">t t t t t t t t</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-top: 3pt;padding-left: 26pt;text-indent: 0pt;text-align: left;">Q<span class="s259">λ</span><span class="p">的一个等价的递归定义为：</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="padding-top: 5pt;padding-left: 28pt;text-indent: 0pt;line-height: 10pt;text-align: left;">Q<span class="s184"> </span><span class="s33">(</span>s <span class="s33">, </span>a <span class="s33">) </span><span class="s38"> </span>r</p><p class="s33" style="padding-top: 3pt;padding-left: 3pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><span class="s38"> </span><span class="s119"> </span>[(1 <span class="s38"> </span><span class="s119"></span>) max <i>Q</i><span class="s31">ˆ</span> (<i>s </i>, <i>a </i>) <span class="s38"> </span><span class="s119"></span><i>Q</i><span class="s184"></span><span class="s181"> </span>(<i>s </i>, <i>a </i>)]</p><p class="s41" style="padding-left: 53pt;text-indent: 0pt;line-height: 7pt;text-align: left;">t t t</p><p class="s69" style="padding-left: 53pt;text-indent: 0pt;line-height: 11pt;text-align: left;">a <span class="s41">t t</span></p><p class="s41" style="text-indent: 0pt;line-height: 7pt;text-align: right;">t <span class="s40"></span><span class="s42">1</span></p><p class="s41" style="padding-left: 9pt;text-indent: 0pt;line-height: 7pt;text-align: left;">t <span class="s40"></span><span class="s42">1</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 3pt;padding-left: 6pt;text-indent: 21pt;text-align: justify;">注意如果我们选择<span class="s47">λ</span><span class="s6">=0</span>，则得到原来的训练估计<span class="s21">Q</span><span class="s46">(1)</span>，它只考虑 <span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span>估计中的单步差异。当 <span class="s47">λ</span>增大时，此算法重点逐渐转移到更远的前瞻步中。在极端情况<span class="s47">λ</span><span class="s6">=1 </span>时，只考虑观察到的<span class="s21">r</span><span class="s36">t</span><span class="s42">+</span><span class="s41">i </span>值，当前的 <span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span>估计对其没有贡献。注意当 <span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span><span class="s6">=</span><span class="s21">Q</span>时，由<span class="s21">Q</span><span class="s259">λ</span>给出的训练值对于 <span class="s6">0</span>≤<span class="s47">λ</span>≤<span class="s6">1 </span>的所有</p><p class="s47" style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">λ<span class="p">值都相同。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 109%;text-align: justify;"><span class="s6">TD(</span><span class="s47">λ</span><span class="s6">)</span>的动机是，在某些条件下，如果考虑更远的前瞻，训练会更有效。例如，当<span class="s6">agent </span>遵循最优策略选择动作时，<span class="s47">λ</span><span class="s6">=1 </span>的<span class="s21">Q</span><span class="s259">λ</span>将提供对真实<span class="s21">Q</span>值的完美估计，不论 <span class="s30">Q</span><span class="s31">ˆ </span>有多么不精确。 另一方面，如果动作序列的选择是次优的，那么对未来的观察<span class="s21">r</span><span class="s36">t</span><span class="s42">+</span><span class="s41">i</span>可能有误导性。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 3pt;padding-left: 5pt;text-indent: 21pt;text-align: left;"><span class="s6">Peng &amp; Williams</span>（<span class="s6">1994</span>）提供了进一步的讨论和实验结果，显示了<span class="s21">Q</span><span class="s259">λ</span>在一个问题领域上的 卓越性能。<span class="s6">Dayan(1992)</span>显示了在一定条件下见类似的<span class="s6">TD(</span><span class="s47">λ</span><span class="s6">)</span>方法应用到学习<span class="s21">V</span><span class="s46">*</span>函数中，对于 <span class="s6">0</span></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">≤<span class="s47">λ</span>≤<span class="s6">1 </span>的任意<span class="s47">λ</span>值都可正确收敛。<span class="s6">Tesauro(1995) </span>在其<span class="s6">TD-Gammon</span>程序西洋双陆棋对弈中使 用了<span class="s6">TD(</span><span class="s47">λ</span><span class="s6">)</span>方法。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 6pt;text-indent: 0pt;text-align: left;">13.6 <span class="s17">从样例中泛化</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 6pt;text-indent: 21pt;line-height: 109%;text-align: justify;">至此，在 <span class="s21">Q </span>学习中可能最具有约束性的假定是其目标函数被表示为一个显式的查找表， 对每个不同输入值（即状态<span class="s6">-</span>动作对）有一个表项。因此我们的讨论的算法执行一种机械的学 习方法，并且不会尝试通过从已看到的状态<span class="s6">-</span>动作对中泛化以估计未看到的状态<span class="s6">-</span>动作对的 <span class="s21">Q </span>值。这个机械学习假定在收敛性证明中反映出来，它证明了只有每个可能的状态<span class="s6">-</span>动作被无限 频繁的访问，学习过程才会收敛。在大的或无限的空间中，或者执行动作的开销很大时，这显 然是不切实际的假定。作为结果，更实际的系统通常合并了其他章讨论的函数逼近方法以及这 里讨论的 <span class="s21">Q </span>学习训练规则。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 106%;text-align: justify;">很容易把反向传播这样的函数逼近算法结合到 <span class="s21">Q </span>学习算法中，通过用神经网络替代查找 表，并且把每个 <span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span><span class="s6">(</span><span class="s21">s</span><span class="s6">,</span><span class="s21">a</span><span class="s6">)</span>更新作为训练样例。例如，我们可把状态 <span class="s21">s </span>和动作 <span class="s21">a </span>编码为网络输入， 并且训练网络以输出 <span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span>的目标值，在给定式 <span class="s6">13.7 </span>和式 <span class="s6">13.10 </span>的训练规则的条件下，另一种有时</p><p style="padding-top: 2pt;padding-left: 5pt;text-indent: 0pt;line-height: 112%;text-align: justify;">在实践中更成功的方法是对每个动作训练一个单独的网络，使用状态作为输入， <span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span>为输出。还 有一种通常使用的方法是训练一个网络，它以状态作为输入，但对每个动作输出一个 <span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span>值。回 忆第 <span class="s6">1 </span>章中我们讨论了在棋盘状态上使用线形函数和 <span class="s6">LMS </span>算法来逼近估计函数。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;">在实践中，已开发出了许多成功的增强学习系统，它们通过结合这样的函数逼近算法来代 替查找表。<span class="s6">Tesauro </span>的成功的 <span class="s6">TD-Gammon </span>程序使用了神经网络和反向传播算法，与 <span class="s6">TD(</span><span class="s47">λ</span><span class="s6">)</span>训 练规则相结合。<span class="s6">Zhang &amp; Dietterich(1996)</span>使用相似的反向传播与 <span class="s6">TD(</span><span class="s47">λ</span><span class="s6">)</span>的结合用于 <span class="s6">job-shop </span>调 度任务。<span class="s6">Crites &amp; Barto</span>（<span class="s6">1996</span>）描述了一个神经网络增强学习方法，用于电梯调度任务。 <span class="s6">Thrun(1996)</span>报告了一个基于神经网络的 <span class="s21">Q </span>学习，它可学习带有声纳和摄像头传感器的移动机 器人的基本控制过程。<span class="s6">Mahadevan &amp; Connell(1991)</span>描述了一个基于聚类状态的 <span class="s21">Q </span>学习方法，应 用于简单的移动机器人控制问题。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 109%;text-align: justify;">虽然这些系统获得了成功，对于其他的任务，一但引入了泛化函数逼近器，增强学习将不 能收敛。这样的有问题的任务由<span class="s6">Boyan &amp; Moore(1995)</span>，<span class="s6">Baird(1995)</span>和<span class="s6">Gordon(1995)</span>介绍。注意 本章前面讨论的收敛性定理只应用于 <span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span>表示为明确的表形式时，为了看到困难所在，考虑使用 一个神经网络而不是明确的表来表示 <span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span>。如果学习器更新网络以更好地匹配特定转换的<span class="s6">&lt;</span><span class="s21">s</span><span class="s36">i</span><span class="s6">,</span><span class="s21">a</span><span class="s36">i</span><span class="s6">&gt; </span>的训练<span class="s21">Q</span>值，变化了的网络权值也会修改其他的任意转换的 <span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span>估计。因为这些权值变化会增加 其他转换的 <span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span>估计的误差，原来定理中的证明步骤不再成立。关于带有泛化函数逼近器的增强 学习的理论分析由<span class="s6">Gordon(1995)</span>和<span class="s6">Tsitsiklis(1994)</span>作出。<span class="s6">Baird(1995)</span>提出了基于梯度的方法，它 通过直接最小化对相邻状态的估计中的差异平方和来解决这一难题（也被称为<span class="s6">Bellman</span>残留误 差<span class="s6">Bellman residual error</span>）。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 6pt;text-indent: 0pt;text-align: justify;">13.7 <span class="s17">与动态规划的联系</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;line-height: 109%;text-align: justify;"><span class="p">像 </span><i>Q </i><span class="p">学习这样的增强学习方法，与长期研究的用于解决马尔可夫决策过程的动态规划方 法有着紧密的联系。这些早期的工作通过假定 </span>agent <span class="p">拥有它所处环境的函数</span><span class="s47">δ</span>(<i>s</i>,<i>a</i>)<span class="p">和 </span><i>r</i>(<i>s</i>,<i>a</i>)<span class="p">的完 美知识。因此，它主要解决的问题是用最小的计算量得到最优策略，假定环境可被完美地模 拟，不需要直接的交互。</span>Q <span class="p">学习的崭新之处在于它假定不具有</span><span class="s47">δ</span>(<i>s</i>,<i>a</i>)<span class="p">和 </span><i>r</i>(<i>s</i>,<i>a</i>)<span class="p">的知识，它不能 在内部模拟的状态空间中移动，而必须在现实世界中移动并观察后果。在后一种情况下我们主 要考虑的是 </span>agent <span class="p">为收敛到一个可接受的策略必须执行的真实世界动作数量，而不是须花费的 计算迭代次数。原因是在许多实际的领域中，比如生产问题，在外部世界中执行动作的时间和 费用开销比计算开销更值得关注。在真实环境中移动进行学习，并且观察其结果的系统通常称 为在线</span>(online)<span class="p">系统，而主要通过模型模拟动作的学习被称为离线（</span>offline<span class="p">）系统。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 107%;text-align: justify;">通过考虑 <span class="s6">Bellman </span>等式，可以清楚地看到早期的方法和这里讨论的增强学习问题之间的密 切相关性。<span class="s6">Bellman </span>等式形成了解决 <span class="s6">MDP </span>的动态规划方法的基础，其形式如下：</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s33" style="padding-top: 3pt;padding-left: 119pt;text-indent: 0pt;text-align: left;">(<span class="s38"></span><i>s </i><span class="s38"> </span><i>S </i>)<i>V </i><span class="s46">*</span><span class="s42"> </span>(<i>s</i>) <span class="s38"> </span><i>E</i>[<i>r</i>(<i>s</i>,<span class="s119"> </span>(<i>s</i>)) <span class="s38"> </span><span class="s119"></span><i>V </i><span class="s46">*</span><span class="s42"> </span>(<span class="s119"> </span>(<i>s</i>,<span class="s119"> </span>(<i>s</i>)))]</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">请注意<span class="s6">Bellman</span>等式和前面式 <span class="s6">13.2 </span>中定义的最优策略之间非常紧密的联系。<span class="s6">Bellman(1957)</span></p><p class="s6" style="padding-top: 1pt;padding-left: 5pt;text-indent: 0pt;line-height: 109%;text-align: justify;"><span class="p">证明了最优策略</span><span class="s47">π</span><span class="s46">*</span><span class="p">满足上述等式，且满足此等式的策略</span><span class="s47">π</span><span class="p">为一个最优策略。动态规划方面的 早期工作包括</span>Bellman-Ford<span class="p">最短路径算法（</span>Bellman 1958; Ford &amp; Fulkerson 1962<span class="p">）。它通过不 断更新每个图结点到终点的估计距离，来学习图中的路径，基于结点邻居的距离。在此算法中 图的各边以及目标结点已知的假定，等价于</span><span class="s47">δ</span>(<i>s</i>,<i>a</i>)<span class="p">和</span><i>r</i>(<i>s</i>,<i>a</i>)<span class="p">已知的假定。</span>Barto et al.<span class="p">（</span>1995<span class="p">）讨 论了增强学习和动态规划的紧密联系。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 6pt;text-indent: 0pt;text-align: justify;">13.8 <span class="s17">小结和补充读物</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 4pt;text-indent: 0pt;text-align: center;">本章的要点包括：</p><p style="padding-top: 6pt;padding-left: 49pt;text-indent: -21pt;line-height: 94%;text-align: left;"><span class="s10"> </span>增强学习解决自治 <span class="s6">agent </span>学习控制策略的问题。它假定训练信息的形式为对每个状 态<span class="s6">-</span>动作转换给出的实值回报信号。<span class="s6">agent </span>的目标是学习一个行动策略，它使 <span class="s6">agent </span>从任意起始状态收到的总回报为最大。</p><p class="s10" style="padding-left: 49pt;text-indent: -21pt;text-align: justify;"> <span class="p">本章介绍的增强学习算法适合一类被称为马尔可夫决策过程的问题。在马尔可夫 决策过程中，应用任意动作到任意状态上的输出只取决于此动作和状态（与以前 的动作或状态无关）。马尔可夫决策过程覆盖了范围很广的问题，包括许多机器 人控制，工厂自动化和调度问题。</span></p><p class="s21" style="padding-left: 49pt;text-indent: -21pt;line-height: 94%;text-align: left;"><span class="s10"> </span>Q <span class="p">学习是增强学习的一种形式。其中 </span><span class="s6">agent </span><span class="p">学习的是一组状态和动作上的估计函 数。确切地讲，估计函数 </span>Q<span class="s6">(</span>s<span class="s6">,</span>a<span class="s6">)</span><span class="p">被定义为 </span><span class="s6">agent </span><span class="p">应用动作 </span>a <span class="p">到状态 </span>s <span class="p">上可获得的最 大期望折算积累回报。</span>Q <span class="p">学习的优点是，即使在学习器不具有其动作怎样影响环境 的先验知识情况下，此算法仍可应用。</span></p><p class="s6" style="padding-top: 1pt;padding-left: 49pt;text-indent: -21pt;text-align: justify;"><span class="s10"> </span><span class="p">可以证明，在适当假定下，如果学习器的假设 </span><span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span>(<i>s</i>,<i>a</i>)<span class="p">被表示为一个查找表，且对每 个</span>&lt;<i>s</i>,<i>a</i>&gt;<span class="p">对有单独的表项，那么 </span><i>Q </i><span class="p">学习可以收敛到正确的 </span><i>Q </i><span class="p">函数。在确定性和非确 定性的 </span>MDP <span class="p">下此算法都可收敛。在实践中 </span><i>Q </i><span class="p">学习即使在规模适中的问题中也需要 数千次的训练循环。</span></p><p style="padding-top: 1pt;padding-left: 49pt;text-indent: -21pt;line-height: 14pt;text-align: left;"><span class="s10"> </span><span class="s21">Q </span>学习是一类更广泛的称为时间差异算法中的一种。一般说来，时间差异算法通过 不断减小 <span class="s6">agent </span>在不同时间内产生的估计的差异来进行学习。</p><p class="s6" style="padding-left: 49pt;text-indent: -21pt;line-height: 92%;text-align: left;"><span class="s10"> </span><span class="p">增强学习与应用于马尔可夫决策过程的动态规划有紧密联系。其差异关键在于， 历史上这些动态规划方法假定 </span>agent <span class="p">拥有状态转换函数</span><span class="s47">δ</span>(<i>s</i>,<i>a</i>)<span class="p">和回报函数 </span><i>r</i>(<i>s</i>,<i>a</i>)<span class="p">的知 识。相反，</span><i>Q </i><span class="p">学习这样的增强学习算法假定学习器缺少这些知识。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-top: 1pt;padding-left: 5pt;text-indent: 21pt;line-height: 109%;text-align: justify;"><span class="p">在增强学习方面许多工作中，通常的主题是迭代地减小的后继状态的估计之间的差异。使 用这种方法的某些最早的工作可见 </span>Samuel(1959)<span class="p">，它的西洋双陆棋学习程序试图通过后继状态 的估计来生成先前状态的训练值，从而学到西洋双陆棋的估计函数。几乎同时，</span>Bellman-Ford <span class="p">的单目的最短路径算法被开发出来（</span>Bellman 1958; Ford &amp; Fulkerson 1962<span class="p">），它把到目的的距 离值从结点传播到它的邻居。在最优控制方面的研究导致了使用相似方法来解决马尔可夫决策 过程（</span>Bellman1961; Blackwell 1965<span class="p">）。</span>Holland<span class="p">（</span>1986<span class="p">）的学习分类系统的组桶式（</span>bucket brigade<span class="p">）方法使用了类似的方法在延迟回报的情况下传播信用。</span>Barto et al.<span class="p">（</span>1983<span class="p">）讨论一种 时间信用分配的方法，导致了 </span>Sutton<span class="p">（</span>1988<span class="p">）的论文，其中定义了 </span>TD(<span class="s47">λ</span>)<span class="p">方法并证明了在</span><span class="s47">λ</span></p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 109%;text-align: justify;"><span class="s6">=0 </span>时它的收敛性。<span class="s6">Dayan(1992)</span>把这个结果扩展到<span class="s47">λ</span>的任意值。<span class="s6">Watkin</span>（<span class="s6">1989</span>）介绍了用 <span class="s21">Q </span>学 习在回报和动作转换函数未知的情况下获取最优策略。在这些方法上的收敛性证明有几个变 种。除了本章展示的收敛性证明外，可见（<span class="s6">Baird 1995; Bertsekas 1987; Tsitsiklis 1994, Singh </span>和 <span class="s6">Sutton 1996</span>）。</p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 109%;text-align: justify;">增强学习仍是一个活跃的研究领域。例如 <span class="s6">McCallum(1995)</span>和 <span class="s6">Littman</span>（<span class="s6">1996</span>）讨论了增强 学习的扩展，以适应有隐藏状态变量破坏马尔可夫假定的情况。许多当前的研究致力于把这些 方法升级到更庞大更实际的问题中。例如 <span class="s6">Maclin </span>和 <span class="s6">Shavlik</span>（<span class="s6">1996</span>）描述了一种方法，其中增 强学习 <span class="s6">agent </span>可接受施教者的不完美建议，基于 <span class="s6">KBANN </span>算法（第 <span class="s6">12 </span>章）的一个扩展。<span class="s6">Lin</span></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 107%;text-align: justify;">（<span class="s6">1992</span>）考虑了通过提供建议动作序列来施教的作用。<span class="s6">Singh</span>（<span class="s6">1993</span>）和 <span class="s6">Lin</span>（<span class="s6">1993</span>）建议使用 层次化的动作来升级这些算法。<span class="s6">Dietterich &amp; Flann</span>（<span class="s6">1995</span>）探索了基于解释的方法和增强学习 的集成，<span class="s6">Mitchell &amp; Thrun</span>（<span class="s6">1993</span>）描述了应用 <span class="s6">EBNN </span>算法（第 <span class="s6">12 </span>章）到 <span class="s21">Q </span>学习中。<span class="s6">Ring</span></p><p style="padding-left: 6pt;text-indent: 0pt;text-align: justify;">（<span class="s6">1994</span>）考虑了 <span class="s6">agent </span>在多个任务中的持续学习。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 107%;text-align: justify;">近期关于增强学习的调查由 <span class="s6">Kaelbling et al.</span>（<span class="s6">1996</span>）<span class="s6">; Barto(1992); Barto et al.(1995); Dean et al.</span>（<span class="s6">1993</span>）作出。</p><p style="padding-top: 3pt;padding-left: 27pt;text-indent: 0pt;text-align: left;">习题</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 27pt;text-indent: 0pt;text-align: left;">13.1 <span class="p">给出图 </span>13-2 <span class="p">所示问题的另一种最优策略。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 107%;text-align: justify;"><span class="s6">13.2 </span>考虑下图显示的一个确定性格子世界，其中含有吸收目标状态 <span class="s21">G</span>。这里作了标记的转 换的立即回报为 <span class="s6">10</span>，而其他转换都为 <span class="s6">0</span>。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 5pt;text-indent: 21pt;text-align: justify;">(a)<span class="p">给出格子世界中每个状态的</span><i>V</i><span class="s46">*</span><span class="p">值。给出每个转换的</span><i>Q</i>(<i>s</i>,<i>a</i>)<span class="p">值。最后，写出一个最优策 略，使用</span><span class="s47">γ</span>=0.8<span class="p">。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 6pt;text-indent: 20pt;line-height: 107%;text-align: justify;">(b)<span class="p">试改变回报函数</span><i>r</i>(<i>s</i>,<i>a</i>)<span class="p">，使</span><i>Q</i>(<i>s</i>,<i>a</i>)<span class="p">变化，但不改变最优策略。试修改</span><i>r</i>(<i>s</i>,<i>a</i>)<span class="p">，使</span><i>Q</i>(<i>s</i>,<i>a</i>)<span class="p">变 化，但不改变</span><i>V</i><span class="s46">*</span>(<i>s</i>,<i>a</i>)<span class="p">。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 21pt;line-height: 112%;text-align: justify;"><span class="s6">(c)</span>现在考虑应用 <span class="s21">Q </span>学习到此格子世界，假定 <span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span>值表被初始化为 <span class="s6">0</span>。假定 <span class="s6">agent </span>开始于左下 的方格然后顺时针沿着周边的格子移动，直至达到吸收目标状态，完成第一个训练情节。试写 出此情节的结果导致哪些 <span class="s30">Q</span><span class="s31">ˆ</span><span class="s33"> </span>值的修改，给出修正后的值。现如果 <span class="s6">agent </span>第二次运用同样的情 节，再次回答此问题。同样在第三个情节后回答此问题。</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 13pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="569" height="1" alt="image" src="机器学习/Image_488.png"/></span></p><p class="s48" style="padding-left: 15pt;text-indent: 0pt;text-align: left;">插图——原书页码： <span class="s21">388</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 14pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="553" height="1" alt="image" src="机器学习/Image_489.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-top: 1pt;padding-left: 6pt;text-indent: 21pt;line-height: 107%;text-align: left;">13.3 <span class="p">考虑与一个随机下棋的对家对弈 </span>Tic-Tac-Toe<span class="p">。确切地讲，假定对家在有多个选择时以 均匀的概率选择走棋，除非有一个强制性的走棋（这时它采取显然正确的步子）。</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 21pt;line-height: 107%;text-align: left;"><span class="s6">(a)</span>在此情况下，将学习最优的 <span class="s6">Tic-Tac-Toe </span>策略形成一个 <span class="s21">Q </span>学习问题。在此非确定性马尔 可夫决策过程中，何为状态、动作以及回报？</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 27pt;text-indent: 0pt;text-align: left;">(b)<span class="p">如果对家选择最优的走棋而不是随机走棋，你的程序能否胜利？</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 29pt;text-indent: 0pt;text-align: left;"><span class="s6">13.4 </span>在许多<span class="s6">MDP</span>中，有可能找到两个策略<span class="s47">π</span><span class="s35">1</span>和<span class="s47">π</span><span class="s35">2</span>，如果<span class="s6">agent</span>开始于状态<span class="s21">s</span><span class="s35">1</span>，则<span class="s47">π</span><span class="s35">1</span>优于</p><p class="s181" style="text-indent: 0pt;line-height: 7pt;text-align: left;"></p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-left: 6pt;text-indent: 0pt;text-align: left;"><span class="s47">π </span><span class="s35">2</span><span class="s42"> </span>；如果 <span class="s6">agent </span>开始于另一状 态 <span class="s21">s</span><span class="s35">2</span><span class="s42"> </span>，则 <span class="s47">π </span><span class="s35">2</span><span class="s42"> </span>优于 <span class="s47">π </span><span class="s35">1</span><span class="s42"> </span>。换言之 <span class="s30">V </span><span class="s182">1</span></p><p class="s181" style="text-indent: 0pt;line-height: 9pt;text-align: left;"><span class="s41"> </span><span class="s197">2</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s33" style="padding-top: 1pt;text-indent: 0pt;text-align: left;">(<i>s</i><span class="s79">1 </span>) <span class="s38"> </span><i>V</i></p><p class="s33" style="text-indent: 0pt;text-align: left;">(<i>s</i><span class="s79">1 </span>) <span class="p">但</span></p><p class="s255" style="padding-left: 6pt;text-indent: 0pt;text-align: left;">V<span class="s30"> </span><span class="s181"> </span><span class="s197">2</span></p><p class="s181" style="text-indent: 0pt;line-height: 9pt;text-align: left;"><span class="s197">1</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s33" style="padding-top: 1pt;text-indent: 0pt;text-align: left;">(<i>s</i><span class="s79">2 </span>) <span class="s38"> </span><i>V</i></p><p class="s33" style="padding-top: 1pt;text-indent: 0pt;text-align: left;">(<i>s</i><span class="s79">2 </span>) <span class="p">。解释为什么总存在一个策略，能对于任意一个初始状态</span><span class="s21">s</span><span class="p">使</span><span class="s21">V</span></p><p class="s6" style="padding-top: 1pt;text-indent: 0pt;text-align: left;"><span class="s259">π</span>(<i>s</i>)<span class="p">最大化</span></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">（ 即 最优策 略 <span class="s47">π </span><span class="s46">*</span><span class="s42"> </span>） 。换言 之 ，解释 为 什么一 个 <span class="s6">MDP </span>总有 一个策 略 <span class="s47">π </span><span class="s46">*</span><span class="s42"> </span>，使 </p><p class="s189" style="padding-top: 2pt;padding-left: 55pt;text-indent: 0pt;line-height: 2pt;text-align: left;">*</p><p class="s33" style="padding-left: 7pt;text-indent: 0pt;line-height: 14pt;text-align: left;">(<span class="s38"></span><span class="s119"> </span>, <i>s</i>)<i>V </i><span class="s184"></span></p><p class="s33" style="padding-left: 4pt;text-indent: 0pt;line-height: 14pt;text-align: left;">(<i>s</i>) <span class="s38"> </span><i>V </i><span class="s184"> </span>(<i>s</i>) <span class="p">。</span></p></body></html>
